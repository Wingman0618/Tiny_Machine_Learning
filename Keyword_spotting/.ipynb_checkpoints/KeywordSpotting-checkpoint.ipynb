{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9304d1ad-73f9-41c5-b925-3c70fa85b239",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-29 22:29:57.612988: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-29 22:29:58.762853: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/cx0618/.local/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/home/cx0618/.local/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/home/cx0618/.local/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl8OkStatusEv']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/home/cx0618/.local/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/home/cx0618/.local/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/home/cx0618/.local/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZNK10tensorflow4data11DatasetBase8FinalizeEPNS_15OpKernelContextESt8functionIFN4absl12lts_202301258StatusOrIN3tsl4core11RefCountPtrIS1_EEEEvEE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Audio\n",
    "from scipy.io import wavfile\n",
    "import librosa\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "import tensorflow_io as tfio\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69103891-afbe-4c47-9a73-8c764f05a324",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "016097b5-d4fd-4b7c-afb5-5ad4d469b1dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2, -6, -4, -4, -4, -1, 1, 2, 0, 2, 2, 1, 0, 2, 1, -1, 1, 1, -3, -2, 1, -1, -3, -1, 1, -1, -3, -2, -2, -3, -5, 0, 3, 1, -2, -2, -3, -3, 2, 2, 3, 0, -1, -1, 0, 2, -1, -3, -2, -3, -2, -3, 0, -4, -5, 0, 2, 1, 1, 3, 0, 0, 1, 5, 4, 2, 2, 0, 0, 1, 1, 1, -2, -1, 1, -1, 1, 0, 2, -2, -1, 0, -3, 0, 1, 2, -4, 0, 2, 1, 0, 3, -1, -2, 1, 3, -5, -4, -6, -1, -5, -1, 2, 1, -2, 0, 2, 1, -2, -1, 1, 2, 6, 3, 0, -4, 1, 0, -1, -1, 1, 2, 2, 3, 2, 1, 1, 3, 3, 0, 3, 3, 2, 3, 2, 2, 2, 1, 0, 3, 4, 0, -4, -5, -6, -8, -1, 5, 3, -1, 4, 0, -3, -4, 5, 1, 0, -4, 1, -6, -3, -4, 1, -3, 3, 5, 3, -6, 2, -1, -3, -5, -1, -2, -3, 0, -1, 0, -1, -1, -3, -1, -3, 3, 0, 1, -1, 6, 0, 1, -8, -1, 1, 7, -2, 3, -4, 4, 4, 7, -1, 2, 4, 4, -2, 0, 1, -2, -4, -2, -3, -5, 0, 0, 3, -4, 4, -1, 4, -5, 7, -4, 0, -10, 5, -5, 11, -4, 7, -13, 8, -6, 11, -10, 7, -9, 6, -10, 9, -4, 10, -11, 3, -10, 8, -7, 1, -14, 1, -7, 5, -7, -3, -15, 4, -4, 7, -7, 1, -12, 11, 3, 13, -7, 10, -6, 10, -9, 20, -12, 4, -12, 21, -13, 14, -9, 16, -18, 19, -8, 14, -22, 23, -7, 18, -13, 24, -20, 4, -5, 29, -18, 2, -8, 13, -16, 11, -2, -3, -26, 16, 0, 4, -16, 19, -11, 5, -2, 19, -24, -1, -6, 18, -24, 20, -3, 9, -26, 25, -4, 6, -20, 17, -13, 0, 1, 17, -17, -2, 2, 11, -12, 14, 2, 2, -19, 18, -9, 7, -16, 12, -33, 8, -10, 15, -38, 13, -16, 6, -24, 22, -21, 1, -16, 21, -20, 2, 2, 4, -11, -3, 19, -15, 9, -14, 24, -36, 28, -16, 31, -33, 34, -22, 12, -20, 37, -7, 8, -1, 12, -8, 1, 20, 7, 0, -6, 17, -7, 4, 0, 13, -12, -2, 5, 1, -6, -11, 15, -20, 7, -16, 31, -31, 18, -17, 32, -33, 30, -14, 11, -31, 20, -12, -1, -6, 12, -14, -12, 4, -1, -11, -6, 10, -13, -8, -7, 10, -16, 8, -8, 12, -4, 17, -7, 8, -3, 2, -14, 13, -1, -2, -7, 20, -9, -5, -5, 29, -17, 8, -10, 28, -36, 31, -5, 21, -46, 33, -13, 17, -32, 31, -26, 9, -11, 34, -34, 5, -12, 20, -23, 20, -2, 3, -22, 22, 9, 4, -13, 15, -7, -2, 1, 21, -10, -16, 7, 14, -3, -20, 16, -17, 14, -16, 32, -53, 26, -36, 60, -73, 43, -52, 71, -79, 57, -44, 46, -86, 60, -7, 39, -70, 39, -47, 53, 17, 35, -133, 41, 61, 53, -101, 8, 3, 42, 34, -7, -91, -15, 146, 25, -134, -66, 137, 44, -64, -45, -8, 7, 115, 14, -168, -83, 221, 64, -154, -136, 140, 43, 54, -89, -62, -83, 265, 40, -181, -215, 273, 113, -126, -163, 112, 17, 15, 35, -61, -148, 137, 176, -149, -216, 181, 162, -119, -146, 121, 19, -5, 26, 1, -167, 101, 173, -93, -243, 139, 185, -74, -152, 68, 2, 20, 55, 17, -216, 74, 172, 38, -276, 83, 93, 61, -141, 79, -77, 49, 33, 58, -162, 13, 112, 46, -131, -34, 74, 44, -38, -32, -46, 34, 65, 13, -142, 9, 85, 55, -94, -15, -21, 39, 45, 31, -130, -21, 106, 89, -126, -40, 39, 79, -38, 15, -52, -6, 14, 102, -60, -78, -3, 126, -30, -61, -27, 49, 3, 37, -1, -77, -34, 97, 87, -92, -86, 71, 77, -29, -51, 38, -43, 30, 42, 38, -165, 58, 80, 40, -156, 58, 3, 33, -36, 59, -137, 41, 78, 86, -204, 19, 26, 111, -78, 46, -145, 33, 92, 133, -208, -82, 110, 152, -74, -38, -34, -46, 42, 197, -75, -232, -10, 286, -21, -145, -84, 111, -26, 135, -39, -136, -133, 296, 67, -184, -193, 194, 83, -18, -110, -32, -26, 161, 68, -133, -181, 151, 163, -34, -203, 36, 71, 86, -49, -21, -119, 108, 116, -19, -206, 85, 136, -36, -135, 35, 79, -12, 19, -74, -16, 16, 171, -132, -97, 5, 234, -76, -127, -66, 127, 50, -33, -88, -57, 89, 91, -45, -146, -2, 149, 28, -75, -140, 102, 55, 76, -178, -5, 11, 176, -79, -95, -79, 148, 79, -50, -122, -11, 116, 79, -53, -155, 27, 153, 86, -156, -89, 61, 157, 1, -109, -113, 93, 158, -7, -190, -46, 124, 132, -49, -112, -78, 130, 110, -47, -174, 27, 115, 71, -93, -73, -10, 102, 45, -71, -82, 20, 95, -15, -40, -55, 38, 9, 44, -37, -42, -10, 48, 1, -9, 3, -29, -25, 35, 28, -16, -35, -21, -26, 77, 38, -61, -116, 92, 101, 10, -108, -31, 45, 121, -5, -129, -61, 158, 64, -98, -145, 127, 31, 62, -153, 33, -89, 254, -109, -33, -167, 322, -117, -26, -153, 240, -103, 79, -117, 16, -30, 192, -56, -193, 50, 162, 32, -224, 88, -22, 97, -68, 85, -180, 86, 72, 34, -162, 36, 93, -33, -39, -18, 40, -56, 82, -49, 0, -56, 89, -57, 15, 19, 1, -54, 11, 99, -76, 4, -56, 97, -65, 107, -142, 43, -14, 141, -148, 31, 5, 51, -76, 66, -6, -39, -17, 77, -19, -65, 38, 34, -26, -30, 69, -46, -17, 22, 50, -104, 30, 40, 12, -84, 69, -17, -6, -30, 70, -59, -6, 27, 15, -45, -7, 55, -53, 11, 8, 55, -110, 45, -11, 54, -59, 76, -76, 4, 24, 75, -97, -32, 56, 55, -38, -45, 7, 2, 54, -35, -21, -64, 129, -32, 10, -116, 93, -25, 101, -116, -3, -43, 175, -70, -30, -88, 130, -7, 31, -103, -17, 27, 118, -39, -156, 46, 102, 70, -176, 21, -27, 136, -52, 11, -176, 124, 94, 38, -253, 22, 142, 91, -147, -53, -5, 105, 60, -36, -177, 28, 224, 22, -176, -131, 194, 71, 20, -189, 23, 4, 233, -115, -111, -143, 293, 36, -66, -209, 91, 107, 90, -95, -133, 20, 179, 80, -188, -122, 94, 219, -92, -118, -102, 181, 36, 18, -178, -24, 104, 131, -95, -189, 65, 146, 66, -211, 9, 9, 185, -140, 8, -142, 196, -27, 30, -190, 120, 22, 71, -144, 41, -12, 104, -51, -31, -29, 62, 78, -118, 23, -52, 170, -174, 115, -165, 186, -169, 199, -234, 155, -113, 180, -191, 40, -4, 52, -13, -78, 85, -111, 141, -129, 107, -198, 228, -136, 122, -238, 215, -146, 181, -197, 138, -139, 185, -112, 44, -117, 153, -23, 24, -84, 59, 31, 25, -25, -44, 33, 48, -2, -41, -29, 63, 2, 29, -57, 11, 18, 49, -32, -34, 16, 41, -22, -30, -16, 11, 18, -16, -7, -63, 50, -5, 5, -67, 19, 54, -9, -42, -44, 42, 26, -5, -59, -15, 23, 57, -67, -20, -12, 92, -10, -17, -48, 16, 56, 34, -47, -47, 61, 71, -14, -79, 51, 16, 68, -71, 41, -86, 106, -27, 43, -123, 111, -17, 65, -146, 94, -40, 90, -86, 34, -45, 36, 21, -38, -22, -21, 97, -82, 18, -111, 138, -123, 138, -174, 157, -169, 200, -178, 117, -141, 178, -80, 57, -102, 56, 18, 37, -30, -65, 63, 22, 54, -134, 47, -7, 132, -96, 5, -66, 118, 12, -8, -111, 28, 77, 48, -103, -51, 47, 96, -22, -102, -21, 38, 75, -42, -63, -58, 84, 61, -73, -96, 33, 109, 18, -82, -90, 53, 62, 40, -106, -15, -21, 151, -34, -135, -69, 140, 89, -132, -68, -5, 147, 45, -122, -98, 72, 158, -69, -77, -60, 99, 99, -17, -163, 14, 111, 124, -136, -41, -27, 206, 3, -84, -111, 118, 121, -9, -132, 9, 54, 131, -89, -29, -100, 194, 3, -16, -214, 149, 26, 90, -181, -7, 16, 112, -1, -168, -11, 48, 107, -85, -125, 26, 47, 97, -146, -89, -11, 99, 65, -167, -5, -6, 190, -122, -33, -130, 202, -11, 80, -224, 143, -30, 167, -177, 44, -43, 164, -26, -37, -84, 85, 86, 12, -57, -52, 106, -8, 67, -178, 84, -20, 179, -160, -51, -24, 117, -13, -60, -86, 66, 43, 6, -127, -23, 64, -2, 124, -218, 72, -94, 267, -222, 35, -97, 184, -58, 41, -186, 134, -29, 180, -218, 51, -34, 158, -33, -70, 49, -5, 110, -73, 30, -89, 136, -19, 76, -133, 107, -70, 155, -118, 12, -12, 59, 5, -91, 63, -84, 85, -71, 40, -115, 89, -107, 117, -142, 93, -152, 156, -108, -25, 46, -36, 81, -154, 148, -151, 125, -89, 75, -65, 79, -87, 102, -141, 153, -124, 166, -180, 109, -82, 115, -74, 33, -68, 146, -36, 0, -85, 59, 129, -148, 85, -164, 265, -251, 181, -172, 120, -128, 162, -131, 29, -125, 230, -140, 90, -126, 109, 1, -39, 31, -105, 140, -69, 45, -100, 10, 30, 34, -35, -19, 25, 58, -37, -16, 76, -88, 131, -68, 109, -197, 152, -21, 63, -117, 36, -68, 178, -170, 57, -124, 243, -155, 56, -114, 38, 34, 91, -173, 21, 39, 91, -181, 49, -57, 67, 72, -121, -36, -14, 180, -198, 133, -159, 137, -33, 199, -290, 53, 127, 131, -189, -59, 82, 107, 68, -249, 41, 69, 227, -392, 188, -60, 79, -134, 235, -175, -126, 201, 59, -74, -158, 129, -30, 221, -337, 74, -116, 369, -437, 264, -241, 163, -71, 214, -312, -27, 281, -5, -165, 38, 15, 120, 37, -57, -144, -6, 452, -361, -34, -58, 384, -216, -70, -11, 58, 60, -2, -69, 27, -1, 44, -29, 35, -16, -210, 331, -89, 61, -402, 243, 163, 60, -398, 64, 156, 372, -543, -17, 95, 349, -108, -254, 128, -65, 247, -109, 19, -266, 251, 41, 42, -310, 165, -224, 320, -61, -70, -257, 162, 306, -297, 19, -94, 151, 43, -17, -146, -69, 79, 277, -384, 28, 46, -103, 206, -92, 6, -361, 283, 348, -449, 42, -90, 447, -274, 177, -372, 141, 289, -64, -161, 128, -290, 408, -7, -119, -264, 159, 619, -807, 467, -126, -105, 81, 308, -212, -313, 242, 497, -793, 424, -342, 510, -547, 192, 303, -798, 642, -469, 739, -787, -13, 483, 0, -311, -98, 252, 179, -486, 818, -817, 272, -223, 1053, -989, 13, 437, -81, 50, -137, 171, -294, 261, 548, -831, 235, 120, 251, -277, -35, 119, -307, 576, -211, -122, -338, 422, 98, -213, -40, -400, 891, -618, 477, -1002, 1038, -587, 235, 299, -707, 184, 9, 852, -1496, 210, 1239, -524, -1288, 1037, 543, -870, -597, 1197, -298, -514, 947, -1167, 352, 362, 403, -1186, 263, 1007, -762, 35, -149, 324, 66, -162, 237, -130, 81, -579, 1208, -110, -1162, 196, 1512, -478, -1333, 591, 838, -358, -323, -207, 8, 846, -558, -670, 250, 1104, -949, -666, 1166, -332, -486, 186, 630, -636, -383, 1091, -572, -442, 642, -323, -6, -70, 777, -1298, 252, 1400, -1478, 61, 790, 211, -1303, 339, 1793, -1722, -195, 634, 780, -881, -467, 765, 67, -605, 640, -104, -582, -38, 1242, -560, -1133, 1035, 437, -396, -811, 1193, -703, 447, -527, 872, -650, -229, 523, 209, -737, -8, 957, -91, -1990, 2224, 182, -1216, -669, 1401, 913, -2195, 1304, -879, 953, -348, 512, -1222, 77, 992, 664, -2092, 637, 261, 765, -1296, 742, 38, -665, 644, -358, 462, -546, 593, -737, 264, 726, -313, -727, -12, 890, 554, -1437, 227, 407, 606, -379, -38, 359, -743, 1486, 110, -679, -568, 1553, 1009, -1301, -204, 1185, -294, 664, -344, 1166, -1660, 1564, 366, 0, -1464, 1598, 305, 311, -1100, 648, -636, 888, 177, -562, -422, 448, 365, -905, -447, 374, 559, -573, -126, -420, -128, -189, 745, -413, -41, -346, 308, -307, 205, -440, 586, 336, -43, -687, 80, 1181, -900, 1008, -676, 914, -474, 1093, -1439, 732, 314, 1022, -1100, 314, -389, 685, -411, 1233, -1188, 301, -72, 762, -856, -173, 611, 296, -1117, 1258, -970, -135, 8, 1195, -970, -1416, 1858, -75, -739, -682, 310, 834, 4, -733, -695, 792, 428, -74, -722, 537, -621, 1101, -139, -29, -400, 222, 515, 321, -287, 79, 291, 179, -713, 442, 1246, -702, -900, 133, 1101, -25, -973, -95, -191, 1104, -814, 54, -1756, 1192, -308, 307, -1589, 276, -1129, 1017, -654, -180, -2474, 1810, -552, 76, -2630, 965, -603, 752, -2337, 449, -845, 345, -1481, 496, -1004, -1008, 174, 143, -1299, -793, 507, -558, -646, -330, -60, -795, 708, -549, -386, -627, 797, 286, -214, -1096, 873, 998, 904, -1043, -152, 415, 2827, 287, -449, -253, 2075, 1631, 45, 1761, -334, 1280, 1727, 2131, -323, 728, 1306, 2339, 598, 1198, -589, 2187, 1551, 409, -263, 1994, 1304, -1072, 32, 2165, 799, -683, -727, 762, 754, -362, -1069, -457, 976, -170, -465, -2351, -466, 846, 1682, -3064, -1922, 626, 1227, -1361, -1200, -919, -518, 1932, -340, -2743, -1884, 2583, 483, -78, -1703, -944, 186, 1981, 209, -884, -311, 916, 791, 661, -407, 87, 1420, 730, 749, -454, 128, -44, 956, -21, -274, 225, -1636, -716, -848, -722, -2069, -995, -1514, -2834, -2235, -3437, -2601, -1913, -2604, -3481, -3451, -3248, -3654, -3362, -2251, -2330, -1745, -3949, -2358, -1195, -1656, -2628, 1718, 1440, -1636, -1959, 1934, 1545, 1888, 1001, 2993, 1953, 2143, 264, 3420, 5481, 1756, 1852, 3369, 3554, 1968, 3199, 3777, 1553, 3950, 4136, 1354, 1419, 3334, 3125, 3363, 3094, 1310, 645, 3890, 2611, 1469, 2034, 2160, 971, 1120, 3019, 659, 1069, 443, 1583, 592, 1248, 155, -899, 301, 1832, 667, -508, -1976, -287, 227, 1459, -650, -2744, -512, -168, 43, -3176, -2648, -1830, -336, -1228, -3042, -4906, -3624, -2583, -859, -3958, -2710, -4616, -2652, -3138, -1317, -3427, -2768, 34, -463, -1100, -1766, -240, 296, 2281, 2101, 843, 401, 1461, 1658, 2379, 678, 647, 1395, 1355, -280, -1072, -1064, -1121, -1096, -1671, -2408, -2059, -3253, -3681, -4279, -3268, -3504, -2160, -3626, -4929, -4686, -3906, -3102, -2047, -1607, -1909, -2193, -1730, -1678, 1116, 1969, 2151, 1649, 2304, 2395, 3831, 4553, 3988, 4784, 4914, 5338, 4454, 5003, 3250, 3786, 4584, 5265, 3461, 1668, 327, 1710, 1893, 1860, -808, -258, -2125, -417, -2064, -1591, -2380, -1755, -1046, -1744, -2297, -3360, -75, 496, 27, -972, 1778, 1452, 3380, 1621, 2425, 1809, 7671, 6974, 3758, 2016, 4752, 6927, 5209, 5508, 5856, 4973, 3359, 1687, 4190, 2718, 4176, 2831, 1366, -1565, -1746, 368, -1067, -1597, -2228, -2865, -3226, -6616, -7325, -6549, -1748, -4046, -7574, -9161, -8011, -5576, -4039, -4054, -5943, -5847, -3154, -1135, -1805, -2962, -2113, 2033, 2666, 3609, 951, 636, 1217, 5197, 5715, 4164, 3066, 2399, 2115, 2690, 2236, 2253, 474, 26, -1699, -1274, -1127, -3542, -6064, -9253, -2922, -1681, -3758, -12352, -10644, -8002, -3939, -4429, -5783, -7672, -7380, -3963, -2517, -1755, -3232, 287, 2724, 3426, 1354, 2807, 4225, 7085, 8711, 9669, 8493, 7769, 7621, 8310, 11020, 11704, 10340, 7767, 6630, 6947, 6897, 6191, 5047, 4347, 2737, 626, -160, -1028, -2510, -3389, -4006, -3508, -6169, -7484, -8854, -6454, -7424, -7648, -7812, -6879, -6878, -7438, -5973, -4369, -2798, -2612, -1362, -329, 230, 1885, 4295, 6253, 6053, 5529, 7121, 7533, 9467, 10240, 12205, 8027, 8311, 8577, 10566, 8704, 8949, 6041, 7350, 9270, 3964, 821, 1905, 5195, -633, 2028, 415, -2478, -5346, -4885, -4784, -5932, -2664, -6310, -5169, -8631, -5892, -8777, -6065, -8461, -4120, -2980, -787, -1677, -802, -4622, -4656, -1341, 5018, 8167, 7631, 414, -4518, 254, 5305, 6735, 3069, 1666, 1097, 1811, -3031, -5929, -5481, -1825, -1483, -3358, -9172, -10746, -9667, -10084, -11855, -10651, -7487, -6916, -9426, -13630, -11162, -7030, -7817, -9348, -1324, 3769, -228, -5826, -2366, 3497, 6396, 6546, 8588, 12334, 10848, 8753, 6779, 8139, 10649, 17524, 17011, 10195, 5792, 6823, 8727, 8495, 8370, 5535, 3863, 2042, 584, -1765, -2314, -3187, -2260, -3131, -5164, -7604, -8517, -8766, -7469, -4205, -3870, -5232, -6092, -6069, -4207, -679, -112, -807, -104, 4427, 4088, 4038, 1675, 3983, 5617, 6826, 6540, 6442, 6459, 4062, 5345, 6044, 5340, 3953, 3788, 4351, 1380, 1001, 1382, 4174, 1065, -3254, -3544, -90, 3325, -243, -2795, -5633, -454, 3223, 2079, -2597, -2780, 1686, 2324, 1990, 1206, -321, -393, -881, 5500, 2743, 1514, -5194, -528, -1500, 1153, 586, 1449, -1787, -4482, -3861, -2729, -1221, 929, 4451, 5109, 981, -4244, -5607, -1696, 6795, 10116, 7007, -3344, -5168, -2389, 2762, 75, -2144, -1069, 199, -882, -7477, -9657, -11528, -7691, -6863, -4382, -5844, -8083, -11772, -14709, -12595, -8693, -2570, -1601, -3317, -9415, -10626, -5919, 2304, 6223, 3903, 1226, 1458, 5167, 7584, 8113, 7212, 8205, 11533, 12775, 10918, 7222, 5933, 5604, 7146, 7657, 6886, 4488, 1248, -2387, -4470, -3319, -1641, -1810, -3349, -5085, -6783, -6905, -4341, -1942, -2041, -2045, -1296, 102, -152, 2112, 1558, 2397, 2293, 5593, 5019, 4594, 3086, 1982, 1963, 2604, 4386, 2809, 1667, -2430, -3364, -3927, -2165, -1453, -2109, -5221, -8781, -5503, -4230, -2685, -5206, -2832, -5787, -4423, -3315, 22, 897, 2581, 3843, 2291, 1900, 1564, 5191, 9083, 11797, 9849, 6664, 7336, 9254, 12155, 8885, 9527, 7803, 10143, 5178, 6825, 3099, 3931, -318, 3408, -223, -3285, -9721, -6460, -5397, -4659, -6994, -5409, -6673, -10053, -13014, -11209, -6479, -489, 4491, 4421, -1183, -5052, -3373, 2274, 6740, 11038, 11953, 9606, 4395, 717, 1037, 3854, 6967, 6088, 3759, -895, -3783, -6630, -8544, -11013, -10367, -8328, -7029, -8763, -12914, -17931, -19571, -16102, -12218, -7308, -3847, -3323, -9789, -12366, -8924, -449, 4164, 6447, 7169, 8246, 7777, 6756, 7632, 10094, 14162, 15645, 14667, 11076, 9204, 7497, 6090, 5207, 4837, 5857, 4534, 978, -5618, -8123, -8163, -5884, -5077, -4908, -5728, -7481, -9782, -11020, -7609, -3520, -1614, -770, 927, 1578, 1044, 1099, 1448, 3469, 7401, 10181, 9288, 6273, 3470, 2810, 4225, 4045, 4201, 3766, 2942, -2090, -4790, -6400, -6390, -5756, -4980, -4930, -6582, -7961, -10060, -11406, -9381, -6821, -1681, -1743, -1186, -3090, -288, 537, 1644, 4848, 8033, 12053, 9111, 7723, 8043, 11995, 12230, 10097, 11301, 8506, 10409, 7762, 5700, 1128, 2666, 600, -1465, -1270, -4695, -8796, -10732, -11459, -12474, -9795, -7337, -11333, -12590, -11080, -8377, -10452, -10510, -6018, 2872, 8340, 8065, 5724, 2491, 1996, 6816, 14081, 17025, 17878, 15906, 8771, 657, -146, 3368, 4787, 2746, 57, -3237, -8754, -14567, -17326, -17390, -17117, -15282, -13221, -14081, -16116, -17897, -18658, -18147, -13782, -7554, -366, 2844, 96, -2542, 193, 6031, 10344, 13879, 15791, 16652, 16356, 14511, 12419, 12196, 13801, 14889, 12727, 8740, 6114, 4963, 592, -4662, -6119, -4040, -2058, -3795, -9181, -14296, -14542, -13244, -11750, -8538, -4643, -3576, -4371, -4176, -2807, -348, 2767, 8030, 11746, 12334, 11682, 12725, 12402, 10859, 10853, 10875, 10692, 10106, 9681, 4800, -719, -5154, -5531, -5163, -5825, -7331, -10270, -12419, -15367, -14142, -12900, -9618, -10340, -10660, -10110, -6165, -4045, -2604, -1048, 1437, 4448, 7922, 8802, 9673, 8840, 10817, 10677, 13621, 11736, 14028, 11378, 8917, 4579, 7404, 8176, 5340, 1701, 165, -32, -4918, -5546, -6247, -5179, -8572, -7861, -10264, -9698, -8577, -6713, -9112, -8091, -4254, -1020, -895, -854, -3204, -3122, 2912, 13681, 17894, 15298, 9470, 6446, 5272, 7154, 11247, 15854, 15185, 7956, -835, -5833, -7043, -6308, -7139, -9381, -10615, -10589, -13389, -18880, -22523, -23449, -21493, -17170, -11913, -8693, -7276, -8841, -10874, -10973, -6059, 1382, 8471, 11079, 12173, 13181, 11578, 6655, 6564, 13042, 19198, 18771, 14438, 10228, 6926, 3060, -925, -2259, -731, 1749, 752, -4177, -10495, -14200, -14599, -13002, -9267, -5447, -2899, -3779, -5556, -7021, -6452, -2855, 2983, 9146, 11720, 12150, 10643, 9055, 7455, 9267, 12047, 12614, 12328, 13036, 12326, 8122, 2891, -1838, -3021, -1246, 714, -347, -3774, -9186, -13989, -15338, -13210, -10548, -9857, -7963, -6022, -5903, -8550, -8211, -5860, -1460, 2565, 5780, 6977, 7370, 6495, 6236, 7872, 8718, 9599, 11527, 12690, 8974, 6385, 5110, 4850, 3097, 3247, 2805, 2870, 1389, -727, -3193, -4801, -4853, -2686, -727, -2141, -3308, -3489, -4611, -6805, -5476, -3096, -2511, -2149, 747, 1043, -3308, -5055, -1026, 2718, 2930, 2202, 165, 100, 5049, 10924, 11650, 9594, 7169, 4326, 2552, 4268, 8966, 12006, 8178, -384, -5608, -5718, -5395, -6333, -8639, -10402, -10643, -10521, -14196, -17000, -18070, -17818, -17823, -14041, -9118, -4512, -4266, -6677, -8623, -6577, -2273, 3358, 8458, 10329, 9680, 8468, 9476, 11460, 11315, 6200, 4100, 8732, 13307, 10315, 4704, 1032, -1625, -5428, -7628, -6333, -2987, -1357, -2436, -6446, -10375, -10631, -6782, -4232, -2877, -949, 2690, 4249, 4457, 2552, 2588, 4899, 8839, 10740, 12327, 13234, 11706, 7612, 3131, 2578, 5111, 7041, 4496, 1935, -234, -2596, -6609, -9337, -10245, -8499, -7479, -8019, -8264, -8362, -9904, -11184, -8713, -6211, -3659, -704, 3457, 3341, 599, -772, 3368, 8401, 9552, 8201, 6300, 6758, 7037, 8624, 7136, 7269, 4097, 2208, 683, 4191, 3504, 1985, -1743, -2504, -2618, -372, -1104, -1672, -1887, -1565, -164, 1498, 276, -3260, -2211, -859, 339, 254, 2281, 916, -513, -3291, -3345, -4412, -3141, -1391, 1761, -172, -1029, -2147, -4212, -7485, -430, 8751, 11691, 7568, 6671, 6298, 5446, 2165, 1532, 3953, 8828, 9090, 4112, -3415, -6229, -5649, -7889, -12652, -11812, -7026, -7288, -11575, -15308, -16941, -17432, -15617, -13208, -8041, -2550, -1004, -4119, -5233, -3837, -429, 4082, 9158, 11979, 12761, 11843, 10236, 7587, 4948, 5255, 8599, 9472, 6820, 4407, 3048, -822, -6074, -9975, -9793, -7114, -4696, -4341, -5204, -7219, -9440, -9535, -8175, -4931, 34, 4429, 5487, 4967, 4641, 5015, 6519, 7960, 9867, 13013, 14809, 12789, 9845, 7054, 3591, 1691, 2644, 2809, 2064, 1350, -788, -4475, -7861, -9817, -9776, -6955, -5832, -6141, -6623, -6053, -6382, -6070, -6571, -6635, -4136, 275, 1848, 1177, 589, 1732, 1765, 1122, 983, 3911, 6654, 7286, 6311, 4287, 1879, 2157, 4093, 4907, 3675, 4605, 4294, 3396, 881, 29, -687, -718, -657, -525, 622, 1121, 330, -2271, -4086, -2684, -917, -550, -746, 888, 1172, -2180, -4720, -5527, -2738, -1831, -2080, -2478, 689, 825, -3617, -5022, -2298, -1291, -1300, 3191, 9427, 10954, 8635, 6808, 8229, 9824, 8351, 6281, 7269, 10433, 9479, 4016, -1808, -4287, -5307, -7579, -10586, -11473, -10146, -10327, -13880, -17819, -18558, -16084, -14591, -14562, -12403, -7254, -3577, -2619, -2893, -1321, 1511, 5027, 6874, 9304, 11776, 12689, 12131, 12255, 13534, 10852, 4807, 2490, 5761, 6399, 1523, 80, 409, -3183, -9816, -11226, -9156, -8103, -8073, -7028, -5227, -5886, -5457, -3328, -1679, -1662, 1300, 7171, 9932, 10121, 9268, 10535, 10743, 9455, 8038, 10266, 13034, 11361, 7139, 3601, 1951, -571, -3375, -5147, -4017, -2726, -3245, -6329, -9242, -10208, -8132, -6789, -6048, -5950, -4282, -2937, -1843, -2138, -1434, 472, 2223, 2125, 1908, 2806, 3924, 4041, 2581, 2050, 2836, 4037, 3140, 2123, 1177, 2040, 2508, 2738, 567, 406, 1142, 2953, 2087, 1278, 1595, 3334, 2632, 111, -528, 2981, 4803, 4134, 1461, 1657, 995, 2027, 1876, 1390, -616, -693, -337, -1624, -3795, -4426, -3578, -4316, -7197, -6969, -2548, 1164, -2951, -7911, -8100, -3978, -1097, 2135, 5887, 8298, 8788, 7000, 5322, 4941, 5819, 6652, 7947, 8036, 5872, 4560, 2177, -1404, -5632, -7296, -8277, -7177, -7266, -9043, -11364, -12887, -14790, -15049, -13411, -10976, -8310, -5783, -4904, -4521, -3305, -1337, 1158, 2870, 3693, 5733, 9478, 11413, 10273, 7948, 7096, 7409, 7690, 6589, 5291, 3466, 1147, -1075, -2673, -3115, -3836, -4711, -5832, -6488, -6722, -5400, -3085, -1925, -1491, -846, 388, 1948, 4096, 6459, 8114, 8494, 8734, 9726, 10130, 8695, 7140, 6747, 6265, 5003, 3468, 1867, -539, -2768, -4234, -4608, -5222, -5985, -6582, -6705, -6972, -6799, -5766, -4479, -4175, -4265, -3217, -1529, -275, 240, 421, -20, 1316, 2947, 2495, 1227, 2204, 2495, 1656, 1393, 1691, 1577, 2464, 1421, -930, -1012, 1061, 889, 386, 1045, 1966, 2548, 2739, 1301, 493, 2616, 4866, 4987, 3743, 2858, 2833, 3627, 3646, 2242, 1662, 784, 211, -956, -842, -1640, -2009, -3455, -3889, -4529, -5585, -6310, -5535, -5146, -5641, -4571, -3667, -4270, -5400, -4660, -2131, 2161, 5157, 7547, 10461, 12953, 11093, 9583, 9737, 11400, 10257, 9121, 7319, 7813, 6319, 3210, -2067, -5989, -9288, -10306, -11066, -12671, -14034, -14826, -15642, -16938, -16895, -16635, -15045, -12786, -10205, -7323, -3319, -496, -51, 401, 2638, 5712, 8412, 9794, 11091, 13221, 14246, 11071, 8606, 9205, 9503, 6710, 4371, 2670, 166, -1860, -2283, -2317, -4253, -7063, -8445, -6551, -5301, -5878, -5729, -4283, -3598, -2749, -310, 1785, 3021, 3368, 3512, 4666, 6895, 8314, 8217, 8081, 7592, 7083, 5955, 4905, 4169, 3175, 1252, -119, -174, -832, -1609, -2662, -4076, -5450, -4707, -4208, -4833, -5362, -5181, -5061, -4482, -3001, -2335, -2616, -3090, -3136, -2815, -1066, 1049, 1186, -494, -1104, 147, 1265, 1382, 1526, 2590, 3667, 2853, 1542, 1601, 2715, 3163, 3736, 4851, 5657, 5672, 4335, 2521, 1562, 2778, 2954, 3054, 3163, 3541, 2174, 1157, -322, -1022, -930, 308, 340, -46, -715, -981, -1588, -1719, -2799, -2768, -1910, -665, -2250, -3667, -4253, -2777, -3159, -4699, -6523, -6317, -5428, -3054, -498, 1335, 2997, 5632, 7072, 6335, 6429, 8559, 9105, 7929, 7841, 9475, 9527, 6862, 2961, 359, -1631, -4041, -5973, -7056, -7875, -9539, -10926, -12653, -14257, -15027, -14179, -13209, -12470, -10451, -8041, -5670, -4865, -3481, -1459, 1262, 1825, 3383, 7188, 10724, 10352, 9636, 10558, 10586, 8993, 7970, 7327, 5823, 3997, 2650, 2196, 1826, 88, -2424, -4515, -5999, -6742, -6483, -6539, -7003, -6055, -4458, -3900, -3532, -2102, -768, 691, 2419, 4142, 6197, 7992, 8619, 8024, 8244, 8266, 8192, 7438, 7061, 6136, 5812, 4485, 2332, -18, -1010, -2279, -3704, -4777, -5864, -6905, -7074, -6615, -7101, -8222, -8641, -7918, -7055, -6702, -5726, -3508, -1226, -746, -2, 1409, 2355, 2859, 3780, 4896, 5222, 6200, 6148, 5514, 3984, 3737, 2894, 2939, 2529, 3017, 2601, 1908, 71, -172, -140, -440, -557, 968, 1762, 1319, 524, -180, 74, 1527, 2168, 1375, 680, 1665, 2351, 2346, 166, -795, -656, 1167, 0, -563, -515, -407, -2737, -4053, -4284, -3081, -2259, -2923, -4382, -4282, -3542, -4651, -6916, -8243, -7853, -4193, 1925, 5540, 5351, 4724, 5428, 5709, 5463, 5547, 8232, 10568, 10042, 7755, 7630, 6461, 2785, -1372, -2728, -3242, -3406, -3991, -5463, -8392, -10196, -10960, -11550, -12518, -12445, -11570, -10199, -9251, -7815, -5995, -4037, -3252, -2131, 117, 3236, 4787, 5558, 5941, 6378, 7464, 8547, 7994, 6325, 5232, 5163, 5421, 5094, 3553, 2534, 1999, 1129, -107, -424, -417, -815, -1641, -2086, -1541, -547, -166, -736, -1394, -1649, -821, 1131, 1735, 830, 505, 1158, 927, 913, 1176, 1530, 1779, 1442, 641, 805, 1424, 792, -994, -2034, -1251, -245, -195, -1191, -1865, -2318, -2956, -3023, -1775, -1381, -1492, -856, -106, 321, 854, 981, 722, 421, 939, 2112, 3397, 3227, 1875, 1298, 2211, 2473, 2322, 2223, 1740, 1273, 1738, 1696, 1030, 699, 502, 130, 889, 2172, 2276, 1707, 952, 219, -188, -270, -340, -172, -32, 11, -141, -464, -979, -1152, -1443, -1872, -1894, -1730, -2267, -1930, -1228, -1945, -2891, -2426, -1293, -397, -855, -2890, -3951, -2415, -497, -812, -1599, -1839, -1378, -212, 120, -1170, -1457, -1039, -1219, -342, 2418, 5066, 4307, 1612, 513, 1986, 3901, 3971, 1559, 153, 1038, 1828, 1312, -667, -2414, -3477, -4413, -5010, -5005, -4192, -3903, -5217, -6752, -6083, -4399, -3318, -3642, -4106, -2417, -45, 708, 148, -3, 505, 1282, 1850, 2990, 4853, 5993, 4672, 2670, 2482, 3423, 3818, 3600, 2877, 2715, 3755, 4485, 3548, 2203, 1289, 856, 893, 1237, 1391, 1703, 1287, -37, -770, -369, -150, -1038, -2474, -3119, -2256, -1046, -1194, -2597, -2823, -1461, -241, -17, -287, 181, 659, 148, -512, -56, 409, 495, 147, 193, 655, 1154, 1032, 442, -49, 105, 335, 217, 82, -183, -53, -83, -257, -407, -10, 46, 200, -78, -600, -342, 1093, 1512, 536, 93, 566, 225, -585, -910, -719, -293, -409, -1321, -1623, -1274, -1804, -2762, -2931, -2659, -1876, -1013, -1345, -2699, -2778, -2263, -2368, -1908, -72, 1994, 3489, 3576, 2797, 3242, 5110, 5666, 5403, 5041, 5770, 6048, 6161, 5131, 3227, 2007, 1525, 508, -479, -935, -910, -2227, -4037, -4516, -4026, -4223, -4893, -5459, -5571, -4933, -3951, -4478, -5543, -4532, -3804, -4183, -4535, -2967, -1088, -360, -574, -1804, -1052, 2033, 3063, 1623, 775, 2098, 3469, 3969, 3571, 2716, 2335, 2492, 2122, 1549, 1344, 1962, 1685, 14, -174, 1403, 1144, -427, -1210, -1157, -1181, -1168, -900, -1055, -1447, -770, 138, -493, -1169, -476, 763, -145, -1119, -429, 1827, 2167, 570, 27, 970, 1262, 406, -185, -252, 481, 875, 493, -336, -476, -171, -191, -1211, -1301, -588, 93, 123, 158, 178, -83, 346, 763, 211, 309, 1627, 2085, 1315, 1433, 2072, 1916, 1389, 1344, 1427, 1639, 1648, 1025, 194, 772, 687, -686, -1457, -292, 931, 185, -885, -297, 301, -241, -1437, -1446, -578, -174, -66, -206, -627, -293, -142, -1285, -2658, -2136, -1508, -785, -640, -1057, -1002, -1262, -1691, -2594, -2666, -1823, -1062, -1081, -1882, -1909, -1246, -1510, -2612, -2372, -844, -417, -1237, -1700, -1000, -182, -571, -889, -486, 763, 507, -382, 345, 1197, 1268, 1505, 692, 890, 1721, 2292, 1826, 1093, 1273, 2025, 1828, 620, 1135, 3262, 2596, 598, 602, 1581, -38, -525, 839, 722, -416, 171, 1342, -1239, -2514, -344, 664, -996, -1465, 688, 2604, 1808, -293, -864, 1106, 1169, -105, 706, 3998, 3589, 148, 565, 1685, -329, -1365, -158, -68, -2117, 147, 2702, -431, -2619, -2403, -913, -2140, -2580, -551, 600, 1191, 515, 143, -45, 202, 858, -217, -43, 794, 1532, 2056, 486, -230, -767, -564, -514, -616, 126, -1063, -1581, 58, 124, -2043, -2301, -1074, -2801, -4234, -1499, 9, -2032, -3529, -1111, -2000, -4313, -3265, -1457, -2714, -2868, -1698, -1206, -144, 61, -2040, -2540, -611, 871, -716, -328, 2087, 2105, -699, -318, 3150, 76, -329, 2028, 2530, 196, -906, 2617, 3930, -1189, -2596, 586, 4431, 371, -1711, 1343, -223, 2270, 958, -939, 1747, 1591, 275, -2293, 2755, 2013, -2096, 2936, 1681, -1386, -1685, 2680, 1606, -3295, -52, 522, 407, 1148, -567, 1191, 698, 223, -2044, 513, 1697, 1130, -1816, -1547, 3195, 701, -247, 132, 3067, 239, -3376, 2141, 2602, -468, -1443, 2335, 2537, -1558, 2605, 940, -809, -915, 1234, -116, -3201, 3068, 1430, -3890, -416, 890, -1202, -4217, -1943, -357, -2629, -1588, -626, -536, -3272, -1552, -1312, 739, -1834, -2010, 2082, 242, -612, -1427, 1845, 1782, -458, 97, 1383, -105, 1487, -100, -1492, -2870, 3642, -666, -1932, 40, 2005, -873, -2887, 2057, 248, -292, -1761, 1590, -431, 178, 613, -373, 792, -888, 1288, 527, -1637, 2454, -930, -248, 1297, -575, 174, -48, 1632, -462, -1185, 2243, 1420, -1827, 121, 3874, -334, -3602, 1397, 3586, -1892, -1995, 2602, 633, -4674, -1123, 2922, -3193, -2200, 1937, 628, -3667, -444, 2694, -598, -4762, 328, 2387, 1443, 314, -426, 81, 2026, 2329, -1881, 701, 2387, 1013, -506, 1175, 2892, 764, -863, 1116, 520, 672, -2046, 2015, 655, -525, -3673, 3502, 1834, -2931, -1981, 2225, 838, -1914, -526, 3037, -144, -2735, 818, 2141, -1449, -3685, 2382, 1487, -2293, -3116, 2952, 2761, -3445, -3530, 2679, 2861, -1851, -5440, 3047, 1791, -3156, 355, 2164, -256, -3718, 2694, 592, -4275, -2079, 4549, 2580, -4718, 183, 3747, 1879, -6268, 1118, 4406, -2668, 116, 1572, 3649, -3304, -284, 3146, -2429, -1018, 1275, 1830, -4180, 2081, 2653, -4935, 64, 2699, -1092, -5037, 2747, 4337, -5230, -3190, 3860, 963, -4198, -2138, 2492, 1754, -5118, 145, 5693, -4699, -3480, 2600, 3599, -6159, -2825, 2439, 2902, -792, -4361, 2523, 2683, 310, -2715, -1065, 4004, -315, -2523, 519, 2554, 1552, -1308, 105, 3794, -3531, -1301, 2164, -196, -4073, 1245, 6648, -3517, -5228, 7003, 4303, -8544, -4605, 11645, -611, -8382, 3540, 7308, -2593, -4007, 4839, -2491, 561, 506, 761, 19, -1393, 3188, -281, -1482, -155, 1130, 2188, -3980, 1600, 1848, 1270, -1860, 284, 2149, -1551, 431, -676, 1368, 866, -694, -663, -585, 1414, -1444, -1046, 573, 1660, -1469, -759, 2882, -3045, 673, 1633, -4181, 2295, 811, 527, -4481, 3169, 4147, -5791, -1958, 4394, 2317, -5705, -1855, 3640, -1612, -2655, 3153, -2391, -1021, 769, 567, -2932, -1549, 2332, -1820, -1143, 610, -921, 229, 126, 2243, -5505, 2401, 5142, -4292, -3541, 5668, 1229, -3710, -651, 3363, 671, -3951, 2436, 1586, -2374, -2966, 5014, 567, -5200, 1312, 5269, -1699, -5065, 756, 7174, -3129, -3830, 1610, 4818, -172, -2595, -1255, 5366, -1032, -4528, 2401, 5264, -2897, -4790, 5163, 3021, -3405, -1893, 1385, 4512, -4259, -2919, 2252, 2656, -421, -6262, 2415, 4170, -1188, -5441, 1935, 6086, -5160, -1688, 2410, 4089, -3167, -4941, 4768, 1323, -3086, -2837, 5196, 1687, -5016, -1446, 5719, 104, -8955, 2619, 7574, -3582, -7840, 6634, 4783, -4580, -3533, -992, 6876, -2974, -4829, 1626, 2093, 263, -2937, 189, 410, -61, 503, -3628, 1702, 1069, -76, -2715, 1167, 3649, -3515, -147, 1717, -465, -1024, 803, 3379, -2240, 1352, -399, 661, -250, -1127, 839, -535, 972, -1642, 2410, 393, -1040, -2098, 1819, 2200, -2404, -424, -71, 2983, -459, 614, -176, -1636, 1609, 2923, 1088, -7164, 2485, 7789, -4946, -4322, 3293, 6108, -7409, -4690, 8334, 704, -6667, 117, 4962, -258, -3655, -1450, 2746, 2037, -3524, -1075, 3338, 1177, -4117, 1130, 3675, -1312, -3438, 411, 4377, -1042, -3828, 726, 196, 2699, -2084, -608, 242, 3160, -2026, -2756, 2094, 2283, -1834, -2257, 2654, 2157, -3086, 144, 2581, -1437, -2270, 1208, 4946, -3563, -1078, 2411, 1292, -1905, -7, 2120, -3461, 1607, 2469, -3273, -165, -395, 925, -2618, 1588, -1237, -1564, 1026, 772, 748, -4143, 3122, -895, 653, -1105, -154, -15, 476, 2692, -4283, 1725, 624, 638, 1143, -4045, 980, 1404, 3428, -2279, -5886, 4012, 4248, -2239, -6344, 3890, 5428, -5012, -3642, 3223, 5477, -7602, -2669, 7279, -1050, -6655, 1981, 5557, -4515, -2786, 5009, -3281, -15, 3000, -873, -4723, 2868, 4667, -4739, -2230, 4064, 3021, -5435, -240, 4357, -47, -4119, 1296, 3514, -784, -5672, 3236, 3339, -1123, -7211, 2812, 7171, -4773, -4235, 2010, 7562, -7414, -1136, 3745, 2371, -2676, -1574, 3259, 2571, -2367, -227, 404, 4667, -3570, -355, 582, 5019, -3437, -1556, 1499, 2478, -862, -4592, 2184, 3208, -1680, -6046, 2099, 6086, -3934, -2422, -569, 2605, 500, -3889, 1320, 2209, 15, -2398, -672, 4141, -2235, -1834, 996, 2119, -2888, -272, 3784, -416, -5534, 3880, 2284, -4021, -2401, 7063, -1772, -4968, 2570, 2930, -1246, -3794, 4412, 619, -3669, -538, 4490, 404, -4204, -1756, 5956, 619, -5718, -681, 5998, -1328, -3541, 146, 4749, -2426, -2069, 1842, 2059, -2348, -1176, 3304, 2545, -4335, -608, 3455, -1178, -2966, 3048, -1208, 1381, -1151, -777, 169, -414, 1082, -3051, 398, 2208, 351, -2077, -313, 1594, 220, -2552, 1921, 1001, 481, -2702, 2747, -203, -529, -1512, -22, 1328, 724, -615, -1080, 1760, -1495, -2215, 3956, -1162, -2154, 698, 3690, -3913, -664, 4691, -1294, -5008, 1367, 6167, -2547, -5937, 3806, 2956, -2252, -3929, 3256, 3719, -4935, -855, 3160, 774, -2625, -209, 3744, 1211, -6660, 3029, 4471, -1297, -4154, -280, 5065, 642, -3331, -1682, 2433, 2863, -5336, -1411, 4133, 154, -4522, 2051, 3206, -4854, -863, 1988, 2721, -5923, -2434, 8381, -1631, -4094, -2400, 6461, 1455, -7857, 1164, 5159, 1229, -7114, 2623, 4402, -1534, -973, 596, 882, -2372, 4136, 209, -786, -1573, 2889, 1936, -2767, 1589, -3146, 2853, 539, -1744, -974, 574, 2121, -2773, 1378, -3171, 1600, -213, -1072, 138, -12, 427, -3775, 3688, 840, -3857, -854, 4594, -88, -4258, 2979, 71, 966, -1450, -1045, 957, 1656, -1671, 174, 1537, -2117, 2959, -1795, -320, 1184, -1613, 3319, -3554, -825, 2801, 1960, -3019, -2335, 2822, 1770, -2953, -942, 3347, -1149, -2152, 2268, 2227, -2723, -3144, 5669, 3045, -9594, 1366, 10029, -3074, -9150, 5932, 7000, -6633, -4055, 4701, 3824, -5664, -2737, 4607, 1904, -6024, -80, 6062, -1273, -6993, 3065, 2996, -1352, -2106, -185, 2309, 1718, -1442, -1932, -139, 3498, 51, -5036, 2554, 2589, -1155, -1511, 887, 1092, -30, -2774, 791, 3576, -3509, -1194, 2649, 1871, -4857, 1326, 3659, -2902, -694, 3281, -1267, -2899, 4516, 1577, -5832, -891, 7401, -421, -6534, -1235, 8813, -1420, -8078, 2617, 7218, -7640, -3318, 7335, 2364, -10039, 2172, 6687, -2169, -5189, 1722, 3437, -522, -2715, 413, 761, 1565, -1380, -1858, 1853, 709, -2676, 311, 2166, -842, -650, 947, -661, -336, 2513, -172, -264, -2834, 2824, 1349, -3, -2926, -367, 5102, -3995, -655, 1772, 56, -1718, 328, -754, 3269, -3022, 1391, -1265, 45, 1733, 2523, -5512, -1146, 6627, 1441, -5976, -1696, 8335, -3216, -3891, 2794, 5476, -8543, -2687, 11026, 553, -11675, -1094, 11825, 538, -12343, -682, 11540, -1086, -10051, 445, 10055, -793, -10038, 2320, 7380, -187, -7130, 1363, 7831, -4637, -5141, 7354, 3657, -6081, -5824, 7692, 6303, -8963, -6122, 8303, 5374, -8811, -3512, 7335, 852, -4063, -2128, 2677, 621, 765, -2546, -1731, 2785, 2299, -2581, -3089, 6212, -2253, -862, 246, -589, 1773, -28, -372, -601, 1505, 72, -2216, 3009, 881, -5092, 1852, 3543, -16, -4287, -967, 4726, 1543, -7477, -2018, 9334, -875, -6643, -656, 6374, -2057, -2426, 162, 5366, -5649, -2610, 8674, -1402, -3861, -2611, 7181, 2147, -8326, 1189, 5519, 240, -5902, -3485, 11252, -834, -9306, 947, 9084, -1749, -10854, 4360, 10955, -6344, -9345, 6880, 10478, -9382, -6927, 7804, 5962, -7272, -4158, 6328, 5134, -6657, -4791, 6826, 4419, -8679, -4251, 9949, 5694, -12494, -7974, 14734, 8516, -14591, -10885, 13933, 11601, -13797, -9052, 11122, 9625, -11376, -6772, 11183, 2361, -6805, -2180, 6619, -749, -5837, 1677, 7133, -2242, -8099, -525, 11033, 103, -7642, -6403, 8539, 10823, -10821, -10548, 8519, 13236, -7052, -15575, 6812, 14190, -3646, -13435, 3952, 9912, -4524, -5631, 2835, 4163, -2458, -6445, 7500, 2846, -7748, -1845, 7709, 1824, -7841, -4127, 9176, 4889, -8173, -5114, 5687, 4835, -2901, -5498, 2868, 3863, -663, -7028, 4585, 6607, -7626, -4436, 6645, 4484, -7005, -2965, 7398, 584, -7091, 808, 5874, 748, -5942, -4852, 10665, 3985, -13740, 942, 9171, 2907, -12442, -1277, 16109, -4776, -12713, 3989, 14430, -7405, -12444, 9503, 8710, -5796, -10573, 5408, 11257, -7127, -8053, 4091, 10472, -6430, -9505, 6953, 7943, -5738, -8771, 5060, 9335, -4309, -9289, 4478, 8476, -2710, -11822, 7913, 11558, -11778, -8384, 12543, 5982, -10089, -7196, 12455, 2537, -8465, -3656, 8317, 1205, -5537, -1679, 2447, 4101, -2992, -5322, 5270, 750, -1396, -2867, 1716, 4079, -3628, -2413, 1886, 5886, -6405, -1695, 3007, 4402, -3775, -5076, 6891, 865, -5891, 1022, 5111, -2195, -4749, 3740, 3087, -4404, -392, 3543, -268, -4160, 2327, 1797, 398, -2625, -3211, 4371, 4471, -6343, -1429, 1071, 5264, -2349, -4510, 972, 5001, -1905, -2941, 2891, -1967, 2324, -529, -1502, -109, 2606, 745, -2963, -1135, 2638, 2947, -3566, -2612, 2263, 3464, -3351, -598, 3350, -2124, -3632, 3170, 5063, -4961, -6095, 6680, 4095, -6317, -2958, 5040, 3086, -5073, -1732, 3099, 3170, -2893, -2077, 680, 2337, -33, -1765, 1924, -65, -2188, 2827, -1436, 603, -334, -2029, 3452, -1171, -750, -1151, 3884, -2991, -1681, 1857, 1261, -2666, -1220, 4281, -2338, -2199, 3974, -1049, -2214, -1295, 5818, -1202, -5646, 4007, 2043, -817, -2992, 3394, -3084, 1395, 3911, -5207, -934, 5995, -2337, -3756, 1332, 5187, -5163, -1205, 3468, -1195, 565, -2106, 4149, -4244, -937, 5065, -2458, -1794, 1493, -15, 1634, -1279, 287, -1278, 2190, 133, -2496, 310, 3413, -2130, -63, -1650, 1802, 2095, -1885, -4633, 3655, 4994, -6486, -1443, 5270, 906, -6698, 2184, 5310, -1462, -7543, 4526, 7834, -6320, -4061, 3281, 4098, -510, -5680, 943, 4490, -126, -5181, 2122, 4415, -4537, -3141, 4917, 3712, -6327, -5717, 10546, 4821, -14023, -1144, 12187, 3650, -16953, -190, 14576, 2721, -16862, -1726, 15784, 269, -12255, -327, 9995, -1410, -7106, 2919, 4881, -3107, -3781, 3472, 2589, -2138, -4375, 3231, 6504, -6657, -5881, 8152, 6515, -9980, -5644, 8998, 4407, -6787, -4147, 6235, 2773, -5165, -1792, 2474, 3456, -2922, -3821, 4122, 820, -83, -4244, 3208, 2665, -5012, 194, 2280, 1701, -3006, 111, 1985, -1823, 231, 1586, 335, -2293, -121, 2699, 722, -3216, -1478, 4873, 949, -4773, -1572, 4472, 4423, -7254, -1378, 4179, 3137, -3685, -3872, 4087, 2696, -3307, -2714, 2499, 2992, -2731, -1445, 815, 692, -348, -174, 1007, -3673, 470, 4970, -286, -7169, 1013, 7699, -44, -9024, 673, 7966, 1146, -8084, -1143, 6929, 3610, -9320, -1602, 7384, 1599, -4620, -3387, 3769, 2679, -1328, -3653, 1255, 2667, -1556, -895, 2319, -2572, -28, 2506, 903, -3616, -2806, 6640, 3451, -9339, -3112, 9926, 4053, -10926, -3860, 11283, 3471, -9134, -5399, 8024, 8031, -8462, -8428, 8519, 7381, -7435, -7006, 9348, 824, -6129, 62, 6373, -2511, -8563, 9665, 3180, -9347, -3364, 9879, 4498, -11597, -3633, 11412, 3993, -10846, -3707, 9256, 4089, -7700, -5136, 8510, 3774, -7038, -2522, 5403, 2916, -6625, -359, 4006, 3477, -6704, -754, 5000, -734, -838, -2241, 3027, -663, -2882, 5320, -1075, -4834, 46, 6270, 1000, -8647, -845, 9037, 161, -8363, -1030, 6736, 3333, -7858, -3718, 7383, 3137, -4501, -4645, 2956, 4642, -1732, -1795, -2558, 1487, 4165, 798, -4972, -2681, 4428, 3216, 404, -5945, -4220, 9567, 4960, -9068, -6982, 9209, 7795, -8111, -8181, 6835, 8638, -6438, -7135, 5224, 3331, -2068, -1429, 338, -2406, 3785, 1711, -4446, -1720, 3678, 2483, -2937, -3156, 803, 4235, 1514, -5895, -2967, 6413, 3864, -6510, -2381, 4451, 1127, 522, -3255, -186, 884, 3714, 293, -5844, -660, 7570, -282, -5728, -1340, 6648, 509, -6024, 16, 3454, 2506, -3623, -3660, 3083, 5448, -3398, -4834, 1743, 4809, -1577, -2570, -1738, 4133, -48, -2043, -807, 969, 1686, -2335, -144, 1594, -390, -1372, 1925, -1238, -550, 934, 716, -868, -1186, 929, 2226, -1373, -2079, 336, 3583, 498, -5109, 268, 4844, 488, -4656, -1878, 4423, 3252, -3915, -5446, 3802, 5862, -2500, -5938, 523, 4185, 2968, -5340, -2954, 4844, 1441, -2864, -855, 988, 786, 354, 45, -3610, 1257, 4759, -1883, -3493, -690, 4648, 2091, -5926, -1565, 5415, 783, -3428, -1041, 1381, 1889, -891, -2741, 3011, 664, -3120, 72, 4623, -2428, -2939, 718, 4433, -977, -4504, 1361, 4329, -185, -6421, 1750, 6424, -2903, -4696, 2226, 4031, -2369, -3387, 3495, 990, -3174, -512, 4503, -667, -5088, 1238, 4968, -2198, -3780, 2187, 2163, -598, -3591, 3110, 1134, -2668, 183, 1310, 1539, -3333, 1426, 587, -572, 1291, -1151, -374, 2406, -1363, -2304, 2310, 2162, -3189, -2560, 4344, 1787, -5612, 680, 3342, -937, -2329, 1167, 2550, -3203, 1391, 88, -334, -137, 377, 727, -1742, 490, 136, 1277, -600, -1654, -62, 1892, 821, -2158, -2620, 3775, 2248, -3340, -2488, 1862, 4183, -2204, -4794, 2579, 3716, -1858, -2068, 661, -267, 2128, -219, -2462, 304, 1222, 1946, -2046, -1798, 2001, 970, 48, -2217, -184, 2265, 1355, -2614, -1593, 2007, 2788, -1479, -3408, 937, 3488, 549, -4258, -582, 3136, 823, -531, -3155, 2371, -512, 1282, -448, -1662, 285, 558, 859, -328, -970, -543, 261, 2769, -2079, -2105, 1986, 2272, -2659, -1439, 1890, 1314, -395, -3732, 2291, 2957, -959, -4357, 1371, 4196, -1452, -1856, -959, 1680, 2864, -2984, -2207, 2613, 2372, -3331, -1289, 3442, 463, -3848, 61, 3397, -824, -3272, 2063, 1776, -1321, -2992, 1985, 3546, -3237, -2239, 2842, 1319, -651, -2054, 656, 1995, -1538, -194, 642, -163, -344, 399, 48, -217, 14, -866, 836, 1358, -2971, 1160, 946, -50, -951, -1109, 2197, 1607, -3936, -921, 4519, 1224, -5233, -950, 5324, 1761, -6659, -567, 6062, 1029, -6512, -229, 5701, -302, -4427, 151, 4252, -2623, -509, 627, 980, -1254, -1342, 2006, 778, -3224, 1018, 2020, -1155, -2004, 2202, -1050, 940, 236, -1077, 668, 250, -297, -52, 1365, -692, -620, -355, 1987, 1031, -3212, -135, 2088, 993, -2030, -1219, 1839, 515, -286, -2463, 1386, 879, -1724, 1605, -886, -1056, 501, 436, 1349, -2389, -1690, 3713, 716, -3305, -20, 2576, 962, -3802, -220, 4856, -1614, -2952, 1312, 3494, -1718, -2443, 937, 3318, -236, -5313, 2907, 3220, -1083, -3188, -358, 5267, -991, -5144, 206, 6397, -1298, -6238, 1576, 5505, -935, -6222, 2157, 4978, -2942, -3197, 1131, 4251, -2884, -2283, 2367, 1559, -2774, -370, 1899, 1055, -1887, -1519, 1983, 2152, -972, -5345, 4155, 3622, -3521, -3772, 3302, 4903, -4938, -3118, 4820, 1468, -3014, -3309, 5570, -896, -1775, -288, 1217, 1813, -4762, 2079, 2972, -1996, -1810, -1218, 3079, 1828, -3028, -1784, 1540, 3307, -2785, -1935, 2303, 690, -2600, 1888, 599, -618, -1296, 868, 3033, -2185, -3567, 3217, 1888, -571, -2503, -87, 1183, 1178, -204, -2939, 741, 1037, 1108, 128, -3011, 863, 1757, -49, -171, -2981, 1928, 1775, -407, -754, -2694, 4039, -537, -692, -940, -330, 1986, -329, -64, -2239, 1773, 2023, -2582, -111, -134, 2117, -324, -1907, 381, 156, 2353, -1225, -2949, 1366, 3232, -1748, -2311, 1643, 482, -1304, 600, 1224, -3216, 1028, 2929, -2657, -854, 174, 2806, -549, -3467, 2255, 336, 2049, -3992, 1268, 2784, -2039, -1841, 1167, 3160, -1634, -3463, 2035, 2437, -2350, -278, 459, 1560, -2347, -1382, 3106, 1375, -3504, -2554, 6080, 1186, -6935, 822, 6413, -1369, -5920, 1934, 5387, -1303, -4761, 438, 5478, -448, -4690, -1393, 6200, 141, -4227, -1124, 3562, 2256, -3995, -2887, 5182, 1930, -4701, -1176, 3749, 1430, -2956, -1506, 2568, 1042, -1928, -1601, 3449, -695, -2915, 1170, 2511, -1291, -3220, 929, 3903, -1807, -3236, 1109, 3530, -2038, -3467, 3203, 2187, -927, -4283, 2023, 3761, -682, -2662, -1064, 3370, 615, -963, -1015, 349, -213, 1926, -934, -789, -117, 246, 1877, -1642, -1205, -160, 2555, -211, -2810, 24, 1769, 1665, -3168, -1507, 3012, 487, -2596, -694, 1256, 2574, -2114, -3576, 2031, 4425, -3002, -3658, 2633, 3396, -3090, -2488, 2235, 3073, -1579, -4597, 3690, 1935, -1552, -1219, 783, 1077, -1699, 2089, 338, -2680, -85, 2814, 1520, -3299, -2412, 3662, 3099, -3438, -3133, 2619, 2536, -786, -2364, -600, 2722, 1172, -3599, -342, 2628, 162, -1629, -945, 1477, 241, -1624, 1629, -350, -176, -2451, 3220, 504, -2803, -554, 1551, 2942, -3354, -2271, 3324, 1780, -2675, -1543, 2012, 1010, -814, -271, 286, -583, 442, 592, -794, 517, -244, 48, 128, 79, -369, -471, 1677, -1301, -562, 1769, -35, -1015, -1626, 4099, -513, -3336, 1039, 2529, 283, -3216, 643, 2212, -1403, -450, 451, 1654, -2129, -462, 2706, -790, -2686, 967, 1970, -822, -1138, 323, 656, 599, -402, -822, -900, 1889, 1411, -3572, 484, 3207, -975, -3172, 1722, 2262, -2376, -1839, 2344, 2329, -3237, -1467, 2512, 566, -366, -2145, 891, 1921, -774, -1092, -1134, 2816, 203, -1867, -819, 1808, 785, -886, -1109, 622, 390, -67, -266, 1353, -2053, -1093, 2835, 959, -3089, -1577, 2700, 1939, -1456, -1974, 221, 1627, 1677, -2337, -2114, 2226, 1763, -1412, -1291, 1238, 1134, -2215, 631, 1494, -238, -2273, 1114, 1642, -845, -1034, -123, 1850, -127, -2800, 1199, 2912, -1460, -3678, 2503, 3222, -2380, -2624, 2185, 1946, -2273, -1034, 2470, 18, -2540, 970, 1405, -292, -1757, 434, 1605, -1003, -441, -241, 1329, -140, -277, -805, 266, 777, -89, -662, -262, 1238, -232, -1439, 742, 1870, -899, -1969, 536, 1959, -205, -1400, -788, 1708, 47, -686, 649, -689, -756, 1131, 1568, -1935, -1674, 1972, 1178, -730, -1906, 44, 1498, 632, -1029, -1028, 733, 937, -1033, -381, 1395, -981, -852, 1382, 266, -1279, 194, 1177, -1341, -157, 194, 1408, -1388, -781, 1569, -661, -328, -525, 2295, -921, -2247, 1643, 1443, -1233, -893, 740, 1293, -1746, 589, 1075, 80, -1745, 248, 1988, -863, -478, 603, -37, -26, -210, 720, -325, -790, -98, 1107, 395, -471, -1284, 151, 1231, 305, -575, -2083, 211, 2854, 413, -2541, -1195, 1818, 1310, -11, -1967, -1087, 2208, 1843, -1232, -3020, 2357, 2337, -2577, -453, 1176, 201, -176, 476, -1904, 1058, 1354, -840, -1400, -391, 2027, -329, -661, -1253, 1080, 1483, -1981, -316, 335, 1353, -1158, -118, 538, -1015, 1095, -381, 197, -176, -11, -465, 1115, 669, -1729, -560, 1318, 977, -1205, -1123, 1849, -414, -69, -1157, 780, 1306, -1516, -569, 1548, 998, -2710, 64, 3365, -1984, -1068, 64, 1549, 834, -1505, -1719, 1903, 1967, -2427, -1154, 1119, 2261, -1731, -1832, 784, 2722, -927, -3192, 1197, 2795, -1852, -1538, 1912, 638, -1325, -30, 635, 639, -401, -1019, 26, 2564, -613, -2871, 1141, 2670, -651, -2322, -124, 2439, 583, -2335, -757, 2523, -43, -2546, 37, 2930, -554, -3055, -80, 3870, -482, -3686, -151, 4205, 82, -4296, -104, 3519, 1364, -3567, -1978, 2833, 2128, -1050, -2909, -126, 3087, 527, -1877, -1551, 964, 1751, 119, -2010, -538, 1490, 1402, -1140, -2529, 1503, 2352, -6, -3939, 514, 3457, 166, -1814, -2173, 1452, 2216, 1114, -2993, -2560, 3237, 3007, -1877, -3423, -178, 4281, 329, -3689, -1199, 3103, 2369, -4275, -1486, 3199, 823, -2395, -472, 1300, 150, -747, 883, 73, -1461, -317, 1927, 1245, -2737, -1382, 3592, 892, -2139, -2273, 2083, 3046, -2315, -1488, -475, 2900, 433, -2058, -867, 675, 1290, 468, -1269, -1101, -247, 2865, 91, -2124, -1162, 1202, 2867, -992, -3315, 203, 2686, 1344, -2662, -1279, 1020, 1190, 482, -863, -1842, 789, 2126, -1162, -980, 806, 12, -668, -22, 1505, -1013, -955, 146, 1636, 99, -872, -1693, 1704, 2737, -2702, -1841, 2990, 887, -1667, -1298, 2729, -215, -1215, -297, 1139, 162, -367, -227, -560, 1361, -176, -1015, -4, 385, 464, -665, -629, 729, -50, -230, -22, -176, -263, 87, 783, -715, -556, -250, 1873, -223, -1922, -36, 2186, 278, -1539, -1359, 2182, 1170, -1677, -574, 620, 1409, -863, -717, 532, 291, -555, -56, 881, -348, -928, -112, 1142, 988, -2076, -942, 1805, 1185, -2297, -1001, 1889, 846, -2012, -1030, 2453, 50, -2294, 282, 2258, -1092, -2501, 1719, 2862, -2001, -2898, 1910, 2740, -1111, -2606, 449, 2528, 29, -2370, 245, 1854, -22, -1351, -494, 1663, 843, -2109, 20, 1036, 473, -563, -265, 25, 444, 246, -353, -410, 649, 384, -1474, 1020, 97, -1086, 387, 1184, -1650, -342, 1157, 705, -1362, -308, 686, 274, 490, -988, -358, 1137, 711, -1249, -826, 1514, 527, -1309, -266, 1215, 237, -1304, 761, 413, -647, 173, 184, 488, -400, -573, 204, 615, -14, -1691, 1318, 91, -1058, 320, 689, -383, -1561, 2029, -558, -1168, 1480, -438, -533, 464, 150, 279, -576, 151, 396, -415, 276, 35, -239, 233, -1500, 1779, 458, -2016, -103, 1749, 503, -2322, 164, 2251, -95, -1882, -306, 1853, -98, -203, -780, -783, 1471, 926, -1587, -777, 1129, 1122, -1653, -731, 1362, 1144, -503, -2240, 948, 1993, 207, -2307, -487, 2130, 171, -784, -422, 548, 53, -656, 1192, -389, -1455, 1212, 1165, -495, -2864, 1464, 2591, -1136, -2247, -434, 3438, 73, -3049, -113, 2324, -83, -2218, 285, 1990, -591, -1866, 828, 1352, -742, -1798, 1008, 1642, -1054, -1337, 1217, 876, -1779, 464, 2084, -1535, -900, -68, 1556, 1356, -1971, -1580, 1066, 2147, -290, -2437, 58, 2461, -189, -1759, 446, 1304, -1811, -162, 1445, 1181, -2284, -2279, 2989, 2213, -1750, -3417, 1224, 3413, 361, -3517, -1026, 3384, 692, -2094, -223, 295, 442, 151, 428, -709, -1136, 1240, 571, 122, -1020, -667, 1054, 1079, -645, -1862, 983, 1702, -744, -1889, 187, 1939, 544, -2318, -1193, 2152, 1772, -2580, -1275, 1850, 792, -655, -884, 534, 129, 525, -3, -1180, 283, 1702, -1014, -918, 891, 62, -601, 1016, 22, -1842, 547, 2518, -1119, -2797, 1537, 2609, -1612, -2269, 1063, 2365, -832, -2172, 458, 1873, -187, -1109, -744, 1765, 117, -1538, -249, 1682, -25, -1271, 322, 1153, -790, -585, 1594, -268, -2012, 1433, 1699, -1129, -1955, 1296, 1632, -1288, -1262, 781, 1292, -837, -810, 606, 363, -411, -846, 1223, 318, -1354, -250, 1423, 441, -2241, 898, 1191, -562, -1208, 546, 1284, -803, -877, 421, 631, -279, 106, 160, -1000, 580, 1000, -535, -637, 26, 1129, -152, -690, -30, 772, -472, -163, 131, -101, -297, -267, 1268, -222, -1917, 396, 2284, -724, -2128, 559, 1577, 282, -1983, -126, 1868, -524, -717, -214, 145, 574, 450, -919, -1178, 1167, 1228, -716, -1833, 1186, 1265, -878, -528, 164, 587, -151, -80, -309, 68, 225, 324, -25, -797, -90, 628, 490, -423, -826, 746, -52, 603, -196, -525, -232, 760, 1158, -1772, -91, 979, 328, -240, -225, -98, -402, 1197, -345, -1070, 274, 737, 193, -1029, 184, 190, -280, 708, -1021, 61, 482, 776, -1130, -1292, 1688, 559, -1235, -967, 1333, 278, -543, 150, -27, -499, 311, 674, 335, -1566, 260, 763, 1263, -706, -2277, 829, 2531, 36, -3171, 285, 2601, 326, -2339, -535, 1610, 886, -696, -1545, 192, 2108, -104, -1906, 124, 1212, 56, -1006, 152, -62, 278, -64, -101, -319, -107, 353, 171, -78, -811, 323, 917, 74, -1125, 212, 1110, -520, -852, 854, 834, -1090, -677, 1058, 502, -1044, -119, 599, 300, -853, -476, 697, 1184, -684, -1079, -23, 1401, 665, -2026, -790, 1700, 1311, -1637, -1322, 1250, 1149, -1009, -940, 359, 774, -278, 216, -395, -422, -13, 1108, -83, -1601, 109, 1408, -308, -734, -52, 466, -106, -67, -172, 250, 137, -728, 586, 301, -159, -84, -110, 286, 151, 443, -445, -917, 976, 1199, -577, -1337, 396, 1064, 482, -928, -978, 1376, 822, -897, -1040, 799, 1243, -750, -948, 377, 870, 143, -760, -817, 545, 1168, -964, -794, 435, 736, -813, -519, 669, -417, 19, 210, 110, -784, 101, 1305, -442, -1235, 201, 2041, -216, -2197, 456, 1523, 646, -1924, -431, 1514, 480, -441, -1417, 739, 897, 145, -956, -376, 874, -17, 73, -366, -349, -200, 169, 893, -592, -747, -41, 831, -140, -1111, 903, 252, -574, -476, 965, 521, -897, -170, 409, 484, -417, 89, 54, -564, 522, 568, -399, -944, 18, 865, -83, -225, -470, -159, 144, 693, 246, -1183, -720, 969, 1268, -938, -1430, 988, 825, -1017, -67, 476, -41, -143, 203, -105, -176, 451, 280, -202, -364, 140, 397, 544, -59, -1381, 305, 1495, -159, -1517, -199, 1639, 315, -1826, -491, 2157, 493, -2217, -648, 2199, 750, -2041, -758, 1450, 745, -297, -838, 155, 195, 247, -13, -79, -337, -160, 456, 888, -316, -1717, 465, 1978, -320, -1985, 61, 1990, 195, -1815, -402, 1427, 569, -1329, -889, 1196, 1293, -1098, -1480, 823, 1530, -60, -1714, 226, 1037, -246, -723, 450, 443, -575, -324, 353, 552, -395, -731, 335, 708, -266, -662, 0, 1313, 206, -1379, -508, 1553, 700, -1311, -604, 1405, 418, -967, 46, 788, -641, -262, 841, -155, -578, -90, 761, 127, -962, -28, 464, 86, -507, -437, 153, 478, -77, -981, -150, 596, 291, -1101, -496, 1168, 322, -1296, -108, 730, 335, -829, -342, 901, 496, -1075, -352, 884, 282, -537, -189, 140, 221, 252, -152, 109, -613, 250, 989, -194, -896, -2, 1046, 585, -1107, -993, 1299, 1262, -1359, -1323, 911, 1437, -480, -1620, 579, 975, -367, -673, 524, 700, -800, -499, 1298, 623, -1538, -246, 1856, 116, -1701, -38, 1911, 199, -1677, -15, 1692, -43, -1198, 134, 538, 91, -260, -280, 535, 373, -411, -769, 288, 572, -268, -643, 54, 578, -590, -104, 231, -335, -519, 394, 881, -499, -832, 681, 655, -423, -682, 358, 35, 418, 395, -574, -615, 629, 835, -778, -506, 613, 241, -873, 271, 857, -627, -938, 851, 1059, -767, -1296, 772, 1315, -628, -1492, 398, 1081, -214, -1174, 34, 1153, -241, -942, 165, 656, -15, -264, -347, 252, 475, 17, -121, -117, -139, 302, 665, -311, -786, 433, 939, -60, -1246, -180, 1220, 720, -1177, -1034, 1327, 925, -877, -892, 700, 660, -695, -483, 529, 515, -617, -519, 416, 435, -261, -801, 167, 709, -244, -576, -52, 238, 25, 94, -220, -211, 76, 354, 138, -664, -474, 804, 295, -741, -417, 675, 349, -561, -282, 687, 254, -625, -231, 329, 265, -134, -349, 201, 485, -23, -359, 33, 579, 46, -731, 18, 870, 109, -1031, -371, 1065, 784, -1266, -1080, 1436, 1222, -1168, -1221, 501, 1164, -216, -1000, -322, 620, 534, 97, -473, -808, 379, 1154, -54, -1456, -450, 1673, 789, -1552, -1149, 1602, 1532, -1135, -1730, 578, 1849, -307, -1766, 53, 1624, 157, -1393, -331, 798, 528, -441, -532, -181, 313, 515, -120, -903, -395, 807, 725, -607, -1003, 330, 1310, 80, -1610, -530, 1506, 749, -1353, -926, 1256, 1233, -958, -1304, 687, 1553, -472, -1272, 391, 1144, 138, -742, -319, 348, 722, 308, -688, -622, 782, 1267, -354, -1602, 71, 1765, 259, -1866, -449, 1589, 515, -1202, -728, 486, 530, -5, -492, -605, 292, 921, -146, -1198, -161, 1221, 303, -1065, -582, 969, 648, -1082, -744, 581, 545, -439, -490, 18, 157, 391, -250, -671, 36, 675, 55, -911, -4, 812, 89, -799, -276, 668, 361, -476, -309, 384, 338, -102, -235, -126, 147, 391, 9, -413, 69, 675, 124, -702, -138, 755, 291, -518, -426, 450, 450, -331, -415, 146, 436, 259, -350, -383, 504, 697, -453, -688, 373, 863, -84, -687, -77, 586, 216, -423, -247, 243, 214, -228, -250, 8, 159, 6, -14, 59, 61, 104, 32, -213, -174, 252, 226, -405, -491, 347, 624, -325, -845, 199, 819, -95, -869, -128, 773, 119, -692, -314, 609, 463, -477, -579, 375, 662, -291, -684, 60, 520, -14, -650, -163, 630, 242, -564, -459, 402, 593, -88, -654, -177, 609, 406, -331, -644, -157, 600, 384, -499, -763, 184, 858, -162, -1075, -47, 1212, 303, -1020, -281, 1005, 438, -788, -406, 718, 531, -435, -400, 282, 516, -227, -508, 132, 346, -72, -93, 189, -30, -179, 211, 249, -393, -446, 391, 520, -437, -580, 338, 601, -331, -687, 231, 684, 62, -389, 70, 474, 185, -211, -49, 518, 325, -383, -165, 461, 281, -394, -226, 258, 55, -90, -28, -142, -166, 151, 196, -281, -174, 396, 328, -182, -325, 145, 391, 166, -231, -424, 125, 587, 105, -735, -494, 542, 498, -560, -848, 198, 794, -66, -923, -252, 818, 432, -740, -644, 612, 644, -508, -630, 440, 558, -380, -359, 256, 193, -275, -40, 296, -172, -406, 249, 549, -348, -735, 248, 730, -208, -931, 82, 847, 18, -791, -222, 720, 268, -649, -357, 514, 474, -258, -243, 270, 268, -138, -247, 155, 171, -140, -112, 131, 103, -164, -117, 96, -59, -261, 65, 244, -37, -215, 28, 301, 71, -237, -116, 317, 211, -200, -70, 361, 252, -300, -209, 435, 325, -388, -441, 327, 591, -143, -664, -94, 633, 272, -510, -502, 261, 593, -126, -624, 12, 508, 59, -407, -147, 174, 22, 42, 99, -110, -118, 246, 225, -292, -348, 80, 202, -121, -243, 82, 160, -199, -292, 0, 125, -73, -313, -209, 247, 411, -50, -436, -8, 556, 222, -473, -268, 428, 454, -116, -306, 144, 299, -13, -148, 13, 107, 12, 71, 68, -149, -139, 43, 80, -144, -150, 88, -11, -169, -58, 80, -46, -204, 32, 213, -65, -322, -94, 290, 155, -259, -222, 194, 330, -108, -331, 6, 378, 188, -227, -151, 222, 332, 17, -337, -89, 416, 277, -189, -185, 198, 277, -43, -206, -104, 31, 100, 12, -267, -247, 158, 267, -167, -386, 47, 342, -60, -410, -76, 347, 191, -239, -164, 248, 235, -170, -280, 21, 268, 169, -65, -62, 31, 208, 238, -62, -295, 24, 446, 124, -322, -48, 413, 136, -372, -209, 205, 96, -172, -23, 135, -67, -180, 24, 49, -155, -147, 63, 51, -144, -70, 104, -36, -243, -3, 332, 27, -356, -49, 379, 95, -326, -77, 360, 196, -286, -198, 240, 220, -202, -241, 153, 198, -139, -192, 64, 96, -163, -200, -26, 4, 15, 80, -13, -211, -139, 212, 120, -293, -250, 213, 359, -103, -372, -8, 306, -10, -426, -238, 191, 205, -77, -195, -60, 127, 46, -196, -217, 64, 220, 6, -157, -43, 144, 94, -160, -153, 59, 115, -15, -93, -12, 166, 156, -24, -139, 40, 231, 65, -100, -38, 185, 193, 59, -39, -14, 158, 155, -6, -60, 81, 170, 30, -71, 68, 108, -11, -32, -35, -97, -86, 36, 11, -117, -17, 58, -166, -167, 106, 58, -202, -84, 209, 168, -100, -94, 96, 148, 22, -80, 4, 119, 120, 17, -5, 79, 78, 70, 70, 99, 63, 97, 165, 124, 45, 74, 123, 21, -1, -3, -3, -38, -35, -65, -74, -14, -76, -193, -134, 92, 21, -203, -161, 85, 49, -204, -219, -16, 63, -53, -57, -22, 17, 47, -25, -44, 31, 51, -3, 69, 122, -6, -59, 122, 133, -69, -57, 68, -18, -137, -26, 66, -54, -155, -45, -9, -106, -98, -68, -61, 22, 82, -55, -113, 72, 138, -54, -122, 51, 147, -9, -107, 10, 116, -3, -131, -59, 38, 6, -14, -6, 16, 49, 54, 72, -29, -95, 35, 105, -37, -154, -26, 159, 74, -183, -160, 75, 68, -140, -188, -5, 71, -13, -93, -34, 43, -5, -68, -21, 33, -14, 6, 1, -62, 18, 88, 44, -46, -47, 99, 128, -51, -69, 166, 228, 22, -59, 78, 178, 20, -182, -86, 136, 127, -67, -53, 98, 117, 23, -115, -89, 44, 55, -31, -80, 7, 81, 8, -76, -113, -49, 25, 19, 16, -19, 50, 154, 82, -62, -56, 44, 33, -85, -88, 79, 109, -49, -108, 44, 67, -130, -167, 14, 80, -53, -136, -39, 57, -11, -98, -111, -20, 87, 36, -66, -7, 129, 165, 17, -83, 37, 117, 20, -66, 26, 161, 122, -16, -17, 106, 92, -53, -52, 60, 82, 8, -73, -56, 26, 10, -64, -88, -28, 35, 31, -51, -129, -44, 31, -43, -157, -117, 10, 14, -33, -64, -14, 41, -19, -76, -65, -9, 14, 8, 20, 23, 45, 33, 41, 81, 80, 41, 38, 92, 136, 82, -6, 33, 148, 102, -51, -54, 62, 96, 8, -57, 38, 134, 2, -143, -107, 9, 22, -89, -94, -8, 12, -83, -114, -50, -28, -16, -36, -76, -21, 4, -29, -77, -109, -20, 57, 4, -85, -26, 101, 62, -36, -45, 64, 81, -5, -20, 28, 64, 50, -9, -51, -41, 4, 41, 30, 28, 58, 94, 46, -26, -55, -27, -5, -25, -1, 26, 18, -6, -20, -9, -16, -9, 28, 47, 35, -44, -53, -17, -29, -55, -72, -26, 5, -37, -61, 17, 43, -27, -52, 18, 19, -35, -61, -25, 3, -22, -55, -4, 18, -25, 1, 49, 54, 38, 43, 68, 66, 12, 29, 66, 60, 26, 9, 67, 59, 34, 51, 43, -14, -39, 19, 3, -95, -97, -47, -37, -63, -76, -59, -21, -42, -28, -37, -23, 44, 16, -26, -2, 57, 13, -86, -25, 99, 43, -42, 14, 123, 57, -66, 5, 134, 90, 9, 43, 86, 9, -53, 25, -7, -87, -51, 61, 61, -49, -7, 75, 16, -84, -68, -1, -48, -136, -77, 30, 12, -76, -50, 27, 36, -50, -75, 2, 44, -1, -49, 0, 63, 57, 35, 21, 48, 100, 85, 64, 30, 39, 56, 49, 36, -6, -38, -16, -23, -41, -26, 11, 27, -2, -23, -6, 9, -6, -21, -69, -76, -41, -57, -60, -37, 14, 21, 21, 17, 1, -29, -64, -28, -6, -20, -13, 34, 53, 19, -11, -10, 11, -4, -25, -4, 40, 63, 43, 9, -10, -7, -3, 8, 3, 0, 18, 26, 9, 7, 17, 32, 3, -58, -51, 11, -6, -72, -60, 1, 36, -14, -17, 50, 84, 53, 1, 35, 52, 27, -30, -3, 30, -18, -45, -50, -6, -31, -64, -43, 1, -12, -68, -73, -61, -48, -41, -9, 9, 5, 12, -3, 1, -6, 19, 50, 51, 73, 73, 59, 39, 42, 52, 38, 32, 53, 45, -5, -55, -31, -18, -47, -31, -9, -18, -80, -57, -30, -59, -76, -38, 12, 19, -2, 25, 53, 32, 30, 12, -3, 11, 66, 67, 5, -12, 38, 59, 12, -9, 26, 41, -8, -40, -7, -1, -8, -45, -30, -5, -33, -20, -6, -41, -74, -79, -49, -39, -32, 7, 19, 13, 36, 40, 14, 27, 56, 78, 114, 106, 91, 97, 69, 60, 17, -5, 18, -2, -65, -87, -56, -50, -64, -69, -58, -33, -59, -96, -88, -62, -27, -31, -31, 21, 45, 55, 29, 1, 25, 32, 29, -4, 0, 26, 23, 34, 58, 36, 18, 16, 11, -5, -30, -11, -24, -11, -11, -19, -1, 7, 8, -7, 11, -10, -10, 9, -5, 14, 15, 2, 14, 2, 4, 3, -22, -26, -12, 13, 19, 7, 22, 33, 10, -7, -18, 7, 31, 28, 48, 45, -4, -24, -12, -19, -26, -15, 4, -3, -34, -31, -43, -60, -49, -27, -15, -19, -2, 6, -12, -22, 4, 3, -2, 17, 32, 57, 56, 27, 35, 39, 55, 62, 40, 33, 28, 10, -3, -1, 31, 50, 35, -1, -25, -8, -32, -65, -66, -53, -35, -28, -38, -48, -68, -64, -72, -75, -28, -3, -4, 5, 33, 21, 16, 46, 49, 7, -23, -6, 13, -4, -26, -13, 9, -1, -3, 14, 22, 24, 9, -5, -14, -39, -27, -12, 21, 61, 28, -23, -66, -63, -39, -55, -15, 69, 125, 104, 64, 54, -31, -47, -16, -8, -34, -21, 69, 85, 63, 57, 106, 98, 18, -43, -91, -105, -96, -104, -60, 10, 65, 77, 22, -5, -14, -38, -81, -95, -48, -6, 24, 61, 57, 27, 1, 7, -11, -42, -53, -23, 2, -7, 13, 45, 76, 85, 48, 32, -6, -69, -88, -92, -54, -37, -23, 15, 35, 31, -16, -47, -46, -53, -41, -34, -25, -17, 3, 39, 56, 70, 69, 57, 19, 6, 21, 22, 37, 50, 74, 59, 25, 24, 24, -15, -29, 15, 22, 1, -6, -17, -34, -17, -18, -39, -33, -21, -12, -44, -57, -39, -21, -10, -29, -38, -14, -8, -37, -31, -32, -27, -13, -6, -1, -16, 24, 44, 42, 48, 58, 85, 56, 42, 62, 66, 39, 23, 45, 51, 38, 25, 23, 25, -3, -55, -95, -88, -81, -80, -65, -35, -13, -7, -24, -44, -36, -23, -20, -26, -15, -34, -48, -28, 12, 51, 41, 70, 70, 31, -4, -44, -43, -35, -12, -9, -19, -15, -4, 14, 5, 1, 16, 41, 36, 13, 17, 18, 27, 28, 13, 10, 51, 40, 13, 15, 20, 45, 47, 36, 22, 12, -12, -54, -61, -72, -62, -28, 0, 10, -5, 3, -11, -37, -44, -40, -7, 17, 12, 4, -23, -38, -30, 1, 31, 59, 76, 40, -8, -14, -13, -22, -11, -8, 5, 2, -28, -6, 23, 35, 79, 91, 63, 31, -11, -43, -72, -88, -30, 12, 26, 42, 38, 24, -17, -29, -43, -46, -40, -22, -2, 5, 12, 25, 6, -6, -6, -31, -66, -74, -74, -79, -82, -59, -3, 27, 39, 35, 42, 3, -24, -23, -23, -2, 2, 12, -1, 9, 26, 36, 36, 25, 31, 3, -15, 2, -16, -8, -5, -8, 7, -22, -12, 26, 43, 45, 58, 65, 52, 46, 8, -30, -23, -6, 4, -4, 12, 45, 42, 22, 7, 22, 12, 3, -4, -25, -2, 13, 9, 3, -12, 6, 3, -38, -13, 3, -5, -29, -47, -24, -46, -41, -18, -10, 12, -16, -30, -12, -21, -25, -24, -18, 7, 2, -9, -6, 4, -7, -28, -23, 20, 32, 18, 51, 62, 42, 50, 34, 24, 22, 34, 46, 34, 39, 27, 16, 7, -23, -17, -13, -14, 12, -9, -29, -21, -18, -10, -27, -12, -4, -16, -19, -25, 0, 11, 29, 26, -9, -15, -11, -12, -28, -29, -50, -41, -20, -50, -36, -32, -4, -7, -12, -3, -11, 1, -23, -29, 5, 25, 37, 52, 60, 49, 25, 12, 28, 42, 41, 21, 8, 9, 2, -8, -23, 25, 38, 13, 2, -28, -22, -36, -42, -48, -27, -8, -8, 0, 22, 33, 29, 18, 12, 12, -1, -17, -37, -15, -43, -55, -7, -17, -33, -37, -29, -35, -35, -19, -10, -8, -12, -13, 1, 8, 16, 5, 1, 27, 33, 27, 23, 18, 16, 10, 21, 40, 34, 35, 27, 10, 2, -8, -17, -22, -8, -4, 14, 18, 10, 30, 21, 18, 24, 17, 4, -11, -6, 9, 1, 1, 10, 27, 9, -14, 14, -6, -3, 5, -5, 16, 8, -16, -45, -44, -41, -54, -53, -52, -34, -37, -44, -10, 11, 24, 24, 14, 23, 18, 3, -7, -1, 0, -15, -1, 7, 10, 27, 10, 27, 2, -13, -9, 0, 31, 18, 10, 37, 38, 29, 1, -15, -9, -16, 5, 7, 34, 37, -13, -21, -10, -18, -6, 8, 30, 40, -6, -2, -16, -24, -38, -48, -43, -42, -22, -63, -54, -24, 2, 27, 26, 37, 39, 17, -23, -61, -38, 1, 24, 20, 29, 35, 17, 7, -19, -11, 16, 25, 20, 18, 26, 13, 5, 10, 10, 3, 40, 53, 36, 14, -5, -28, -37, -23, -31, -23, -22, -23, -25, -20, -21, -19, 7, 12, 1, 26, 38, 20, 21, 4, -12, -14, -3, 6, 10, 24, 12, 10, 10, 21, 36, 43, 27, 24, 38, 38, 33, 0, 0, 10, 3, -13, -18, -11, -23, -25, -25, -26, -16, -32, -27, -26, -30, -32, -32, -42, -45, -26, -24, -5, -4, 3, 13, 18, 0, -19, -4, -23, -32, -8, 9, 0, -13, 10, 21, 29, 36, 41, 61, 45, 16, 14, 21, 21, 27, 32, 25, 19, 12, -6, -21, -6, 2, 9, 8, 13, 12, 8, 12, -9, 4, 7, -3, -16, -53, -56, -54, -56, -44, -45, -61, -60, -36, -8, -2, -5, -8, -15, -15, -15, 13, 30, 22, 50, 51, 13, 4, 1, 3, -5, -3, 25, 31, 11, 3, 12, 27, 18, 17, 24, 15, 0, -26, -27, -11, -1, 20, 43, 42, 37, 18, 9, -6, -15, 8, 2, 16, 29, -4, -16, -20, -23, -29, -19, 1, 6, 22, 34, 22, -8, -24, -20, -18, 3, 27, 43, 43, 18, -3, -4, -4, 2, 33, 43, 37, 22, 0, -3, -21, -28, -5, -15, -11, 3, -23, -37, -31, -21, -21, -18, -19, -18, -6, -9, -24, -41, -41, -34, -17, -25, -26, -26, -19, -25, -29, -29, -49, -35, -22, -11, 8, 26, 37, 29, 25, 4, 11, 17, 10, 32, 37, 18, 22, 28, 20, 21, 28, 26, 11, 20, 12, 8, 10, 19, 27, 14, -3, -21, -41, -38, -19, -12, 7, 12, 19, 18, -3, -24, -37, -44, -32, -10, 3, 2, -3, 14, 11, -3, -5, -10, -6, 9, 21, 23, 16, 22, 30, 34, 36, 47, 63, 37, 34, 17, -11, -4, -11, 2, 24, 17, 9, 2, -1, -21, -56, -51, -31, -11, -1, 1, -12, -29, -36, -40, -41, -35, -23, -27, -23, -26, -38, -27, -8, -12, -11, -2, -9, -26, -22, -21, -30, -1, -1, 3, 23, 18, 14, 20, 32, 20, 34, 54, 38, 34, 19, 16, 20, 9, 21, 31, 9, -18, -16, -26, -16, 2, 5, 18, 5, 1, -15, -22, -28, -28, -15, -12, -4, 18, 25, 25, 26, 0, -19, -28, -21, -4, 16, 38, 43, 60, 57, 49, 41, 6, 6, 3, -4, 17, 24, 40, 27, 13, 10, 12, 9, 3, 7, 1, 11, 5, -21, -19, -36, -36, -33, -50, -38, -39, -51, -52, -57, -61, -48, -33, -20, -15, -21, -31, -31, -27, -16, -2, 13, 13, 13, 1, 2, 19, 22, 35, 51, 41, 28, 35, 36, 36, 36, 56, 58, 55, 57, 38, 34, 33, 35, 31, 27, 23, -17, -49, -46, -77, -60, -37, -29, -5, -21, -35, -45, -57, -48, -39, -28, -26, -32, -25, -23, -23, -13, -3, -3, 3, -3, 1, 12, 7, 6, 13, 5, -3, 6, 14, 25, 26, 28, 39, 30, 22, 19, 12, 9, 14, 16, 26, 29, 16, 7, 23, 6, -16, -11, -14, -17, -28, -38, -44, -37, -34, -41, -34, -34, -45, -47, -48, -42, -37, -56, -55, -17, -3, 8, 19, 10, 9, -19, -28, -17, 7, 32, 49, 76, 74, 58, 47, 39, 37, 27, 20, 28, 19, 31, 43, 42, 52, 54, 55, 48, 17, 15, 5, -7, 8, 17, 36, 29, 28, 14, 12, 18, -1, 3, -9, -21, -23, -20, -39, -35, -23, -47, -38, -35, -51, -50, -47, -44, -39, -34, -33, -30, -23, -7, 3, -7, -1, -9, -13, -18, -11, 2, 7, 5, 14, 24, 8, -3, -11, -7, -1, 5, 24, 11, -1, -6, -13, -7, 6, 31, 33, 33, 29, 22, 1, -18, -3, 1, -1, -19, -24, -7, -11, -26, -31, -40, -44, -36, -33, -18, -9, -14, -10, -9, 10, 7, 11, 30, 8, 14, -1, 7, 26, 15, 7, 17, 16, 21, 18, 14, 10, 2, 4, -11, 1, 3, -12, -7, -20, -15, -16, -27, -3, 8, 6, -8, -3, -1, -7, -12, 0, 15, 14, 23, 12, -6, -16, -21, -18, 1, 2, 10, 9, -3, -7, -16, -25, -37, -37, -29, -18, 7, 5, -9, 2, -8, -16, -4, -17, -24, -22, -25, -10, 0, 20, 39, 42, 41, 18, 15, -5, -19, 11, 21, 27, 34, 21, 16, -14, -22, -22, -15, 8, 10, 30, 24, 18, 12, -1, 2, 10, 15, 9, 10, 22, 21, 16, 28, 26, 32, 25, 7, -7, -11, -18, -6, 7, 13, 19, -5, 0, 13, 19, 21, 24, 31, 15, 0, 0, -3, 6, -2, -1, 13, -4, -18, -20, -26, -31, -41, -42, -35, -33, -30, -34, -42, -40, -58, -56, -38, -23, -16, -13, -18, -22, -37, -35, -43, -49, -48, -40, -32, -28, -11, 7, 17, 8, -1, 6, 14, 16, 26, 34, 30, 13, 25, 40, 47, 58, 44, 44, 31, 22, 22, 19, 22, -9, -16, -24, -20, -12, -20, -11, -14, -8, 3, -10, -7, -11, -4, 2, -8, 12, 14, 25, 14, 7, 15, -8, -15, -9, 15, 12, 2, 12, 10, -2, 4, 10, 10, 11, 14, 14, 21, 35, 40, 40, 21, 18, 11, 9, 23, 26, 43, 40, 32, 47, 46, 30, 6, -10, -24, -27, -6, -3, 13, 14, -15, -31, -21, -3, -4, 3, 6, 6, -10, -7, 5, -8, -18, -9, -5, -23, -45, -36, -33, -45, -41, -26, -21, -23, -20, -33, -29, -23, -12, -4, 3, 6, 4, 14, 9, 15, 8, 1, 9, 10, -14, -5, 15, 19, 18, 7, -2, -11, -23, -36, -31, -36, -24, 16, 24, 10, 21, -13, -25, -3, -8, 1, 19, 18, 12, 1, -6, -4, -9, -7, 4, 9, 0, 11, 20, 14, 21, 15, 23, 33, 17, 22, 33, 15, 16, 24, 16, 27, 37, 10, 13, 8, 2, 21, 21, 28, 26, 9, 16, 33, 36, 20, 3, -8, -12, -3, -11, -21, -22, -29, -35, -32, -9, 17, 25, 26, 25, 6, -17, 0, -5, -10, 5, 4, 2, 2, -2, -33, -45, -49, -41, -28, -15, 1, 7, -15, -20, -26, -15, 13, 19, 14, 18, 15, 17, 9, -6, 13, 5, 0, 4, -2, -14, -16, -18, -22, -29, -34, -13, -15, -15, -11, -26, -27, -12, 9, 13, 9, 20, 14, -3, -11, 8, 28, 33, 42, 20, 4, -3, 11, 19, 5, 5, 10, 0, -8, -2, 7, 3, -4, 6, 7, 16, -5, -23, -27, -23, -23, -11, 28, 12, 7, 1, -7, -1, -10, -7, -1, 8, -11, -26, 4, -7, -5, 9, 11, 5, -16, -14, -20, -18, -4, 17, 15, 10, 9, -14, -12, -5, -7, 12, 12, 10, 17, 8, 6, 9, 18, 26, 38, 23, 3, -2, -12, -9, -7, -1, 24, 28, 6, -10, -21, -16, -18, -21, -15, -4, 2, -2, 12, 23, 32, 24, 16, 25, 28, 34, 33, 32, 22, 10, 9, 15, 9, 2, -8, -17, -5, -1, -13, -18, -15, -5, 4, -4, 11, -8, -9, 28, 30, 32, 33, 22, 28, 18, -6, 9, 3, -17, -33, -45, -37, -44, -38, -32, -33, -36, -31, -45, -35, -19, -14, 14, 16, 7, 6, -5, 0, 5, 5, 13, 27, 40, 37, 27, 13, 9, 1, 13, 9, 3, 2, -14, -21, -31, -30, -14, -22, -36, -20, -34, -55, -43, -39, -37, -38, -20, -4, -13, -4, -10, -15, -25, -14, -3, -9, 16, 20, 11, 19, 38, 35, 25, 31, 36, 18, 19, 32, 25, 21, 32, 19, -1, -15, -30, -25, -24, -19, -12, 4, 3, 19, 35, 24, 23, 39, 12, 11, 15, -4, 8, 0, 30, 39, 25, 25, 10, 1, -4, 14, 23, 13, 9, 13, 11, 5, -3, -9, -22, -3, 9, -14, -13, -30, -51, -55, -34, -8, 6, 23, 4, -1, 13, -14, 7, 25, 24, 28, 48, 40, 1, -11, -19, -12, -2, -9, 9, -1, -22, -7, -32, -40, -17, -25, -10, -6, 0, 15, 8, 16, 14, 17, 20, 34, 35, 30, 26, 23, 27, 27, 24, 27, 21, 11, 21, 10, -18, -18, -10, -31, -23, -4, -6, -3, -13, -24, -14, -22, -17, -16, -27, -18, -20, -19, -27, -31, -9, -11, 3, 6, -11, -11, -8, -17, -6, 11, 16, 19, 31, 26, 5, 8, 0, 1, -5, -17, -28, -44, -39, -56, -37, -25, -31, -6, -36, -36, -33, -43, -38, -23, -7, 2, 7, -1, -10, 1, 14, 7, 18, 18, 13, 6, 15, 32, 23, 33, 39, 31, 49, 21, 13, 18, 2, -5, 1, 4, 12, 34, 28, 29, 28, 12, 15, 4, -7, -11, -25, -23, -23, -34, -37, -24, -7, -7, 5, 13, -8, -4, 5, -7, -7, -5, -1, 5, 9, 20, 26, 30, 31, 30, 25, 12, 11, 14, 6, -3, 8, 15, 9, 16, 15, 13, 32, 33, 34, 33, 44, 28, 11, 25, 18, 13, 28, 12, 17, 4, -23, -16, -13, -21, -35, -27, -21, -26, -27, -13, -21, -6, 7, 4, 5, 1, 4, 6, 0, 10, 7, -1, -7, -26, -35, -39, -46, -46, -50, -43, -41, -29, -19, -30, -23, -32, -28, -21, -24, -21, -9, 3, 22, 21, 18, 27, 35, 48, 53, 38, 40, 38, 30, 20, 1, 3, 21, 26, 29, 17, 27, 20, 4, 2, -6, -13, -13, -21, -15, -2, -15, -20, -22, -29, -36, -20, -20, -27, -25, -35, -46, -41, -27, -25, -6, 12, 23, 48, 36, 30, 24, 22, 36, 33, 27, 18, 20, 12, 8, -2, -10, 4, -1, -4, -10, -11, -11, -21, -17, -20, -7, 0, 13, 26, 10, 17, 16, 21, 40, 53, 51, 26, 26, 20, 10, 10, 18, 14, -10, -23, -34, -55, -76, -60, -42, -46, -37, -40, -51, -53, -53, -42, -41, -24, -10, -17, -24, -23, -28, -32, -12, -9, 4, 9, 1, -2, -4, -8, -12, 2, 16, 25, 31, 19, 13, 13, 13, 5, 35, 52, 29, 38, 31, 27, 29, 20, 42, 42, 54, 47, 21, 19, 8, 2, 10, 23, 19, 19, 19, 4, 2, 2, 23, 17, 9, 24, 6, 15, -14, -26, -14, -30, -29, -13, -20, -31, -46, -47, -53, -39, -14, 3, 7, 6, -10, -20, -11, 1, 25, 37, 20, 16, -1, -1, -1, -8, 12, 5, -3, -14, -23, -33, -24, -12, 0, 3, 19, 15, 11, 22, 23, 15, 12, 8, -1, -24, -32, -26, -20, 5, 7, 5, 6, -6, -16, -30, -52, -47, -54, -60, -59, -62, -64, -62, -42, -13, -8, 21, 17, 9, 10, -9, -2, -3, 7, 20, 22, 25, 33, 32, 30, 38, 38, 40, 28, 21, 20, 13, 32, 14, 15, 28, 26, 28, 43, 55, 58, 53, 47, 33, 27, 26, 19, 16, 21, 26, 18, 7, -7, 11, 9, 4, 8, -1, -7, -14, -31, -26, -25, -43, -40, -35, -23, -19, -36, -38, -32, -26, -42, -30, -14, -12, -8, -14, -16, -14, -7, -5, -12, 2, 13, 18, 14, 14, 19, 6, 1, 7, 5, 3, 4, 3, -4, 3, -1, -2, 9, -2, 6, -9, -13, -20, -34, -36, -45, -28, -38, -29, -5, -9, 1, -7, -4, -2, -2, -1, -11, -19, -29, -31, -29, -26, -6, -2, 11, 20, 13, 19, 26, 29, 24, 22, 23, 24, 21, 24, 21, 21, 21, 18, 21, 37, 30, 17, 15, 14, 15, 18, 42, 43, 46, 35, 3, 17, 23, 22, 30, 30, 25, 14, 11, 6, 7, 6, -3, 0, 7, 4, -4, 0, -4, 2, 5, 7, 14, 15, 0, -11, -18, -37, -37, -27, -21, -26, -31, -30, -38, -41, -29, -10, -3, -3, -8, -12, -19, -22, -25, -15, -5, 1, 4, 5, -6, -2, -7, -17, -6, 1, 1, -11, -2, 7, -13, -7, 1, 8, 11, 7, 10, 18, 21, 7, 11, 8, -3, 6, 25, 22, 31, 26, 8, 6, 10, 9, 10, 16, 6, 2, -7, -6, -7, -6, 1, -15, -19, -13, -14, -13, 3, 8, 5, 2, 4, 13, 14, 20, 16, 21, 13, -10, -21, -8, 3, 13, 6, 2, 1, -11, -11, -14, 0, 11, 5, -6, 1, -1, -16, -18, -13, -21, -23, -21, -24, -19, -17, -11, -10, -6, 3, 11, 14, 14, 16, 3, 11, 15, 6, 15, 26, 23, 13, -2, 11, 14, 7, 11, 12, 10, -20, -31, -15, -15, -5, -2, -11, -4, 2, -1, 1, 6, 18, 10, 6, 4, 3, 13, 4, 9, 2, -12, -7, -10, -2, -6, -9, 5, -13, -20, -19, -15, -2, 0, 2, -2, -2, -2, 3, 8, 9, 16, 16, 6, 11, 6, -3, 5, 3, 8, 2, 1, 2, 8, 10, 6, 8, 6, 2, 8, 1, -11, -3, -3, -17, -23, -18, -8, -6, 2, 5, 2, 1, -5, 8, -1, 7, 20, 6, 15, 6, -15, -10, -5, -12, -21, -17, -21, -30, -40, -33, -18, -12, -24, -17, -14, -11, -8, -6, 2, 7, 8, 12, 5, 5, 12, 9, 11, 11, 15, 1, 13, 14, 8, 10, 11, 8, 0, -3, 4, 2, -8, -6, 4, 2, -13, -2, 6, 3, -9, -25, -9, -4, -3, 5, 8, 9, 12, -2, 3, 13, 23, 23, 18, 18, 4, 2, 2, 5, 6, 2, -9, -7, -6, -2, 5, 2, -14, -22, -7, -4, -3, 4, -2, 3, 1, 2, 5, 24, 30, 32, 30, 27, 36, 39, 41, 36, 24, 17, 23, 12, 0, -11, -18, -13, -17, -22, -15, -4, -5, -14, -4, -6, -3, 8, 0, -2, 11, 9, 0, -5, -11, -18, -15, -19, -20, -19, -14, -4, -11, -11, -12, -4, 0, -6, 0, -7, -16, -22, -21, -7, -5, -5, -14, -22, -21, -14, -6, -5, -1, 10, -6, -4, 12, 4, 2, 1, -11, -6, 2, 13, 15, 15, 14, 15, 19, 25, 31, 18, 20, 11, 2, 7, 4, 4, -2, -5, -2, 0, -3, -10, -7, 3, -5, -10, -2, -10, -12, -16, -20, -12, 3, 19, 13, 5, 15, 2, 8, 23, 29, 18, 11, 2, -12, -10, -6, -1, 5, 7, -1, 3, -3, -8, -7, -7, -7, -5, -4, -19, -19, -10, -21, -5, 16, 14, 16, 24, 15, 4, 1, 2, -2, 1, 1, -8, -14, -9, -17, -20, -12, -7, -5, -12, -3, 10, 6, 8, 5, 0, 14, 17, 16, 17, 19, 12, 0, 2, -2, -6, -3, -10, -14, -13, -18, -28, -23, -19, -15, -2, -6, -13, -15, -13, -9, 3, 4, 0, 2, -1, -5, -5, -10, -3, 6, -2, 4, 8, 12, 11, 0, -4, -2, 6, 14, 12, 3, -1, -2, -5, -15, 6, 9, 7, 19, 12, 7, 6, -5, -6, 11, 24, 15, 2, -3, -1, -3, -1, 6, 11, 11, 2, 4, 1, 3, 14, 7, 8, 13, -1, -8, 2, 8, -1, -7, 1, 9, 0, 9, 12, 9, 5, -5, 0, -4, -2, -8, -18, -18, -25, -15, -17, -11, -2, -2, -3, -5, -2, -3, -4, 5, -1, 2, 6, -2, -8, -12, -4, 16, 20, 15, 13, 21, 14, 16, 20, 18, 21, 12, 8, 4, -6, -9, -15, -14, -7, -2, -1, -11, -12, -3, 1, 1, -2, 2, 7, 4, 1, -1, 2, 3, 2, 0, -19, -23, -10, -14, 0, 10, 6, 4, -9, -21, -18, -11, -2, 0, -22, -21, -19, -7, -6, -6, 3, -3, 1, 1, 5, -1, -6, -6, -2, 7, 6, 1, -5, -5, -2, -6, -4, 3, -2, -3, -6, -6, -6, -8, -15, -16, 2, 5, 7, 16, 11, 12, 1, 4, 21, 19, 29, 18, 19, 21, 11, 15, 9, 20, 18, 10, 10, 6, 5, 11, 17, 12, 15, 2, 3, 3, -1, 5, 15, 18, 3, -1, -6, -11, -7, -1, 6, 3, 11, 3, -12, -20, -19, -19, -20, 1, -2, -7, -8, -11, -4, -12, -6, 1, 6, 7, 3, -2, -7, -7, -9, -5, -7, -2, -4, -8, 0, 2, 5, 4, 2, -2, -4, 0, -1, -9, -1, 2, 2, 15, 16, 10, 12, 3, 3, 16, 16, 15, 15, 3, -6, -1, -1, 6, -2, -4, -3, -18, -17, -22, -23, -14, -19, -20, -21, -26, -21, -18, -10, -9, -10, -3, -5, 5, 4, 0, 5, 5, 11, 18, 22, 10, 0, 3, -4, -4, -6, -3, 3, 5, 13, 13, 7, 12, 5, 7, 12, 10, 11, 2, -5, -4, 2, 14, 10, 5, 1, -8, -1, -2, 3, -2, -11, -6, -12, -3, -15, -21, -20, -25, -13, -9, -6, -11, -14, -6, -8, -3, -4, -5, 7, 7, 27, 32, 35, 26, 10, 7, 7, 15, 21, 28, 17, 14, 2, 4, 8, 3, 14, 14, 22, 18, 20, 10, 0, 2, -3, -4, -2, 3, -8, -17, -17, -14, -19, -17, -10, -14, -17, -23, -29, -28, -22, -23, -28, -10, -8, -9, -2, -11, -6, -5, 5, 26, 31, 21, 5, 4, 4, 6, 5, 9, 15, 7, 1, -6, -17, -15, -16, -19, -8, -6, 2, 1, -8, -9, -19, -9, -8, -3, 9, 6, 16, 11, 14, 1, -11, -6, -2, 8, 13, 8, -11, -18, -18, -7, 7, 12, 16, 13, 3, -1, 2, 4, 13, 12, 8, 7, -9, -10, -4, 6, 15, 10, 6, -2, -6, -9, -14, 8, 11, 13, 9, -2, -7, -4, -2, 13, 15, 17, 6, -8, 0, -7, -5, -7, -8, -4, -13, -13, -13, -1, -7, -11, -4, -16, -7, -8, -6, -4, 0, 8, 17, 22, 20, 20, 5, 1, 11, 14, 6, 2, 4, -1, -12, -18, -16, -2, 2, 10, 9, -1, -8, -24, -24, -16, -12, 2, 0, 0, -5, -13, -7, -7, 14, 17, 7, 5, -1, -2, -11, -16, -6, -1, 7, 5, 1, 4, -3, -6, 3, 11, 5, -1, -4, -17, -26, -25, -23, -1, 10, 2, 7, -3, -15, -16, -10, -7, -1, 13, 27, 21, 4, -5, -8, 1, 16, 26, 37, 34, 11, 12, 11, 8, 20, 27, 27, 21, 13, -3, -6, -4, -1, 4, -4, -15, -13, -19, -20, -12, 7, 14, 9, 6, -4, -3, -15, -11, -2, -3, -2, 2, 6, 0, -7, -12, -6, -3, -6, 1, -7, -10, -9, -6, -7, 1, 9, 12, 18, 4, 9, -3, -14, 2, -7, -2, -9, -12, -14, -14, -12, -6, 2, -1, -3, -7, -13, -12, -5, 5, 8, 12, 3, 0, 5, 10, 20, 39, 56, 32, 16, 5, -10, -10, -4, 7, 5, 1, 4, 4, 4, 9, -1, 3, 0, -17, -13, -20, -26, -15, -14, -15, -11, -11, -13, -13, -9, -13, -2, 2, 1, -4, -20, -18, -22, -23, -16, -12, 5, 14, 11, 12, 4, -2, -1, 6, 18, 25, 28, 23, 17, 7, 1, 2, 3, 10, 9, 1, -14, -23, -6, -2, 5, 8, -5, 5, -6, -12, -3, 8, 17, 14, 10, 4, -6, -10, -8, 1, 21, 18, 3, 0, -10, -23, -23, -11, -1, 8, 9, -7, 3, 2, -9, 3, -4, -2, 8, 5, 3, -11, -16, -11, -10, -2, 2, 3, -8, -11, -5, 2, 3, 7, 6, 5, -3, 1, 7, 5, 13, 23, 22, 18, 21, 25, 13, 7, 12, 14, 12, 8, 14, 8, 3, -7, -13, -18, -25, -23, -23, -21, -19, -25, -28, -29, -17, -7, -5, 1, 9, 10, 12, 1, 6, 15, 3, 7, -2, -1, 3, 3, 5, 2, 8, -8, -20, -13, -10, 9, 0, -13, -21, -35, -32, -31, -18, 7, 11, 16, 3, -9, -15, -7, -4, 6, 31, 32, 22, 14, 7, 2, 4, 7, 20, 28, 21, 9, 1, 6, 0, 10, 19, 14, 6, -2, -5, 2, 8, 4, 4, 0, -6, -14, -14, -20, -17, -4, -1, 0, -8, -19, -30, -32, -19, -4, 10, 15, 11, 1, -4, 0, -1, 1, 14, 10, 19, 11, -11, -22, -14, -22, -13, 8, 5, 1, -10, -20, -11, -7, 5, 9, 10, 17, 8, -1, 9, 6, 11, 26, 30, 26, 16, 10, 6, 3, 6, 13, 8, 8, 9, -2, -7, -14, -18, -13, -17, -20, -15, -18, -19, -13, -6, -9, -6, -10, -17, -17, -14, -12, -9, -4, -4, 2, 9, 3, 3, 5, 0, 8, 9, 12, 9, 7, 6, 9, 13, 30, 26, 23, 20, 18, 17, 14, 8, -3, 0, 0, -3, -13, -5, -2, -7, 3, 8, 4, -8, -22, -23, -19, -21, -17, -3, -2, 2, 4, 0, 16, 24, 28, 29, 18, 6, -5, -16, -8, 16, 19, 14, 13, -1, -7, -18, -19, -2, -2, 2, -4, -13, -15, -19, -25, -7, 1, 4, 0, -14, -20, -21, -18, -10, 10, 12, 4, 8, 2, -3, 8, 4, 15, 21, 12, 7, -3, -6, 0, 1, 2, 12, 2, -9, -8, -15, -9, -4, -4, -5, 1, -2, -14, -2, -9, -7, 7, 9, 10, -4, -10, -12, -19, -10, -1, 3, 11, 8, 0, 7, 8, 1, 13, 12, 14, 16, 1, 4, 4, -11, -12, -17, -4, 12, 2, 1, -1, -10, -16, -13, 0, 11, 19, 14, 2, 6, 4, -5, 11, 19, 24, 22, 11, 5, -2, -9, -18, -14, -6, -4, -9, -17, -19, -23, -24, -23, -10, -4, -4, -1, -8, -8, -7, -9, 0, 2, 2, 2, -1, 7, 2, 2, 3, -1, -4, -5, 1, 11, 7, 8, 5, 4, 1, -3, -4, -5, -4, -11, -9, 0, 8, 15, 14, 11, 6, 7, 8, 7, 12, 10, 10, 11, 14, 15, 14, 14, 10, 17, 20, 18, 15, 2, 3, -2, -5, -5, -6, -1, 1, -3, 0, 0, 5, 2, 6, 3, 1, -9, -8, 0, 0, 7, 3, -3, -3, -2, -9, -7, -3, 0, -4, -6, -4, -12, -15, -9, -13, 1, 7, -2, -9, -20, -12, -16, -17, -5, -4, -11, -15, -22, -15, -6, 0, 2, -1, 6, -1, -5, 0, 4, 17, 13, 16, 13, 7, 17, 8, 9, 13, 3, 2, -5, 2, 6, 2, 13, 14, 15, 10, 6, 0, -3, -3, -4, -5, 3, 10, 1, 4, 12, 14, 23, 23, 20, 16, 16, 4, -5, -4, -5, -3, -15, -16, -12, -7, -7, -9, -11, -14, -15, -19, -13, -5, -15, -15, -14, -4, 10, 7, 18, 14, 14, 9, 1, 10, 7, 5, 1, 6, 5, 3, -1, -8, -3, -2, 1, -4, -2, 5, -5, -5, -14, -18, -12, -12, -15, -23, -12, -6, -7, -3, 9, 10, 0, -4, 0, 11, 13, 10, 9, 6, 5, -8, -2, 4, -1, 1, -9, -2, 3, 0, -5, -15, -8, -13, -20, -19, -5, -2, 3, 5, 3, 15, 16, 15, 8, 10, 13, 7, 20, 19, 17, 8, -1, 0, 2, 6, 4, 6, 1, -1, 1, -1, -5, 1, 3, 1, 3, 2, 2, 4, 0, 5, 4, -1, -5, -9, -3, -12, -5, -1, 2, 5, -4, -4, -18, -15, -6, 0, 1, -3, -2, -12, -9, -13, -6, 4, 10, 4, -9, -6, -3, -5, -12, -28, -29, -29, -25, -15, -4, 0, 3, 6, -2, 2, 2, 3, 7, 8, 9, 4, 7, 13, 5, 7, -2, -5, -1, 2, -5, -13, -11, -13, -7, -13, -10, 0, 4, 8, 2, 12, 25, 23, 16, 3, 5, 11, 19, 17, 10, 5, 8, 1, -7, 2, -7, -6, -5, -10, -4, -7, -3, 0, 4, 13, 11, 16, 17, 14, 12, 10, 7, 3, -1, -6, -6, -9, -5, 3, 4, 9, 2, 0, -9, -16, -15, -15, 0, 1, 6, 14, 15, 21, 15, 8, 5, 7, 6, -3, -6, -6, -17, -24, -25, -21, -7, -10, -4, -3, 0, 3, -9, -2, 3, -4, 2, 2, 6, 9, 7, 15, 9, 6, 5, 2, 6, 15, 10, -4, -9, -14, -14, -12, -5, -3, -4, 8, 2, 3, 9, 10, 13, 3, -4, -11, -15, -10, -2, -1, -6, -5, -18, -19, -10, -11, -8, -1, 3, -4, -1, -4, -5, -2, -1, 1, -6, -4, -5, -4, -5, -8, -3, -4, 2, -4, 0, 1, 3, 3, -2, -11, -17, -11, -6, 1, 9, 11, 12, 5, 2, -7, -7, 0, -3, 2, 4, -2, -6, -4, 10, 12, 11, 15, 15, 8, 8, 8, 6, 12, 5, 4, -6, -5, 4, -2, 10, 16, 12, 13, 8, 13, 1, -1, 3, -5, -2, 3, 2, 7, 11, 14, 9, 13, 9, 2, 8, 3, -6, -17, -20, -15, -11, -6, -3, 1, 3, 6, 3, 2, 5, 2, 0, -3, 0, -1, -2, -1, 0, 4, -2, -5, -3, 0, 4, -1, -5, -6, -4, -6, -11, -5, 5, 6, 6, 2, 2, 4, 3, 1, 0, 2, 9, 5, -7, -15, -17, -20, -23, -9, -1, 2, 2, -4, -6, -6, -3, -4, -2, 9, 17, 8, 9, 14, 14, 7, 0, -1, 1, 7, 3, 2, 6, 6, 3, -4, -8, -9, -10, -10, -8, -7, 1, -2, -1, 4, 0, 0, 1, 9, 9, 4, 6, -6, -12, -6, -7, -5, 0, 5, 10, 2, 3, 9, 3, 5, 9, 3, 5, 9, 15, 18, 20, 16, 12, 13, 10, 7, 2, 2, -2, -4, -7, -9, 0, -2, 0, -1, -2, 0, -7, -9, -12, -13, -7, 0, -1, -5, -3, -5, -18, -19, -15, -15, -7, 0, 4, 3, 0, -7, -16, -8, 3, 7, 11, 13, 10, 5, 3, 4, 4, 2, 3, 1, -1, -2, -4, -9, -10, -16, -20, -22, -16, -6, -7, -1, -7, -10, -5, -5, -8, -9, -3, -1, 7, 4, -4, 0, -4, -10, -13, -18, -4, 4, 11, 8, 3, 6, 7, 3, -5, -4, 4, 6, 16, 17, 21, 24, 19, 15, 6, 5, -8, -6, -3, -7, 1, -3, -8, -4, -7, -3, 3, 2, 15, 8, -2, 2, 0, -1, 4, 9, 6, 8, 8, 3, -2, 6, 7, 4, 11, 5, -2, -4, -9, -4, -3, -4, 8, 5, 3, 9, 14, 13, 4, 5, 8, 4, 3, -2, -1, 1, 4, 4, 1, 6, 11, 8, 7, 5, -4, -4, -10, -18, -7, -3, 0, 4, 4, 2, -1, -5, -12, -10, -12, -13, -7, -8, -5, -10, -9, -10, -10, -11, -14, -11, -4, 0, 7, 5, 7, 15, 9, 11, 2, -2, 6, 8, 10, 9, 9, 0, -5, -13, -15, -11, -19, -20, -19, -23, -19, -13, -10, -12, -6, -8, -16, -15, -23, -16, -6, -3, 3, 1, -6, -2, -3, -6, -4, 0, 2, 11, 13, 16, 16, 5, 6, 12, 5, 12, 20, 17, 25, 22, 10, 3, 6, 0, -2, 4, 5, 11, 3, -9, -23, -27, -13, -15, -14, 1, 4, -4, -12, -17, -21, -18, -18, -13, -4, 0, 3, 3, 2, 15, 12, 4, 8, 13, 12, 15, 23, 22, 27, 34, 34, 32, 20, 19, 13, 4, 6, 15, 9, 8, 8, 7, 10, -1, -6, -4, -11, -12, -7, -16, -5, 1, 3, 1, -5, -1, -6, -7, -9, -11, -6, -3, -4, 1, 1, 6, 18, 18, 14, 19, 16, 15, 19, 7, 11, 8, 7, 17, 12, 9, 4, 2, -5, -8, -11, -15, -11, -13, -13, -15, -21, -20, -20, -22, -22, -14, -14, -13, -9, -20, -22, -23, -26, -16, -12, -3, 2, 3, -5, -19, -19, -14, -8, -2, -2, 7, 10, 5, 3, -2, 2, 3, 1, 2, -1, 0, -6, -8, -8, -11, -5, -8, -7, -5, -6, -9, -12, -9, -5, -1, -5, 1, 0, -2, -2, -5, 2, -4, 1, 2, 8, 13, 14, 4, 0, 1, 2, 0, 5, 9, 6, 13, 14, 14, 11, 8, 17, 8, -6, 1, -1, -2, 8, 4, -4, 0, -12, -18, -19, -16, -8, -7, -14, -8, -11, -16, -12, -9, -4, -7, -1, 7, 8, 7, 6, 6, 7, 6, 2, 2, 1, 0, -1, 0, 1, 5, 10, 3, 6, 4, 3, 1, 2, -2, 2, 3, 7, 12, 8, 8, 4, 5, 10, 7, 5, 7, 8, 4, 5, -5, -6, -2, -3, 2, 7, 12, 8, 9, 7, 2, 0, 4, 7, 10, 8, 6, 10, 11, 12, 12, 17, 17, 19, 14, 15, 15, 10, 9, 15, 22, 17, 15, 10, 10, 7, -2, 1, 4, 2, -6, -11, -8, -6, -4, -5, -6, -5, -9, -8, -9, -6, -7, -9, -4, -3, -9, -7, -12, -8, -2, -5, -12, -6, -7, -8, -8, -15, -13, -14, -13, -13, -10, -9, -7, -11, -17, -14, -17, -14, -7, -4, -2, 5, -1, 0, 1, -8, -8, -2, 2, 3, 4, -1, -6, -5, -4, -5, 2, -1, -1, 0, -1, 2, 0, 3, 11, 5, 3, 15, 14, 5, 7, 5, 0, -3, -9, -6, -4, -7, -10, -15, -20, -19, -20, -22, -11, -10, -4, -2, -6, -5, -8, -7, 0, -2, 7, 9, 8, 7, -3, -9, -15, -7, -5, -1, -2, -2, 0, 4, -2, 0, 5, -1, 2, 4, 8, 12, 9, 6, 2, -3, 2, -1, 5, 5, 3, 4, -3, 5, 0, -6, 0, 1, 9, 6, 0, 3, 1, 4, 2, 2, 2, 8, 8, 6, 11, 7, 6, 4, 5, 9, 4, 1, 12, 4, -4, -1, 2, 2, 5, 6, 3, 3, 1, 5, 4, 5, 13, 17, 13, 8, 8, 7, 10, 10, -3, -9, -13, -13, -13, -9, -10, -9, -3, -8, -6, -6, -10, -6, -1, -3, -3, -4, -4, -4, -6, -5, -13, -17, -15, -18, -16, -12, -21, -18, -18, -21, -15, -12, -4, -3, -6, -8, -11, -13, -11, -5, -7, -4, 0, -5, -7, -7, -11, -6, -1, -1, 2, 2, 4, -5, -5, 5, 7, 10, 8, 8, 3, 2, 2, -1, -5, 2, 2, -8, 1, -1, -7, -7, -4, 0, 5, 12, 4, 7, 9, 3, 1, 2, 12, 6, 6, 12, 12, 7, 2, 10, 5, 6, 9, 6, 12, 12, 6, 2, 4, 5]\n",
      "load done\n"
     ]
    }
   ],
   "source": [
    "## Building the data tensor set\n",
    "## Using 3400 audios for each classes\n",
    "## for counting number of data in the dataset through file system;\n",
    "## Reference method: image_count = len(list(DATASETPATH.glob('./*.wav')))\n",
    "## Padding the data with zeros to length 15872\n",
    "data_tensor_yes = []\n",
    "data_tensor_no = []\n",
    "data_tensor_test_yes = []\n",
    "data_tensor_test_no = []\n",
    "for i in range(3400):\n",
    "    filename = './Dataset/yes/yes' + str(i+1) + '.wav'\n",
    "    data_rate, data_audio_tensor = wavfile.read(filename)\n",
    "    if len(data_audio_tensor)>15872:\n",
    "        data_audio_tensor = data_audio_tensor[:15872]\n",
    "    else:\n",
    "        for j in range(15872-len(data_audio_tensor)):\n",
    "            data_audio_tensor = np.append(data_audio_tensor,[0])\n",
    "    data_tensor_yes.append(data_audio_tensor)\n",
    "    \n",
    "for i in range(3400):\n",
    "    filename = './Dataset/no/no' + str(i+1) + '.wav'\n",
    "    data_rate, data_audio_tensor = wavfile.read(filename)\n",
    "    if len(data_audio_tensor)>15872:\n",
    "        data_audio_tensor = data_audio_tensor[:15872]\n",
    "    else:\n",
    "        for j in range(15872-len(data_audio_tensor)):\n",
    "            data_audio_tensor = np.append(data_audio_tensor,[0])\n",
    "    data_tensor_no.append(data_audio_tensor)\n",
    "    \n",
    "## load test dataset\n",
    "for i in range(490):\n",
    "    filename = './test_set/yes/yes' + str(i+1) + '.wav'\n",
    "    data_rate, data_audio_tensor = wavfile.read(filename)\n",
    "    if len(data_audio_tensor)>15872:\n",
    "        data_audio_tensor = data_audio_tensor[:15872]\n",
    "    else:\n",
    "        for j in range(15872-len(data_audio_tensor)):\n",
    "            data_audio_tensor = np.append(data_audio_tensor,[0])\n",
    "    data_tensor_test_yes.append(data_audio_tensor)\n",
    "    \n",
    "for i in range(490):\n",
    "    filename = './test_set/no/no' + str(i+1) + '.wav'\n",
    "    data_rate, data_audio_tensor = wavfile.read(filename)\n",
    "    if len(data_audio_tensor)>=15872:\n",
    "        data_audio_tensor = data_audio_tensor[:15872]\n",
    "    else:\n",
    "        for j in range(15872-len(data_audio_tensor)):\n",
    "            data_audio_tensor = np.append(data_audio_tensor,[0])\n",
    "    data_tensor_test_no.append(data_audio_tensor)\n",
    "print(data_tensor_yes[0].tolist())\n",
    "print(\"load done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b99f0e-c9f2-4714-b650-4ba346a18fe9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Data pre-process by the librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "108a7dbd-8077-47d0-8683-5e90b378136f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Construct the mfcc set\n",
    "'''\n",
    "mfcc_set_yes = []\n",
    "mfcc_set_no = []\n",
    "\n",
    "mfcc_test_set_yes = []\n",
    "mfcc_test_set_no = []\n",
    "\n",
    "mfcc_train_labels = []\n",
    "mfcc_test_labels = []\n",
    "for i in data_tensor_yes:\n",
    "    mfcc_audio = librosa.power_to_db(librosa.feature.melspectrogram(y=np.float32(i),\n",
    "                                                               sr=16000,\n",
    "                                                               n_fft=512,\n",
    "                                                               hop_length=256,\n",
    "                                                               n_mels=40))\n",
    "    mfcc_set_yes.append(mfcc_audio)\n",
    "    mfcc_train_labels.append(1)\n",
    "    \n",
    "for i in data_tensor_no:\n",
    "    mfcc_audio = librosa.power_to_db(librosa.feature.melspectrogram(y=np.float32(i),\n",
    "                                                               sr=16000,\n",
    "                                                               n_fft=512,\n",
    "                                                               hop_length=256,\n",
    "                                                               n_mels=40))\n",
    "    mfcc_set_no.append(mfcc_audio)\n",
    "    mfcc_train_labels.append(0)\n",
    "\n",
    "\n",
    "## load test mfccs\n",
    "for i in data_tensor_test_yes:\n",
    "    mfcc_audio = librosa.power_to_db(librosa.feature.melspectrogram(y=np.float32(i),\n",
    "                                                               sr=16000,\n",
    "                                                               n_fft=512,\n",
    "                                                               hop_length=256,\n",
    "                                                               n_mels=40))\n",
    "    mfcc_test_set_yes.append(mfcc_audio)\n",
    "    mfcc_test_labels.append(1)\n",
    "\n",
    "for i in data_tensor_test_no:\n",
    "    mfcc_audio = librosa.power_to_db(librosa.feature.melspectrogram(y=np.float32(i),\n",
    "                                                               sr=16000,\n",
    "                                                               n_fft=512,\n",
    "                                                               hop_length=256,\n",
    "                                                               n_mels=40))\n",
    "    mfcc_test_set_no.append(mfcc_audio)\n",
    "    mfcc_test_labels.append(0)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99b9082-581c-4b46-91cc-4ff7fa299d6e",
   "metadata": {},
   "source": [
    "## Mel_spectrogram generating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db75b420-d843-4463-9072-59d762b204af",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the functions\n",
    "import sys\n",
    "\n",
    "def hamming(length):\n",
    "    weight = []\n",
    "    for i in range(length):\n",
    "        weight.append(0.56-0.46*np.cos((2.*np.pi*float(i))/(float(length)-1.)))\n",
    "    max_x = np.max(weight)\n",
    "    min_x = np.min(weight)\n",
    "    for i in range(length):\n",
    "        weight[i] = (weight[i]-min_x)/(max_x - min_x)\n",
    "    return weight\n",
    "\n",
    "def stft(data, num_of_inputs, window_size, hop_length):\n",
    "    num_of_ffts = (num_of_inputs - window_size)/hop_length\n",
    "    n_fft = (window_size/2)+1\n",
    "    fft_arr = []\n",
    "    counter = 0\n",
    "    pointer = 0\n",
    "    while(counter != num_of_ffts):\n",
    "        window = data[pointer:(pointer+window_size)]\n",
    "        weight = hamming(window_size)\n",
    "        fft_ = np.fft.fft(window*weight)\n",
    "        fft_arr.append(np.abs(fft_[:int(n_fft)]))\n",
    "        pointer+=hop_length\n",
    "        counter+=1\n",
    "    return fft_arr\n",
    "\n",
    "def mel_spec(data, num_of_inputs, window_size, hop_length, n_mels, sample_rate):\n",
    "    num_of_ffts = (num_of_inputs - window_size)/hop_length\n",
    "    n_ffts = (window_size/2)+1\n",
    "\n",
    "    lower_freq = 300\n",
    "    upper_freq = 8000\n",
    "\n",
    "    mel_lower_freq = 1125*np.log(1+lower_freq/700)\n",
    "    mel_upper_freq = 1125*np.log(1+upper_freq/700)\n",
    "    mel_gap = (mel_upper_freq - mel_lower_freq)/(n_mels+1)\n",
    "\n",
    "    ## Define the filterbank\n",
    "    mel_value = mel_lower_freq\n",
    "    fbin = []\n",
    "    counter = 0\n",
    "    while(counter<n_mels+2):\n",
    "        mel_to_hz = 700*(np.exp(mel_value/1125)-1)\n",
    "\n",
    "        rounding_freq = np.floor((n_ffts*mel_to_hz)/sample_rate)\n",
    "        fbin.append(rounding_freq)\n",
    "        mel_value+=mel_gap\n",
    "\n",
    "        counter+=1\n",
    "\n",
    "    filterbank = np.zeros((n_mels, int(n_ffts)))\n",
    "    for m in range(1, n_mels+1):\n",
    "        f_min = int(fbin[m-1])\n",
    "        f_mid = int(fbin[m])\n",
    "        f_max = int(fbin[m+1])\n",
    "\n",
    "        for k in range(f_min, f_mid):\n",
    "            filterbank[m-1, k] = (k - fbin[m-1])/(fbin[m] - fbin[m-1])\n",
    "        for k in range(f_mid, f_max):\n",
    "            filterbank[m-1, k] = (fbin[m+1] - k)/(fbin[m+1] - fbin[m])\n",
    "    \n",
    "    stft_arr = stft(data, num_of_inputs, window_size, hop_length)\n",
    "    mel_spec_arr = np.dot(np.array(stft_arr), filterbank.T)\n",
    "    \n",
    "\n",
    "    return mel_spec_arr\n",
    "\n",
    "def amplitude_to_db(mel_spec_arr):\n",
    "    ref_value = np.max(mel_spec_arr)\n",
    "    mel_spec_arr = np.square(mel_spec_arr)\n",
    "    ref_value = ref_value**2\n",
    "    mel_spec_arr_db = 10*np.log10(np.maximum(sys.float_info.min, mel_spec_arr))\n",
    "    mel_spec_arr_db -= 10*np.log10(np.maximum(sys.float_info.min, ref_value))\n",
    "    mel_spec_arr_db = np.maximum(mel_spec_arr_db, mel_spec_arr_db.max()-80)\n",
    "\n",
    "    return mel_spec_arr_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2383cde5-50ea-47b5-974d-cf0454a01080",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 40)\n",
      "[[-80.         -80.         -80.         -80.         -80.\n",
      "  -80.         -80.         -80.         -80.         -80.\n",
      "  -80.         -80.         -80.         -78.97969468 -80.\n",
      "  -80.         -80.         -80.         -80.         -80.\n",
      "  -80.         -80.         -80.         -80.         -80.\n",
      "  -80.         -80.         -80.         -80.         -80.\n",
      "  -78.64563495 -80.         -74.1480606  -70.36661866 -67.5225434\n",
      "  -75.67403686 -77.29147045 -74.19117969 -80.         -79.13420895]\n",
      " [-80.         -80.         -79.48334978 -80.         -80.\n",
      "  -80.         -80.         -79.87234044 -80.         -80.\n",
      "  -80.         -80.         -80.         -80.         -80.\n",
      "  -80.         -80.         -80.         -80.         -80.\n",
      "  -80.         -80.         -80.         -80.         -80.\n",
      "  -80.         -80.         -80.         -80.         -76.37778465\n",
      "  -79.01255835 -79.42314436 -71.10043184 -70.95889082 -61.07290572\n",
      "  -56.25906793 -45.21187992 -37.37273998 -50.16971052 -64.16402019]\n",
      " [-80.         -80.         -79.19506178 -80.         -80.\n",
      "  -80.         -80.         -80.         -80.         -80.\n",
      "  -80.         -80.         -80.         -80.         -78.14415022\n",
      "  -80.         -80.         -80.         -80.         -77.74638956\n",
      "  -80.         -80.         -80.         -80.         -80.\n",
      "  -80.         -80.         -80.         -79.49820078 -69.3325811\n",
      "  -74.25201886 -78.97832507 -75.49110336 -64.80644438 -57.87310076\n",
      "  -50.67168917 -38.13662425 -34.39765155 -46.26189008 -57.02767302]\n",
      " [-80.         -80.         -80.         -80.         -78.97812571\n",
      "  -80.         -80.         -80.         -80.         -80.\n",
      "  -80.         -80.         -80.         -80.         -78.45824441\n",
      "  -80.         -80.         -80.         -80.         -80.\n",
      "  -80.         -80.         -80.         -79.01119785 -80.\n",
      "  -80.         -80.         -80.         -75.62296485 -72.19553666\n",
      "  -71.33936758 -78.04061191 -76.55061816 -71.1583216  -66.03565202\n",
      "  -60.48274555 -44.00571432 -35.03253984 -46.46611267 -57.1214453 ]\n",
      " [-78.30451204 -77.46086839 -80.         -69.70958514 -67.74937245\n",
      "  -80.         -70.65030201 -76.9267302  -80.         -80.\n",
      "  -80.         -80.         -80.         -80.         -74.58800084\n",
      "  -80.         -80.         -80.         -80.         -80.\n",
      "  -80.         -80.         -80.         -77.92288547 -77.94780332\n",
      "  -75.43280564 -78.41971849 -71.70051115 -74.24043356 -68.74785215\n",
      "  -66.00000206 -74.43948191 -72.84293387 -76.48576234 -74.4763713\n",
      "  -66.68660011 -52.09424242 -37.00467014 -50.72946456 -57.87696586]\n",
      " [-76.76997333 -80.         -77.87721282 -74.48393785 -74.09071701\n",
      "  -68.72492529 -65.42017007 -74.11840476 -80.         -80.\n",
      "  -79.07451705 -80.         -80.         -78.90768413 -67.43995209\n",
      "  -71.09980761 -78.93056275 -75.79672447 -80.         -80.\n",
      "  -80.         -80.         -80.         -77.33516086 -80.\n",
      "  -79.1721144  -72.73470749 -70.72571538 -73.73608857 -67.18647444\n",
      "  -62.18366568 -71.14138608 -74.85313421 -76.54848454 -70.33040721\n",
      "  -64.41687085 -47.66836073 -37.7075149  -47.84581186 -44.70139857]\n",
      " [-65.17571652 -73.26570638 -65.72799624 -59.8554439  -63.86271375\n",
      "  -63.49775078 -60.22500516 -67.31438093 -71.0892753  -63.84965671\n",
      "  -69.74988927 -77.01805098 -79.30151157 -73.51029768 -65.14480312\n",
      "  -64.66240093 -80.         -80.         -80.         -77.36159444\n",
      "  -79.50691637 -80.         -80.         -76.75182267 -70.51494973\n",
      "  -75.36403041 -70.8445679  -66.43952751 -63.01695403 -54.07085514\n",
      "  -54.14777195 -60.61498581 -62.42940533 -61.43958886 -52.6944669\n",
      "  -46.32773203 -33.09444848 -30.45048026 -28.72517519 -31.91957964]\n",
      " [-35.48777844 -40.24760388 -40.49438609 -35.62484201 -35.84082679\n",
      "  -42.77464951 -38.39542487 -47.16090178 -53.82936798 -48.59256397\n",
      "  -50.4574232  -59.54773769 -67.32871088 -69.84118042 -63.18222986\n",
      "  -62.1625456  -66.77279748 -66.47868901 -69.20607091 -79.56643773\n",
      "  -68.0123446  -69.18474071 -78.19741979 -67.72208882 -68.04246364\n",
      "  -71.75726445 -66.85151017 -65.53761482 -58.89099654 -48.25575199\n",
      "  -38.31834584 -39.33994028 -46.41683919 -51.10300042 -35.48665046\n",
      "  -29.71455284 -24.33528461 -21.52660548 -25.34458319 -29.17924932]\n",
      " [-20.93224617 -28.45306327 -24.57665375 -24.02664104 -25.23625776\n",
      "  -23.50880645 -16.41076376 -14.63922618 -28.35548117 -32.47821555\n",
      "  -30.63880543 -35.27734961 -36.44473076 -43.87760183 -42.18773401\n",
      "  -44.49193329 -53.22671056 -51.25733603 -55.8747007  -55.94782742\n",
      "  -57.57878618 -64.88353509 -63.58485563 -60.27418177 -61.68810977\n",
      "  -57.44341204 -52.64884037 -49.75844259 -47.31139786 -29.02930807\n",
      "  -22.59321892 -29.19601662 -29.5605107  -30.6894606  -24.95757723\n",
      "  -20.76068351 -19.2841423  -19.70353237 -23.43463671 -27.28948182]\n",
      " [-24.6656814  -21.79007261 -16.04714921 -16.33134356 -19.77651796\n",
      "  -24.01102962  -5.18375397  -6.1521371  -20.25126692 -19.01141709\n",
      "  -28.04342609 -32.53264532 -37.27787376 -35.41723508 -39.09452097\n",
      "  -38.42927491 -47.26861285 -53.01113123 -56.01663018 -54.43015625\n",
      "  -47.92745902 -49.03073211 -55.10684274 -48.7431839  -43.55046379\n",
      "  -40.50524186 -34.0095207  -32.51944097 -19.18424606 -12.37894063\n",
      "  -18.42733665 -21.08085099 -20.22012005 -21.94719814 -15.42929476\n",
      "  -16.08006739 -17.16057568 -15.67032419 -15.01669931 -20.07700932]\n",
      " [-36.62701763 -21.02551258 -14.25189409 -16.87149002 -27.52494894\n",
      "  -18.53782068 -15.56267921 -11.84090645  -8.26348046  -6.61053336\n",
      "  -17.50243845 -24.41981694 -29.08836659 -25.23126115 -35.819131\n",
      "  -39.14281726 -42.80945741 -43.6559728  -43.2214596  -45.6193345\n",
      "  -43.48128404 -42.04379534 -47.20610145 -45.57910255 -34.92920307\n",
      "  -27.78869844 -26.48100482 -21.57692726 -14.01483671  -8.62145975\n",
      "  -13.80724101 -22.62495651 -15.45075868 -13.69327281 -17.14979885\n",
      "  -18.4756148  -14.8712332  -16.91248984 -22.63623015 -22.4039373 ]\n",
      " [-38.98927424 -21.43993839 -14.93689136 -19.78999645 -36.30341527\n",
      "  -26.19007837 -17.59916892 -17.13162126  -4.02886503   0.\n",
      "  -12.1061901  -20.40704235 -25.30477826 -22.44085301 -36.08115724\n",
      "  -37.01173079 -34.07993585 -37.36635308 -45.08323172 -43.15275685\n",
      "  -38.33270734 -34.95519824 -40.45680107 -40.47218581 -35.80628816\n",
      "  -27.5863386  -21.48316227 -14.82134908  -8.94069815 -12.32936785\n",
      "  -20.70937324 -19.04427105 -16.16970506 -15.63323458 -23.21142343\n",
      "  -22.88828186 -22.15656587 -16.7581031  -19.18572277 -24.32662965]\n",
      " [-35.83575673 -23.06030212 -15.84712878 -20.43584235 -27.05860785\n",
      "  -20.04331341 -18.60313908 -13.64170989  -4.84747921  -6.67147343\n",
      "   -7.68035234 -12.67281675 -23.72220659 -22.96847457 -31.38715678\n",
      "  -38.61929965 -33.97760844 -39.66878033 -39.91834105 -44.39526006\n",
      "  -35.23465683 -35.34545963 -40.89606044 -34.04311627 -31.08512455\n",
      "  -27.63052225 -17.62948753  -9.2637713  -12.45213352 -14.32199495\n",
      "  -19.6208283  -19.5423229  -14.34259733 -15.91362464 -21.29889738\n",
      "  -20.47515133 -19.92439549 -16.10624878 -18.03329889 -19.53008359]\n",
      " [-46.37944961 -22.22111214 -17.3896389  -23.77484461 -27.85086352\n",
      "  -19.60969309 -19.29444394  -9.1533912   -7.6165655  -11.89102165\n",
      "   -4.24641293 -13.87440376 -19.99473362 -24.19871293 -22.85426783\n",
      "  -30.90023926 -34.14998371 -36.46137    -36.97852274 -40.62485284\n",
      "  -34.60011199 -39.58890631 -35.29674042 -30.92723691 -33.21078264\n",
      "  -25.88371418 -15.63073685 -10.13086969 -17.67408629 -23.34678938\n",
      "  -30.20221442 -26.75891666 -24.15963463 -25.46866837 -28.792374\n",
      "  -26.50373508 -21.68491533 -16.90127202 -16.06034901 -17.23899126]\n",
      " [-41.89412252 -20.51162773 -17.78965045 -27.83180502 -25.42136199\n",
      "  -17.7590013  -15.92333227  -9.68197789 -11.28414647 -13.92141548\n",
      "   -3.28193277 -17.92119926 -20.12811149 -22.84270862 -25.44495276\n",
      "  -31.92047814 -31.78961612 -30.68284794 -35.65112331 -39.93827426\n",
      "  -32.02368659 -32.57586767 -34.53067544 -34.04913039 -29.43241378\n",
      "  -22.47506467 -19.89451135 -19.83429545 -23.25439781 -23.92512868\n",
      "  -27.34272894 -29.25562785 -23.28308359 -23.92758074 -27.87872214\n",
      "  -27.13555456 -27.08996665 -19.40498043 -24.46666298 -27.08765898]\n",
      " [-33.55198282 -21.394465   -19.88864953 -28.713354   -21.30815815\n",
      "  -16.95601686 -18.31905129  -8.779288   -14.50511125  -8.1878501\n",
      "   -5.94665025 -21.41886611 -19.80784678 -21.57702106 -27.51835364\n",
      "  -25.57026934 -33.1046698  -31.75276097 -30.99121191 -34.01955962\n",
      "  -35.05159657 -33.48573521 -31.20796827 -34.11476746 -27.59004382\n",
      "  -20.11284207 -20.59100705 -23.23047865 -25.72452785 -27.14878571\n",
      "  -32.98602116 -34.79706405 -27.30765202 -25.92596413 -26.96995736\n",
      "  -33.79634088 -29.9834884  -23.20720901 -24.0248956  -29.59770245]\n",
      " [-32.22291935 -26.42143731 -27.7914681  -30.39957885 -23.35874685\n",
      "  -17.66559348 -17.33961922 -15.80099524 -23.67499614 -15.60688466\n",
      "  -15.21863583 -22.6590169  -25.39391215 -25.36153109 -30.02091831\n",
      "  -39.74792549 -37.27626111 -38.90598529 -36.77107892 -37.4618494\n",
      "  -40.22598503 -42.48044246 -36.66241963 -29.10641725 -31.29843252\n",
      "  -28.51701304 -24.17559323 -24.05115423 -31.45330533 -35.37373401\n",
      "  -37.16176795 -36.39549834 -28.93314822 -19.34749465 -25.35625408\n",
      "  -29.72321616 -35.17910345 -22.40344891 -22.22440713 -31.91205572]\n",
      " [-25.67594533 -33.3858986  -34.00738704 -24.52382233 -23.08410844\n",
      "  -26.75230494 -20.02967007 -20.33572931 -26.53511772 -19.16779068\n",
      "  -25.52361688 -32.98575754 -30.19543582 -36.65557699 -34.4528509\n",
      "  -37.55589521 -38.0788482  -38.70446057 -46.44690416 -47.33631759\n",
      "  -45.75569643 -44.48076009 -43.74554351 -36.53972019 -34.30213168\n",
      "  -27.37714515 -27.64963018 -28.87309793 -36.67470709 -38.01896742\n",
      "  -37.92480596 -37.70334722 -30.64725792 -28.67083863 -34.84471293\n",
      "  -33.16294169 -29.87358749 -23.32087981 -22.63203535 -31.16395235]\n",
      " [-29.80307233 -33.06214849 -37.4416598  -44.49044404 -29.6632185\n",
      "  -31.57715382 -29.6151563  -30.94868061 -36.46078082 -27.46647395\n",
      "  -36.00108331 -36.58221576 -37.86614623 -31.76006581 -44.94613541\n",
      "  -46.01690669 -48.68874606 -44.16351757 -49.60026366 -51.17407235\n",
      "  -43.8515868  -47.54746436 -41.4848921  -34.50625983 -32.58267499\n",
      "  -29.04483505 -29.42249456 -35.81280508 -33.17253233 -36.76407781\n",
      "  -42.821821   -40.46169587 -31.36022216 -26.09703284 -30.72608835\n",
      "  -33.32537988 -27.92218586 -20.97353933 -20.59375996 -20.23896783]\n",
      " [-36.76751123 -38.45513529 -45.61251503 -47.89645429 -40.86700803\n",
      "  -40.86274598 -45.93320493 -46.74687449 -44.24602944 -40.07242757\n",
      "  -41.79520166 -44.59953671 -40.43850821 -41.14204178 -45.7759393\n",
      "  -50.20921227 -48.89798787 -50.56821832 -55.82652861 -54.83373569\n",
      "  -46.04192346 -44.48497295 -43.0972952  -34.5517694  -36.19493488\n",
      "  -30.1829085  -34.67734798 -34.200342   -38.549221   -38.13665712\n",
      "  -45.7582685  -42.54728114 -35.35529114 -35.46223445 -32.85573804\n",
      "  -32.80899742 -26.3430173  -20.59563601 -15.04989274 -13.78535594]\n",
      " [-60.96763622 -44.43854777 -47.63084389 -51.21144707 -43.75406684\n",
      "  -45.19435196 -53.13395958 -46.98621711 -43.33312062 -39.05117866\n",
      "  -39.24250518 -45.58924459 -42.96090709 -46.65957927 -46.84346204\n",
      "  -47.3507886  -50.23738165 -50.01347294 -54.51992127 -48.40019598\n",
      "  -49.16319546 -45.22656371 -55.35981203 -51.60739965 -42.14922474\n",
      "  -36.36419782 -39.30643583 -40.06760619 -41.63749389 -42.62282237\n",
      "  -51.32908032 -44.4925007  -35.76213328 -33.98973652 -31.28851753\n",
      "  -27.92346278 -22.67616172 -18.36725336 -17.78339707 -14.08609294]\n",
      " [-59.40831788 -60.11749699 -59.90905098 -45.6986299  -43.75134995\n",
      "  -45.41999148 -41.43370093 -39.60171178 -41.84975906 -42.67932279\n",
      "  -44.03835421 -56.54419952 -50.4214799  -42.72142332 -50.32514736\n",
      "  -55.49165325 -59.66069478 -63.82588742 -62.14145663 -53.13805464\n",
      "  -50.14788464 -50.5134243  -54.74045905 -46.70486297 -44.42284065\n",
      "  -36.1830124  -38.81840235 -39.42544989 -37.28704936 -45.33637776\n",
      "  -51.02266502 -43.54041932 -36.46426188 -32.09101671 -32.17938884\n",
      "  -28.41594405 -24.0615429  -17.45579188 -16.28724422 -15.81672162]\n",
      " [-61.13133437 -63.21659738 -60.33072554 -53.41570104 -56.63745399\n",
      "  -59.07136442 -50.33286352 -50.74533877 -50.63866216 -42.94376674\n",
      "  -38.7738631  -44.65278562 -51.09422896 -43.41226267 -53.33793545\n",
      "  -48.78131165 -55.62536951 -56.92910384 -60.86288888 -58.76916444\n",
      "  -56.30390475 -54.80112075 -53.860194   -52.82742289 -43.74378192\n",
      "  -40.91667383 -46.93446512 -44.39893146 -40.59208545 -45.72181424\n",
      "  -53.38044739 -45.73478325 -34.59393844 -28.56332199 -30.08750438\n",
      "  -23.48460109 -23.72789814 -10.06936364 -12.12526383 -11.69294905]\n",
      " [-58.15813871 -62.77716773 -68.99171777 -69.01260887 -73.19262445\n",
      "  -60.00772191 -57.50532242 -53.57333906 -51.99659196 -46.18280162\n",
      "  -48.38606058 -48.36710132 -61.14767424 -52.17334238 -56.93959918\n",
      "  -62.82082949 -59.3635165  -58.95238709 -62.34081738 -64.38358181\n",
      "  -59.27568958 -58.19607698 -53.55678131 -53.25069468 -50.43644284\n",
      "  -44.71716146 -43.23227106 -46.19876614 -43.79180329 -50.65135958\n",
      "  -51.62675217 -51.37076038 -37.02604839 -30.65404374 -26.19766115\n",
      "  -25.59869752 -25.99437037 -14.35583375 -13.72729396 -11.54918729]\n",
      " [-59.26696077 -62.84181278 -62.77878744 -61.21487501 -57.07967388\n",
      "  -52.783786   -53.40092257 -48.93710149 -56.79356562 -58.86465863\n",
      "  -51.628506   -59.21855627 -58.4357607  -55.11497434 -52.55682896\n",
      "  -57.63483419 -59.56165352 -65.51063937 -64.05081921 -59.62128854\n",
      "  -58.70133348 -57.26603952 -55.45012091 -58.93329899 -56.27330708\n",
      "  -45.81491963 -46.64372725 -46.77971789 -50.23562406 -54.21168637\n",
      "  -50.40914152 -49.50816819 -35.26236309 -31.93227371 -31.85175608\n",
      "  -27.10893941 -26.65443329 -14.89677033  -5.574531   -11.45603281]\n",
      " [-60.67468794 -80.         -66.4115162  -66.8077979  -67.91748185\n",
      "  -54.08812455 -50.64867461 -55.07157777 -60.67997966 -56.09476352\n",
      "  -51.33108217 -56.60007767 -62.94749052 -56.04593686 -58.87131171\n",
      "  -56.6108203  -56.07832476 -60.44750375 -58.52792838 -65.2673494\n",
      "  -60.56928757 -54.92100945 -60.69539485 -58.6007164  -60.44760377\n",
      "  -54.53609591 -53.13044192 -51.57534962 -49.79877766 -47.72099469\n",
      "  -51.94326123 -47.56924463 -39.66920266 -40.42901048 -31.85224836\n",
      "  -27.32745784 -25.1369344  -16.01580511  -6.55710797 -10.1555192 ]\n",
      " [-65.56121405 -62.32240036 -72.84284093 -65.23102964 -62.87544443\n",
      "  -58.40431958 -49.48700992 -49.25630723 -51.65364304 -50.8766864\n",
      "  -51.70090222 -65.4103035  -65.39010916 -56.78983996 -58.46819474\n",
      "  -62.17384473 -69.60497626 -68.67547572 -59.82987174 -62.27387493\n",
      "  -62.56443551 -59.7709169  -57.27608661 -59.31853158 -56.78414562\n",
      "  -47.79704097 -50.7386517  -48.41825813 -50.06621764 -50.65705295\n",
      "  -57.05689338 -48.67754634 -39.49492646 -37.64537769 -36.37538786\n",
      "  -31.02476639 -24.5250601  -18.80573395 -15.50815803 -14.38422496]\n",
      " [-63.80160456 -62.85447425 -66.22309994 -55.57732217 -52.06699646\n",
      "  -51.77434396 -48.81717433 -49.74057443 -59.05099944 -66.07475632\n",
      "  -53.65479188 -54.64373061 -51.07822138 -54.88461133 -64.38631788\n",
      "  -72.10522428 -72.94722937 -63.31446706 -62.77220531 -70.67980544\n",
      "  -65.3304452  -61.86781358 -59.77993529 -60.6455082  -54.86249926\n",
      "  -51.40682305 -50.83253793 -48.88255139 -52.35009372 -50.99772526\n",
      "  -57.38831758 -45.751664   -37.47139042 -34.70373057 -32.61486249\n",
      "  -26.96162653 -24.7728478  -18.35007115 -13.03538382 -14.20789292]\n",
      " [-58.82775614 -66.41436904 -62.73028167 -62.24578339 -71.18891249\n",
      "  -60.0560708  -58.04177749 -59.55701654 -59.80859426 -59.15347101\n",
      "  -55.36201729 -60.63673079 -59.33586081 -60.37570191 -65.61769465\n",
      "  -67.63003866 -74.42689029 -71.30087679 -59.87011564 -58.21336047\n",
      "  -65.95146969 -58.1808808  -59.74703291 -65.50260542 -51.96812683\n",
      "  -49.61111388 -53.70349134 -46.3103414  -49.3413205  -54.07284769\n",
      "  -53.80893165 -50.89763363 -43.32958323 -36.83416504 -35.19289554\n",
      "  -26.78218658 -22.54074737 -18.66751627 -18.73658293 -20.85608481]\n",
      " [-69.94470205 -63.19470147 -73.35657726 -73.92374842 -64.15208573\n",
      "  -55.23722901 -51.24220435 -57.87554261 -80.         -58.15500241\n",
      "  -49.68647314 -60.09694732 -68.58923824 -69.00596604 -66.40494214\n",
      "  -64.68044593 -66.28640974 -63.77319462 -65.1427195  -60.57846923\n",
      "  -64.00110204 -67.01946553 -71.04230732 -62.23418056 -57.41582265\n",
      "  -52.19546867 -50.67338291 -52.66841891 -55.17719739 -53.65424711\n",
      "  -59.14946635 -54.54953613 -46.12861143 -39.53952971 -31.98440124\n",
      "  -29.52279318 -22.44762645 -14.14535687 -11.09530777 -13.87079433]\n",
      " [-62.68113532 -60.09296051 -63.25286675 -67.29065313 -64.27160029\n",
      "  -60.67384768 -54.95459423 -51.04907292 -66.44428173 -67.30758347\n",
      "  -57.5324989  -65.8587845  -64.51243349 -58.60375447 -54.26112412\n",
      "  -52.85310499 -63.88939955 -64.28902492 -59.96506914 -61.16108242\n",
      "  -62.53183271 -69.66638602 -59.90149479 -60.98874419 -61.87041265\n",
      "  -66.26478391 -53.7057536  -52.24705804 -56.18552908 -55.49879523\n",
      "  -57.08452849 -49.43509175 -42.62108491 -36.95046021 -34.30501712\n",
      "  -31.48476722 -23.91082002 -21.46976409 -17.48227902 -20.85750989]\n",
      " [-69.19440524 -65.03367982 -66.35310413 -63.1252754  -59.89384032\n",
      "  -57.98021823 -62.3970506  -59.60432175 -56.88514753 -65.10826243\n",
      "  -69.027703   -68.18304227 -69.76384687 -65.12938315 -54.88513763\n",
      "  -58.66926565 -65.59625222 -70.87247946 -65.42538322 -68.24805805\n",
      "  -60.95820616 -66.09128392 -69.62149382 -67.15109872 -58.58629012\n",
      "  -57.76240376 -52.10524056 -52.92075535 -54.68375342 -54.67633428\n",
      "  -56.89972634 -55.48217866 -47.01238026 -40.87972097 -44.30781587\n",
      "  -33.61545296 -29.59101624 -20.06411897 -18.6630136  -19.86246249]\n",
      " [-68.71902236 -68.05256967 -62.64750174 -58.01898271 -62.96016488\n",
      "  -57.12123374 -57.80925357 -52.68274188 -56.32702238 -54.66847305\n",
      "  -55.82176451 -65.691572   -70.6362465  -66.15803671 -56.77029607\n",
      "  -55.26650758 -62.43487724 -68.09173825 -71.36748689 -65.20199241\n",
      "  -65.70406533 -67.65336003 -72.54561728 -64.62452745 -57.21886795\n",
      "  -54.17051141 -55.95470134 -54.49422717 -53.61225713 -52.64577826\n",
      "  -58.12934473 -52.97551391 -45.10041426 -42.01743805 -35.59450517\n",
      "  -30.56331654 -27.59314776 -22.87022482 -18.8860608  -23.09918669]\n",
      " [-58.62461173 -54.80087439 -58.81585454 -65.22256838 -60.59711514\n",
      "  -65.40455945 -51.36487309 -51.05391157 -56.73324531 -62.44892901\n",
      "  -64.87591215 -64.17561491 -68.86547051 -65.00222714 -55.53370652\n",
      "  -57.6992189  -71.69969759 -78.22364927 -75.14371563 -64.95840138\n",
      "  -60.04126446 -54.26950166 -59.44847095 -64.99137236 -60.29103648\n",
      "  -54.60011335 -50.33712406 -50.31949846 -52.66399511 -52.5234707\n",
      "  -55.03604017 -55.06808139 -45.92479016 -43.64291966 -43.42739657\n",
      "  -37.78548822 -29.62891805 -24.68598627 -21.20332929 -24.10398758]\n",
      " [-55.04679571 -55.31601457 -54.99466363 -59.11342915 -61.88107569\n",
      "  -61.24204007 -59.11990052 -64.61013486 -61.36078905 -63.53406066\n",
      "  -57.30756229 -62.29254499 -61.81071118 -65.68085791 -56.35324371\n",
      "  -54.23271465 -66.57938296 -70.1482038  -61.6714776  -68.39941702\n",
      "  -63.39548394 -54.81187499 -58.89395009 -60.03357191 -64.24710395\n",
      "  -58.33482842 -53.0716163  -50.49096713 -56.00936814 -55.83749555\n",
      "  -56.30554526 -57.41199259 -55.0492668  -50.21877768 -47.58212558\n",
      "  -45.18013231 -36.12784152 -28.22767652 -17.38231839 -27.76919965]\n",
      " [-59.10272306 -61.20667267 -67.9348948  -71.36453876 -61.84384822\n",
      "  -57.8211688  -55.80972321 -55.73013678 -61.06434464 -59.62779717\n",
      "  -51.12394885 -52.70274703 -64.59941148 -60.88193153 -57.3867455\n",
      "  -57.084615   -68.98452426 -70.40849614 -67.27344136 -69.20473493\n",
      "  -65.0308062  -69.44206883 -63.95734431 -62.20726088 -57.22221363\n",
      "  -50.73719687 -58.27621961 -54.45223604 -59.90368364 -58.1586845\n",
      "  -62.03916449 -69.21000195 -58.46880133 -52.55023939 -50.09524047\n",
      "  -45.73359967 -36.61420328 -31.18753439 -26.03871682 -31.32514056]\n",
      " [-64.43901408 -75.36286503 -67.59525203 -59.52013673 -57.00245024\n",
      "  -54.64121832 -52.09189844 -50.15126617 -59.01598798 -66.05418087\n",
      "  -60.83591087 -62.85046089 -60.39260006 -63.8648445  -60.89117552\n",
      "  -57.4326208  -63.95584457 -66.49880354 -67.79066799 -67.70307527\n",
      "  -73.94551446 -71.91246211 -70.47149123 -65.14497327 -53.81264922\n",
      "  -52.5012694  -57.13727041 -55.06643911 -62.21498221 -59.02546947\n",
      "  -59.28941603 -62.1088266  -56.52280609 -58.04159282 -63.28824119\n",
      "  -50.3478093  -45.0295188  -37.24061222 -33.53135328 -44.58873195]\n",
      " [-68.9396882  -73.90983933 -71.65644442 -58.02666953 -54.24484334\n",
      "  -54.2928802  -55.09657766 -52.89471941 -67.66218584 -63.24765926\n",
      "  -59.57255982 -66.19557712 -68.43134155 -68.18181506 -70.61423799\n",
      "  -65.89160541 -68.14105739 -66.52030224 -62.98564534 -57.47557201\n",
      "  -62.65006492 -67.0968885  -72.08016945 -62.83122583 -54.86070643\n",
      "  -51.37223842 -58.18085583 -60.67533065 -68.01607686 -57.85128188\n",
      "  -64.77137163 -74.7290756  -67.31181029 -63.92407012 -68.81700842\n",
      "  -60.13070762 -49.02832208 -44.89400711 -38.26422973 -44.92583944]\n",
      " [-80.         -79.45145424 -71.31255455 -65.62939733 -65.38319221\n",
      "  -58.90056511 -55.14361758 -55.2822469  -55.71920864 -56.97425791\n",
      "  -57.08317929 -59.96168053 -62.86376177 -67.33699998 -68.71502996\n",
      "  -60.85376445 -70.00438951 -69.431659   -66.96318197 -55.32181587\n",
      "  -60.3522521  -64.16924588 -62.32103392 -57.08982102 -57.7058957\n",
      "  -59.58736236 -61.11861444 -57.92199544 -66.77631895 -62.21557905\n",
      "  -65.12776305 -65.57906402 -66.538924   -60.78909701 -69.51768939\n",
      "  -62.65866679 -56.10706681 -53.27037972 -49.69849891 -50.59179721]\n",
      " [-70.26805266 -70.59731817 -67.16922704 -62.38315951 -64.94850863\n",
      "  -65.30255328 -65.11288603 -57.69224098 -53.29036568 -58.27034684\n",
      "  -56.60996948 -60.36308364 -64.40503635 -62.21969693 -63.18303825\n",
      "  -64.75750553 -75.27263379 -63.87191878 -61.49806129 -61.02597323\n",
      "  -61.38147591 -58.05351459 -52.80833266 -50.04210962 -57.33554381\n",
      "  -61.09659718 -63.97834461 -54.68707988 -58.57831856 -59.09150988\n",
      "  -62.73800174 -66.3883709  -65.3373843  -66.3730699  -66.5654255\n",
      "  -63.40217168 -60.11938734 -56.59121572 -57.99095182 -57.56229289]\n",
      " [-67.25061434 -73.11727029 -70.21079392 -64.24113073 -58.62325385\n",
      "  -59.41875196 -57.2177487  -59.01918673 -63.18317385 -60.68870415\n",
      "  -56.54820068 -60.52978967 -61.80092285 -64.98409171 -63.62452416\n",
      "  -68.46284207 -67.05255354 -69.53362679 -62.63205449 -58.32160027\n",
      "  -52.35021351 -56.85051324 -53.57374672 -55.31266628 -56.27368863\n",
      "  -63.56703757 -62.79927442 -57.45751593 -53.29542475 -58.54554074\n",
      "  -60.80521612 -70.87946935 -66.61220425 -72.23984945 -72.01565438\n",
      "  -69.2130858  -62.18091791 -59.15613176 -59.365818   -61.08268811]\n",
      " [-75.78729104 -75.33244967 -67.1893834  -58.6249111  -59.48662099\n",
      "  -72.06539517 -65.71202457 -72.27314434 -75.12685301 -73.33357231\n",
      "  -57.74853636 -58.538834   -67.08953209 -67.36466885 -67.64028686\n",
      "  -65.2973412  -66.32690353 -61.99118734 -66.84246967 -63.45678597\n",
      "  -60.31986538 -60.28819862 -62.59015843 -62.76588455 -64.1985982\n",
      "  -64.64681596 -61.70124299 -61.94299826 -61.25364666 -61.98054865\n",
      "  -68.64742863 -68.28427836 -66.45643251 -68.231705   -70.19884525\n",
      "  -73.95507151 -65.12405669 -64.18088075 -61.94654752 -58.71984472]\n",
      " [-72.60596979 -66.85393029 -63.79209393 -68.26143291 -65.3996196\n",
      "  -57.50365365 -58.39559768 -68.87638247 -80.         -68.05273595\n",
      "  -64.23728534 -66.99876628 -67.61250099 -67.79108958 -60.39963683\n",
      "  -64.54204365 -66.52534106 -62.95648339 -66.66241603 -63.72672661\n",
      "  -66.72948088 -63.59787827 -63.65685615 -64.40900175 -63.47314093\n",
      "  -64.05741009 -59.76187873 -57.12270871 -64.236752   -61.23678403\n",
      "  -66.51657526 -68.40650407 -67.14472149 -67.32496303 -69.4509528\n",
      "  -68.63658114 -68.00238974 -65.62364766 -65.0715008  -65.24520575]\n",
      " [-64.39397212 -64.11594274 -68.87831667 -64.49095795 -67.18012359\n",
      "  -55.20313908 -54.15671223 -67.50345585 -78.12148341 -74.95817728\n",
      "  -66.89729302 -71.76012522 -66.07255103 -72.54177423 -69.25823735\n",
      "  -67.62814025 -67.27218413 -73.67370833 -76.11932863 -65.50011371\n",
      "  -69.45049767 -64.09530578 -64.92498921 -58.21628396 -60.46453892\n",
      "  -60.09696875 -63.74037343 -60.16029718 -60.33534333 -62.21999593\n",
      "  -69.48374897 -67.32022037 -69.01398144 -73.07449046 -72.15638499\n",
      "  -68.81293285 -69.22372376 -71.46616666 -71.40459339 -71.72493153]\n",
      " [-62.78917029 -63.60982905 -69.00732828 -60.57419716 -58.76019935\n",
      "  -58.244235   -67.86386625 -66.71007047 -69.82905989 -67.12307238\n",
      "  -61.4071729  -64.345919   -68.79128042 -67.93731092 -75.48743489\n",
      "  -72.26620356 -71.85438006 -72.76196757 -72.64919528 -68.85522253\n",
      "  -68.10245904 -65.13247301 -61.77075677 -61.67356153 -61.57680902\n",
      "  -62.54506273 -66.81982343 -60.8597202  -64.08331583 -62.87295499\n",
      "  -69.77779723 -66.91477276 -67.24417272 -72.76091671 -70.83920433\n",
      "  -72.68990484 -71.31184815 -75.08397476 -71.12533056 -64.85617121]\n",
      " [-62.3960217  -79.28460981 -67.19475241 -65.01528185 -61.41619784\n",
      "  -61.17276047 -66.02170524 -67.3742666  -69.8209524  -71.46332965\n",
      "  -69.60511286 -61.81195865 -63.27174679 -66.58524242 -66.26158872\n",
      "  -74.03885851 -66.15930613 -71.54607131 -78.3977421  -68.62794682\n",
      "  -64.89061286 -76.96694876 -72.43132052 -62.51643204 -60.98066346\n",
      "  -61.99204501 -64.73611978 -64.42104358 -63.06812396 -65.26394107\n",
      "  -71.46452748 -63.45609558 -63.35168779 -69.1739686  -71.07132964\n",
      "  -75.86697652 -68.92066865 -72.89312301 -73.9849585  -67.21346074]\n",
      " [-67.12647798 -71.84874668 -72.07573697 -76.49557835 -74.85603197\n",
      "  -69.56275372 -62.15090164 -65.98250679 -65.39340843 -62.67159947\n",
      "  -57.54388258 -64.74798296 -63.498001   -62.71174394 -68.43968663\n",
      "  -69.37898148 -69.23973086 -75.20347484 -78.65857368 -68.42519232\n",
      "  -74.35496998 -72.17069655 -66.38010897 -64.02257064 -70.11364396\n",
      "  -68.20705195 -65.87919059 -64.92256443 -59.66772454 -62.46725857\n",
      "  -67.80943937 -66.73830122 -66.09642332 -67.72368234 -68.30558857\n",
      "  -73.20108352 -68.55307303 -71.24917946 -68.70396809 -67.12957268]\n",
      " [-67.92857241 -72.13842411 -64.13778546 -65.11024029 -65.39814388\n",
      "  -66.91663121 -61.54967114 -59.451589   -64.64797341 -59.40181704\n",
      "  -64.9714562  -72.97966704 -62.70423487 -62.21755914 -70.53280241\n",
      "  -70.63284922 -68.34372452 -70.3115011  -71.19254895 -65.11446052\n",
      "  -65.18673333 -61.87631417 -67.74792244 -68.90807408 -73.07062574\n",
      "  -71.26043603 -65.41396681 -61.15967182 -63.29487612 -64.20682465\n",
      "  -70.23275002 -75.46936471 -76.48029194 -68.76566302 -70.62698963\n",
      "  -73.09428669 -69.41699203 -72.88706177 -73.44946073 -70.22685117]\n",
      " [-60.57637758 -66.92078218 -67.16557653 -56.98835154 -57.46733802\n",
      "  -71.98466615 -71.44960028 -65.40488279 -63.37127593 -59.71133316\n",
      "  -59.47501003 -66.74477336 -58.85924998 -67.10784773 -73.44793621\n",
      "  -68.90349941 -66.44262792 -76.14972452 -69.76677758 -63.55005928\n",
      "  -62.94722368 -65.89776641 -76.25600977 -79.91108943 -80.\n",
      "  -72.15276157 -66.98456431 -62.20521753 -57.54510588 -63.27354786\n",
      "  -67.38568341 -69.65786392 -71.57247997 -73.87344605 -73.90717468\n",
      "  -71.6230802  -70.031561   -72.4937941  -69.66022741 -70.13596554]\n",
      " [-60.11511765 -63.81798922 -66.34469348 -61.36671299 -62.28014751\n",
      "  -67.33398283 -65.28063134 -69.13650477 -71.57719848 -68.27898579\n",
      "  -67.09363114 -75.9084191  -72.52879002 -68.53802528 -68.30433236\n",
      "  -65.20416661 -73.48745246 -73.2086888  -68.03023787 -62.34574868\n",
      "  -69.38259994 -66.40084053 -76.24199228 -76.36215931 -75.6650756\n",
      "  -74.64411406 -67.37549233 -63.18579818 -64.24969374 -68.91389314\n",
      "  -66.57890983 -67.25516454 -70.41821345 -76.56945034 -76.28708999\n",
      "  -75.4546772  -76.08807854 -74.77904479 -69.80469319 -67.23250592]\n",
      " [-72.30750021 -77.82650027 -76.67880248 -67.23652028 -69.30942166\n",
      "  -80.         -80.         -74.66725225 -69.58687876 -63.37411387\n",
      "  -60.81863927 -72.8163905  -69.85428927 -65.71403625 -70.45899094\n",
      "  -67.44968857 -72.21863491 -71.35467678 -75.15771209 -73.46903237\n",
      "  -76.66236874 -80.         -77.56767753 -77.93918339 -74.40986173\n",
      "  -80.         -72.59173475 -69.75017795 -72.67723579 -71.04654653\n",
      "  -65.44236602 -67.61954325 -70.4632448  -74.20475309 -79.85017313\n",
      "  -75.10670874 -71.4974069  -68.44525433 -68.87301601 -69.54415386]\n",
      " [-76.85017368 -80.         -68.76270667 -74.36727623 -80.\n",
      "  -80.         -70.25145325 -67.49580277 -80.         -72.72632225\n",
      "  -65.65175041 -66.71077517 -69.67753652 -70.57244582 -70.8393502\n",
      "  -71.59066826 -70.93288283 -70.27482256 -68.28689093 -69.97902736\n",
      "  -72.67881104 -78.73869946 -80.         -80.         -77.93204453\n",
      "  -76.65571297 -73.97126233 -66.21824475 -65.33131817 -67.57048398\n",
      "  -67.85593499 -71.6510275  -69.62541531 -71.8990565  -74.05523806\n",
      "  -74.3462892  -77.13357559 -71.00224393 -70.55285876 -69.09152985]\n",
      " [-79.10231136 -70.60117704 -75.54794096 -69.60858774 -66.01076455\n",
      "  -65.75361446 -68.24268602 -75.20963776 -75.83497086 -69.8432096\n",
      "  -69.503382   -66.3532339  -80.         -80.         -74.4683787\n",
      "  -73.95306682 -76.57501969 -76.12314562 -72.24145295 -76.20014483\n",
      "  -73.17211953 -76.61887361 -80.         -80.         -71.91439685\n",
      "  -69.35486686 -69.70379622 -67.38211134 -65.09695624 -69.30386203\n",
      "  -69.20434991 -73.70676094 -70.64905353 -68.60709553 -73.11125981\n",
      "  -77.44518558 -75.54892798 -75.84150944 -75.28297247 -73.34574046]\n",
      " [-74.30257636 -80.         -70.17638496 -76.75246016 -73.6895117\n",
      "  -73.77159391 -70.42018619 -68.34342188 -68.29490719 -67.97892765\n",
      "  -73.69398598 -80.         -66.70323507 -72.85589153 -76.27707966\n",
      "  -76.70846956 -80.         -73.91527825 -73.7357621  -70.25288152\n",
      "  -66.3687573  -79.10617007 -80.         -76.58989097 -72.80179626\n",
      "  -67.42922189 -74.37312745 -64.52874973 -59.30259288 -64.12087839\n",
      "  -65.1523435  -75.10828217 -73.16618638 -72.76347485 -77.45357691\n",
      "  -73.99670031 -75.67499073 -80.         -75.69345276 -69.82694009]\n",
      " [-77.7716458  -80.         -70.20287558 -66.09696452 -76.53859742\n",
      "  -73.53655618 -73.93075755 -65.32231283 -65.90946557 -66.37473683\n",
      "  -68.36843907 -67.21167366 -67.93299651 -75.90109918 -78.07138115\n",
      "  -71.01286189 -79.70055225 -73.02210862 -76.32164949 -71.77078698\n",
      "  -68.25610563 -77.39108216 -80.         -77.07348956 -70.28680619\n",
      "  -64.87804971 -66.52578826 -65.76720051 -60.97136515 -62.67374247\n",
      "  -66.39421021 -73.99958567 -73.28696807 -71.88363528 -74.22769798\n",
      "  -75.91464358 -77.68944353 -77.71879016 -70.11961224 -71.464144  ]\n",
      " [-73.87819634 -73.89109929 -80.         -70.87980857 -73.47341591\n",
      "  -77.8107306  -67.46547593 -65.85563068 -66.95565165 -66.04540327\n",
      "  -70.25172231 -70.67332455 -75.26267196 -73.74608895 -70.94929175\n",
      "  -75.76387344 -76.09505194 -80.         -73.05374007 -73.19413369\n",
      "  -66.90238962 -68.71424818 -77.79821287 -74.58721052 -74.17157837\n",
      "  -76.77197303 -68.04884992 -65.70910488 -60.0899463  -62.11832764\n",
      "  -72.54868583 -75.09793627 -73.43913321 -76.23240708 -73.96306837\n",
      "  -79.73441488 -80.         -80.         -72.30227043 -68.10383459]\n",
      " [-68.41109732 -73.03055905 -72.60073077 -72.46937459 -76.15591316\n",
      "  -78.51659302 -78.90598344 -77.74331399 -77.42089039 -64.24459131\n",
      "  -65.46859605 -71.92970832 -75.29577467 -70.48752124 -76.41467918\n",
      "  -76.13348124 -78.44750205 -78.90223671 -70.72598414 -68.50950266\n",
      "  -68.56084086 -73.18215714 -80.         -80.         -71.39819293\n",
      "  -70.98869946 -75.60850142 -76.27958206 -70.69552961 -67.41629603\n",
      "  -72.21798065 -75.20665964 -70.96911726 -78.94571086 -76.01542682\n",
      "  -79.19829737 -76.82440138 -77.23502867 -69.11866755 -70.56512025]\n",
      " [-80.         -72.66411027 -77.43462457 -80.         -80.\n",
      "  -80.         -75.60534023 -78.97079915 -77.94266983 -77.6570607\n",
      "  -80.         -72.49474386 -66.05119354 -64.20448956 -76.44368783\n",
      "  -80.         -80.         -80.         -69.74664005 -67.54050519\n",
      "  -66.13158355 -76.50737271 -76.70844638 -74.67518206 -79.25139601\n",
      "  -67.54626624 -74.21457214 -71.98514535 -75.13349098 -68.98773769\n",
      "  -68.25937067 -71.38755568 -72.92030021 -80.         -76.90905879\n",
      "  -76.89509054 -72.9250171  -76.66745902 -72.1221566  -74.37072851]\n",
      " [-78.18603854 -80.         -80.         -80.         -80.\n",
      "  -72.55387597 -66.90789434 -70.15394873 -80.         -80.\n",
      "  -76.61944354 -77.44179358 -71.68799258 -67.07974473 -80.\n",
      "  -80.         -80.         -80.         -79.48799189 -70.76624637\n",
      "  -70.78522702 -77.00800443 -72.32242716 -72.52251112 -70.21054825\n",
      "  -67.36951126 -67.80627234 -72.67565677 -77.55378145 -71.74773104\n",
      "  -76.69016772 -73.70101143 -77.08726279 -79.87331081 -80.\n",
      "  -78.7864415  -73.43261997 -75.24714821 -71.17722099 -76.22502038]\n",
      " [-75.48349288 -74.00784531 -78.80374475 -80.         -76.1081381\n",
      "  -69.1424043  -59.54920621 -62.6773378  -80.         -80.\n",
      "  -78.02124969 -78.41344671 -76.83807638 -72.23334063 -74.50430486\n",
      "  -80.         -80.         -80.         -80.         -77.65247874\n",
      "  -74.15565422 -71.24468279 -69.1143602  -69.02686127 -67.77532377\n",
      "  -68.6640339  -67.41328089 -69.30391739 -73.87442946 -72.37589129\n",
      "  -77.41208668 -78.03690776 -80.         -80.         -77.42476334\n",
      "  -77.54211905 -74.77780231 -77.98838817 -71.57845786 -75.38246149]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0, 11000.0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## testing the results\n",
    "mel_spec_arr = mel_spec(data_tensor_yes[0], 15872, 512, 256, 40, 16000)\n",
    "mel_spec_db = amplitude_to_db(mel_spec_arr)\n",
    "print(np.array(mel_spec_db).shape)\n",
    "print(np.array(mel_spec_db))\n",
    "fig, ax = plt.subplots(figsize=(6, 3))\n",
    "librosa.display.specshow(\n",
    "    mel_spec_db,\n",
    "    y_axis=\"hz\",\n",
    "    x_axis=\"time\",\n",
    "    ax=ax,\n",
    "    fmax=6000\n",
    ")\n",
    "plt.ylim([0, 11000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199300c9-e7a4-4b3d-bdb4-74c89b0be537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 'yes': ##########\n",
      "train set 'yes' finished\n",
      "Loading 'no': #####"
     ]
    }
   ],
   "source": [
    "## Processing the data to mel_spectrogram\n",
    "import datetime\n",
    "\n",
    "melSpec_set_yes = []\n",
    "melSpec_set_no = []\n",
    "melSpec_train_labels = []\n",
    "\n",
    "window_size = 512\n",
    "step = 256\n",
    "num_of_inputs = 15872\n",
    "sample_rate = 16000\n",
    "\n",
    "count = 0\n",
    "print(\"Loading 'yes': \", end=\"\")\n",
    "for i in data_tensor_yes:\n",
    "    mel_spec_arr = mel_spec(i, num_of_inputs, window_size, step, 40, sample_rate)\n",
    "    ref_value = np.max(mel_spec_arr )\n",
    "    mel_spec_arr = np.square(mel_spec_arr)\n",
    "    ref_value = ref_value**2\n",
    "    mel_spec_db = 10*np.log10(np.maximum(sys.float_info.min, mel_spec_arr))\n",
    "    mel_spec_db -= 10*np.log10(np.maximum(sys.float_info.min, ref_value))\n",
    "    mel_spec_db = np.maximum(mel_spec_db, mel_spec_db.max()-80)\n",
    "\n",
    "    melSpec_set_yes.append(mel_spec_db)\n",
    "    melSpec_train_labels.append(1)\n",
    "    count += 1\n",
    "    if(count%340==0):\n",
    "        print(\"#\", end=\"\")\n",
    "\n",
    "print()\n",
    "print(\"train set 'yes' finished\")\n",
    "print(\"Loading 'no': \", end=\"\")\n",
    "count = 0\n",
    "for i in data_tensor_no:\n",
    "    mel_spec_arr = mel_spec(i, num_of_inputs, window_size, step, 40, sample_rate)\n",
    "    ref_value = np.max(mel_spec_arr )\n",
    "    mel_spec_arr = np.square(mel_spec_arr)\n",
    "    ref_value = ref_value**2\n",
    "    mel_spec_db = 10*np.log10(np.maximum(sys.float_info.min, mel_spec_arr))\n",
    "    mel_spec_db -= 10*np.log10(np.maximum(sys.float_info.min, ref_value))\n",
    "    mel_spec_db = np.maximum(mel_spec_db, mel_spec_db.max()-80)\n",
    "\n",
    "    melSpec_set_no.append(mel_spec_db)\n",
    "    melSpec_train_labels.append(0)\n",
    "    count += 1\n",
    "    if(count%340==0):\n",
    "        print(\"#\", end=\"\")\n",
    "print()\n",
    "print(\"train set 'no' finished\")    \n",
    "print(np.array(melSpec_set_yes).shape)\n",
    "print(np.array(melSpec_set_no).shape)\n",
    "## print the time finished\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "96c41705-f8af-4f79-aa6e-031186f56abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 'yes': ##########\n",
      "test set 'yes' finished\n",
      "Loading 'no': ##########\n",
      "train set 'no' finished\n",
      "(490, 60, 40)\n",
      "(490, 60, 40)\n",
      "2024-05-27 11:32:51.917257\n"
     ]
    }
   ],
   "source": [
    "window_size = 512\n",
    "step = 256\n",
    "num_of_inputs = 15872\n",
    "sample_rate = 16000\n",
    "\n",
    "melSpec_test_set_yes = []\n",
    "melSpec_test_set_no = []\n",
    "melSpec_test_labels = []\n",
    "\n",
    "counter = 0\n",
    "print(\"Loading 'yes': \", end=\"\")\n",
    "for i in data_tensor_test_yes:\n",
    "    mel_spec_arr = mel_spec(i, num_of_inputs, window_size, step, 40, sample_rate)\n",
    "    ref_value = np.max(mel_spec_arr )\n",
    "    mel_spec_arr = np.square(mel_spec_arr)\n",
    "    ref_value = ref_value**2\n",
    "    mel_spec_db = 10*np.log10(np.maximum(sys.float_info.min, mel_spec_arr))\n",
    "    mel_spec_db -= 10*np.log10(np.maximum(sys.float_info.min, ref_value))\n",
    "    mel_spec_db = np.maximum(mel_spec_db, mel_spec_db.max()-80)\n",
    "    \n",
    "    melSpec_test_set_yes.append(mel_spec_db)\n",
    "    melSpec_test_labels.append(1)\n",
    "    count += 1\n",
    "    if(count%49==0):\n",
    "        print(\"#\", end=\"\")\n",
    "\n",
    "print()\n",
    "print(\"test set 'yes' finished\")\n",
    "print(\"Loading 'no': \", end=\"\")\n",
    "count = 0\n",
    "for i in data_tensor_test_no:\n",
    "    mel_spec_arr = mel_spec(i, num_of_inputs, window_size, step, 40, sample_rate)\n",
    "    ref_value = np.max(mel_spec_arr )\n",
    "    mel_spec_arr = np.square(mel_spec_arr)\n",
    "    ref_value = ref_value**2\n",
    "    mel_spec_db = 10*np.log10(np.maximum(sys.float_info.min, mel_spec_arr))\n",
    "    mel_spec_db -= 10*np.log10(np.maximum(sys.float_info.min, ref_value))\n",
    "    mel_spec_db = np.maximum(mel_spec_db, mel_spec_db.max()-80)\n",
    "    \n",
    "    melSpec_test_set_no.append(mel_spec_db)\n",
    "    melSpec_test_labels.append(0)\n",
    "    count += 1\n",
    "    if(count%49==0):\n",
    "        print(\"#\", end=\"\")\n",
    "\n",
    "print()\n",
    "print(\"train set 'no' finished\") \n",
    "print(np.array(melSpec_test_set_yes).shape)\n",
    "print(np.array(melSpec_test_set_no).shape)\n",
    "## print the time finished\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3954b9f0-fb51-4822-9d4d-b12633306643",
   "metadata": {},
   "source": [
    "## Flatten the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7a0c116e-6e4c-4fb6-ae75-fa6831861438",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 40)\n",
      "(6800, 2400)\n",
      "(2400,)\n"
     ]
    }
   ],
   "source": [
    "train_ds = []\n",
    "test_ds = []\n",
    "print(melSpec_set_yes[0].shape)\n",
    "##print(melSpec_set_yes[0])\n",
    "\n",
    "## resize\n",
    "for i in melSpec_set_yes:\n",
    "    resized = np.resize(i, (60, 40))\n",
    "    resized = resized.flatten()\n",
    "    train_ds.append(resized)\n",
    "for i in melSpec_set_no:\n",
    "    resized = np.resize(i, (60, 40))\n",
    "    resized = resized.flatten()\n",
    "    train_ds.append(resized)\n",
    "\n",
    "for i in melSpec_test_set_yes:\n",
    "    resized = np.resize(i, (60, 40))\n",
    "    resized = resized.flatten()\n",
    "    test_ds.append(resized)\n",
    "for i in melSpec_test_set_no:\n",
    "    resized = np.resize(i, (60, 40))\n",
    "    resized = resized.flatten()\n",
    "    test_ds.append(resized)\n",
    "\n",
    "train_ds = np.array(train_ds)\n",
    "test_ds = np.array(test_ds)\n",
    "\n",
    "train_ds = train_ds.astype('float32')\n",
    "##train_ds = np.reshape(train_ds, (len(train_ds), 128, 32, 1))\n",
    "\n",
    "test_ds = test_ds.astype('float32')\n",
    "##test_ds = np.reshape(test_ds, (len(test_ds), 128, 32, 1))\n",
    "print(train_ds.shape)\n",
    "\n",
    "y_train = np.array(melSpec_train_labels)\n",
    "y_test = np.array(melSpec_test_labels)\n",
    "print(train_ds[0].shape)\n",
    "##print(y_test[0])\n",
    "##print(test_ds[0].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81998d4-99e9-4160-be15-fa2e738a5e6e",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9edbad41-b952-4292-aef6-3688410c60d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ reshape_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)             │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ reshape_6 (\u001b[38;5;33mReshape\u001b[0m)             │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_6 (\u001b[38;5;33mFlatten\u001b[0m)             │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_classes = 2\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Reshape((60, 40, 1)),\n",
    "##    tf.keras.layers.DepthwiseConv2D(3, activation='relu'),\n",
    "##    tf.keras.layers.MaxPooling2D(),\n",
    "##    tf.keras.layers.DepthwiseConv2D(3, activation='relu'),\n",
    "##    tf.keras.layers.MaxPooling2D(),\n",
    "##    tf.keras.layers.DepthwiseConv2D(3, activation='relu'),\n",
    "##    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(11, 3, 3, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.50),\n",
    "    tf.keras.layers.Flatten(),\n",
    "##    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax'),\n",
    "])\n",
    "model.summary()\n",
    "## Complie the model\n",
    "model.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5387a410-f398-4503-a268-feb12416a8fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5247 - loss: 10.2660 - val_accuracy: 0.7847 - val_loss: 0.9423\n",
      "Epoch 2/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6068 - loss: 4.9075 - val_accuracy: 0.7980 - val_loss: 0.6983\n",
      "Epoch 3/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6356 - loss: 2.8383 - val_accuracy: 0.7878 - val_loss: 0.6108\n",
      "Epoch 4/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6560 - loss: 1.6275 - val_accuracy: 0.7367 - val_loss: 0.5872\n",
      "Epoch 5/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6643 - loss: 1.0134 - val_accuracy: 0.7378 - val_loss: 0.5783\n",
      "Epoch 6/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6700 - loss: 0.8811 - val_accuracy: 0.7418 - val_loss: 0.5512\n",
      "Epoch 7/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6867 - loss: 0.7081 - val_accuracy: 0.7541 - val_loss: 0.5076\n",
      "Epoch 8/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7001 - loss: 0.6508 - val_accuracy: 0.7806 - val_loss: 0.4585\n",
      "Epoch 9/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7241 - loss: 0.5938 - val_accuracy: 0.7929 - val_loss: 0.4440\n",
      "Epoch 10/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7344 - loss: 0.5778 - val_accuracy: 0.8133 - val_loss: 0.4165\n",
      "Epoch 11/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7461 - loss: 0.5474 - val_accuracy: 0.8235 - val_loss: 0.4009\n",
      "Epoch 12/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7767 - loss: 0.5060 - val_accuracy: 0.8367 - val_loss: 0.3818\n",
      "Epoch 13/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7855 - loss: 0.4749 - val_accuracy: 0.8449 - val_loss: 0.3686\n",
      "Epoch 14/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7972 - loss: 0.4551 - val_accuracy: 0.8459 - val_loss: 0.3621\n",
      "Epoch 15/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7940 - loss: 0.4554 - val_accuracy: 0.8602 - val_loss: 0.3476\n",
      "Epoch 16/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8040 - loss: 0.4290 - val_accuracy: 0.8602 - val_loss: 0.3413\n",
      "Epoch 17/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8152 - loss: 0.4214 - val_accuracy: 0.8653 - val_loss: 0.3267\n",
      "Epoch 18/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8180 - loss: 0.4159 - val_accuracy: 0.8724 - val_loss: 0.3141\n",
      "Epoch 19/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8252 - loss: 0.4029 - val_accuracy: 0.8735 - val_loss: 0.3097\n",
      "Epoch 20/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8350 - loss: 0.3929 - val_accuracy: 0.8806 - val_loss: 0.2985\n",
      "Epoch 21/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8281 - loss: 0.3770 - val_accuracy: 0.8939 - val_loss: 0.2887\n",
      "Epoch 22/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8406 - loss: 0.3606 - val_accuracy: 0.8969 - val_loss: 0.2776\n",
      "Epoch 23/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8496 - loss: 0.3462 - val_accuracy: 0.8929 - val_loss: 0.2770\n",
      "Epoch 24/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.3540 - val_accuracy: 0.9000 - val_loss: 0.2678\n",
      "Epoch 25/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8536 - loss: 0.3401 - val_accuracy: 0.9010 - val_loss: 0.2622\n",
      "Epoch 26/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8570 - loss: 0.3399 - val_accuracy: 0.9020 - val_loss: 0.2498\n",
      "Epoch 27/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8607 - loss: 0.3386 - val_accuracy: 0.8969 - val_loss: 0.2562\n",
      "Epoch 28/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8604 - loss: 0.3382 - val_accuracy: 0.9010 - val_loss: 0.2438\n",
      "Epoch 29/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8714 - loss: 0.3052 - val_accuracy: 0.9071 - val_loss: 0.2420\n",
      "Epoch 30/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8714 - loss: 0.3168 - val_accuracy: 0.9092 - val_loss: 0.2315\n",
      "Epoch 31/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8708 - loss: 0.2926 - val_accuracy: 0.9112 - val_loss: 0.2367\n",
      "Epoch 32/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8775 - loss: 0.3116 - val_accuracy: 0.9102 - val_loss: 0.2277\n",
      "Epoch 33/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8849 - loss: 0.2828 - val_accuracy: 0.9173 - val_loss: 0.2260\n",
      "Epoch 34/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8838 - loss: 0.2808 - val_accuracy: 0.9163 - val_loss: 0.2194\n",
      "Epoch 35/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8821 - loss: 0.2828 - val_accuracy: 0.9194 - val_loss: 0.2180\n",
      "Epoch 36/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8873 - loss: 0.2743 - val_accuracy: 0.9194 - val_loss: 0.2074\n",
      "Epoch 37/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8897 - loss: 0.2714 - val_accuracy: 0.9163 - val_loss: 0.2087\n",
      "Epoch 38/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8958 - loss: 0.2642 - val_accuracy: 0.9245 - val_loss: 0.2083\n",
      "Epoch 39/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8937 - loss: 0.2512 - val_accuracy: 0.9153 - val_loss: 0.2126\n",
      "Epoch 40/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8925 - loss: 0.2560 - val_accuracy: 0.9235 - val_loss: 0.1980\n",
      "Epoch 41/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9009 - loss: 0.2562 - val_accuracy: 0.9276 - val_loss: 0.1921\n",
      "Epoch 42/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9077 - loss: 0.2396 - val_accuracy: 0.9194 - val_loss: 0.1971\n",
      "Epoch 43/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9016 - loss: 0.2523 - val_accuracy: 0.9286 - val_loss: 0.1913\n",
      "Epoch 44/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9055 - loss: 0.2354 - val_accuracy: 0.9286 - val_loss: 0.1816\n",
      "Epoch 45/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9010 - loss: 0.2396 - val_accuracy: 0.9296 - val_loss: 0.1768\n",
      "Epoch 46/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9084 - loss: 0.2259 - val_accuracy: 0.9327 - val_loss: 0.1765\n",
      "Epoch 47/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9073 - loss: 0.2281 - val_accuracy: 0.9367 - val_loss: 0.1703\n",
      "Epoch 48/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9007 - loss: 0.2412 - val_accuracy: 0.9367 - val_loss: 0.1712\n",
      "Epoch 49/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9116 - loss: 0.2147 - val_accuracy: 0.9378 - val_loss: 0.1724\n",
      "Epoch 50/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9112 - loss: 0.2238 - val_accuracy: 0.9429 - val_loss: 0.1643\n",
      "Epoch 51/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9229 - loss: 0.2016 - val_accuracy: 0.9429 - val_loss: 0.1643\n",
      "Epoch 52/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9185 - loss: 0.2064 - val_accuracy: 0.9429 - val_loss: 0.1592\n",
      "Epoch 53/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9133 - loss: 0.2136 - val_accuracy: 0.9469 - val_loss: 0.1589\n",
      "Epoch 54/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9139 - loss: 0.2180 - val_accuracy: 0.9418 - val_loss: 0.1574\n",
      "Epoch 55/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9154 - loss: 0.2045 - val_accuracy: 0.9418 - val_loss: 0.1586\n",
      "Epoch 56/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9186 - loss: 0.2020 - val_accuracy: 0.9418 - val_loss: 0.1582\n",
      "Epoch 57/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9188 - loss: 0.2041 - val_accuracy: 0.9408 - val_loss: 0.1569\n",
      "Epoch 58/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9238 - loss: 0.1961 - val_accuracy: 0.9398 - val_loss: 0.1575\n",
      "Epoch 59/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9237 - loss: 0.1977 - val_accuracy: 0.9459 - val_loss: 0.1563\n",
      "Epoch 60/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9194 - loss: 0.1999 - val_accuracy: 0.9490 - val_loss: 0.1513\n",
      "Epoch 61/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9243 - loss: 0.1889 - val_accuracy: 0.9459 - val_loss: 0.1493\n",
      "Epoch 62/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9250 - loss: 0.1811 - val_accuracy: 0.9459 - val_loss: 0.1524\n",
      "Epoch 63/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9186 - loss: 0.1912 - val_accuracy: 0.9459 - val_loss: 0.1502\n",
      "Epoch 64/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9266 - loss: 0.1800 - val_accuracy: 0.9490 - val_loss: 0.1463\n",
      "Epoch 65/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9297 - loss: 0.1836 - val_accuracy: 0.9490 - val_loss: 0.1486\n",
      "Epoch 66/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9242 - loss: 0.2014 - val_accuracy: 0.9520 - val_loss: 0.1444\n",
      "Epoch 67/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9290 - loss: 0.1862 - val_accuracy: 0.9480 - val_loss: 0.1438\n",
      "Epoch 68/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9324 - loss: 0.1776 - val_accuracy: 0.9439 - val_loss: 0.1513\n",
      "Epoch 69/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9251 - loss: 0.1881 - val_accuracy: 0.9490 - val_loss: 0.1451\n",
      "Epoch 70/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9351 - loss: 0.1781 - val_accuracy: 0.9459 - val_loss: 0.1437\n",
      "Epoch 71/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9368 - loss: 0.1686 - val_accuracy: 0.9429 - val_loss: 0.1451\n",
      "Epoch 72/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9292 - loss: 0.1869 - val_accuracy: 0.9520 - val_loss: 0.1408\n",
      "Epoch 73/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9348 - loss: 0.1770 - val_accuracy: 0.9469 - val_loss: 0.1470\n",
      "Epoch 74/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9415 - loss: 0.1646 - val_accuracy: 0.9541 - val_loss: 0.1417\n",
      "Epoch 75/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9229 - loss: 0.1799 - val_accuracy: 0.9480 - val_loss: 0.1475\n",
      "Epoch 76/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9285 - loss: 0.1814 - val_accuracy: 0.9469 - val_loss: 0.1423\n",
      "Epoch 77/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9302 - loss: 0.1863 - val_accuracy: 0.9480 - val_loss: 0.1408\n",
      "Epoch 78/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9316 - loss: 0.1762 - val_accuracy: 0.9480 - val_loss: 0.1437\n",
      "Epoch 79/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9403 - loss: 0.1609 - val_accuracy: 0.9429 - val_loss: 0.1378\n",
      "Epoch 80/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9300 - loss: 0.1849 - val_accuracy: 0.9459 - val_loss: 0.1389\n",
      "Epoch 81/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9327 - loss: 0.1720 - val_accuracy: 0.9520 - val_loss: 0.1370\n",
      "Epoch 82/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9386 - loss: 0.1617 - val_accuracy: 0.9510 - val_loss: 0.1370\n",
      "Epoch 83/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9342 - loss: 0.1704 - val_accuracy: 0.9531 - val_loss: 0.1378\n",
      "Epoch 84/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9316 - loss: 0.1685 - val_accuracy: 0.9541 - val_loss: 0.1362\n",
      "Epoch 85/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9317 - loss: 0.1753 - val_accuracy: 0.9541 - val_loss: 0.1351\n",
      "Epoch 86/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9345 - loss: 0.1620 - val_accuracy: 0.9510 - val_loss: 0.1313\n",
      "Epoch 87/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9354 - loss: 0.1670 - val_accuracy: 0.9571 - val_loss: 0.1339\n",
      "Epoch 88/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9362 - loss: 0.1722 - val_accuracy: 0.9510 - val_loss: 0.1334\n",
      "Epoch 89/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9368 - loss: 0.1610 - val_accuracy: 0.9582 - val_loss: 0.1305\n",
      "Epoch 90/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9347 - loss: 0.1669 - val_accuracy: 0.9531 - val_loss: 0.1303\n",
      "Epoch 91/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9353 - loss: 0.1637 - val_accuracy: 0.9551 - val_loss: 0.1316\n",
      "Epoch 92/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9348 - loss: 0.1625 - val_accuracy: 0.9622 - val_loss: 0.1260\n",
      "Epoch 93/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9351 - loss: 0.1623 - val_accuracy: 0.9500 - val_loss: 0.1364\n",
      "Epoch 94/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9404 - loss: 0.1576 - val_accuracy: 0.9500 - val_loss: 0.1289\n",
      "Epoch 95/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9429 - loss: 0.1504 - val_accuracy: 0.9500 - val_loss: 0.1334\n",
      "Epoch 96/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9369 - loss: 0.1622 - val_accuracy: 0.9469 - val_loss: 0.1311\n",
      "Epoch 97/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9369 - loss: 0.1628 - val_accuracy: 0.9571 - val_loss: 0.1306\n",
      "Epoch 98/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9418 - loss: 0.1590 - val_accuracy: 0.9510 - val_loss: 0.1317\n",
      "Epoch 99/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9373 - loss: 0.1574 - val_accuracy: 0.9541 - val_loss: 0.1325\n",
      "Epoch 100/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9316 - loss: 0.1622 - val_accuracy: 0.9510 - val_loss: 0.1263\n",
      "Epoch 101/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9337 - loss: 0.1680 - val_accuracy: 0.9490 - val_loss: 0.1320\n",
      "Epoch 102/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9396 - loss: 0.1524 - val_accuracy: 0.9561 - val_loss: 0.1317\n",
      "Epoch 103/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9381 - loss: 0.1570 - val_accuracy: 0.9582 - val_loss: 0.1296\n",
      "Epoch 104/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9401 - loss: 0.1616 - val_accuracy: 0.9459 - val_loss: 0.1267\n",
      "Epoch 105/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9393 - loss: 0.1614 - val_accuracy: 0.9561 - val_loss: 0.1265\n",
      "Epoch 106/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9373 - loss: 0.1566 - val_accuracy: 0.9571 - val_loss: 0.1242\n",
      "Epoch 107/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9432 - loss: 0.1498 - val_accuracy: 0.9592 - val_loss: 0.1267\n",
      "Epoch 108/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9380 - loss: 0.1580 - val_accuracy: 0.9592 - val_loss: 0.1271\n",
      "Epoch 109/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9362 - loss: 0.1533 - val_accuracy: 0.9551 - val_loss: 0.1263\n",
      "Epoch 110/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9409 - loss: 0.1587 - val_accuracy: 0.9561 - val_loss: 0.1333\n",
      "Epoch 111/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9394 - loss: 0.1537 - val_accuracy: 0.9520 - val_loss: 0.1301\n",
      "Epoch 112/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9479 - loss: 0.1458 - val_accuracy: 0.9561 - val_loss: 0.1268\n",
      "Epoch 113/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9431 - loss: 0.1483 - val_accuracy: 0.9561 - val_loss: 0.1236\n",
      "Epoch 114/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9401 - loss: 0.1559 - val_accuracy: 0.9602 - val_loss: 0.1237\n",
      "Epoch 115/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9497 - loss: 0.1403 - val_accuracy: 0.9541 - val_loss: 0.1213\n",
      "Epoch 116/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9421 - loss: 0.1408 - val_accuracy: 0.9582 - val_loss: 0.1219\n",
      "Epoch 117/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9466 - loss: 0.1377 - val_accuracy: 0.9612 - val_loss: 0.1228\n",
      "Epoch 118/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9390 - loss: 0.1574 - val_accuracy: 0.9602 - val_loss: 0.1207\n",
      "Epoch 119/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9480 - loss: 0.1476 - val_accuracy: 0.9551 - val_loss: 0.1210\n",
      "Epoch 120/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9436 - loss: 0.1465 - val_accuracy: 0.9622 - val_loss: 0.1203\n",
      "Epoch 121/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9345 - loss: 0.1571 - val_accuracy: 0.9541 - val_loss: 0.1200\n",
      "Epoch 122/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9432 - loss: 0.1454 - val_accuracy: 0.9602 - val_loss: 0.1209\n",
      "Epoch 123/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9423 - loss: 0.1465 - val_accuracy: 0.9582 - val_loss: 0.1206\n",
      "Epoch 124/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9424 - loss: 0.1479 - val_accuracy: 0.9551 - val_loss: 0.1247\n",
      "Epoch 125/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9425 - loss: 0.1549 - val_accuracy: 0.9582 - val_loss: 0.1272\n",
      "Epoch 126/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9411 - loss: 0.1424 - val_accuracy: 0.9571 - val_loss: 0.1259\n",
      "Epoch 127/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9434 - loss: 0.1426 - val_accuracy: 0.9571 - val_loss: 0.1231\n",
      "Epoch 128/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9500 - loss: 0.1352 - val_accuracy: 0.9571 - val_loss: 0.1223\n",
      "Epoch 129/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9364 - loss: 0.1608 - val_accuracy: 0.9571 - val_loss: 0.1204\n",
      "Epoch 130/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9396 - loss: 0.1525 - val_accuracy: 0.9612 - val_loss: 0.1205\n",
      "Epoch 131/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9467 - loss: 0.1439 - val_accuracy: 0.9571 - val_loss: 0.1269\n",
      "Epoch 132/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9407 - loss: 0.1537 - val_accuracy: 0.9469 - val_loss: 0.1259\n",
      "Epoch 133/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9447 - loss: 0.1472 - val_accuracy: 0.9592 - val_loss: 0.1218\n",
      "Epoch 134/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9452 - loss: 0.1436 - val_accuracy: 0.9571 - val_loss: 0.1209\n",
      "Epoch 135/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9454 - loss: 0.1407 - val_accuracy: 0.9602 - val_loss: 0.1213\n",
      "Epoch 136/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9424 - loss: 0.1489 - val_accuracy: 0.9602 - val_loss: 0.1219\n",
      "Epoch 137/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9433 - loss: 0.1495 - val_accuracy: 0.9551 - val_loss: 0.1268\n",
      "Epoch 138/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9368 - loss: 0.1629 - val_accuracy: 0.9602 - val_loss: 0.1197\n",
      "Epoch 139/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9494 - loss: 0.1305 - val_accuracy: 0.9500 - val_loss: 0.1230\n",
      "Epoch 140/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9497 - loss: 0.1329 - val_accuracy: 0.9561 - val_loss: 0.1151\n",
      "Epoch 141/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9476 - loss: 0.1405 - val_accuracy: 0.9531 - val_loss: 0.1202\n",
      "Epoch 142/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9489 - loss: 0.1382 - val_accuracy: 0.9592 - val_loss: 0.1229\n",
      "Epoch 143/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9503 - loss: 0.1342 - val_accuracy: 0.9592 - val_loss: 0.1230\n",
      "Epoch 144/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9397 - loss: 0.1464 - val_accuracy: 0.9561 - val_loss: 0.1231\n",
      "Epoch 145/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9471 - loss: 0.1473 - val_accuracy: 0.9592 - val_loss: 0.1208\n",
      "Epoch 146/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9415 - loss: 0.1520 - val_accuracy: 0.9551 - val_loss: 0.1185\n",
      "Epoch 147/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9387 - loss: 0.1451 - val_accuracy: 0.9612 - val_loss: 0.1225\n",
      "Epoch 148/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9454 - loss: 0.1412 - val_accuracy: 0.9551 - val_loss: 0.1284\n",
      "Epoch 149/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9454 - loss: 0.1355 - val_accuracy: 0.9571 - val_loss: 0.1201\n",
      "Epoch 150/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9504 - loss: 0.1330 - val_accuracy: 0.9582 - val_loss: 0.1204\n",
      "Epoch 151/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9513 - loss: 0.1300 - val_accuracy: 0.9612 - val_loss: 0.1210\n",
      "Epoch 152/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9444 - loss: 0.1413 - val_accuracy: 0.9531 - val_loss: 0.1156\n",
      "Epoch 153/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9459 - loss: 0.1431 - val_accuracy: 0.9602 - val_loss: 0.1175\n",
      "Epoch 154/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9499 - loss: 0.1313 - val_accuracy: 0.9582 - val_loss: 0.1156\n",
      "Epoch 155/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9514 - loss: 0.1345 - val_accuracy: 0.9592 - val_loss: 0.1227\n",
      "Epoch 156/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9412 - loss: 0.1494 - val_accuracy: 0.9582 - val_loss: 0.1175\n",
      "Epoch 157/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9437 - loss: 0.1500 - val_accuracy: 0.9582 - val_loss: 0.1159\n",
      "Epoch 158/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9437 - loss: 0.1413 - val_accuracy: 0.9582 - val_loss: 0.1164\n",
      "Epoch 159/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9505 - loss: 0.1299 - val_accuracy: 0.9561 - val_loss: 0.1180\n",
      "Epoch 160/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9439 - loss: 0.1375 - val_accuracy: 0.9582 - val_loss: 0.1150\n",
      "Epoch 161/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9433 - loss: 0.1445 - val_accuracy: 0.9561 - val_loss: 0.1233\n",
      "Epoch 162/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9428 - loss: 0.1408 - val_accuracy: 0.9602 - val_loss: 0.1163\n",
      "Epoch 163/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9480 - loss: 0.1294 - val_accuracy: 0.9592 - val_loss: 0.1177\n",
      "Epoch 164/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9456 - loss: 0.1414 - val_accuracy: 0.9571 - val_loss: 0.1166\n",
      "Epoch 165/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9449 - loss: 0.1341 - val_accuracy: 0.9582 - val_loss: 0.1171\n",
      "Epoch 166/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9489 - loss: 0.1408 - val_accuracy: 0.9582 - val_loss: 0.1232\n",
      "Epoch 167/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9492 - loss: 0.1412 - val_accuracy: 0.9602 - val_loss: 0.1154\n",
      "Epoch 168/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9495 - loss: 0.1343 - val_accuracy: 0.9592 - val_loss: 0.1141\n",
      "Epoch 169/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9444 - loss: 0.1398 - val_accuracy: 0.9602 - val_loss: 0.1155\n",
      "Epoch 170/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9367 - loss: 0.1503 - val_accuracy: 0.9592 - val_loss: 0.1170\n",
      "Epoch 171/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9415 - loss: 0.1456 - val_accuracy: 0.9592 - val_loss: 0.1164\n",
      "Epoch 172/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9366 - loss: 0.1512 - val_accuracy: 0.9561 - val_loss: 0.1230\n",
      "Epoch 173/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9462 - loss: 0.1442 - val_accuracy: 0.9612 - val_loss: 0.1122\n",
      "Epoch 174/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9472 - loss: 0.1325 - val_accuracy: 0.9633 - val_loss: 0.1120\n",
      "Epoch 175/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9489 - loss: 0.1272 - val_accuracy: 0.9612 - val_loss: 0.1181\n",
      "Epoch 176/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9467 - loss: 0.1359 - val_accuracy: 0.9602 - val_loss: 0.1162\n",
      "Epoch 177/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9478 - loss: 0.1311 - val_accuracy: 0.9612 - val_loss: 0.1231\n",
      "Epoch 178/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9429 - loss: 0.1412 - val_accuracy: 0.9622 - val_loss: 0.1176\n",
      "Epoch 179/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9469 - loss: 0.1308 - val_accuracy: 0.9531 - val_loss: 0.1202\n",
      "Epoch 180/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9472 - loss: 0.1337 - val_accuracy: 0.9633 - val_loss: 0.1165\n",
      "Epoch 181/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9474 - loss: 0.1385 - val_accuracy: 0.9561 - val_loss: 0.1231\n",
      "Epoch 182/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9480 - loss: 0.1404 - val_accuracy: 0.9571 - val_loss: 0.1141\n",
      "Epoch 183/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9495 - loss: 0.1363 - val_accuracy: 0.9582 - val_loss: 0.1176\n",
      "Epoch 184/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9432 - loss: 0.1358 - val_accuracy: 0.9633 - val_loss: 0.1140\n",
      "Epoch 185/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9511 - loss: 0.1354 - val_accuracy: 0.9643 - val_loss: 0.1128\n",
      "Epoch 186/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9424 - loss: 0.1449 - val_accuracy: 0.9582 - val_loss: 0.1163\n",
      "Epoch 187/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9474 - loss: 0.1346 - val_accuracy: 0.9622 - val_loss: 0.1150\n",
      "Epoch 188/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9505 - loss: 0.1375 - val_accuracy: 0.9592 - val_loss: 0.1229\n",
      "Epoch 189/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9465 - loss: 0.1378 - val_accuracy: 0.9622 - val_loss: 0.1151\n",
      "Epoch 190/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9410 - loss: 0.1472 - val_accuracy: 0.9592 - val_loss: 0.1176\n",
      "Epoch 191/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9452 - loss: 0.1428 - val_accuracy: 0.9622 - val_loss: 0.1139\n",
      "Epoch 192/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9534 - loss: 0.1293 - val_accuracy: 0.9582 - val_loss: 0.1167\n",
      "Epoch 193/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9515 - loss: 0.1366 - val_accuracy: 0.9602 - val_loss: 0.1131\n",
      "Epoch 194/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9573 - loss: 0.1192 - val_accuracy: 0.9612 - val_loss: 0.1139\n",
      "Epoch 195/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9452 - loss: 0.1414 - val_accuracy: 0.9633 - val_loss: 0.1091\n",
      "Epoch 196/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9519 - loss: 0.1290 - val_accuracy: 0.9622 - val_loss: 0.1134\n",
      "Epoch 197/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9490 - loss: 0.1272 - val_accuracy: 0.9612 - val_loss: 0.1132\n",
      "Epoch 198/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9531 - loss: 0.1237 - val_accuracy: 0.9602 - val_loss: 0.1140\n",
      "Epoch 199/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9446 - loss: 0.1409 - val_accuracy: 0.9592 - val_loss: 0.1121\n",
      "Epoch 200/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9460 - loss: 0.1453 - val_accuracy: 0.9622 - val_loss: 0.1131\n",
      "Epoch 201/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9506 - loss: 0.1317 - val_accuracy: 0.9612 - val_loss: 0.1119\n",
      "Epoch 202/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9547 - loss: 0.1220 - val_accuracy: 0.9602 - val_loss: 0.1110\n",
      "Epoch 203/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9517 - loss: 0.1296 - val_accuracy: 0.9592 - val_loss: 0.1109\n",
      "Epoch 204/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9511 - loss: 0.1377 - val_accuracy: 0.9622 - val_loss: 0.1145\n",
      "Epoch 205/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9471 - loss: 0.1309 - val_accuracy: 0.9582 - val_loss: 0.1104\n",
      "Epoch 206/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9492 - loss: 0.1365 - val_accuracy: 0.9633 - val_loss: 0.1141\n",
      "Epoch 207/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9524 - loss: 0.1313 - val_accuracy: 0.9643 - val_loss: 0.1117\n",
      "Epoch 208/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9503 - loss: 0.1360 - val_accuracy: 0.9602 - val_loss: 0.1125\n",
      "Epoch 209/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9510 - loss: 0.1275 - val_accuracy: 0.9571 - val_loss: 0.1161\n",
      "Epoch 210/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9491 - loss: 0.1292 - val_accuracy: 0.9592 - val_loss: 0.1151\n",
      "Epoch 211/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9530 - loss: 0.1226 - val_accuracy: 0.9622 - val_loss: 0.1170\n",
      "Epoch 212/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9519 - loss: 0.1357 - val_accuracy: 0.9592 - val_loss: 0.1165\n",
      "Epoch 213/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9503 - loss: 0.1262 - val_accuracy: 0.9592 - val_loss: 0.1157\n",
      "Epoch 214/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9572 - loss: 0.1231 - val_accuracy: 0.9582 - val_loss: 0.1136\n",
      "Epoch 215/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9510 - loss: 0.1237 - val_accuracy: 0.9582 - val_loss: 0.1154\n",
      "Epoch 216/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9424 - loss: 0.1426 - val_accuracy: 0.9571 - val_loss: 0.1159\n",
      "Epoch 217/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9525 - loss: 0.1284 - val_accuracy: 0.9612 - val_loss: 0.1161\n",
      "Epoch 218/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9512 - loss: 0.1278 - val_accuracy: 0.9622 - val_loss: 0.1184\n",
      "Epoch 219/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9490 - loss: 0.1276 - val_accuracy: 0.9571 - val_loss: 0.1159\n",
      "Epoch 220/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9547 - loss: 0.1241 - val_accuracy: 0.9592 - val_loss: 0.1146\n",
      "Epoch 221/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9535 - loss: 0.1218 - val_accuracy: 0.9592 - val_loss: 0.1162\n",
      "Epoch 222/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9491 - loss: 0.1289 - val_accuracy: 0.9633 - val_loss: 0.1150\n",
      "Epoch 223/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9506 - loss: 0.1276 - val_accuracy: 0.9602 - val_loss: 0.1155\n",
      "Epoch 224/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9508 - loss: 0.1246 - val_accuracy: 0.9633 - val_loss: 0.1139\n",
      "Epoch 225/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9535 - loss: 0.1288 - val_accuracy: 0.9592 - val_loss: 0.1168\n",
      "Epoch 226/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9524 - loss: 0.1293 - val_accuracy: 0.9622 - val_loss: 0.1109\n",
      "Epoch 227/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9508 - loss: 0.1327 - val_accuracy: 0.9612 - val_loss: 0.1116\n",
      "Epoch 228/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9500 - loss: 0.1275 - val_accuracy: 0.9633 - val_loss: 0.1133\n",
      "Epoch 229/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9524 - loss: 0.1185 - val_accuracy: 0.9612 - val_loss: 0.1110\n",
      "Epoch 230/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9463 - loss: 0.1390 - val_accuracy: 0.9653 - val_loss: 0.1083\n",
      "Epoch 231/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9498 - loss: 0.1279 - val_accuracy: 0.9622 - val_loss: 0.1123\n",
      "Epoch 232/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9532 - loss: 0.1258 - val_accuracy: 0.9643 - val_loss: 0.1070\n",
      "Epoch 233/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9446 - loss: 0.1424 - val_accuracy: 0.9622 - val_loss: 0.1113\n",
      "Epoch 234/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9542 - loss: 0.1226 - val_accuracy: 0.9602 - val_loss: 0.1085\n",
      "Epoch 235/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9529 - loss: 0.1266 - val_accuracy: 0.9622 - val_loss: 0.1081\n",
      "Epoch 236/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9530 - loss: 0.1263 - val_accuracy: 0.9592 - val_loss: 0.1132\n",
      "Epoch 237/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9481 - loss: 0.1342 - val_accuracy: 0.9602 - val_loss: 0.1155\n",
      "Epoch 238/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9501 - loss: 0.1301 - val_accuracy: 0.9633 - val_loss: 0.1131\n",
      "Epoch 239/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9567 - loss: 0.1161 - val_accuracy: 0.9582 - val_loss: 0.1122\n",
      "Epoch 240/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9523 - loss: 0.1231 - val_accuracy: 0.9633 - val_loss: 0.1139\n",
      "Epoch 241/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9412 - loss: 0.1500 - val_accuracy: 0.9643 - val_loss: 0.1116\n",
      "Epoch 242/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9541 - loss: 0.1199 - val_accuracy: 0.9643 - val_loss: 0.1090\n",
      "Epoch 243/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9474 - loss: 0.1258 - val_accuracy: 0.9643 - val_loss: 0.1121\n",
      "Epoch 244/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9469 - loss: 0.1331 - val_accuracy: 0.9592 - val_loss: 0.1078\n",
      "Epoch 245/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9519 - loss: 0.1222 - val_accuracy: 0.9653 - val_loss: 0.1121\n",
      "Epoch 246/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9526 - loss: 0.1214 - val_accuracy: 0.9633 - val_loss: 0.1125\n",
      "Epoch 247/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9530 - loss: 0.1223 - val_accuracy: 0.9612 - val_loss: 0.1102\n",
      "Epoch 248/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9519 - loss: 0.1213 - val_accuracy: 0.9582 - val_loss: 0.1140\n",
      "Epoch 249/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9542 - loss: 0.1207 - val_accuracy: 0.9612 - val_loss: 0.1110\n",
      "Epoch 250/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9513 - loss: 0.1259 - val_accuracy: 0.9592 - val_loss: 0.1117\n",
      "Epoch 251/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9572 - loss: 0.1153 - val_accuracy: 0.9602 - val_loss: 0.1187\n",
      "Epoch 252/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9483 - loss: 0.1291 - val_accuracy: 0.9602 - val_loss: 0.1158\n",
      "Epoch 253/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9527 - loss: 0.1277 - val_accuracy: 0.9571 - val_loss: 0.1150\n",
      "Epoch 254/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9510 - loss: 0.1376 - val_accuracy: 0.9612 - val_loss: 0.1116\n",
      "Epoch 255/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9509 - loss: 0.1227 - val_accuracy: 0.9582 - val_loss: 0.1108\n",
      "Epoch 256/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9489 - loss: 0.1336 - val_accuracy: 0.9643 - val_loss: 0.1130\n",
      "Epoch 257/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9492 - loss: 0.1211 - val_accuracy: 0.9612 - val_loss: 0.1117\n",
      "Epoch 258/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9498 - loss: 0.1258 - val_accuracy: 0.9612 - val_loss: 0.1130\n",
      "Epoch 259/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9563 - loss: 0.1153 - val_accuracy: 0.9592 - val_loss: 0.1111\n",
      "Epoch 260/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9546 - loss: 0.1228 - val_accuracy: 0.9582 - val_loss: 0.1156\n",
      "Epoch 261/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9531 - loss: 0.1267 - val_accuracy: 0.9622 - val_loss: 0.1091\n",
      "Epoch 262/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9478 - loss: 0.1359 - val_accuracy: 0.9612 - val_loss: 0.1107\n",
      "Epoch 263/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9526 - loss: 0.1226 - val_accuracy: 0.9582 - val_loss: 0.1127\n",
      "Epoch 264/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9491 - loss: 0.1317 - val_accuracy: 0.9622 - val_loss: 0.1059\n",
      "Epoch 265/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9533 - loss: 0.1304 - val_accuracy: 0.9592 - val_loss: 0.1119\n",
      "Epoch 266/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9519 - loss: 0.1313 - val_accuracy: 0.9582 - val_loss: 0.1105\n",
      "Epoch 267/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9523 - loss: 0.1166 - val_accuracy: 0.9602 - val_loss: 0.1091\n",
      "Epoch 268/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9497 - loss: 0.1285 - val_accuracy: 0.9633 - val_loss: 0.1104\n",
      "Epoch 269/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9539 - loss: 0.1193 - val_accuracy: 0.9612 - val_loss: 0.1114\n",
      "Epoch 270/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9551 - loss: 0.1187 - val_accuracy: 0.9612 - val_loss: 0.1088\n",
      "Epoch 271/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9534 - loss: 0.1222 - val_accuracy: 0.9592 - val_loss: 0.1116\n",
      "Epoch 272/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9515 - loss: 0.1323 - val_accuracy: 0.9622 - val_loss: 0.1083\n",
      "Epoch 273/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9468 - loss: 0.1390 - val_accuracy: 0.9592 - val_loss: 0.1133\n",
      "Epoch 274/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9501 - loss: 0.1298 - val_accuracy: 0.9582 - val_loss: 0.1148\n",
      "Epoch 275/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9534 - loss: 0.1255 - val_accuracy: 0.9612 - val_loss: 0.1110\n",
      "Epoch 276/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9530 - loss: 0.1259 - val_accuracy: 0.9643 - val_loss: 0.1072\n",
      "Epoch 277/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9511 - loss: 0.1265 - val_accuracy: 0.9541 - val_loss: 0.1118\n",
      "Epoch 278/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9558 - loss: 0.1266 - val_accuracy: 0.9643 - val_loss: 0.1071\n",
      "Epoch 279/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9540 - loss: 0.1261 - val_accuracy: 0.9592 - val_loss: 0.1086\n",
      "Epoch 280/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9512 - loss: 0.1197 - val_accuracy: 0.9612 - val_loss: 0.1102\n",
      "Epoch 281/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9558 - loss: 0.1179 - val_accuracy: 0.9582 - val_loss: 0.1166\n",
      "Epoch 282/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9464 - loss: 0.1250 - val_accuracy: 0.9602 - val_loss: 0.1044\n",
      "Epoch 283/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9512 - loss: 0.1267 - val_accuracy: 0.9643 - val_loss: 0.1102\n",
      "Epoch 284/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9538 - loss: 0.1208 - val_accuracy: 0.9592 - val_loss: 0.1167\n",
      "Epoch 285/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9477 - loss: 0.1318 - val_accuracy: 0.9602 - val_loss: 0.1145\n",
      "Epoch 286/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9555 - loss: 0.1218 - val_accuracy: 0.9612 - val_loss: 0.1086\n",
      "Epoch 287/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9540 - loss: 0.1196 - val_accuracy: 0.9622 - val_loss: 0.1080\n",
      "Epoch 288/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9528 - loss: 0.1193 - val_accuracy: 0.9622 - val_loss: 0.1075\n",
      "Epoch 289/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9604 - loss: 0.1085 - val_accuracy: 0.9622 - val_loss: 0.1053\n",
      "Epoch 290/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9533 - loss: 0.1224 - val_accuracy: 0.9571 - val_loss: 0.1116\n",
      "Epoch 291/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9591 - loss: 0.1055 - val_accuracy: 0.9612 - val_loss: 0.1092\n",
      "Epoch 292/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9529 - loss: 0.1221 - val_accuracy: 0.9612 - val_loss: 0.1093\n",
      "Epoch 293/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9570 - loss: 0.1219 - val_accuracy: 0.9612 - val_loss: 0.1113\n",
      "Epoch 294/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9531 - loss: 0.1282 - val_accuracy: 0.9612 - val_loss: 0.1064\n",
      "Epoch 295/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9492 - loss: 0.1272 - val_accuracy: 0.9612 - val_loss: 0.1058\n",
      "Epoch 296/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9573 - loss: 0.1132 - val_accuracy: 0.9643 - val_loss: 0.1103\n",
      "Epoch 297/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9564 - loss: 0.1164 - val_accuracy: 0.9612 - val_loss: 0.1095\n",
      "Epoch 298/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9535 - loss: 0.1357 - val_accuracy: 0.9653 - val_loss: 0.1085\n",
      "Epoch 299/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9542 - loss: 0.1171 - val_accuracy: 0.9622 - val_loss: 0.1112\n",
      "Epoch 300/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9495 - loss: 0.1279 - val_accuracy: 0.9612 - val_loss: 0.1077\n",
      "Epoch 301/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9547 - loss: 0.1226 - val_accuracy: 0.9643 - val_loss: 0.1071\n",
      "Epoch 302/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9544 - loss: 0.1249 - val_accuracy: 0.9622 - val_loss: 0.1108\n",
      "Epoch 303/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9591 - loss: 0.1060 - val_accuracy: 0.9622 - val_loss: 0.1084\n",
      "Epoch 304/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9600 - loss: 0.1076 - val_accuracy: 0.9622 - val_loss: 0.1088\n",
      "Epoch 305/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9560 - loss: 0.1138 - val_accuracy: 0.9571 - val_loss: 0.1205\n",
      "Epoch 306/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9468 - loss: 0.1302 - val_accuracy: 0.9622 - val_loss: 0.1071\n",
      "Epoch 307/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9564 - loss: 0.1178 - val_accuracy: 0.9602 - val_loss: 0.1077\n",
      "Epoch 308/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9591 - loss: 0.1103 - val_accuracy: 0.9612 - val_loss: 0.1076\n",
      "Epoch 309/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9495 - loss: 0.1241 - val_accuracy: 0.9622 - val_loss: 0.1100\n",
      "Epoch 310/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9556 - loss: 0.1121 - val_accuracy: 0.9622 - val_loss: 0.1112\n",
      "Epoch 311/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9528 - loss: 0.1239 - val_accuracy: 0.9612 - val_loss: 0.1096\n",
      "Epoch 312/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9493 - loss: 0.1286 - val_accuracy: 0.9622 - val_loss: 0.1088\n",
      "Epoch 313/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9578 - loss: 0.1154 - val_accuracy: 0.9643 - val_loss: 0.1115\n",
      "Epoch 314/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9553 - loss: 0.1191 - val_accuracy: 0.9633 - val_loss: 0.1072\n",
      "Epoch 315/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9479 - loss: 0.1365 - val_accuracy: 0.9592 - val_loss: 0.1152\n",
      "Epoch 316/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9503 - loss: 0.1205 - val_accuracy: 0.9643 - val_loss: 0.1085\n",
      "Epoch 317/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9534 - loss: 0.1212 - val_accuracy: 0.9633 - val_loss: 0.1019\n",
      "Epoch 318/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9600 - loss: 0.1046 - val_accuracy: 0.9673 - val_loss: 0.1057\n",
      "Epoch 319/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9596 - loss: 0.1147 - val_accuracy: 0.9612 - val_loss: 0.1064\n",
      "Epoch 320/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9471 - loss: 0.1427 - val_accuracy: 0.9633 - val_loss: 0.1115\n",
      "Epoch 321/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9538 - loss: 0.1133 - val_accuracy: 0.9633 - val_loss: 0.1102\n",
      "Epoch 322/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9528 - loss: 0.1332 - val_accuracy: 0.9612 - val_loss: 0.1084\n",
      "Epoch 323/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9535 - loss: 0.1187 - val_accuracy: 0.9653 - val_loss: 0.1106\n",
      "Epoch 324/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9545 - loss: 0.1147 - val_accuracy: 0.9643 - val_loss: 0.1076\n",
      "Epoch 325/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9532 - loss: 0.1194 - val_accuracy: 0.9592 - val_loss: 0.1071\n",
      "Epoch 326/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9559 - loss: 0.1104 - val_accuracy: 0.9622 - val_loss: 0.1066\n",
      "Epoch 327/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9516 - loss: 0.1274 - val_accuracy: 0.9622 - val_loss: 0.1066\n",
      "Epoch 328/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9520 - loss: 0.1217 - val_accuracy: 0.9602 - val_loss: 0.1081\n",
      "Epoch 329/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9539 - loss: 0.1205 - val_accuracy: 0.9622 - val_loss: 0.1097\n",
      "Epoch 330/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9510 - loss: 0.1248 - val_accuracy: 0.9612 - val_loss: 0.1060\n",
      "Epoch 331/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9523 - loss: 0.1230 - val_accuracy: 0.9612 - val_loss: 0.1074\n",
      "Epoch 332/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9520 - loss: 0.1245 - val_accuracy: 0.9612 - val_loss: 0.1031\n",
      "Epoch 333/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9587 - loss: 0.1139 - val_accuracy: 0.9622 - val_loss: 0.1029\n",
      "Epoch 334/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9530 - loss: 0.1152 - val_accuracy: 0.9653 - val_loss: 0.1069\n",
      "Epoch 335/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9538 - loss: 0.1241 - val_accuracy: 0.9643 - val_loss: 0.1064\n",
      "Epoch 336/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9482 - loss: 0.1302 - val_accuracy: 0.9653 - val_loss: 0.1044\n",
      "Epoch 337/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9589 - loss: 0.1107 - val_accuracy: 0.9643 - val_loss: 0.1049\n",
      "Epoch 338/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9569 - loss: 0.1188 - val_accuracy: 0.9663 - val_loss: 0.1058\n",
      "Epoch 339/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9548 - loss: 0.1270 - val_accuracy: 0.9602 - val_loss: 0.1056\n",
      "Epoch 340/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9516 - loss: 0.1242 - val_accuracy: 0.9622 - val_loss: 0.1075\n",
      "Epoch 341/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9525 - loss: 0.1173 - val_accuracy: 0.9633 - val_loss: 0.1043\n",
      "Epoch 342/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9566 - loss: 0.1178 - val_accuracy: 0.9602 - val_loss: 0.1129\n",
      "Epoch 343/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9512 - loss: 0.1285 - val_accuracy: 0.9622 - val_loss: 0.1107\n",
      "Epoch 344/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9481 - loss: 0.1290 - val_accuracy: 0.9622 - val_loss: 0.1122\n",
      "Epoch 345/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9569 - loss: 0.1190 - val_accuracy: 0.9633 - val_loss: 0.1126\n",
      "Epoch 346/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9474 - loss: 0.1224 - val_accuracy: 0.9633 - val_loss: 0.1073\n",
      "Epoch 347/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9561 - loss: 0.1197 - val_accuracy: 0.9622 - val_loss: 0.1124\n",
      "Epoch 348/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9536 - loss: 0.1238 - val_accuracy: 0.9612 - val_loss: 0.1081\n",
      "Epoch 349/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9587 - loss: 0.1089 - val_accuracy: 0.9684 - val_loss: 0.1049\n",
      "Epoch 350/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9564 - loss: 0.1115 - val_accuracy: 0.9612 - val_loss: 0.1094\n",
      "Epoch 351/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9596 - loss: 0.1096 - val_accuracy: 0.9663 - val_loss: 0.1030\n",
      "Epoch 352/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9547 - loss: 0.1163 - val_accuracy: 0.9622 - val_loss: 0.1080\n",
      "Epoch 353/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9522 - loss: 0.1232 - val_accuracy: 0.9653 - val_loss: 0.1068\n",
      "Epoch 354/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9524 - loss: 0.1190 - val_accuracy: 0.9582 - val_loss: 0.1095\n",
      "Epoch 355/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9559 - loss: 0.1127 - val_accuracy: 0.9643 - val_loss: 0.1078\n",
      "Epoch 356/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9586 - loss: 0.1089 - val_accuracy: 0.9622 - val_loss: 0.1102\n",
      "Epoch 357/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9588 - loss: 0.1098 - val_accuracy: 0.9622 - val_loss: 0.1061\n",
      "Epoch 358/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9540 - loss: 0.1206 - val_accuracy: 0.9643 - val_loss: 0.1063\n",
      "Epoch 359/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9545 - loss: 0.1174 - val_accuracy: 0.9643 - val_loss: 0.1064\n",
      "Epoch 360/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9529 - loss: 0.1321 - val_accuracy: 0.9571 - val_loss: 0.1127\n",
      "Epoch 361/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9597 - loss: 0.1134 - val_accuracy: 0.9622 - val_loss: 0.1152\n",
      "Epoch 362/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9566 - loss: 0.1094 - val_accuracy: 0.9663 - val_loss: 0.1050\n",
      "Epoch 363/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9499 - loss: 0.1263 - val_accuracy: 0.9602 - val_loss: 0.1141\n",
      "Epoch 364/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9536 - loss: 0.1209 - val_accuracy: 0.9571 - val_loss: 0.1173\n",
      "Epoch 365/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9616 - loss: 0.1045 - val_accuracy: 0.9653 - val_loss: 0.1047\n",
      "Epoch 366/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9531 - loss: 0.1232 - val_accuracy: 0.9622 - val_loss: 0.1084\n",
      "Epoch 367/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9525 - loss: 0.1232 - val_accuracy: 0.9622 - val_loss: 0.1097\n",
      "Epoch 368/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9556 - loss: 0.1186 - val_accuracy: 0.9633 - val_loss: 0.1111\n",
      "Epoch 369/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9534 - loss: 0.1136 - val_accuracy: 0.9633 - val_loss: 0.1069\n",
      "Epoch 370/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9531 - loss: 0.1225 - val_accuracy: 0.9633 - val_loss: 0.1097\n",
      "Epoch 371/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9469 - loss: 0.1333 - val_accuracy: 0.9622 - val_loss: 0.1077\n",
      "Epoch 372/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9653 - loss: 0.1044 - val_accuracy: 0.9653 - val_loss: 0.1082\n",
      "Epoch 373/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9574 - loss: 0.1097 - val_accuracy: 0.9633 - val_loss: 0.1072\n",
      "Epoch 374/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9563 - loss: 0.1114 - val_accuracy: 0.9622 - val_loss: 0.1084\n",
      "Epoch 375/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9562 - loss: 0.1092 - val_accuracy: 0.9622 - val_loss: 0.1107\n",
      "Epoch 376/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9533 - loss: 0.1108 - val_accuracy: 0.9592 - val_loss: 0.1163\n",
      "Epoch 377/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9594 - loss: 0.1081 - val_accuracy: 0.9592 - val_loss: 0.1108\n",
      "Epoch 378/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9571 - loss: 0.1140 - val_accuracy: 0.9622 - val_loss: 0.1082\n",
      "Epoch 379/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9555 - loss: 0.1141 - val_accuracy: 0.9633 - val_loss: 0.1096\n",
      "Epoch 380/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9560 - loss: 0.1102 - val_accuracy: 0.9622 - val_loss: 0.1089\n",
      "Epoch 381/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9524 - loss: 0.1167 - val_accuracy: 0.9571 - val_loss: 0.1096\n",
      "Epoch 382/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9540 - loss: 0.1179 - val_accuracy: 0.9633 - val_loss: 0.1063\n",
      "Epoch 383/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9577 - loss: 0.1178 - val_accuracy: 0.9653 - val_loss: 0.1126\n",
      "Epoch 384/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9576 - loss: 0.1128 - val_accuracy: 0.9602 - val_loss: 0.1149\n",
      "Epoch 385/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9612 - loss: 0.1028 - val_accuracy: 0.9622 - val_loss: 0.1142\n",
      "Epoch 386/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9600 - loss: 0.1045 - val_accuracy: 0.9643 - val_loss: 0.1074\n",
      "Epoch 387/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9534 - loss: 0.1199 - val_accuracy: 0.9612 - val_loss: 0.1099\n",
      "Epoch 388/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9597 - loss: 0.1097 - val_accuracy: 0.9622 - val_loss: 0.1118\n",
      "Epoch 389/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9551 - loss: 0.1147 - val_accuracy: 0.9643 - val_loss: 0.1098\n",
      "Epoch 390/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9548 - loss: 0.1143 - val_accuracy: 0.9622 - val_loss: 0.1091\n",
      "Epoch 391/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9535 - loss: 0.1248 - val_accuracy: 0.9643 - val_loss: 0.1084\n",
      "Epoch 392/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9558 - loss: 0.1141 - val_accuracy: 0.9633 - val_loss: 0.1110\n",
      "Epoch 393/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9601 - loss: 0.1138 - val_accuracy: 0.9643 - val_loss: 0.1088\n",
      "Epoch 394/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9571 - loss: 0.1102 - val_accuracy: 0.9622 - val_loss: 0.1106\n",
      "Epoch 395/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9552 - loss: 0.1094 - val_accuracy: 0.9663 - val_loss: 0.1108\n",
      "Epoch 396/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9592 - loss: 0.1112 - val_accuracy: 0.9663 - val_loss: 0.1099\n",
      "Epoch 397/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9524 - loss: 0.1268 - val_accuracy: 0.9622 - val_loss: 0.1076\n",
      "Epoch 398/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9531 - loss: 0.1272 - val_accuracy: 0.9653 - val_loss: 0.1094\n",
      "Epoch 399/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9571 - loss: 0.1145 - val_accuracy: 0.9633 - val_loss: 0.1059\n",
      "Epoch 400/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9533 - loss: 0.1162 - val_accuracy: 0.9663 - val_loss: 0.1115\n",
      "Epoch 401/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9542 - loss: 0.1123 - val_accuracy: 0.9643 - val_loss: 0.1074\n",
      "Epoch 402/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9519 - loss: 0.1238 - val_accuracy: 0.9622 - val_loss: 0.1074\n",
      "Epoch 403/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9565 - loss: 0.1176 - val_accuracy: 0.9663 - val_loss: 0.1075\n",
      "Epoch 404/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9501 - loss: 0.1197 - val_accuracy: 0.9653 - val_loss: 0.1095\n",
      "Epoch 405/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9565 - loss: 0.1088 - val_accuracy: 0.9653 - val_loss: 0.1080\n",
      "Epoch 406/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9555 - loss: 0.1114 - val_accuracy: 0.9643 - val_loss: 0.1089\n",
      "Epoch 407/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9579 - loss: 0.1086 - val_accuracy: 0.9653 - val_loss: 0.1054\n",
      "Epoch 408/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9523 - loss: 0.1193 - val_accuracy: 0.9622 - val_loss: 0.1108\n",
      "Epoch 409/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9520 - loss: 0.1223 - val_accuracy: 0.9643 - val_loss: 0.1095\n",
      "Epoch 410/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9566 - loss: 0.1131 - val_accuracy: 0.9663 - val_loss: 0.1066\n",
      "Epoch 411/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9538 - loss: 0.1171 - val_accuracy: 0.9622 - val_loss: 0.1111\n",
      "Epoch 412/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9591 - loss: 0.1095 - val_accuracy: 0.9663 - val_loss: 0.1094\n",
      "Epoch 413/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9581 - loss: 0.1117 - val_accuracy: 0.9653 - val_loss: 0.1102\n",
      "Epoch 414/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9590 - loss: 0.1067 - val_accuracy: 0.9643 - val_loss: 0.1110\n",
      "Epoch 415/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9601 - loss: 0.1107 - val_accuracy: 0.9684 - val_loss: 0.1074\n",
      "Epoch 416/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9577 - loss: 0.1054 - val_accuracy: 0.9694 - val_loss: 0.1095\n",
      "Epoch 417/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9582 - loss: 0.1052 - val_accuracy: 0.9663 - val_loss: 0.1055\n",
      "Epoch 418/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9555 - loss: 0.1090 - val_accuracy: 0.9663 - val_loss: 0.1078\n",
      "Epoch 419/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9607 - loss: 0.1028 - val_accuracy: 0.9653 - val_loss: 0.1094\n",
      "Epoch 420/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9559 - loss: 0.1185 - val_accuracy: 0.9643 - val_loss: 0.1106\n",
      "Epoch 421/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9540 - loss: 0.1215 - val_accuracy: 0.9663 - val_loss: 0.1050\n",
      "Epoch 422/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9628 - loss: 0.0994 - val_accuracy: 0.9673 - val_loss: 0.1065\n",
      "Epoch 423/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9597 - loss: 0.1099 - val_accuracy: 0.9653 - val_loss: 0.1088\n",
      "Epoch 424/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9531 - loss: 0.1287 - val_accuracy: 0.9653 - val_loss: 0.1074\n",
      "Epoch 425/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9614 - loss: 0.1011 - val_accuracy: 0.9673 - val_loss: 0.1074\n",
      "Epoch 426/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9623 - loss: 0.1015 - val_accuracy: 0.9653 - val_loss: 0.1092\n",
      "Epoch 427/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9538 - loss: 0.1138 - val_accuracy: 0.9663 - val_loss: 0.1093\n",
      "Epoch 428/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9597 - loss: 0.1083 - val_accuracy: 0.9643 - val_loss: 0.1121\n",
      "Epoch 429/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9572 - loss: 0.1038 - val_accuracy: 0.9684 - val_loss: 0.1097\n",
      "Epoch 430/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9573 - loss: 0.1094 - val_accuracy: 0.9633 - val_loss: 0.1097\n",
      "Epoch 431/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9560 - loss: 0.1142 - val_accuracy: 0.9643 - val_loss: 0.1165\n",
      "Epoch 432/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9612 - loss: 0.0998 - val_accuracy: 0.9653 - val_loss: 0.1123\n",
      "Epoch 433/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9565 - loss: 0.1148 - val_accuracy: 0.9643 - val_loss: 0.1102\n",
      "Epoch 434/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9524 - loss: 0.1189 - val_accuracy: 0.9643 - val_loss: 0.1122\n",
      "Epoch 435/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9518 - loss: 0.1239 - val_accuracy: 0.9612 - val_loss: 0.1105\n",
      "Epoch 436/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9588 - loss: 0.1069 - val_accuracy: 0.9663 - val_loss: 0.1110\n",
      "Epoch 437/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9539 - loss: 0.1088 - val_accuracy: 0.9622 - val_loss: 0.1105\n",
      "Epoch 438/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9593 - loss: 0.1072 - val_accuracy: 0.9622 - val_loss: 0.1152\n",
      "Epoch 439/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9551 - loss: 0.1161 - val_accuracy: 0.9643 - val_loss: 0.1117\n",
      "Epoch 440/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9530 - loss: 0.1172 - val_accuracy: 0.9622 - val_loss: 0.1117\n",
      "Epoch 441/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9625 - loss: 0.0997 - val_accuracy: 0.9643 - val_loss: 0.1086\n",
      "Epoch 442/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9596 - loss: 0.1157 - val_accuracy: 0.9612 - val_loss: 0.1105\n",
      "Epoch 443/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9605 - loss: 0.1015 - val_accuracy: 0.9633 - val_loss: 0.1113\n",
      "Epoch 444/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9535 - loss: 0.1213 - val_accuracy: 0.9633 - val_loss: 0.1094\n",
      "Epoch 445/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9601 - loss: 0.1058 - val_accuracy: 0.9633 - val_loss: 0.1093\n",
      "Epoch 446/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9508 - loss: 0.1231 - val_accuracy: 0.9653 - val_loss: 0.1121\n",
      "Epoch 447/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9581 - loss: 0.1121 - val_accuracy: 0.9633 - val_loss: 0.1073\n",
      "Epoch 448/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9576 - loss: 0.1186 - val_accuracy: 0.9653 - val_loss: 0.1103\n",
      "Epoch 449/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9582 - loss: 0.1148 - val_accuracy: 0.9633 - val_loss: 0.1095\n",
      "Epoch 450/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9559 - loss: 0.1150 - val_accuracy: 0.9663 - val_loss: 0.1104\n",
      "Epoch 451/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9601 - loss: 0.1044 - val_accuracy: 0.9663 - val_loss: 0.1065\n",
      "Epoch 452/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9650 - loss: 0.1049 - val_accuracy: 0.9663 - val_loss: 0.1066\n",
      "Epoch 453/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9561 - loss: 0.1108 - val_accuracy: 0.9643 - val_loss: 0.1092\n",
      "Epoch 454/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9590 - loss: 0.1042 - val_accuracy: 0.9633 - val_loss: 0.1082\n",
      "Epoch 455/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9575 - loss: 0.1126 - val_accuracy: 0.9633 - val_loss: 0.1106\n",
      "Epoch 456/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9613 - loss: 0.0961 - val_accuracy: 0.9633 - val_loss: 0.1073\n",
      "Epoch 457/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9563 - loss: 0.1147 - val_accuracy: 0.9612 - val_loss: 0.1099\n",
      "Epoch 458/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9549 - loss: 0.1146 - val_accuracy: 0.9602 - val_loss: 0.1131\n",
      "Epoch 459/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9549 - loss: 0.1126 - val_accuracy: 0.9612 - val_loss: 0.1126\n",
      "Epoch 460/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9572 - loss: 0.1208 - val_accuracy: 0.9612 - val_loss: 0.1100\n",
      "Epoch 461/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9574 - loss: 0.1062 - val_accuracy: 0.9633 - val_loss: 0.1095\n",
      "Epoch 462/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9578 - loss: 0.1110 - val_accuracy: 0.9643 - val_loss: 0.1063\n",
      "Epoch 463/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9612 - loss: 0.1032 - val_accuracy: 0.9622 - val_loss: 0.1100\n",
      "Epoch 464/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9643 - loss: 0.0956 - val_accuracy: 0.9643 - val_loss: 0.1118\n",
      "Epoch 465/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9621 - loss: 0.1084 - val_accuracy: 0.9643 - val_loss: 0.1085\n",
      "Epoch 466/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9587 - loss: 0.1083 - val_accuracy: 0.9663 - val_loss: 0.1088\n",
      "Epoch 467/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9574 - loss: 0.1153 - val_accuracy: 0.9643 - val_loss: 0.1101\n",
      "Epoch 468/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9570 - loss: 0.1136 - val_accuracy: 0.9653 - val_loss: 0.1071\n",
      "Epoch 469/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9572 - loss: 0.1052 - val_accuracy: 0.9653 - val_loss: 0.1065\n",
      "Epoch 470/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9623 - loss: 0.1156 - val_accuracy: 0.9663 - val_loss: 0.1121\n",
      "Epoch 471/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9578 - loss: 0.1106 - val_accuracy: 0.9684 - val_loss: 0.1084\n",
      "Epoch 472/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9530 - loss: 0.1213 - val_accuracy: 0.9673 - val_loss: 0.1056\n",
      "Epoch 473/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9524 - loss: 0.1210 - val_accuracy: 0.9673 - val_loss: 0.1065\n",
      "Epoch 474/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9592 - loss: 0.1091 - val_accuracy: 0.9684 - val_loss: 0.1109\n",
      "Epoch 475/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9595 - loss: 0.1134 - val_accuracy: 0.9633 - val_loss: 0.1108\n",
      "Epoch 476/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9616 - loss: 0.1018 - val_accuracy: 0.9622 - val_loss: 0.1126\n",
      "Epoch 477/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9617 - loss: 0.0974 - val_accuracy: 0.9622 - val_loss: 0.1071\n",
      "Epoch 478/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9609 - loss: 0.1070 - val_accuracy: 0.9653 - val_loss: 0.1094\n",
      "Epoch 479/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9580 - loss: 0.1075 - val_accuracy: 0.9602 - val_loss: 0.1138\n",
      "Epoch 480/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9588 - loss: 0.1093 - val_accuracy: 0.9633 - val_loss: 0.1115\n",
      "Epoch 481/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9617 - loss: 0.1060 - val_accuracy: 0.9643 - val_loss: 0.1085\n",
      "Epoch 482/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9571 - loss: 0.1069 - val_accuracy: 0.9653 - val_loss: 0.1098\n",
      "Epoch 483/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9574 - loss: 0.1094 - val_accuracy: 0.9643 - val_loss: 0.1134\n",
      "Epoch 484/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9521 - loss: 0.1250 - val_accuracy: 0.9602 - val_loss: 0.1138\n",
      "Epoch 485/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9578 - loss: 0.1145 - val_accuracy: 0.9673 - val_loss: 0.1102\n",
      "Epoch 486/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9581 - loss: 0.1107 - val_accuracy: 0.9643 - val_loss: 0.1051\n",
      "Epoch 487/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9611 - loss: 0.0998 - val_accuracy: 0.9673 - val_loss: 0.1117\n",
      "Epoch 488/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9616 - loss: 0.1002 - val_accuracy: 0.9663 - val_loss: 0.1090\n",
      "Epoch 489/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9592 - loss: 0.1052 - val_accuracy: 0.9643 - val_loss: 0.1109\n",
      "Epoch 490/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9601 - loss: 0.1092 - val_accuracy: 0.9684 - val_loss: 0.1072\n",
      "Epoch 491/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9554 - loss: 0.1089 - val_accuracy: 0.9643 - val_loss: 0.1094\n",
      "Epoch 492/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9590 - loss: 0.1198 - val_accuracy: 0.9673 - val_loss: 0.1061\n",
      "Epoch 493/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9570 - loss: 0.1153 - val_accuracy: 0.9622 - val_loss: 0.1110\n",
      "Epoch 494/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9559 - loss: 0.1099 - val_accuracy: 0.9673 - val_loss: 0.1049\n",
      "Epoch 495/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9553 - loss: 0.1190 - val_accuracy: 0.9673 - val_loss: 0.1045\n",
      "Epoch 496/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9541 - loss: 0.1173 - val_accuracy: 0.9673 - val_loss: 0.1051\n",
      "Epoch 497/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9516 - loss: 0.1193 - val_accuracy: 0.9663 - val_loss: 0.1046\n",
      "Epoch 498/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9617 - loss: 0.1034 - val_accuracy: 0.9673 - val_loss: 0.1091\n",
      "Epoch 499/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9632 - loss: 0.1121 - val_accuracy: 0.9653 - val_loss: 0.1099\n",
      "Epoch 500/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9665 - loss: 0.0952 - val_accuracy: 0.9673 - val_loss: 0.1090\n",
      "Epoch 501/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9557 - loss: 0.1100 - val_accuracy: 0.9633 - val_loss: 0.1080\n",
      "Epoch 502/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9555 - loss: 0.1118 - val_accuracy: 0.9653 - val_loss: 0.1053\n",
      "Epoch 503/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9584 - loss: 0.1083 - val_accuracy: 0.9684 - val_loss: 0.1055\n",
      "Epoch 504/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9571 - loss: 0.1129 - val_accuracy: 0.9653 - val_loss: 0.1079\n",
      "Epoch 505/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9504 - loss: 0.1174 - val_accuracy: 0.9653 - val_loss: 0.1076\n",
      "Epoch 506/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9566 - loss: 0.1183 - val_accuracy: 0.9643 - val_loss: 0.1094\n",
      "Epoch 507/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9547 - loss: 0.1072 - val_accuracy: 0.9622 - val_loss: 0.1117\n",
      "Epoch 508/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9579 - loss: 0.1127 - val_accuracy: 0.9673 - val_loss: 0.1058\n",
      "Epoch 509/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9611 - loss: 0.1028 - val_accuracy: 0.9663 - val_loss: 0.1118\n",
      "Epoch 510/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9568 - loss: 0.1111 - val_accuracy: 0.9633 - val_loss: 0.1074\n",
      "Epoch 511/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9596 - loss: 0.1028 - val_accuracy: 0.9694 - val_loss: 0.1063\n",
      "Epoch 512/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9615 - loss: 0.1013 - val_accuracy: 0.9633 - val_loss: 0.1054\n",
      "Epoch 513/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9599 - loss: 0.1056 - val_accuracy: 0.9663 - val_loss: 0.1103\n",
      "Epoch 514/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9540 - loss: 0.1127 - val_accuracy: 0.9684 - val_loss: 0.1073\n",
      "Epoch 515/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9555 - loss: 0.1108 - val_accuracy: 0.9663 - val_loss: 0.1078\n",
      "Epoch 516/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9580 - loss: 0.1127 - val_accuracy: 0.9633 - val_loss: 0.1088\n",
      "Epoch 517/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9613 - loss: 0.0993 - val_accuracy: 0.9643 - val_loss: 0.1099\n",
      "Epoch 518/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9551 - loss: 0.1130 - val_accuracy: 0.9653 - val_loss: 0.1082\n",
      "Epoch 519/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9572 - loss: 0.1131 - val_accuracy: 0.9633 - val_loss: 0.1078\n",
      "Epoch 520/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9568 - loss: 0.1171 - val_accuracy: 0.9633 - val_loss: 0.1100\n",
      "Epoch 521/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9633 - loss: 0.1028 - val_accuracy: 0.9653 - val_loss: 0.1094\n",
      "Epoch 522/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9566 - loss: 0.1108 - val_accuracy: 0.9633 - val_loss: 0.1099\n",
      "Epoch 523/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9639 - loss: 0.0961 - val_accuracy: 0.9633 - val_loss: 0.1099\n",
      "Epoch 524/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9591 - loss: 0.1014 - val_accuracy: 0.9592 - val_loss: 0.1136\n",
      "Epoch 525/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9600 - loss: 0.1079 - val_accuracy: 0.9633 - val_loss: 0.1146\n",
      "Epoch 526/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9610 - loss: 0.1040 - val_accuracy: 0.9633 - val_loss: 0.1108\n",
      "Epoch 527/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9608 - loss: 0.1011 - val_accuracy: 0.9653 - val_loss: 0.1098\n",
      "Epoch 528/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9614 - loss: 0.0972 - val_accuracy: 0.9643 - val_loss: 0.1126\n",
      "Epoch 529/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9603 - loss: 0.1091 - val_accuracy: 0.9643 - val_loss: 0.1104\n",
      "Epoch 530/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9579 - loss: 0.1150 - val_accuracy: 0.9622 - val_loss: 0.1102\n",
      "Epoch 531/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9573 - loss: 0.1087 - val_accuracy: 0.9622 - val_loss: 0.1132\n",
      "Epoch 532/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9527 - loss: 0.1144 - val_accuracy: 0.9622 - val_loss: 0.1136\n",
      "Epoch 533/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9625 - loss: 0.1064 - val_accuracy: 0.9622 - val_loss: 0.1114\n",
      "Epoch 534/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9611 - loss: 0.1026 - val_accuracy: 0.9633 - val_loss: 0.1145\n",
      "Epoch 535/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9555 - loss: 0.1194 - val_accuracy: 0.9633 - val_loss: 0.1093\n",
      "Epoch 536/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9597 - loss: 0.1093 - val_accuracy: 0.9643 - val_loss: 0.1112\n",
      "Epoch 537/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9621 - loss: 0.1006 - val_accuracy: 0.9653 - val_loss: 0.1082\n",
      "Epoch 538/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9584 - loss: 0.1047 - val_accuracy: 0.9633 - val_loss: 0.1174\n",
      "Epoch 539/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9582 - loss: 0.1086 - val_accuracy: 0.9633 - val_loss: 0.1105\n",
      "Epoch 540/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9640 - loss: 0.1028 - val_accuracy: 0.9643 - val_loss: 0.1100\n",
      "Epoch 541/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9600 - loss: 0.1056 - val_accuracy: 0.9612 - val_loss: 0.1102\n",
      "Epoch 542/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9629 - loss: 0.1062 - val_accuracy: 0.9653 - val_loss: 0.1105\n",
      "Epoch 543/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9583 - loss: 0.1076 - val_accuracy: 0.9622 - val_loss: 0.1134\n",
      "Epoch 544/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9620 - loss: 0.1037 - val_accuracy: 0.9643 - val_loss: 0.1106\n",
      "Epoch 545/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9634 - loss: 0.0981 - val_accuracy: 0.9633 - val_loss: 0.1122\n",
      "Epoch 546/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9590 - loss: 0.1023 - val_accuracy: 0.9633 - val_loss: 0.1097\n",
      "Epoch 547/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9601 - loss: 0.0978 - val_accuracy: 0.9663 - val_loss: 0.1098\n",
      "Epoch 548/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9580 - loss: 0.1032 - val_accuracy: 0.9653 - val_loss: 0.1081\n",
      "Epoch 549/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9577 - loss: 0.1143 - val_accuracy: 0.9653 - val_loss: 0.1149\n",
      "Epoch 550/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9653 - loss: 0.0899 - val_accuracy: 0.9633 - val_loss: 0.1180\n",
      "Epoch 551/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9604 - loss: 0.1058 - val_accuracy: 0.9622 - val_loss: 0.1095\n",
      "Epoch 552/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9580 - loss: 0.1121 - val_accuracy: 0.9622 - val_loss: 0.1076\n",
      "Epoch 553/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9542 - loss: 0.1087 - val_accuracy: 0.9633 - val_loss: 0.1070\n",
      "Epoch 554/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9589 - loss: 0.1097 - val_accuracy: 0.9663 - val_loss: 0.1102\n",
      "Epoch 555/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9576 - loss: 0.1036 - val_accuracy: 0.9643 - val_loss: 0.1115\n",
      "Epoch 556/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9546 - loss: 0.1172 - val_accuracy: 0.9653 - val_loss: 0.1082\n",
      "Epoch 557/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9634 - loss: 0.0949 - val_accuracy: 0.9643 - val_loss: 0.1086\n",
      "Epoch 558/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9558 - loss: 0.1143 - val_accuracy: 0.9633 - val_loss: 0.1082\n",
      "Epoch 559/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9584 - loss: 0.1128 - val_accuracy: 0.9633 - val_loss: 0.1108\n",
      "Epoch 560/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9598 - loss: 0.1133 - val_accuracy: 0.9643 - val_loss: 0.1122\n",
      "Epoch 561/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9617 - loss: 0.1074 - val_accuracy: 0.9643 - val_loss: 0.1131\n",
      "Epoch 562/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9602 - loss: 0.0973 - val_accuracy: 0.9612 - val_loss: 0.1119\n",
      "Epoch 563/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9557 - loss: 0.1156 - val_accuracy: 0.9643 - val_loss: 0.1123\n",
      "Epoch 564/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9586 - loss: 0.1142 - val_accuracy: 0.9633 - val_loss: 0.1129\n",
      "Epoch 565/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9623 - loss: 0.1018 - val_accuracy: 0.9582 - val_loss: 0.1113\n",
      "Epoch 566/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9638 - loss: 0.0952 - val_accuracy: 0.9622 - val_loss: 0.1168\n",
      "Epoch 567/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9589 - loss: 0.1068 - val_accuracy: 0.9653 - val_loss: 0.1114\n",
      "Epoch 568/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9595 - loss: 0.1031 - val_accuracy: 0.9663 - val_loss: 0.1116\n",
      "Epoch 569/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9571 - loss: 0.1079 - val_accuracy: 0.9622 - val_loss: 0.1119\n",
      "Epoch 570/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9560 - loss: 0.1142 - val_accuracy: 0.9612 - val_loss: 0.1166\n",
      "Epoch 571/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9620 - loss: 0.1035 - val_accuracy: 0.9602 - val_loss: 0.1144\n",
      "Epoch 572/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9535 - loss: 0.1132 - val_accuracy: 0.9684 - val_loss: 0.1113\n",
      "Epoch 573/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9606 - loss: 0.1057 - val_accuracy: 0.9643 - val_loss: 0.1168\n",
      "Epoch 574/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9627 - loss: 0.1013 - val_accuracy: 0.9643 - val_loss: 0.1141\n",
      "Epoch 575/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9594 - loss: 0.1102 - val_accuracy: 0.9633 - val_loss: 0.1161\n",
      "Epoch 576/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9567 - loss: 0.1149 - val_accuracy: 0.9622 - val_loss: 0.1148\n",
      "Epoch 577/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9582 - loss: 0.1168 - val_accuracy: 0.9643 - val_loss: 0.1117\n",
      "Epoch 578/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9572 - loss: 0.1107 - val_accuracy: 0.9622 - val_loss: 0.1169\n",
      "Epoch 579/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9588 - loss: 0.1113 - val_accuracy: 0.9633 - val_loss: 0.1138\n",
      "Epoch 580/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9605 - loss: 0.1029 - val_accuracy: 0.9612 - val_loss: 0.1124\n",
      "Epoch 581/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9585 - loss: 0.1135 - val_accuracy: 0.9643 - val_loss: 0.1132\n",
      "Epoch 582/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9602 - loss: 0.1071 - val_accuracy: 0.9592 - val_loss: 0.1081\n",
      "Epoch 583/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9610 - loss: 0.1132 - val_accuracy: 0.9643 - val_loss: 0.1071\n",
      "Epoch 584/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9503 - loss: 0.1237 - val_accuracy: 0.9663 - val_loss: 0.1084\n",
      "Epoch 585/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9625 - loss: 0.1011 - val_accuracy: 0.9653 - val_loss: 0.1068\n",
      "Epoch 586/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9645 - loss: 0.0943 - val_accuracy: 0.9643 - val_loss: 0.1070\n",
      "Epoch 587/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9598 - loss: 0.0992 - val_accuracy: 0.9643 - val_loss: 0.1077\n",
      "Epoch 588/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9593 - loss: 0.1096 - val_accuracy: 0.9643 - val_loss: 0.1093\n",
      "Epoch 589/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9661 - loss: 0.0887 - val_accuracy: 0.9653 - val_loss: 0.1072\n",
      "Epoch 590/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9624 - loss: 0.1081 - val_accuracy: 0.9633 - val_loss: 0.1101\n",
      "Epoch 591/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9642 - loss: 0.0887 - val_accuracy: 0.9653 - val_loss: 0.1140\n",
      "Epoch 592/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9579 - loss: 0.1059 - val_accuracy: 0.9653 - val_loss: 0.1142\n",
      "Epoch 593/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9647 - loss: 0.0932 - val_accuracy: 0.9633 - val_loss: 0.1112\n",
      "Epoch 594/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9611 - loss: 0.1021 - val_accuracy: 0.9663 - val_loss: 0.1092\n",
      "Epoch 595/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9577 - loss: 0.1114 - val_accuracy: 0.9653 - val_loss: 0.1025\n",
      "Epoch 596/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9618 - loss: 0.0990 - val_accuracy: 0.9684 - val_loss: 0.1069\n",
      "Epoch 597/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9576 - loss: 0.1150 - val_accuracy: 0.9684 - val_loss: 0.1078\n",
      "Epoch 598/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9657 - loss: 0.0931 - val_accuracy: 0.9673 - val_loss: 0.1073\n",
      "Epoch 599/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9580 - loss: 0.1111 - val_accuracy: 0.9694 - val_loss: 0.1116\n",
      "Epoch 600/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9526 - loss: 0.1140 - val_accuracy: 0.9663 - val_loss: 0.1063\n",
      "Epoch 601/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9609 - loss: 0.1034 - val_accuracy: 0.9653 - val_loss: 0.1101\n",
      "Epoch 602/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9608 - loss: 0.1090 - val_accuracy: 0.9684 - val_loss: 0.1097\n",
      "Epoch 603/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9650 - loss: 0.0946 - val_accuracy: 0.9663 - val_loss: 0.1051\n",
      "Epoch 604/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9637 - loss: 0.1065 - val_accuracy: 0.9663 - val_loss: 0.1076\n",
      "Epoch 605/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9626 - loss: 0.0998 - val_accuracy: 0.9673 - val_loss: 0.1069\n",
      "Epoch 606/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9567 - loss: 0.1159 - val_accuracy: 0.9633 - val_loss: 0.1069\n",
      "Epoch 607/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9629 - loss: 0.0980 - val_accuracy: 0.9643 - val_loss: 0.1072\n",
      "Epoch 608/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9638 - loss: 0.0999 - val_accuracy: 0.9653 - val_loss: 0.1063\n",
      "Epoch 609/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9585 - loss: 0.1041 - val_accuracy: 0.9612 - val_loss: 0.1092\n",
      "Epoch 610/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9596 - loss: 0.1011 - val_accuracy: 0.9653 - val_loss: 0.1095\n",
      "Epoch 611/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9569 - loss: 0.1131 - val_accuracy: 0.9633 - val_loss: 0.1064\n",
      "Epoch 612/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9613 - loss: 0.0986 - val_accuracy: 0.9673 - val_loss: 0.1046\n",
      "Epoch 613/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9642 - loss: 0.1086 - val_accuracy: 0.9663 - val_loss: 0.1101\n",
      "Epoch 614/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9616 - loss: 0.1075 - val_accuracy: 0.9643 - val_loss: 0.1070\n",
      "Epoch 615/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9580 - loss: 0.1140 - val_accuracy: 0.9673 - val_loss: 0.1075\n",
      "Epoch 616/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9582 - loss: 0.0997 - val_accuracy: 0.9673 - val_loss: 0.1059\n",
      "Epoch 617/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9602 - loss: 0.0978 - val_accuracy: 0.9643 - val_loss: 0.1043\n",
      "Epoch 618/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9602 - loss: 0.1046 - val_accuracy: 0.9663 - val_loss: 0.1066\n",
      "Epoch 619/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9637 - loss: 0.1003 - val_accuracy: 0.9663 - val_loss: 0.1067\n",
      "Epoch 620/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9647 - loss: 0.0905 - val_accuracy: 0.9653 - val_loss: 0.1073\n",
      "Epoch 621/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9628 - loss: 0.0897 - val_accuracy: 0.9622 - val_loss: 0.1145\n",
      "Epoch 622/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9638 - loss: 0.0970 - val_accuracy: 0.9673 - val_loss: 0.1074\n",
      "Epoch 623/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9650 - loss: 0.0947 - val_accuracy: 0.9684 - val_loss: 0.1111\n",
      "Epoch 624/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9545 - loss: 0.1217 - val_accuracy: 0.9663 - val_loss: 0.1059\n",
      "Epoch 625/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9634 - loss: 0.0949 - val_accuracy: 0.9663 - val_loss: 0.1091\n",
      "Epoch 626/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9608 - loss: 0.1005 - val_accuracy: 0.9663 - val_loss: 0.1105\n",
      "Epoch 627/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9555 - loss: 0.1161 - val_accuracy: 0.9633 - val_loss: 0.1121\n",
      "Epoch 628/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9595 - loss: 0.1069 - val_accuracy: 0.9673 - val_loss: 0.1105\n",
      "Epoch 629/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9534 - loss: 0.1243 - val_accuracy: 0.9673 - val_loss: 0.1083\n",
      "Epoch 630/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9572 - loss: 0.1086 - val_accuracy: 0.9653 - val_loss: 0.1145\n",
      "Epoch 631/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9618 - loss: 0.1052 - val_accuracy: 0.9653 - val_loss: 0.1095\n",
      "Epoch 632/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9669 - loss: 0.0909 - val_accuracy: 0.9643 - val_loss: 0.1051\n",
      "Epoch 633/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9611 - loss: 0.1067 - val_accuracy: 0.9653 - val_loss: 0.1056\n",
      "Epoch 634/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9632 - loss: 0.0950 - val_accuracy: 0.9653 - val_loss: 0.1071\n",
      "Epoch 635/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9642 - loss: 0.0998 - val_accuracy: 0.9663 - val_loss: 0.1086\n",
      "Epoch 636/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9589 - loss: 0.1029 - val_accuracy: 0.9653 - val_loss: 0.1068\n",
      "Epoch 637/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9572 - loss: 0.1039 - val_accuracy: 0.9673 - val_loss: 0.1117\n",
      "Epoch 638/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9621 - loss: 0.1079 - val_accuracy: 0.9653 - val_loss: 0.1083\n",
      "Epoch 639/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9618 - loss: 0.0955 - val_accuracy: 0.9663 - val_loss: 0.1098\n",
      "Epoch 640/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9573 - loss: 0.1070 - val_accuracy: 0.9633 - val_loss: 0.1133\n",
      "Epoch 641/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9618 - loss: 0.1001 - val_accuracy: 0.9694 - val_loss: 0.1111\n",
      "Epoch 642/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9628 - loss: 0.0992 - val_accuracy: 0.9663 - val_loss: 0.1062\n",
      "Epoch 643/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9649 - loss: 0.0936 - val_accuracy: 0.9663 - val_loss: 0.1090\n",
      "Epoch 644/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9565 - loss: 0.1149 - val_accuracy: 0.9663 - val_loss: 0.1036\n",
      "Epoch 645/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9628 - loss: 0.0970 - val_accuracy: 0.9663 - val_loss: 0.1094\n",
      "Epoch 646/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9565 - loss: 0.1045 - val_accuracy: 0.9684 - val_loss: 0.1096\n",
      "Epoch 647/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9640 - loss: 0.1024 - val_accuracy: 0.9663 - val_loss: 0.1102\n",
      "Epoch 648/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9656 - loss: 0.0909 - val_accuracy: 0.9704 - val_loss: 0.1103\n",
      "Epoch 649/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9586 - loss: 0.1117 - val_accuracy: 0.9673 - val_loss: 0.1071\n",
      "Epoch 650/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9591 - loss: 0.1047 - val_accuracy: 0.9663 - val_loss: 0.1102\n",
      "Epoch 651/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9551 - loss: 0.1079 - val_accuracy: 0.9704 - val_loss: 0.1119\n",
      "Epoch 652/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9590 - loss: 0.1033 - val_accuracy: 0.9663 - val_loss: 0.1102\n",
      "Epoch 653/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9601 - loss: 0.1035 - val_accuracy: 0.9653 - val_loss: 0.1122\n",
      "Epoch 654/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9601 - loss: 0.1023 - val_accuracy: 0.9653 - val_loss: 0.1076\n",
      "Epoch 655/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9597 - loss: 0.1095 - val_accuracy: 0.9673 - val_loss: 0.1093\n",
      "Epoch 656/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9609 - loss: 0.1029 - val_accuracy: 0.9673 - val_loss: 0.1077\n",
      "Epoch 657/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9611 - loss: 0.1066 - val_accuracy: 0.9663 - val_loss: 0.1063\n",
      "Epoch 658/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9624 - loss: 0.0979 - val_accuracy: 0.9673 - val_loss: 0.1063\n",
      "Epoch 659/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9603 - loss: 0.1056 - val_accuracy: 0.9684 - val_loss: 0.1050\n",
      "Epoch 660/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9619 - loss: 0.1020 - val_accuracy: 0.9673 - val_loss: 0.1087\n",
      "Epoch 661/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9637 - loss: 0.0981 - val_accuracy: 0.9694 - val_loss: 0.1071\n",
      "Epoch 662/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9611 - loss: 0.1092 - val_accuracy: 0.9684 - val_loss: 0.1093\n",
      "Epoch 663/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9614 - loss: 0.0999 - val_accuracy: 0.9684 - val_loss: 0.1061\n",
      "Epoch 664/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9615 - loss: 0.1113 - val_accuracy: 0.9663 - val_loss: 0.1047\n",
      "Epoch 665/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9592 - loss: 0.1022 - val_accuracy: 0.9673 - val_loss: 0.1076\n",
      "Epoch 666/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9618 - loss: 0.1032 - val_accuracy: 0.9673 - val_loss: 0.1078\n",
      "Epoch 667/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9599 - loss: 0.1059 - val_accuracy: 0.9653 - val_loss: 0.1091\n",
      "Epoch 668/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9617 - loss: 0.1033 - val_accuracy: 0.9673 - val_loss: 0.1082\n",
      "Epoch 669/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9583 - loss: 0.1132 - val_accuracy: 0.9663 - val_loss: 0.1108\n",
      "Epoch 670/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9658 - loss: 0.0929 - val_accuracy: 0.9622 - val_loss: 0.1112\n",
      "Epoch 671/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9652 - loss: 0.0974 - val_accuracy: 0.9673 - val_loss: 0.1078\n",
      "Epoch 672/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9651 - loss: 0.0942 - val_accuracy: 0.9694 - val_loss: 0.1084\n",
      "Epoch 673/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9617 - loss: 0.1103 - val_accuracy: 0.9663 - val_loss: 0.1075\n",
      "Epoch 674/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9592 - loss: 0.1006 - val_accuracy: 0.9653 - val_loss: 0.1117\n",
      "Epoch 675/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9623 - loss: 0.1006 - val_accuracy: 0.9653 - val_loss: 0.1094\n",
      "Epoch 676/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9611 - loss: 0.1058 - val_accuracy: 0.9684 - val_loss: 0.1061\n",
      "Epoch 677/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9596 - loss: 0.1131 - val_accuracy: 0.9684 - val_loss: 0.1103\n",
      "Epoch 678/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9642 - loss: 0.0950 - val_accuracy: 0.9673 - val_loss: 0.1047\n",
      "Epoch 679/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9596 - loss: 0.1098 - val_accuracy: 0.9643 - val_loss: 0.1041\n",
      "Epoch 680/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9641 - loss: 0.0993 - val_accuracy: 0.9633 - val_loss: 0.1178\n",
      "Epoch 681/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9582 - loss: 0.1062 - val_accuracy: 0.9653 - val_loss: 0.1075\n",
      "Epoch 682/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9624 - loss: 0.1091 - val_accuracy: 0.9653 - val_loss: 0.1047\n",
      "Epoch 683/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9613 - loss: 0.0915 - val_accuracy: 0.9653 - val_loss: 0.1044\n",
      "Epoch 684/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9641 - loss: 0.1020 - val_accuracy: 0.9673 - val_loss: 0.1037\n",
      "Epoch 685/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9604 - loss: 0.1091 - val_accuracy: 0.9673 - val_loss: 0.1046\n",
      "Epoch 686/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9656 - loss: 0.0974 - val_accuracy: 0.9663 - val_loss: 0.1028\n",
      "Epoch 687/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9635 - loss: 0.1043 - val_accuracy: 0.9684 - val_loss: 0.1042\n",
      "Epoch 688/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9577 - loss: 0.1094 - val_accuracy: 0.9643 - val_loss: 0.1075\n",
      "Epoch 689/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9596 - loss: 0.1023 - val_accuracy: 0.9643 - val_loss: 0.1033\n",
      "Epoch 690/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9598 - loss: 0.1068 - val_accuracy: 0.9694 - val_loss: 0.1006\n",
      "Epoch 691/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9613 - loss: 0.1073 - val_accuracy: 0.9694 - val_loss: 0.1008\n",
      "Epoch 692/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9628 - loss: 0.0963 - val_accuracy: 0.9704 - val_loss: 0.0982\n",
      "Epoch 693/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9569 - loss: 0.1061 - val_accuracy: 0.9694 - val_loss: 0.1036\n",
      "Epoch 694/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9626 - loss: 0.0999 - val_accuracy: 0.9714 - val_loss: 0.1046\n",
      "Epoch 695/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9576 - loss: 0.1084 - val_accuracy: 0.9673 - val_loss: 0.1009\n",
      "Epoch 696/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9627 - loss: 0.0954 - val_accuracy: 0.9694 - val_loss: 0.1027\n",
      "Epoch 697/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9609 - loss: 0.1062 - val_accuracy: 0.9653 - val_loss: 0.1042\n",
      "Epoch 698/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9612 - loss: 0.0961 - val_accuracy: 0.9653 - val_loss: 0.1053\n",
      "Epoch 699/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9612 - loss: 0.0997 - val_accuracy: 0.9643 - val_loss: 0.1070\n",
      "Epoch 700/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9591 - loss: 0.1086 - val_accuracy: 0.9684 - val_loss: 0.1035\n",
      "Epoch 701/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9591 - loss: 0.1134 - val_accuracy: 0.9684 - val_loss: 0.1050\n",
      "Epoch 702/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9536 - loss: 0.1228 - val_accuracy: 0.9694 - val_loss: 0.1057\n",
      "Epoch 703/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9627 - loss: 0.1037 - val_accuracy: 0.9663 - val_loss: 0.1044\n",
      "Epoch 704/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9643 - loss: 0.1046 - val_accuracy: 0.9653 - val_loss: 0.1098\n",
      "Epoch 705/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9598 - loss: 0.1021 - val_accuracy: 0.9663 - val_loss: 0.1049\n",
      "Epoch 706/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9600 - loss: 0.1002 - val_accuracy: 0.9653 - val_loss: 0.1088\n",
      "Epoch 707/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9572 - loss: 0.1048 - val_accuracy: 0.9622 - val_loss: 0.1150\n",
      "Epoch 708/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9658 - loss: 0.0934 - val_accuracy: 0.9653 - val_loss: 0.1042\n",
      "Epoch 709/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9623 - loss: 0.1037 - val_accuracy: 0.9643 - val_loss: 0.1078\n",
      "Epoch 710/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9615 - loss: 0.0988 - val_accuracy: 0.9633 - val_loss: 0.1124\n",
      "Epoch 711/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9611 - loss: 0.0963 - val_accuracy: 0.9684 - val_loss: 0.1071\n",
      "Epoch 712/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9622 - loss: 0.0986 - val_accuracy: 0.9643 - val_loss: 0.1037\n",
      "Epoch 713/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9598 - loss: 0.1038 - val_accuracy: 0.9643 - val_loss: 0.1123\n",
      "Epoch 714/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9632 - loss: 0.0990 - val_accuracy: 0.9673 - val_loss: 0.1070\n",
      "Epoch 715/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9581 - loss: 0.1033 - val_accuracy: 0.9694 - val_loss: 0.1087\n",
      "Epoch 716/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9624 - loss: 0.0996 - val_accuracy: 0.9663 - val_loss: 0.1079\n",
      "Epoch 717/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9657 - loss: 0.0921 - val_accuracy: 0.9663 - val_loss: 0.1064\n",
      "Epoch 718/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9620 - loss: 0.1056 - val_accuracy: 0.9673 - val_loss: 0.1043\n",
      "Epoch 719/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9604 - loss: 0.1097 - val_accuracy: 0.9663 - val_loss: 0.1035\n",
      "Epoch 720/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9577 - loss: 0.1139 - val_accuracy: 0.9653 - val_loss: 0.1089\n",
      "Epoch 721/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9610 - loss: 0.1075 - val_accuracy: 0.9653 - val_loss: 0.1148\n",
      "Epoch 722/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9603 - loss: 0.1086 - val_accuracy: 0.9633 - val_loss: 0.1036\n",
      "Epoch 723/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9626 - loss: 0.1053 - val_accuracy: 0.9653 - val_loss: 0.1105\n",
      "Epoch 724/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9617 - loss: 0.0994 - val_accuracy: 0.9673 - val_loss: 0.1072\n",
      "Epoch 725/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9649 - loss: 0.1011 - val_accuracy: 0.9643 - val_loss: 0.1072\n",
      "Epoch 726/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9589 - loss: 0.1056 - val_accuracy: 0.9653 - val_loss: 0.1084\n",
      "Epoch 727/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9633 - loss: 0.0965 - val_accuracy: 0.9673 - val_loss: 0.1045\n",
      "Epoch 728/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9579 - loss: 0.1111 - val_accuracy: 0.9663 - val_loss: 0.0997\n",
      "Epoch 729/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9625 - loss: 0.1006 - val_accuracy: 0.9653 - val_loss: 0.1044\n",
      "Epoch 730/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9589 - loss: 0.1106 - val_accuracy: 0.9673 - val_loss: 0.1048\n",
      "Epoch 731/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9615 - loss: 0.0999 - val_accuracy: 0.9653 - val_loss: 0.1063\n",
      "Epoch 732/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9569 - loss: 0.1121 - val_accuracy: 0.9612 - val_loss: 0.1203\n",
      "Epoch 733/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9603 - loss: 0.1097 - val_accuracy: 0.9653 - val_loss: 0.1065\n",
      "Epoch 734/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9599 - loss: 0.1037 - val_accuracy: 0.9643 - val_loss: 0.1091\n",
      "Epoch 735/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9580 - loss: 0.1067 - val_accuracy: 0.9643 - val_loss: 0.1137\n",
      "Epoch 736/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9628 - loss: 0.1018 - val_accuracy: 0.9653 - val_loss: 0.1029\n",
      "Epoch 737/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9641 - loss: 0.0989 - val_accuracy: 0.9633 - val_loss: 0.1041\n",
      "Epoch 738/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9618 - loss: 0.0986 - val_accuracy: 0.9673 - val_loss: 0.1077\n",
      "Epoch 739/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9641 - loss: 0.0914 - val_accuracy: 0.9663 - val_loss: 0.1100\n",
      "Epoch 740/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9642 - loss: 0.0958 - val_accuracy: 0.9653 - val_loss: 0.1078\n",
      "Epoch 741/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9589 - loss: 0.1079 - val_accuracy: 0.9612 - val_loss: 0.1095\n",
      "Epoch 742/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9646 - loss: 0.0969 - val_accuracy: 0.9653 - val_loss: 0.1095\n",
      "Epoch 743/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9623 - loss: 0.1077 - val_accuracy: 0.9633 - val_loss: 0.1078\n",
      "Epoch 744/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9626 - loss: 0.1025 - val_accuracy: 0.9653 - val_loss: 0.1052\n",
      "Epoch 745/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9646 - loss: 0.0942 - val_accuracy: 0.9663 - val_loss: 0.1050\n",
      "Epoch 746/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9593 - loss: 0.1025 - val_accuracy: 0.9663 - val_loss: 0.1085\n",
      "Epoch 747/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9634 - loss: 0.0924 - val_accuracy: 0.9673 - val_loss: 0.1080\n",
      "Epoch 748/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9649 - loss: 0.0969 - val_accuracy: 0.9663 - val_loss: 0.1097\n",
      "Epoch 749/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9589 - loss: 0.1067 - val_accuracy: 0.9653 - val_loss: 0.1120\n",
      "Epoch 750/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9601 - loss: 0.1071 - val_accuracy: 0.9653 - val_loss: 0.1114\n",
      "Epoch 751/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9603 - loss: 0.1113 - val_accuracy: 0.9633 - val_loss: 0.1058\n",
      "Epoch 752/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9537 - loss: 0.1275 - val_accuracy: 0.9643 - val_loss: 0.1099\n",
      "Epoch 753/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9601 - loss: 0.1104 - val_accuracy: 0.9633 - val_loss: 0.1078\n",
      "Epoch 754/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9634 - loss: 0.0948 - val_accuracy: 0.9663 - val_loss: 0.1074\n",
      "Epoch 755/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9583 - loss: 0.1098 - val_accuracy: 0.9643 - val_loss: 0.1102\n",
      "Epoch 756/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9632 - loss: 0.0959 - val_accuracy: 0.9653 - val_loss: 0.1077\n",
      "Epoch 757/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9664 - loss: 0.0880 - val_accuracy: 0.9673 - val_loss: 0.1115\n",
      "Epoch 758/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9634 - loss: 0.0893 - val_accuracy: 0.9633 - val_loss: 0.1101\n",
      "Epoch 759/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9615 - loss: 0.0948 - val_accuracy: 0.9612 - val_loss: 0.1099\n",
      "Epoch 760/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9633 - loss: 0.1015 - val_accuracy: 0.9643 - val_loss: 0.1124\n",
      "Epoch 761/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9644 - loss: 0.0994 - val_accuracy: 0.9592 - val_loss: 0.1217\n",
      "Epoch 762/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9562 - loss: 0.1075 - val_accuracy: 0.9643 - val_loss: 0.1125\n",
      "Epoch 763/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9621 - loss: 0.0977 - val_accuracy: 0.9633 - val_loss: 0.1080\n",
      "Epoch 764/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9638 - loss: 0.1049 - val_accuracy: 0.9643 - val_loss: 0.1111\n",
      "Epoch 765/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9616 - loss: 0.1055 - val_accuracy: 0.9663 - val_loss: 0.1056\n",
      "Epoch 766/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9626 - loss: 0.0993 - val_accuracy: 0.9653 - val_loss: 0.1065\n",
      "Epoch 767/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9592 - loss: 0.1020 - val_accuracy: 0.9653 - val_loss: 0.1072\n",
      "Epoch 768/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9635 - loss: 0.1004 - val_accuracy: 0.9663 - val_loss: 0.1076\n",
      "Epoch 769/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9644 - loss: 0.0973 - val_accuracy: 0.9663 - val_loss: 0.1074\n",
      "Epoch 770/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9597 - loss: 0.1063 - val_accuracy: 0.9633 - val_loss: 0.1080\n",
      "Epoch 771/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9616 - loss: 0.1075 - val_accuracy: 0.9673 - val_loss: 0.1094\n",
      "Epoch 772/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9613 - loss: 0.1021 - val_accuracy: 0.9673 - val_loss: 0.1084\n",
      "Epoch 773/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9565 - loss: 0.1135 - val_accuracy: 0.9602 - val_loss: 0.1085\n",
      "Epoch 774/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9627 - loss: 0.0946 - val_accuracy: 0.9653 - val_loss: 0.1073\n",
      "Epoch 775/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9670 - loss: 0.0965 - val_accuracy: 0.9663 - val_loss: 0.1075\n",
      "Epoch 776/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9597 - loss: 0.1127 - val_accuracy: 0.9684 - val_loss: 0.1070\n",
      "Epoch 777/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9549 - loss: 0.1134 - val_accuracy: 0.9643 - val_loss: 0.1065\n",
      "Epoch 778/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9626 - loss: 0.1057 - val_accuracy: 0.9643 - val_loss: 0.1058\n",
      "Epoch 779/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9608 - loss: 0.1012 - val_accuracy: 0.9653 - val_loss: 0.1069\n",
      "Epoch 780/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9573 - loss: 0.1172 - val_accuracy: 0.9663 - val_loss: 0.1071\n",
      "Epoch 781/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9663 - loss: 0.0943 - val_accuracy: 0.9663 - val_loss: 0.1084\n",
      "Epoch 782/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9585 - loss: 0.1112 - val_accuracy: 0.9673 - val_loss: 0.1117\n",
      "Epoch 783/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9624 - loss: 0.0985 - val_accuracy: 0.9663 - val_loss: 0.1081\n",
      "Epoch 784/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9577 - loss: 0.1070 - val_accuracy: 0.9663 - val_loss: 0.1084\n",
      "Epoch 785/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9588 - loss: 0.1075 - val_accuracy: 0.9643 - val_loss: 0.1085\n",
      "Epoch 786/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9588 - loss: 0.1048 - val_accuracy: 0.9694 - val_loss: 0.1069\n",
      "Epoch 787/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9666 - loss: 0.0933 - val_accuracy: 0.9673 - val_loss: 0.1082\n",
      "Epoch 788/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9629 - loss: 0.0984 - val_accuracy: 0.9663 - val_loss: 0.1096\n",
      "Epoch 789/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9651 - loss: 0.1033 - val_accuracy: 0.9653 - val_loss: 0.1110\n",
      "Epoch 790/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9658 - loss: 0.0966 - val_accuracy: 0.9684 - val_loss: 0.1086\n",
      "Epoch 791/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9577 - loss: 0.1098 - val_accuracy: 0.9673 - val_loss: 0.1092\n",
      "Epoch 792/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9669 - loss: 0.0912 - val_accuracy: 0.9612 - val_loss: 0.1152\n",
      "Epoch 793/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9591 - loss: 0.1097 - val_accuracy: 0.9663 - val_loss: 0.1047\n",
      "Epoch 794/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9686 - loss: 0.0838 - val_accuracy: 0.9643 - val_loss: 0.1109\n",
      "Epoch 795/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9594 - loss: 0.1038 - val_accuracy: 0.9643 - val_loss: 0.1072\n",
      "Epoch 796/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9548 - loss: 0.1055 - val_accuracy: 0.9663 - val_loss: 0.1056\n",
      "Epoch 797/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9639 - loss: 0.0958 - val_accuracy: 0.9673 - val_loss: 0.1055\n",
      "Epoch 798/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9600 - loss: 0.1068 - val_accuracy: 0.9673 - val_loss: 0.1057\n",
      "Epoch 799/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9585 - loss: 0.1047 - val_accuracy: 0.9643 - val_loss: 0.1052\n",
      "Epoch 800/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9609 - loss: 0.1038 - val_accuracy: 0.9663 - val_loss: 0.1038\n",
      "Epoch 801/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9621 - loss: 0.0998 - val_accuracy: 0.9663 - val_loss: 0.1069\n",
      "Epoch 802/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9611 - loss: 0.0981 - val_accuracy: 0.9653 - val_loss: 0.1091\n",
      "Epoch 803/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9660 - loss: 0.0896 - val_accuracy: 0.9663 - val_loss: 0.1090\n",
      "Epoch 804/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9562 - loss: 0.1175 - val_accuracy: 0.9704 - val_loss: 0.1036\n",
      "Epoch 805/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9639 - loss: 0.0964 - val_accuracy: 0.9653 - val_loss: 0.1066\n",
      "Epoch 806/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9595 - loss: 0.1043 - val_accuracy: 0.9663 - val_loss: 0.1106\n",
      "Epoch 807/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9607 - loss: 0.0979 - val_accuracy: 0.9653 - val_loss: 0.1047\n",
      "Epoch 808/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9659 - loss: 0.1020 - val_accuracy: 0.9663 - val_loss: 0.1031\n",
      "Epoch 809/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9625 - loss: 0.1074 - val_accuracy: 0.9633 - val_loss: 0.1162\n",
      "Epoch 810/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9625 - loss: 0.0979 - val_accuracy: 0.9643 - val_loss: 0.1088\n",
      "Epoch 811/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9531 - loss: 0.1162 - val_accuracy: 0.9643 - val_loss: 0.1061\n",
      "Epoch 812/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9666 - loss: 0.0893 - val_accuracy: 0.9663 - val_loss: 0.1105\n",
      "Epoch 813/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9652 - loss: 0.0979 - val_accuracy: 0.9663 - val_loss: 0.1115\n",
      "Epoch 814/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9633 - loss: 0.1004 - val_accuracy: 0.9704 - val_loss: 0.1048\n",
      "Epoch 815/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9548 - loss: 0.1195 - val_accuracy: 0.9653 - val_loss: 0.1090\n",
      "Epoch 816/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9658 - loss: 0.1009 - val_accuracy: 0.9673 - val_loss: 0.1118\n",
      "Epoch 817/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9611 - loss: 0.1027 - val_accuracy: 0.9653 - val_loss: 0.1079\n",
      "Epoch 818/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9610 - loss: 0.0999 - val_accuracy: 0.9694 - val_loss: 0.1100\n",
      "Epoch 819/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9624 - loss: 0.1012 - val_accuracy: 0.9653 - val_loss: 0.1110\n",
      "Epoch 820/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9611 - loss: 0.1003 - val_accuracy: 0.9663 - val_loss: 0.1116\n",
      "Epoch 821/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9632 - loss: 0.0999 - val_accuracy: 0.9653 - val_loss: 0.1074\n",
      "Epoch 822/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9594 - loss: 0.1105 - val_accuracy: 0.9633 - val_loss: 0.1072\n",
      "Epoch 823/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9659 - loss: 0.0925 - val_accuracy: 0.9673 - val_loss: 0.1097\n",
      "Epoch 824/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9644 - loss: 0.1050 - val_accuracy: 0.9673 - val_loss: 0.1093\n",
      "Epoch 825/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9632 - loss: 0.1042 - val_accuracy: 0.9653 - val_loss: 0.1107\n",
      "Epoch 826/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9622 - loss: 0.1009 - val_accuracy: 0.9612 - val_loss: 0.1097\n",
      "Epoch 827/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9633 - loss: 0.0971 - val_accuracy: 0.9663 - val_loss: 0.1087\n",
      "Epoch 828/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9647 - loss: 0.0921 - val_accuracy: 0.9643 - val_loss: 0.1137\n",
      "Epoch 829/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9571 - loss: 0.1106 - val_accuracy: 0.9673 - val_loss: 0.1083\n",
      "Epoch 830/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9613 - loss: 0.1059 - val_accuracy: 0.9673 - val_loss: 0.1122\n",
      "Epoch 831/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9640 - loss: 0.1001 - val_accuracy: 0.9643 - val_loss: 0.1122\n",
      "Epoch 832/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9601 - loss: 0.1008 - val_accuracy: 0.9633 - val_loss: 0.1091\n",
      "Epoch 833/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9661 - loss: 0.0911 - val_accuracy: 0.9684 - val_loss: 0.1060\n",
      "Epoch 834/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9589 - loss: 0.1069 - val_accuracy: 0.9663 - val_loss: 0.1103\n",
      "Epoch 835/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9607 - loss: 0.1077 - val_accuracy: 0.9653 - val_loss: 0.1090\n",
      "Epoch 836/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9560 - loss: 0.1026 - val_accuracy: 0.9653 - val_loss: 0.1079\n",
      "Epoch 837/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9652 - loss: 0.0977 - val_accuracy: 0.9684 - val_loss: 0.1109\n",
      "Epoch 838/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9626 - loss: 0.1044 - val_accuracy: 0.9673 - val_loss: 0.1093\n",
      "Epoch 839/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9665 - loss: 0.0971 - val_accuracy: 0.9633 - val_loss: 0.1111\n",
      "Epoch 840/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9660 - loss: 0.0887 - val_accuracy: 0.9653 - val_loss: 0.1065\n",
      "Epoch 841/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9644 - loss: 0.0989 - val_accuracy: 0.9653 - val_loss: 0.1055\n",
      "Epoch 842/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9671 - loss: 0.0917 - val_accuracy: 0.9684 - val_loss: 0.1081\n",
      "Epoch 843/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9571 - loss: 0.1100 - val_accuracy: 0.9673 - val_loss: 0.1102\n",
      "Epoch 844/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9570 - loss: 0.1105 - val_accuracy: 0.9663 - val_loss: 0.1067\n",
      "Epoch 845/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9619 - loss: 0.0960 - val_accuracy: 0.9673 - val_loss: 0.1059\n",
      "Epoch 846/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9602 - loss: 0.0987 - val_accuracy: 0.9653 - val_loss: 0.1128\n",
      "Epoch 847/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9638 - loss: 0.0994 - val_accuracy: 0.9653 - val_loss: 0.1109\n",
      "Epoch 848/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9613 - loss: 0.1059 - val_accuracy: 0.9643 - val_loss: 0.1110\n",
      "Epoch 849/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9615 - loss: 0.0989 - val_accuracy: 0.9673 - val_loss: 0.1148\n",
      "Epoch 850/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9633 - loss: 0.0972 - val_accuracy: 0.9673 - val_loss: 0.1090\n",
      "Epoch 851/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9628 - loss: 0.1053 - val_accuracy: 0.9684 - val_loss: 0.1101\n",
      "Epoch 852/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9575 - loss: 0.1095 - val_accuracy: 0.9653 - val_loss: 0.1078\n",
      "Epoch 853/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9596 - loss: 0.1125 - val_accuracy: 0.9663 - val_loss: 0.1070\n",
      "Epoch 854/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9619 - loss: 0.0979 - val_accuracy: 0.9643 - val_loss: 0.1102\n",
      "Epoch 855/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9613 - loss: 0.1064 - val_accuracy: 0.9643 - val_loss: 0.1099\n",
      "Epoch 856/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9616 - loss: 0.0991 - val_accuracy: 0.9663 - val_loss: 0.1045\n",
      "Epoch 857/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9629 - loss: 0.0921 - val_accuracy: 0.9673 - val_loss: 0.1087\n",
      "Epoch 858/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9627 - loss: 0.1002 - val_accuracy: 0.9694 - val_loss: 0.1082\n",
      "Epoch 859/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9615 - loss: 0.0985 - val_accuracy: 0.9633 - val_loss: 0.1086\n",
      "Epoch 860/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9570 - loss: 0.1020 - val_accuracy: 0.9663 - val_loss: 0.1068\n",
      "Epoch 861/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9577 - loss: 0.1029 - val_accuracy: 0.9704 - val_loss: 0.1112\n",
      "Epoch 862/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9579 - loss: 0.1101 - val_accuracy: 0.9684 - val_loss: 0.1049\n",
      "Epoch 863/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9608 - loss: 0.0948 - val_accuracy: 0.9663 - val_loss: 0.1050\n",
      "Epoch 864/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9644 - loss: 0.0978 - val_accuracy: 0.9684 - val_loss: 0.1040\n",
      "Epoch 865/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9618 - loss: 0.1000 - val_accuracy: 0.9663 - val_loss: 0.1105\n",
      "Epoch 866/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9656 - loss: 0.0938 - val_accuracy: 0.9684 - val_loss: 0.1077\n",
      "Epoch 867/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9583 - loss: 0.1041 - val_accuracy: 0.9643 - val_loss: 0.1061\n",
      "Epoch 868/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9592 - loss: 0.1143 - val_accuracy: 0.9673 - val_loss: 0.1076\n",
      "Epoch 869/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9605 - loss: 0.0970 - val_accuracy: 0.9673 - val_loss: 0.1021\n",
      "Epoch 870/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9630 - loss: 0.0972 - val_accuracy: 0.9653 - val_loss: 0.1087\n",
      "Epoch 871/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9659 - loss: 0.0875 - val_accuracy: 0.9633 - val_loss: 0.1053\n",
      "Epoch 872/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9676 - loss: 0.0925 - val_accuracy: 0.9673 - val_loss: 0.1058\n",
      "Epoch 873/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9599 - loss: 0.1019 - val_accuracy: 0.9684 - val_loss: 0.1095\n",
      "Epoch 874/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9668 - loss: 0.0863 - val_accuracy: 0.9653 - val_loss: 0.1067\n",
      "Epoch 875/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9610 - loss: 0.1065 - val_accuracy: 0.9653 - val_loss: 0.1046\n",
      "Epoch 876/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9625 - loss: 0.0963 - val_accuracy: 0.9684 - val_loss: 0.1083\n",
      "Epoch 877/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9642 - loss: 0.0996 - val_accuracy: 0.9653 - val_loss: 0.1083\n",
      "Epoch 878/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9627 - loss: 0.1094 - val_accuracy: 0.9673 - val_loss: 0.1053\n",
      "Epoch 879/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9632 - loss: 0.0998 - val_accuracy: 0.9673 - val_loss: 0.1031\n",
      "Epoch 880/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9675 - loss: 0.0906 - val_accuracy: 0.9653 - val_loss: 0.1065\n",
      "Epoch 881/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9652 - loss: 0.0946 - val_accuracy: 0.9663 - val_loss: 0.1077\n",
      "Epoch 882/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9609 - loss: 0.0919 - val_accuracy: 0.9673 - val_loss: 0.1077\n",
      "Epoch 883/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9642 - loss: 0.0943 - val_accuracy: 0.9673 - val_loss: 0.1082\n",
      "Epoch 884/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9671 - loss: 0.0883 - val_accuracy: 0.9643 - val_loss: 0.1090\n",
      "Epoch 885/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9592 - loss: 0.1004 - val_accuracy: 0.9663 - val_loss: 0.1074\n",
      "Epoch 886/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9624 - loss: 0.0909 - val_accuracy: 0.9653 - val_loss: 0.1052\n",
      "Epoch 887/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9693 - loss: 0.0923 - val_accuracy: 0.9663 - val_loss: 0.1088\n",
      "Epoch 888/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9647 - loss: 0.0910 - val_accuracy: 0.9663 - val_loss: 0.1069\n",
      "Epoch 889/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9612 - loss: 0.1036 - val_accuracy: 0.9643 - val_loss: 0.1056\n",
      "Epoch 890/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9664 - loss: 0.1032 - val_accuracy: 0.9673 - val_loss: 0.1065\n",
      "Epoch 891/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9598 - loss: 0.1061 - val_accuracy: 0.9653 - val_loss: 0.1073\n",
      "Epoch 892/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9594 - loss: 0.1045 - val_accuracy: 0.9622 - val_loss: 0.1047\n",
      "Epoch 893/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9670 - loss: 0.0891 - val_accuracy: 0.9633 - val_loss: 0.1049\n",
      "Epoch 894/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9643 - loss: 0.0980 - val_accuracy: 0.9643 - val_loss: 0.1026\n",
      "Epoch 895/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9651 - loss: 0.0964 - val_accuracy: 0.9622 - val_loss: 0.1073\n",
      "Epoch 896/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9620 - loss: 0.1035 - val_accuracy: 0.9673 - val_loss: 0.1056\n",
      "Epoch 897/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9632 - loss: 0.1022 - val_accuracy: 0.9663 - val_loss: 0.1043\n",
      "Epoch 898/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9675 - loss: 0.0931 - val_accuracy: 0.9653 - val_loss: 0.1065\n",
      "Epoch 899/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9586 - loss: 0.1024 - val_accuracy: 0.9653 - val_loss: 0.1066\n",
      "Epoch 900/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9595 - loss: 0.1097 - val_accuracy: 0.9633 - val_loss: 0.1058\n",
      "Epoch 901/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9594 - loss: 0.1026 - val_accuracy: 0.9663 - val_loss: 0.1014\n",
      "Epoch 902/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9570 - loss: 0.1114 - val_accuracy: 0.9673 - val_loss: 0.1012\n",
      "Epoch 903/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9643 - loss: 0.0982 - val_accuracy: 0.9643 - val_loss: 0.1062\n",
      "Epoch 904/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9654 - loss: 0.1005 - val_accuracy: 0.9633 - val_loss: 0.1115\n",
      "Epoch 905/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9614 - loss: 0.1001 - val_accuracy: 0.9633 - val_loss: 0.1063\n",
      "Epoch 906/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9640 - loss: 0.0981 - val_accuracy: 0.9643 - val_loss: 0.1054\n",
      "Epoch 907/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9680 - loss: 0.0826 - val_accuracy: 0.9653 - val_loss: 0.1060\n",
      "Epoch 908/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9608 - loss: 0.0942 - val_accuracy: 0.9673 - val_loss: 0.1075\n",
      "Epoch 909/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9680 - loss: 0.0904 - val_accuracy: 0.9663 - val_loss: 0.1106\n",
      "Epoch 910/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9619 - loss: 0.1013 - val_accuracy: 0.9663 - val_loss: 0.1074\n",
      "Epoch 911/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9692 - loss: 0.0905 - val_accuracy: 0.9643 - val_loss: 0.1069\n",
      "Epoch 912/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9658 - loss: 0.0936 - val_accuracy: 0.9653 - val_loss: 0.1071\n",
      "Epoch 913/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9597 - loss: 0.0928 - val_accuracy: 0.9643 - val_loss: 0.1075\n",
      "Epoch 914/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9666 - loss: 0.0913 - val_accuracy: 0.9694 - val_loss: 0.1081\n",
      "Epoch 915/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9630 - loss: 0.1004 - val_accuracy: 0.9663 - val_loss: 0.1126\n",
      "Epoch 916/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9578 - loss: 0.1109 - val_accuracy: 0.9653 - val_loss: 0.1079\n",
      "Epoch 917/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9611 - loss: 0.1080 - val_accuracy: 0.9633 - val_loss: 0.1103\n",
      "Epoch 918/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9640 - loss: 0.0933 - val_accuracy: 0.9633 - val_loss: 0.1079\n",
      "Epoch 919/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9648 - loss: 0.0954 - val_accuracy: 0.9673 - val_loss: 0.1101\n",
      "Epoch 920/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9581 - loss: 0.1108 - val_accuracy: 0.9643 - val_loss: 0.1077\n",
      "Epoch 921/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9639 - loss: 0.0904 - val_accuracy: 0.9633 - val_loss: 0.1071\n",
      "Epoch 922/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9665 - loss: 0.0951 - val_accuracy: 0.9663 - val_loss: 0.1098\n",
      "Epoch 923/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9652 - loss: 0.0953 - val_accuracy: 0.9643 - val_loss: 0.1081\n",
      "Epoch 924/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9645 - loss: 0.0943 - val_accuracy: 0.9673 - val_loss: 0.1142\n",
      "Epoch 925/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9586 - loss: 0.1069 - val_accuracy: 0.9643 - val_loss: 0.1133\n",
      "Epoch 926/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9639 - loss: 0.0958 - val_accuracy: 0.9653 - val_loss: 0.1068\n",
      "Epoch 927/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9605 - loss: 0.0992 - val_accuracy: 0.9684 - val_loss: 0.1067\n",
      "Epoch 928/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9619 - loss: 0.1015 - val_accuracy: 0.9633 - val_loss: 0.1113\n",
      "Epoch 929/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9662 - loss: 0.0837 - val_accuracy: 0.9643 - val_loss: 0.1093\n",
      "Epoch 930/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9656 - loss: 0.0981 - val_accuracy: 0.9643 - val_loss: 0.1094\n",
      "Epoch 931/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9572 - loss: 0.1114 - val_accuracy: 0.9663 - val_loss: 0.1106\n",
      "Epoch 932/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9635 - loss: 0.0975 - val_accuracy: 0.9673 - val_loss: 0.1086\n",
      "Epoch 933/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9617 - loss: 0.1013 - val_accuracy: 0.9643 - val_loss: 0.1123\n",
      "Epoch 934/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9649 - loss: 0.1004 - val_accuracy: 0.9653 - val_loss: 0.1117\n",
      "Epoch 935/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9632 - loss: 0.0926 - val_accuracy: 0.9694 - val_loss: 0.1124\n",
      "Epoch 936/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9642 - loss: 0.0903 - val_accuracy: 0.9684 - val_loss: 0.1105\n",
      "Epoch 937/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9571 - loss: 0.1081 - val_accuracy: 0.9643 - val_loss: 0.1137\n",
      "Epoch 938/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9602 - loss: 0.1026 - val_accuracy: 0.9673 - val_loss: 0.1103\n",
      "Epoch 939/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9670 - loss: 0.0979 - val_accuracy: 0.9673 - val_loss: 0.1125\n",
      "Epoch 940/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9651 - loss: 0.0926 - val_accuracy: 0.9663 - val_loss: 0.1115\n",
      "Epoch 941/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9633 - loss: 0.1022 - val_accuracy: 0.9643 - val_loss: 0.1086\n",
      "Epoch 942/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9642 - loss: 0.0972 - val_accuracy: 0.9663 - val_loss: 0.1139\n",
      "Epoch 943/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9577 - loss: 0.1102 - val_accuracy: 0.9673 - val_loss: 0.1090\n",
      "Epoch 944/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9664 - loss: 0.0934 - val_accuracy: 0.9622 - val_loss: 0.1086\n",
      "Epoch 945/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9653 - loss: 0.0942 - val_accuracy: 0.9633 - val_loss: 0.1126\n",
      "Epoch 946/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9623 - loss: 0.0987 - val_accuracy: 0.9643 - val_loss: 0.1118\n",
      "Epoch 947/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9631 - loss: 0.0956 - val_accuracy: 0.9643 - val_loss: 0.1090\n",
      "Epoch 948/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9653 - loss: 0.1019 - val_accuracy: 0.9663 - val_loss: 0.1095\n",
      "Epoch 949/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9574 - loss: 0.1136 - val_accuracy: 0.9633 - val_loss: 0.1079\n",
      "Epoch 950/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9639 - loss: 0.0968 - val_accuracy: 0.9673 - val_loss: 0.1110\n",
      "Epoch 951/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9628 - loss: 0.0949 - val_accuracy: 0.9643 - val_loss: 0.1060\n",
      "Epoch 952/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9637 - loss: 0.0902 - val_accuracy: 0.9643 - val_loss: 0.1058\n",
      "Epoch 953/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9597 - loss: 0.1150 - val_accuracy: 0.9724 - val_loss: 0.1071\n",
      "Epoch 954/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9638 - loss: 0.0941 - val_accuracy: 0.9633 - val_loss: 0.1050\n",
      "Epoch 955/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9641 - loss: 0.0956 - val_accuracy: 0.9643 - val_loss: 0.1083\n",
      "Epoch 956/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9647 - loss: 0.0897 - val_accuracy: 0.9673 - val_loss: 0.1046\n",
      "Epoch 957/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9604 - loss: 0.1017 - val_accuracy: 0.9653 - val_loss: 0.1117\n",
      "Epoch 958/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9663 - loss: 0.0885 - val_accuracy: 0.9653 - val_loss: 0.1045\n",
      "Epoch 959/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9661 - loss: 0.1035 - val_accuracy: 0.9633 - val_loss: 0.1101\n",
      "Epoch 960/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9650 - loss: 0.0879 - val_accuracy: 0.9643 - val_loss: 0.1077\n",
      "Epoch 961/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9663 - loss: 0.1007 - val_accuracy: 0.9663 - val_loss: 0.1094\n",
      "Epoch 962/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9630 - loss: 0.0986 - val_accuracy: 0.9694 - val_loss: 0.1105\n",
      "Epoch 963/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9565 - loss: 0.1071 - val_accuracy: 0.9643 - val_loss: 0.1066\n",
      "Epoch 964/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9646 - loss: 0.0946 - val_accuracy: 0.9673 - val_loss: 0.1042\n",
      "Epoch 965/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9649 - loss: 0.0946 - val_accuracy: 0.9673 - val_loss: 0.1049\n",
      "Epoch 966/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9600 - loss: 0.1012 - val_accuracy: 0.9694 - val_loss: 0.1074\n",
      "Epoch 967/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9595 - loss: 0.1092 - val_accuracy: 0.9694 - val_loss: 0.1085\n",
      "Epoch 968/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9615 - loss: 0.1042 - val_accuracy: 0.9673 - val_loss: 0.1062\n",
      "Epoch 969/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9645 - loss: 0.1028 - val_accuracy: 0.9673 - val_loss: 0.1073\n",
      "Epoch 970/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9639 - loss: 0.0999 - val_accuracy: 0.9663 - val_loss: 0.1069\n",
      "Epoch 971/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9682 - loss: 0.0909 - val_accuracy: 0.9653 - val_loss: 0.1084\n",
      "Epoch 972/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9695 - loss: 0.0863 - val_accuracy: 0.9643 - val_loss: 0.1071\n",
      "Epoch 973/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9674 - loss: 0.0893 - val_accuracy: 0.9673 - val_loss: 0.1054\n",
      "Epoch 974/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9593 - loss: 0.1068 - val_accuracy: 0.9694 - val_loss: 0.1081\n",
      "Epoch 975/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9631 - loss: 0.0981 - val_accuracy: 0.9694 - val_loss: 0.1080\n",
      "Epoch 976/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9631 - loss: 0.0979 - val_accuracy: 0.9653 - val_loss: 0.1039\n",
      "Epoch 977/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9647 - loss: 0.0945 - val_accuracy: 0.9653 - val_loss: 0.1109\n",
      "Epoch 978/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9657 - loss: 0.1019 - val_accuracy: 0.9704 - val_loss: 0.1069\n",
      "Epoch 979/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9602 - loss: 0.1045 - val_accuracy: 0.9673 - val_loss: 0.1053\n",
      "Epoch 980/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9673 - loss: 0.0940 - val_accuracy: 0.9663 - val_loss: 0.1061\n",
      "Epoch 981/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9641 - loss: 0.0906 - val_accuracy: 0.9663 - val_loss: 0.1077\n",
      "Epoch 982/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9613 - loss: 0.1074 - val_accuracy: 0.9663 - val_loss: 0.1063\n",
      "Epoch 983/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9614 - loss: 0.0997 - val_accuracy: 0.9663 - val_loss: 0.1050\n",
      "Epoch 984/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9632 - loss: 0.0954 - val_accuracy: 0.9653 - val_loss: 0.1026\n",
      "Epoch 985/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9631 - loss: 0.0930 - val_accuracy: 0.9673 - val_loss: 0.1031\n",
      "Epoch 986/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9610 - loss: 0.1026 - val_accuracy: 0.9663 - val_loss: 0.1042\n",
      "Epoch 987/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9660 - loss: 0.0935 - val_accuracy: 0.9663 - val_loss: 0.1064\n",
      "Epoch 988/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9667 - loss: 0.0922 - val_accuracy: 0.9633 - val_loss: 0.1089\n",
      "Epoch 989/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9627 - loss: 0.0965 - val_accuracy: 0.9653 - val_loss: 0.1060\n",
      "Epoch 990/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9697 - loss: 0.0919 - val_accuracy: 0.9633 - val_loss: 0.1070\n",
      "Epoch 991/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9655 - loss: 0.0949 - val_accuracy: 0.9663 - val_loss: 0.1057\n",
      "Epoch 992/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9639 - loss: 0.0969 - val_accuracy: 0.9684 - val_loss: 0.1059\n",
      "Epoch 993/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9667 - loss: 0.0879 - val_accuracy: 0.9653 - val_loss: 0.1062\n",
      "Epoch 994/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9601 - loss: 0.1071 - val_accuracy: 0.9643 - val_loss: 0.1070\n",
      "Epoch 995/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9619 - loss: 0.1094 - val_accuracy: 0.9694 - val_loss: 0.1071\n",
      "Epoch 996/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9634 - loss: 0.0970 - val_accuracy: 0.9694 - val_loss: 0.1057\n",
      "Epoch 997/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9597 - loss: 0.0976 - val_accuracy: 0.9704 - val_loss: 0.1076\n",
      "Epoch 998/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9659 - loss: 0.0958 - val_accuracy: 0.9663 - val_loss: 0.1068\n",
      "Epoch 999/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9636 - loss: 0.0989 - val_accuracy: 0.9694 - val_loss: 0.1056\n",
      "Epoch 1000/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9629 - loss: 0.0950 - val_accuracy: 0.9694 - val_loss: 0.1058\n"
     ]
    }
   ],
   "source": [
    "## Train the model\n",
    "\n",
    "EPOCHS = 1000\n",
    "his = model.fit(\n",
    "    train_ds,\n",
    "    y_train,\n",
    "    validation_data=(test_ds, y_test),\n",
    "    epochs=EPOCHS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f9cd4923-36fc-4799-abb0-52acd470e6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 869us/step - accuracy: 0.9655 - loss: 0.1081\n",
      "\n",
      "Test score/loss: 0.10583625733852386\n",
      "Test accuracy: 0.9693877696990967\n",
      "dict_keys(['accuracy', 'loss', 'val_accuracy', 'val_loss'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Testing\n",
    "score = model.evaluate(test_ds, y_test, batch_size=32)\n",
    "print(\"\\nTest score/loss:\", score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "# list all data in history\n",
    "print(his.history.keys())\n",
    "\n",
    "# summarize history for accuracy\n",
    "#plt.plot(mo)\n",
    "fig= plt.figure(figsize=(4,3))\n",
    "plt.plot(his.history['accuracy'])\n",
    "plt.plot(his.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d12916-be37-4ce7-95df-f9689f870890",
   "metadata": {},
   "source": [
    "### Export the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0a7e568e-c2fd-4485-8ea6-652ea847782f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/KWS/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/KWS/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'models/KWS'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 2400), dtype=tf.float32, name='keras_tensor_30')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 2), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  130999255730304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  130999255736992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  130999255738224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  130999255914928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "export_dir = 'models/KWS'\n",
    "model.export(export_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "13a9fef0-d7ff-440d-a1ad-fb204190da42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/KWS/variables/variables\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/KWS/variables/variables\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:The given SavedModel MetaGraphDef contains SignatureDefs with the following keys: {'serving_default', '__saved_model_init_op', 'serve'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:The given SavedModel MetaGraphDef contains SignatureDefs with the following keys: {'serving_default', '__saved_model_init_op', 'serve'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/KWS/variables/variables\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/KWS/variables/variables\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/KWS/variables/variables\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-27 13:21:32.193430: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-27 13:21:32.193649: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2024-05-27 13:21:32.193722: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-05-27 13:21:32.193937: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-27 13:21:32.194096: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "INFO:tensorflow:Restoring parameters from models/KWS/variables/variables\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:The given SavedModel MetaGraphDef contains SignatureDefs with the following keys: {'serving_default', '__saved_model_init_op', 'serve'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:The given SavedModel MetaGraphDef contains SignatureDefs with the following keys: {'serving_default', '__saved_model_init_op', 'serve'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/KWS/variables/variables\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/KWS/variables/variables\n",
      "2024-05-27 13:21:32.302969: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-27 13:21:32.303201: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2024-05-27 13:21:32.303270: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-05-27 13:21:32.303535: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-27 13:21:32.303715: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "W0000 00:00:1716812492.335661    5666 tf_tfl_flatbuffer_helpers.cc:390] Ignored output_format.\n",
      "W0000 00:00:1716812492.335687    5666 tf_tfl_flatbuffer_helpers.cc:393] Ignored drop_control_dependency.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "27260"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "tflite_model_file = pathlib.Path('models/KWS.tflite')\n",
    "tflite_model_file.write_bytes(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8043c6-8eab-4e2b-b8b5-a21e0c9f8456",
   "metadata": {},
   "source": [
    "### Post-Quantisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "91e864e0-84b7-43b2-98e8-57a706c2d632",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/KWS/variables/variables\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/KWS/variables/variables\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:The given SavedModel MetaGraphDef contains SignatureDefs with the following keys: {'serving_default', '__saved_model_init_op', 'serve'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:The given SavedModel MetaGraphDef contains SignatureDefs with the following keys: {'serving_default', '__saved_model_init_op', 'serve'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/KWS/variables/variables\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/KWS/variables/variables\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/KWS/variables/variables\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-27 13:21:33.844529: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-27 13:21:33.844751: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2024-05-27 13:21:33.844821: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-05-27 13:21:33.845065: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-27 13:21:33.845227: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "INFO:tensorflow:Restoring parameters from models/KWS/variables/variables\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:The given SavedModel MetaGraphDef contains SignatureDefs with the following keys: {'serving_default', '__saved_model_init_op', 'serve'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:The given SavedModel MetaGraphDef contains SignatureDefs with the following keys: {'serving_default', '__saved_model_init_op', 'serve'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/KWS/variables/variables\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/KWS/variables/variables\n",
      "2024-05-27 13:21:33.959520: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-27 13:21:33.960000: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2024-05-27 13:21:33.960071: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-05-27 13:21:33.960313: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-27 13:21:33.960531: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "W0000 00:00:1716812493.994534    5666 tf_tfl_flatbuffer_helpers.cc:390] Ignored output_format.\n",
      "W0000 00:00:1716812493.994550    5666 tf_tfl_flatbuffer_helpers.cc:393] Ignored drop_control_dependency.\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: INT8, output_inference_type: INT8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10472"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def representative_dataset_gen(num_samples=100):\n",
    "    for data in train_ds[:num_samples]:\n",
    "        yield [data.reshape(1, 40, 60, 1)]\n",
    "##def representative_data_gen():\n",
    "##    for input_value, _ in y_test.take(100):\n",
    "##        yield [input_value]\n",
    "converter_op = tf.lite.TFLiteConverter.from_saved_model(export_dir)\n",
    "converter_op.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter_op.representative_dataset = representative_dataset_gen\n",
    "converter_op.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter_op.inference_input_type = tf.int8\n",
    "converter_op.inference_output_type = tf.int8\n",
    "\n",
    "tflite_model_file = pathlib.Path('models/KWS_op.tflite')\n",
    "tflite_model_file.write_bytes(converter_op.convert())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc64a8ac-2563-4599-b8c3-16a410b19023",
   "metadata": {},
   "source": [
    "## Test the accuracy of lite model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6c99560c-0fb7-49b1-abf1-ecfc04121e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load the dataset again\n",
    "test_ds = []\n",
    "\n",
    "for i in melSpec_test_set_yes:\n",
    "    resized = np.resize(i, (40,60))\n",
    "    resized = resized.flatten()\n",
    "    test_ds.append(resized)\n",
    "for i in melSpec_test_set_no:\n",
    "    resized = np.resize(i, (40,60))\n",
    "    resized = resized.flatten()\n",
    "    test_ds.append(resized)\n",
    "\n",
    "test_ds = np.array(test_ds)\n",
    "test_ds = test_ds.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f1b0ff6a-f8b0-4202-8d43-d9935b8ddb93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3137255012989044\n",
      "127\n",
      "[[-46, -14, -14, -33, -6, -8, -5, -20, -6, -27, -16, -10, 8, 4, -15, 0, 10, 0, 2, 4, 2, -32, -23, -14, -5, 6, -7, -17, -15, -16, -24, -33, -18, -25, -36, -23, -30, -24, -28, -43, 32, 26, -8, 6, 2, 4, -5, 7, -13, 0, 4, 5, -18, 2, 8, 6, 9, 15, 7, -11, 1, -9, -14, -17, 2, 6, -18, -28, 2, -8, -21, -12, -23, -45, -38, -25, -27, -15, -28, -39, -11, -8, 21, 22, 24, 2, 22, -12, -8, 13, -6, -17, -2, -8, 6, 12, 2, 2, -3, -7, -17, -5, -9, -2, -17, -29, -22, -16, -17, -10, -11, -17, -14, -37, -23, -27, -26, -29, -48, -33, 52, 55, 59, 59, 52, 34, 41, 31, 2, 7, 10, 4, 2, 1, 3, 10, 23, 28, 25, 36, 11, 2, 13, -8, -1, 1, -14, -23, -17, 1, -10, -2, -9, -8, -8, -11, 3, -6, -17, -32, 8, 53, 52, 27, 23, 23, 6, 18, 3, -18, -6, -17, -26, -1, -11, -17, -3, 18, 3, 0, -17, -29, -12, -27, -15, -28, -23, -12, -22, -16, -28, -27, -21, -17, -34, -20, -20, -21, -24, -22, 10, 61, 60, 12, 11, 23, 0, 19, -14, -5, -2, -26, -26, -33, -26, -7, -1, 12, -16, 2, -18, -32, -11, -12, -6, -2, -1, -20, -9, -8, 0, 3, -2, -17, -15, -10, -5, -12, -11, -29, 20, 65, 67, 29, 26, 34, 17, 27, 10, 0, 9, -1, 1, 16, 8, -1, 2, 16, -8, -7, 11, 2, -10, -3, 0, -9, -15, -21, -9, -20, -31, -6, -18, -24, -19, -29, -5, -10, -16, -30, 28, 71, 72, 37, 32, 45, 29, 24, 1, 11, 0, -40, -30, -8, -1, -8, -16, -21, -8, 0, 9, -10, -9, -4, -10, -7, 0, -18, -27, -7, -4, -3, -6, -19, -19, -19, -14, -2, -16, -37, 37, 85, 88, 58, 49, 64, 51, 44, 32, 0, -6, -11, -16, 0, 4, -20, 4, 24, -8, -6, 3, -5, -8, 4, -2, -7, -12, -26, 1, -2, 17, 9, -7, -12, -12, -6, 15, 0, -9, -21, 60, 100, 106, 76, 73, 95, 94, 78, 56, 42, 57, 24, 18, 28, 21, 4, 27, 50, 33, 37, 27, 3, -10, 10, 0, 1, 0, -12, -24, -1, 25, 18, 11, 6, 11, 2, 10, 6, 5, -8, 51, 102, 108, 74, 74, 103, 103, 93, 95, 73, 79, 35, 33, 37, 28, 33, 30, 24, 13, 27, 14, 9, 9, 5, 10, 10, -1, 2, 5, 38, 53, 32, 32, 41, 48, 41, 38, 38, 26, 2, 61, 101, 106, 70, 59, 91, 79, 113, 122, 102, 81, 29, 58, 51, 37, 43, 53, 46, 33, 42, 12, -2, 8, 24, 27, 24, 35, 46, 46, 49, 60, 51, 66, 81, 77, 46, 41, 45, 48, 19, 38, 98, 107, 75, 60, 78, 70, 118, 125, 109, 117, 83, 76, 70, 45, 37, 28, 15, 36, 31, 6, 17, 5, 20, 28, 27, 42, 58, 77, 77, 65, 64, 85, 90, 72, 56, 55, 50, 56, 37, 43, 91, 104, 75, 56, 78, 76, 109, 116, 96, 127, 96, 79, 57, 49, 32, 47, 59, 53, 42, 31, 29, 25, 39, 52, 52, 71, 90, 84, 76, 77, 75, 91, 88, 68, 49, 46, 43, 37, 14, 5, 86, 101, 79, 49, 84, 82, 91, 108, 86, 119, 110, 94, 91, 55, 52, 65, 57, 64, 61, 52, 32, 33, 49, 61, 66, 91, 106, 81, 78, 85, 78, 98, 89, 69, 51, 56, 60, 47, 23, 43, 70, 95, 76, 49, 86, 87, 89, 100, 81, 98, 84, 102, 108, 45, 52, 83, 59, 51, 62, 58, 47, 46, 61, 76, 73, 89, 91, 81, 80, 92, 83, 92, 80, 66, 49, 58, 57, 42, 21, 44, 89, 96, 65, 64, 73, 66, 92, 89, 75, 105, 96, 120, 111, 91, 89, 87, 71, 66, 73, 59, 56, 54, 64, 80, 82, 86, 86, 80, 81, 90, 77, 81, 71, 60, 45, 55, 49, 30, -4, 58, 94, 90, 34, 67, 73, 59, 65, 57, 93, 110, 111, 99, 80, 92, 84, 89, 89, 80, 74, 62, 63, 61, 80, 101, 94, 83, 86, 76, 79, 92, 80, 74, 66, 51, 38, 59, 57, 16, -7, 65, 89, 80, 55, 80, 66, 67, 62, 61, 90, 82, 65, 106, 112, 85, 74, 86, 69, 75, 75, 49, 48, 61, 88, 103, 80, 72, 69, 63, 66, 81, 70, 66, 55, 52, 36, 46, 56, 13, -14, 58, 10, 51, 69, 54, 48, 73, 76, 70, 82, 97, 92, 94, 92, 95, 77, 79, 75, 71, 80, 61, 65, 60, 90, 91, 74, 65, 79, 64, 74, 78, 60, 64, 53, 30, 24, 30, 24, -5, -28, 69, 34, 65, 65, 39, 56, 46, 67, 46, 82, 84, 65, 96, 94, 81, 81, 70, 72, 59, 64, 71, 58, 40, 71, 80, 72, 58, 45, 49, 51, 46, 46, 42, 17, 3, -4, -3, 3, -22, -28, 50, 45, 44, 52, 23, 44, 53, 56, 22, 61, 77, 50, 67, 66, 65, 60, 62, 47, 23, 55, 47, 37, 31, 42, 77, 53, 53, 64, 31, 38, 35, 27, 21, 1, -6, -1, -5, 0, -27, -34, 48, 46, 38, 22, 18, 23, 32, 34, 42, 46, 63, 61, 49, 29, 58, 55, 41, 52, 44, 37, 26, 16, 24, 42, 62, 41, 24, 25, 24, 12, -7, 11, 4, -15, -30, -14, -12, -16, -23, -34, 25, 13, -19, -19, -14, 2, 21, 21, 14, 26, 24, 24, 32, 33, 18, 18, 10, -8, 0, -5, -5, 8, 2, 16, 38, 31, -1, -8, -1, 1, 12, 4, -1, -24, -43, -34, -9, -8, -35, -52, -52, -45, -15, -16, -19, -18, 14, -10, -47, 1, 13, -61, 11, 1, -13, -4, -3, -25, 7, -4, -25, -16, -11, 1, 11, 9, 0, -13, -21, -14, 7, 2, -32, -47, -48, -29, -20, -13, -30, -47, -9, -9, -26, -33, -29, -36, -7, -14, -8, 15, 6, -20, -17, -16, 2, 1, 6, -21, -32, 0, 0, -19, -2, 5, -21, -6, 0, -16, -4, -6, -12, -29, -16, -27, -29, -29, -22, -24, -29, -37, -10, -29, -34, -31, -67, -25, 0, -13, -13, -12, 3, 7, -9, -20, -13, 0, -7, 3, -1, -8, -19, -9, 10, 7, -13, 10, 13, 0, -12, -24, 0, -8, -12, -23, -24, -21, -23, -23, -22, -37, 7, -3, -41, -20, -16, -40, -8, -30, -34, -17, 10, -2, -21, -8, 7, 1, 9, 10, -7, -16, -9, -12, -5, 3, 0, -3, -15, -11, -13, -17, -27, -18, -27, -41, -33, -16, -19, -22, -29, -40, -43, -25, -67, -55, -37, -9, 21, 12, 7, 9, -6, -14, -14, 3, -14, -6, -13, 0, 18, 12, -11, -23, 4, 5, 8, -9, -7, -18, -21, -11, -5, -15, -24, -25, -30, -28, -12, -12, -4, -24, -10, -17, -19, -31, -23, -18, 4, 5, -6, -13, 3, -17, -29, -2, -4, 3, -9, 0, -14, -21, -6, -16, -11, 0, -11, -10, -15, -13, -47, -23, -25, -16, -21, -21, -32, -28, -19, -24, -21, -38, -58, -71, -20, -6, -6, -10, -8, -10, -1, -3, -4, -17, -14, -23, 6, -2, 7, 5, -18, -17, -8, -4, -8, -9, -25, -10, -7, -17, -21, -15, -11, -13, -16, -18, -27, -28, -30, -20, -46, -38, -31, -15, -1, -14, -27, -49, -18, -9, -26, -5, -4, -41, -22, 7, -32, -18, 10, 23, -17, -28, -7, -12, 0, 1, -8, -12, -27, -32, -22, -16, -14, -2, -15, -27, -24, -23, -34, -24, -24, -30, 0, -38, -26, -61, -32, -57, -9, -2, -24, -18, 3, 2, -10, -3, 12, 13, 7, 1, 4, 6, -11, -23, -9, -22, -1, 0, -27, -18, -9, -11, -16, -16, -13, -33, -48, -28, -23, -26, -31, -38, -13, -18, -31, -39, -21, -15, -4, 6, -12, 7, -5, -11, 0, -2, 0, -1, -3, 12, 10, 8, 13, -1, -32, -13, -6, 2, -5, -8, 7, -7, -8, -7, -18, -20, -22, -18, -25, -26, -30, -35, -7, -19, -40, -17, -36, -16, 2, -2, -14, -13, -32, -13, -24, -13, 3, -10, -9, 7, -21, -5, 5, 7, -18, -8, 4, -1, -10, -7, 1, 4, 1, -7, -7, -8, -31, -30, -13, -18, -41, -50, -58, -17, -23, -36, -24, -32, -12, -15, -12, 5, 7, -8, -26, -27, -40, -21, -14, 18, 13, -1, -17, 6, -7, -23, -11, -3, -14, -14, -22, -13, -14, -18, -14, -24, -34, -32, -17, -18, -30, -45, -20, -25, -48, -13, -11, -9, 0, 11, -4, 0, -22, -15, -14, -14, -17, 12, 3, -9, -19, -10, -4, 2, -5, 1, 4, 2, -15, -19, -15, -8, -23, -5, 0, -19, -28, -52, -22, -21, -32, -41, 0, -24, -35, -33, -34, -12, -21, -9, -14, -22, -25, -42, -3, 1, -11, 4, -7, 1, -9, 1, 0, -14, -8, -3, -2, -6, -14, -21, -3, -19, -33, -30, -11, -32, -36, -30, -27, -26, -33, -30, -30, -44, -57, -23, 1, 3, -1, -3, -10, -19, -13, -39, -11, -5, -23, -15, -14, -5, 0, -19, -9, -5, 0, 2, -4, -2, -6, -5, -13, -10, -14, -21, -18, -27, -28, -42, -12, -22, -25, -24, 8, -13, -43, -35, -32, -34, -18, 3, 1, -1, -6, -1, -17, -14, -13, -11, 4, 1, -3, -13, -9, 1, 1, -14, -9, -5, -12, -19, -22, -8, -14, -20, -23, -14, -26, -32, -34, -24, -12, -25, -17, -22, -15, -11, -16, -49, 5, 3, -14, -5, -14, -16, -18, 5, 1, 12, 1, -19, -8, -5, 4, -10, -8, -10, -6, -3, -4, -20, -13, -6, -3, -26, -37, -20, -21, -35, -22, -22, -28, -31, -11, 11, 7, -46, -28, -43, -40, -13, 4, 3, -1, -15, -11, -9, 4, 1, -7, 9, 10, 16, 2, -6, -14, 4, -2, -3, -1, -13, -28, -5, -21, -20, 0, -1, -23, -15, -10, -11, 0, -1, -36, -32, -24, -48, -14, -22, -7, -9, -28, -19, 6, -7, -27, -5, 4, -11, -32, -21, 0, -6, 10, -9, 3, 10, 0, -14, -23, -28, -22, 7, -19, -29, -16, -8, -30, -39, -22, -30, -20, -1, -7, 0, -5, -22, -27, -18, -34, -1, -3, 13, -1, -18, -13, -22, -3, 7, 6, 5, -9, -6, -16, -24, -2, 8, 3, 1, -17, -14, -9, -10, -22, -32, -16, -22, -46, -34, -29, -35, -21, -29, 10, 4, -17, -35, -9, -18, -31, -21, -18, -4, -8, 2, -10, 1, 1, -7, 4, 10, -17, -10, -3, 0, 5, -10, -11, -6, -3, -12, -17, -24, -20, -18, -19, -19, -27, -23, -19, -26, -38, -32, -1, -54, -13, -26, -17, -12, -1, -1, 0, 1, 0, 2, -6, -1, -6, 6, 0, -17, -11, -11, -17, -6, -16, -16, -2, -2, -5, -18, -19, -22, -15, -27, -11, -13, -42, -30, -13, -26, -27, -22, -15, -8, -30, -30, -25, -31, -1, -26, -32, -7, -3, -42, -13, -1, 9, -3, -12, 7, 7, 15, -2, -9, -18, -10, -3, -12, -12, -15, -21, 3, -4, -15, -29, -19, -21, -29, -20, -25, -24, -38, -5, -14, -14, -13, -68, -22, -15, 0, 0, -9, -10, -13, -9, -9, -9, 0, -19, 12, -18, -15, 0, -23, -5, -11, -3, -4, -5, -26, -25, -8, -26, -16, -6, -25, -30, -35, -27, -28, -43, -48, 5, 6, -9, -17, -23, -15, -8, -26, -8, -1, 9, -23, -19, -4, -14, 3, -1, -9, -7, -18, -6, -4, -4, 2, 9, 4, -5, -10, -2, -7, -20, -10, -11, -29, -37, -23, -31, -21, -30, -43, -32, -25, -27, -27, -22, -25, -6, -5, -16, 0, -4, -32, -34, -19, -4, 0, -10, -10, -24, -5, 2, -4, -32, -6, -5, -16, -30, -17, 8, -5, -12, -14, -4, -19, -48, -33, -18, -14, -28, -50, -10, -23, -23, -10, -8, -20, 0, 1, 3, 2, -3, -7, -28, -9, -4, 15, 3, 20, 5, 9, 0, -31, -21, -6, -16, -13, -11, -7, -11, -15, -26, -12, -8, -21, -33, -26, -20, -28, -29, -44, 8, -63, -17, -42, -29, -9, -3, 0, -29, -7, -10, -41, -26, -3, 9, -2, -22, 3, 13, 6, 1, -5, -7, -2, 2, -3, -10, -18, -14, -17, -14, -25, -20, -28, -33, -21, -17, -26, -41, -45, -26, 0, -4, -2, -20, -38, -21, 6, -29, -45, -7, -4, -14, -13, 2, 1, -3, -17, -14, 17, 0, -3, -4, -1, 15, -2, -12, -12, -20, -15, -8, -22, -15, -25, -21, -26, -20, -26, -38, -50, -5, -33, -29, -63, -35, -11, 13, 9, -17, -5, -18, -26, -6, -1, 1, -11, 8, 3, -20, 0, -2, -23, -7, -4, -3, -8, -20, -24, -13, -5, -22, -16, -22, -23, -23, -15, -19, -24, -40, -45, 1, -27, -18, -21, -49, -35, -17, 10, 3, -15, -30, -23, -17, -4, 19, 1, 6, 15, 1, 4, 11, -12, -15, -19, -9, -1, -11, -10, -26, -12, -6, -9, -6, -29, -31, -21, -26, -35, -48, -38, -59, -15, -5, 1, -17, -2, -3, -4, 0, -9, -23, -28, -4, 22, -2, 13, 15, 12, -18, -4, 4, 1, 0, -2, -7, -8, -21, -26, -16, -19, -15, -10, -23, -25, -29, -19, -31, -23, -19, -40, -5, -14, -5, -28, -3, -9, -11, -23, -24, -24, -17, -48, -32, -23, -18, 13, 9, -12, -11, 4, -5, -17, -3, 2, -19, -16, -25, 5, -7, -10, -17, -15, -11, -16, -22, -24, -26, -26, -36, -40, -46, -38, -25, -20, -17, -28, -2, -2, -4, -19, 1, -35, -38, 7, 6, -11, -19, 3, 13, 9, -7, -13, -3, 12, 12, -12, -25, -24, -6, -2, -22, -13, -15, -29, -39, -39, -28, -20, -37, -56, -5, -9, -51, 0, 6, -6, -16, -10, -12, -12, -15, -33, -1, 0, -2, -3, 10, -4, -7, 17, 4, -7, -25, -3, 4, 0, -15, -23, -16, -29, -24, -16, -2, -16, -22, -14, -10, -34, -30, -41, -12, -16, -28, -10, 1, -2, 0, -6, -18, -16, 18, -10, -24, -22, -7, -8, -15, 7, 14, 0, 3, -7, 5, 12, 0, -15, -22, -15, -23, -15, -51, -17, -15, -22, -24, -27, -31, -30, -38, -41]]\n",
      "0: 1 [-128  127] 1\n",
      "1: 1 [-128  127] 1\n",
      "2: 1 [-128  127] 1\n",
      "3: 1 [-121  121] 1\n",
      "4: 1 [-110  110] 1\n",
      "5: 1 [-128  127] 1\n",
      "6: 1 [-79  79] 1\n",
      "7: 1 [-56  56] 1\n",
      "8: 1 [-116  116] 1\n",
      "9: 1 [-45  45] 1\n",
      "10: 1 [-83  83] 1\n",
      "11: 1 [-122  122] 1\n",
      "12: 1 [-104  104] 1\n",
      "13: 1 [-128  127] 1\n",
      "14: 1 [-128  127] 1\n",
      "15: 1 [-128  127] 1\n",
      "16: 1 [-32  32] 1\n",
      "17: 1 [-128  127] 1\n",
      "18: 1 [-128  127] 1\n",
      "19: 1 [-128  127] 1\n",
      "20: 1 [-128  127] 1\n",
      "21: 1 [-128  127] 1\n",
      "22: 1 [-128  127] 1\n",
      "23: 1 [-128  127] 1\n",
      "24: 1 [-128  127] 1\n",
      "25: 1 [-128  127] 1\n",
      "26: 1 [-127  127] 1\n",
      "27: 1 [-128  127] 1\n",
      "28: 1 [-128  127] 1\n",
      "29: 1 [-108  108] 1\n",
      "30: 1 [-79  79] 1\n",
      "31: 1 [-124  124] 1\n",
      "32: 1 [-127  127] 1\n",
      "33: 1 [-126  126] 1\n",
      "34: 1 [-128  127] 1\n",
      "35: 1 [-127  127] 1\n",
      "36: 1 [-127  127] 1\n",
      "37: 1 [-128  127] 1\n",
      "38: 1 [-128  127] 1\n",
      "39: 1 [-128  127] 1\n",
      "40: 1 [-128  127] 1\n",
      "41: 1 [-128  127] 1\n",
      "42: 1 [-121  121] 1\n",
      "43: 1 [-127  127] 1\n",
      "44: 1 [-128  127] 1\n",
      "45: 1 [-128  127] 1\n",
      "46: 1 [-110  110] 1\n",
      "47: 1 [-128  127] 1\n",
      "48: 1 [-127  127] 1\n",
      "49: 1 [-125  125] 1\n",
      "50: 1 [-128  127] 1\n",
      "51: 1 [-87  87] 1\n",
      "52: 1 [ 99 -99] 0\n",
      "53: 1 [-128  127] 1\n",
      "54: 1 [-124  124] 1\n",
      "55: 1 [-99  99] 1\n",
      "56: 1 [-112  112] 1\n",
      "57: 1 [-127  127] 1\n",
      "58: 1 [-104  104] 1\n",
      "59: 1 [-125  125] 1\n",
      "60: 1 [-128  127] 1\n",
      "61: 1 [-121  121] 1\n",
      "62: 1 [-128  127] 1\n",
      "63: 1 [-128  127] 1\n",
      "64: 1 [-128  127] 1\n",
      "65: 1 [-128  127] 1\n",
      "66: 1 [-128  127] 1\n",
      "67: 1 [ 123 -123] 0\n",
      "68: 1 [-110  110] 1\n",
      "69: 1 [-79  79] 1\n",
      "70: 1 [-120  120] 1\n",
      "71: 1 [-102  102] 1\n",
      "72: 1 [ 7 -7] 0\n",
      "73: 1 [-91  91] 1\n",
      "74: 1 [-26  26] 1\n",
      "75: 1 [-128  127] 1\n",
      "76: 1 [-128  127] 1\n",
      "77: 1 [-128  127] 1\n",
      "78: 1 [ 79 -79] 0\n",
      "79: 1 [-128  127] 1\n",
      "80: 1 [-126  126] 1\n",
      "81: 1 [-128  127] 1\n",
      "82: 1 [ 83 -83] 0\n",
      "83: 1 [-79  79] 1\n",
      "84: 1 [-128  127] 1\n",
      "85: 1 [-126  126] 1\n",
      "86: 1 [-120  120] 1\n",
      "87: 1 [-79  79] 1\n",
      "88: 1 [-128  127] 1\n",
      "89: 1 [-128  127] 1\n",
      "90: 1 [-126  126] 1\n",
      "91: 1 [-125  125] 1\n",
      "92: 1 [-127  127] 1\n",
      "93: 1 [-119  119] 1\n",
      "94: 1 [-127  127] 1\n",
      "95: 1 [-128  127] 1\n",
      "96: 1 [-127  127] 1\n",
      "97: 1 [-126  126] 1\n",
      "98: 1 [-128  127] 1\n",
      "99: 1 [-128  127] 1\n",
      "100: 1 [-128  127] 1\n",
      "101: 1 [-128  127] 1\n",
      "102: 1 [-127  127] 1\n",
      "103: 1 [-128  127] 1\n",
      "104: 1 [-128  127] 1\n",
      "105: 1 [-125  125] 1\n",
      "106: 1 [-123  123] 1\n",
      "107: 1 [-123  123] 1\n",
      "108: 1 [-128  127] 1\n",
      "109: 1 [-128  127] 1\n",
      "110: 1 [-123  123] 1\n",
      "111: 1 [-128  127] 1\n",
      "112: 1 [-128  127] 1\n",
      "113: 1 [-128  127] 1\n",
      "114: 1 [-128  127] 1\n",
      "115: 1 [-128  127] 1\n",
      "116: 1 [-128  127] 1\n",
      "117: 1 [-128  127] 1\n",
      "118: 1 [-127  127] 1\n",
      "119: 1 [-128  127] 1\n",
      "120: 1 [-128  127] 1\n",
      "121: 1 [-128  127] 1\n",
      "122: 1 [-128  127] 1\n",
      "123: 1 [-127  127] 1\n",
      "124: 1 [-128  127] 1\n",
      "125: 1 [-124  124] 1\n",
      "126: 1 [-128  127] 1\n",
      "127: 1 [-127  127] 1\n",
      "128: 1 [-127  127] 1\n",
      "129: 1 [-126  126] 1\n",
      "130: 1 [-128  127] 1\n",
      "131: 1 [-128  127] 1\n",
      "132: 1 [-128  127] 1\n",
      "133: 1 [-128  127] 1\n",
      "134: 1 [-128  127] 1\n",
      "135: 1 [-128  127] 1\n",
      "136: 1 [-128  127] 1\n",
      "137: 1 [-128  127] 1\n",
      "138: 1 [-126  126] 1\n",
      "139: 1 [-128  127] 1\n",
      "140: 1 [-124  124] 1\n",
      "141: 1 [-7  7] 1\n",
      "142: 1 [ 91 -91] 0\n",
      "143: 1 [-75  75] 1\n",
      "144: 1 [-127  127] 1\n",
      "145: 1 [-128  127] 1\n",
      "146: 1 [-128  127] 1\n",
      "147: 1 [-127  127] 1\n",
      "148: 1 [-128  127] 1\n",
      "149: 1 [-123  123] 1\n",
      "150: 1 [-126  126] 1\n",
      "151: 1 [-128  127] 1\n",
      "152: 1 [-126  126] 1\n",
      "153: 1 [-128  127] 1\n",
      "154: 1 [-128  127] 1\n",
      "155: 1 [-128  127] 1\n",
      "156: 1 [ 20 -20] 0\n",
      "157: 1 [-66  66] 1\n",
      "158: 1 [-7  7] 1\n",
      "159: 1 [-126  126] 1\n",
      "160: 1 [-110  110] 1\n",
      "161: 1 [-128  127] 1\n",
      "162: 1 [-128  127] 1\n",
      "163: 1 [-104  104] 1\n",
      "164: 1 [-121  121] 1\n",
      "165: 1 [-128  127] 1\n",
      "166: 1 [-123  123] 1\n",
      "167: 1 [-121  121] 1\n",
      "168: 1 [-128  127] 1\n",
      "169: 1 [-128  127] 1\n",
      "170: 1 [-128  127] 1\n",
      "171: 1 [-128  127] 1\n",
      "172: 1 [-122  122] 1\n",
      "173: 1 [-128  127] 1\n",
      "174: 1 [-128  127] 1\n",
      "175: 1 [-128  127] 1\n",
      "176: 1 [-128  127] 1\n",
      "177: 1 [-87  87] 1\n",
      "178: 1 [-127  127] 1\n",
      "179: 1 [-26  26] 1\n",
      "180: 1 [-118  118] 1\n",
      "181: 1 [-123  123] 1\n",
      "182: 1 [-127  127] 1\n",
      "183: 1 [-127  127] 1\n",
      "184: 1 [-128  127] 1\n",
      "185: 1 [-128  127] 1\n",
      "186: 1 [-128  127] 1\n",
      "187: 1 [-128  127] 1\n",
      "188: 1 [-128  127] 1\n",
      "189: 1 [-128  127] 1\n",
      "190: 1 [-128  127] 1\n",
      "191: 1 [-128  127] 1\n",
      "192: 1 [-128  127] 1\n",
      "193: 1 [-128  127] 1\n",
      "194: 1 [-128  127] 1\n",
      "195: 1 [-125  125] 1\n",
      "196: 1 [-127  127] 1\n",
      "197: 1 [-124  124] 1\n",
      "198: 1 [ 71 -71] 0\n",
      "199: 1 [0 0] 0\n",
      "200: 1 [-128  127] 1\n",
      "201: 1 [-127  127] 1\n",
      "202: 1 [-128  127] 1\n",
      "203: 1 [-128  127] 1\n",
      "204: 1 [-127  127] 1\n",
      "205: 1 [-128  127] 1\n",
      "206: 1 [-128  127] 1\n",
      "207: 1 [-128  127] 1\n",
      "208: 1 [-128  127] 1\n",
      "209: 1 [-128  127] 1\n",
      "210: 1 [-128  127] 1\n",
      "211: 1 [-128  127] 1\n",
      "212: 1 [-128  127] 1\n",
      "213: 1 [-112  112] 1\n",
      "214: 1 [-126  126] 1\n",
      "215: 1 [-115  115] 1\n",
      "216: 1 [-126  126] 1\n",
      "217: 1 [-126  126] 1\n",
      "218: 1 [-115  115] 1\n",
      "219: 1 [-128  127] 1\n",
      "220: 1 [-128  127] 1\n",
      "221: 1 [-128  127] 1\n",
      "222: 1 [-128  127] 1\n",
      "223: 1 [-128  127] 1\n",
      "224: 1 [-112  112] 1\n",
      "225: 1 [-128  127] 1\n",
      "226: 1 [-128  127] 1\n",
      "227: 1 [-128  127] 1\n",
      "228: 1 [-127  127] 1\n",
      "229: 1 [-125  125] 1\n",
      "230: 1 [-128  127] 1\n",
      "231: 1 [-110  110] 1\n",
      "232: 1 [-126  126] 1\n",
      "233: 1 [-127  127] 1\n",
      "234: 1 [-128  127] 1\n",
      "235: 1 [ 56 -56] 0\n",
      "236: 1 [-128  127] 1\n",
      "237: 1 [-127  127] 1\n",
      "238: 1 [-128  127] 1\n",
      "239: 1 [-128  127] 1\n",
      "240: 1 [-127  127] 1\n",
      "241: 1 [-128  127] 1\n",
      "242: 1 [-128  127] 1\n",
      "243: 1 [-128  127] 1\n",
      "244: 1 [-128  127] 1\n",
      "245: 1 [-128  127] 1\n",
      "246: 1 [-128  127] 1\n",
      "247: 1 [-94  94] 1\n",
      "248: 1 [-116  116] 1\n",
      "249: 1 [-128  127] 1\n",
      "250: 1 [-120  120] 1\n",
      "251: 1 [-45  45] 1\n",
      "252: 1 [-124  124] 1\n",
      "253: 1 [-128  127] 1\n",
      "254: 1 [-119  119] 1\n",
      "255: 1 [ 125 -125] 0\n",
      "256: 1 [-87  87] 1\n",
      "257: 1 [ 124 -124] 0\n",
      "258: 1 [-121  121] 1\n",
      "259: 1 [-127  127] 1\n",
      "260: 1 [-124  124] 1\n",
      "261: 1 [-91  91] 1\n",
      "262: 1 [-128  127] 1\n",
      "263: 1 [-128  127] 1\n",
      "264: 1 [-128  127] 1\n",
      "265: 1 [-128  127] 1\n",
      "266: 1 [-126  126] 1\n",
      "267: 1 [-128  127] 1\n",
      "268: 1 [-128  127] 1\n",
      "269: 1 [-91  91] 1\n",
      "270: 1 [-113  113] 1\n",
      "271: 1 [-39  39] 1\n",
      "272: 1 [-120  120] 1\n",
      "273: 1 [-128  127] 1\n",
      "274: 1 [-128  127] 1\n",
      "275: 1 [-128  127] 1\n",
      "276: 1 [-113  113] 1\n",
      "277: 1 [-112  112] 1\n",
      "278: 1 [-128  127] 1\n",
      "279: 1 [-97  97] 1\n",
      "280: 1 [-56  56] 1\n",
      "281: 1 [-94  94] 1\n",
      "282: 1 [-123  123] 1\n",
      "283: 1 [-128  127] 1\n",
      "284: 1 [-128  127] 1\n",
      "285: 1 [-125  125] 1\n",
      "286: 1 [-128  127] 1\n",
      "287: 1 [-124  124] 1\n",
      "288: 1 [-128  127] 1\n",
      "289: 1 [-128  127] 1\n",
      "290: 1 [-128  127] 1\n",
      "291: 1 [-128  127] 1\n",
      "292: 1 [-128  127] 1\n",
      "293: 1 [-126  126] 1\n",
      "294: 1 [-128  127] 1\n",
      "295: 1 [-124  124] 1\n",
      "296: 1 [-20  20] 1\n",
      "297: 1 [-128  127] 1\n",
      "298: 1 [-127  127] 1\n",
      "299: 1 [-127  127] 1\n",
      "300: 1 [ 106 -106] 0\n",
      "301: 1 [-125  125] 1\n",
      "302: 1 [-128  127] 1\n",
      "303: 1 [-128  127] 1\n",
      "304: 1 [-128  127] 1\n",
      "305: 1 [-128  127] 1\n",
      "306: 1 [-128  127] 1\n",
      "307: 1 [-124  124] 1\n",
      "308: 1 [-128  127] 1\n",
      "309: 1 [-128  127] 1\n",
      "310: 1 [-128  127] 1\n",
      "311: 1 [-128  127] 1\n",
      "312: 1 [-128  127] 1\n",
      "313: 1 [-128  127] 1\n",
      "314: 1 [-127  127] 1\n",
      "315: 1 [-128  127] 1\n",
      "316: 1 [-128  127] 1\n",
      "317: 1 [-128  127] 1\n",
      "318: 1 [-128  127] 1\n",
      "319: 1 [-128  127] 1\n",
      "320: 1 [-128  127] 1\n",
      "321: 1 [-128  127] 1\n",
      "322: 1 [-127  127] 1\n",
      "323: 1 [-127  127] 1\n",
      "324: 1 [-128  127] 1\n",
      "325: 1 [-128  127] 1\n",
      "326: 1 [-128  127] 1\n",
      "327: 1 [-128  127] 1\n",
      "328: 1 [-128  127] 1\n",
      "329: 1 [-127  127] 1\n",
      "330: 1 [-127  127] 1\n",
      "331: 1 [-127  127] 1\n",
      "332: 1 [-128  127] 1\n",
      "333: 1 [-124  124] 1\n",
      "334: 1 [-128  127] 1\n",
      "335: 1 [-128  127] 1\n",
      "336: 1 [-128  127] 1\n",
      "337: 1 [-128  127] 1\n",
      "338: 1 [-128  127] 1\n",
      "339: 1 [-128  127] 1\n",
      "340: 1 [-128  127] 1\n",
      "341: 1 [-128  127] 1\n",
      "342: 1 [-128  127] 1\n",
      "343: 1 [-128  127] 1\n",
      "344: 1 [-110  110] 1\n",
      "345: 1 [-128  127] 1\n",
      "346: 1 [-128  127] 1\n",
      "347: 1 [-127  127] 1\n",
      "348: 1 [-128  127] 1\n",
      "349: 1 [-128  127] 1\n",
      "350: 1 [-128  127] 1\n",
      "351: 1 [-128  127] 1\n",
      "352: 1 [-128  127] 1\n",
      "353: 1 [-125  125] 1\n",
      "354: 1 [-128  127] 1\n",
      "355: 1 [-124  124] 1\n",
      "356: 1 [-127  127] 1\n",
      "357: 1 [-128  127] 1\n",
      "358: 1 [-127  127] 1\n",
      "359: 1 [-127  127] 1\n",
      "360: 1 [-126  126] 1\n",
      "361: 1 [-127  127] 1\n",
      "362: 1 [-128  127] 1\n",
      "363: 1 [-128  127] 1\n",
      "364: 1 [-128  127] 1\n",
      "365: 1 [-128  127] 1\n",
      "366: 1 [-128  127] 1\n",
      "367: 1 [-126  126] 1\n",
      "368: 1 [-97  97] 1\n",
      "369: 1 [ 7 -7] 0\n",
      "370: 1 [-121  121] 1\n",
      "371: 1 [-127  127] 1\n",
      "372: 1 [-20  20] 1\n",
      "373: 1 [-117  117] 1\n",
      "374: 1 [-91  91] 1\n",
      "375: 1 [-128  127] 1\n",
      "376: 1 [-128  127] 1\n",
      "377: 1 [-128  127] 1\n",
      "378: 1 [-128  127] 1\n",
      "379: 1 [-127  127] 1\n",
      "380: 1 [-128  127] 1\n",
      "381: 1 [-104  104] 1\n",
      "382: 1 [-119  119] 1\n",
      "383: 1 [-127  127] 1\n",
      "384: 1 [-125  125] 1\n",
      "385: 1 [-128  127] 1\n",
      "386: 1 [-128  127] 1\n",
      "387: 1 [-127  127] 1\n",
      "388: 1 [-128  127] 1\n",
      "389: 1 [-128  127] 1\n",
      "390: 1 [-127  127] 1\n",
      "391: 1 [-66  66] 1\n",
      "392: 1 [-128  127] 1\n",
      "393: 1 [-102  102] 1\n",
      "394: 1 [ 61 -61] 0\n",
      "395: 1 [-106  106] 1\n",
      "396: 1 [-110  110] 1\n",
      "397: 1 [-113  113] 1\n",
      "398: 1 [-128  127] 1\n",
      "399: 1 [-128  127] 1\n",
      "400: 1 [-128  127] 1\n",
      "401: 1 [-128  127] 1\n",
      "402: 1 [-128  127] 1\n",
      "403: 1 [-115  115] 1\n",
      "404: 1 [-128  127] 1\n",
      "405: 1 [-119  119] 1\n",
      "406: 1 [-102  102] 1\n",
      "407: 1 [-120  120] 1\n",
      "408: 1 [-112  112] 1\n",
      "409: 1 [-7  7] 1\n",
      "410: 1 [-127  127] 1\n",
      "411: 1 [-128  127] 1\n",
      "412: 1 [-123  123] 1\n",
      "413: 1 [-128  127] 1\n",
      "414: 1 [-128  127] 1\n",
      "415: 1 [-128  127] 1\n",
      "416: 1 [-128  127] 1\n",
      "417: 1 [-128  127] 1\n",
      "418: 1 [-128  127] 1\n",
      "419: 1 [-128  127] 1\n",
      "420: 1 [-128  127] 1\n",
      "421: 1 [-121  121] 1\n",
      "422: 1 [-127  127] 1\n",
      "423: 1 [-83  83] 1\n",
      "424: 1 [-123  123] 1\n",
      "425: 1 [-126  126] 1\n",
      "426: 1 [-124  124] 1\n",
      "427: 1 [-128  127] 1\n",
      "428: 1 [-125  125] 1\n",
      "429: 1 [-122  122] 1\n",
      "430: 1 [-112  112] 1\n",
      "431: 1 [-128  127] 1\n",
      "432: 1 [-126  126] 1\n",
      "433: 1 [-128  127] 1\n",
      "434: 1 [-128  127] 1\n",
      "435: 1 [-128  127] 1\n",
      "436: 1 [-128  127] 1\n",
      "437: 1 [-128  127] 1\n",
      "438: 1 [-128  127] 1\n",
      "439: 1 [-128  127] 1\n",
      "440: 1 [-125  125] 1\n",
      "441: 1 [ 20 -20] 0\n",
      "442: 1 [-128  127] 1\n",
      "443: 1 [-128  127] 1\n",
      "444: 1 [-128  127] 1\n",
      "445: 1 [-128  127] 1\n",
      "446: 1 [-108  108] 1\n",
      "447: 1 [-118  118] 1\n",
      "448: 1 [-110  110] 1\n",
      "449: 1 [-127  127] 1\n",
      "450: 1 [-128  127] 1\n",
      "451: 1 [-127  127] 1\n",
      "452: 1 [-128  127] 1\n",
      "453: 1 [-128  127] 1\n",
      "454: 1 [-128  127] 1\n",
      "455: 1 [-125  125] 1\n",
      "456: 1 [-127  127] 1\n",
      "457: 1 [-127  127] 1\n",
      "458: 1 [-128  127] 1\n",
      "459: 1 [ 7 -7] 0\n",
      "460: 1 [-124  124] 1\n",
      "461: 1 [-128  127] 1\n",
      "462: 1 [-122  122] 1\n",
      "463: 1 [-124  124] 1\n",
      "464: 1 [-112  112] 1\n",
      "465: 1 [-127  127] 1\n",
      "466: 1 [-128  127] 1\n",
      "467: 1 [-127  127] 1\n",
      "468: 1 [-128  127] 1\n",
      "469: 1 [-128  127] 1\n",
      "470: 1 [-128  127] 1\n",
      "471: 1 [-128  127] 1\n",
      "472: 1 [-127  127] 1\n",
      "473: 1 [-127  127] 1\n",
      "474: 1 [-83  83] 1\n",
      "475: 1 [-121  121] 1\n",
      "476: 1 [-127  127] 1\n",
      "477: 1 [-97  97] 1\n",
      "478: 1 [-128  127] 1\n",
      "479: 1 [-126  126] 1\n",
      "480: 1 [-128  127] 1\n",
      "481: 1 [-123  123] 1\n",
      "482: 1 [-123  123] 1\n",
      "483: 1 [-83  83] 1\n",
      "484: 1 [-112  112] 1\n",
      "485: 1 [-87  87] 1\n",
      "486: 1 [-121  121] 1\n",
      "487: 1 [-106  106] 1\n",
      "488: 1 [-66  66] 1\n",
      "489: 1 [-128  127] 1\n",
      "490: 0 [ 127 -128] 0\n",
      "491: 0 [ 127 -128] 0\n",
      "492: 0 [ 127 -128] 0\n",
      "493: 0 [ 127 -128] 0\n",
      "494: 0 [ 124 -124] 0\n",
      "495: 0 [-66  66] 1\n",
      "496: 0 [ 32 -32] 0\n",
      "497: 0 [ 20 -20] 0\n",
      "498: 0 [ 120 -120] 0\n",
      "499: 0 [ 127 -128] 0\n",
      "500: 0 [ 127 -128] 0\n",
      "501: 0 [ 126 -126] 0\n",
      "502: 0 [ 126 -126] 0\n",
      "503: 0 [ 124 -124] 0\n",
      "504: 0 [ 127 -128] 0\n",
      "505: 0 [ 127 -128] 0\n",
      "506: 0 [ 127 -128] 0\n",
      "507: 0 [ 127 -128] 0\n",
      "508: 0 [ 127 -128] 0\n",
      "509: 0 [ 127 -128] 0\n",
      "510: 0 [ 127 -127] 0\n",
      "511: 0 [ 125 -125] 0\n",
      "512: 0 [ 108 -108] 0\n",
      "513: 0 [ 119 -119] 0\n",
      "514: 0 [ 126 -126] 0\n",
      "515: 0 [ 127 -128] 0\n",
      "516: 0 [ 117 -117] 0\n",
      "517: 0 [ 127 -128] 0\n",
      "518: 0 [ 104 -104] 0\n",
      "519: 0 [ 108 -108] 0\n",
      "520: 0 [ 121 -121] 0\n",
      "521: 0 [ 127 -128] 0\n",
      "522: 0 [ 127 -128] 0\n",
      "523: 0 [ 127 -128] 0\n",
      "524: 0 [ 127 -128] 0\n",
      "525: 0 [ 127 -128] 0\n",
      "526: 0 [ 125 -125] 0\n",
      "527: 0 [ 127 -128] 0\n",
      "528: 0 [ 127 -128] 0\n",
      "529: 0 [ 127 -128] 0\n",
      "530: 0 [ 127 -127] 0\n",
      "531: 0 [ 125 -125] 0\n",
      "532: 0 [ 127 -128] 0\n",
      "533: 0 [ 127 -128] 0\n",
      "534: 0 [ 127 -128] 0\n",
      "535: 0 [ 127 -127] 0\n",
      "536: 0 [ 127 -128] 0\n",
      "537: 0 [ 127 -128] 0\n",
      "538: 0 [ 127 -128] 0\n",
      "539: 0 [ 127 -128] 0\n",
      "540: 0 [ 127 -127] 0\n",
      "541: 0 [ 127 -128] 0\n",
      "542: 0 [ 127 -128] 0\n",
      "543: 0 [ 127 -127] 0\n",
      "544: 0 [ 127 -128] 0\n",
      "545: 0 [ 127 -128] 0\n",
      "546: 0 [ 126 -126] 0\n",
      "547: 0 [ 56 -56] 0\n",
      "548: 0 [ 125 -125] 0\n",
      "549: 0 [ 127 -128] 0\n",
      "550: 0 [ 120 -120] 0\n",
      "551: 0 [ 121 -121] 0\n",
      "552: 0 [ 113 -113] 0\n",
      "553: 0 [ 127 -128] 0\n",
      "554: 0 [ 127 -128] 0\n",
      "555: 0 [ 119 -119] 0\n",
      "556: 0 [ 127 -128] 0\n",
      "557: 0 [ 119 -119] 0\n",
      "558: 0 [ 127 -128] 0\n",
      "559: 0 [ 123 -123] 0\n",
      "560: 0 [ 127 -128] 0\n",
      "561: 0 [ 127 -128] 0\n",
      "562: 0 [ 127 -128] 0\n",
      "563: 0 [ 127 -127] 0\n",
      "564: 0 [ 79 -79] 0\n",
      "565: 0 [ 126 -126] 0\n",
      "566: 0 [ 120 -120] 0\n",
      "567: 0 [ 127 -128] 0\n",
      "568: 0 [ 97 -97] 0\n",
      "569: 0 [ 127 -128] 0\n",
      "570: 0 [ 127 -127] 0\n",
      "571: 0 [ 104 -104] 0\n",
      "572: 0 [ 127 -127] 0\n",
      "573: 0 [ 115 -115] 0\n",
      "574: 0 [ 124 -124] 0\n",
      "575: 0 [ 127 -127] 0\n",
      "576: 0 [ 102 -102] 0\n",
      "577: 0 [ 127 -128] 0\n",
      "578: 0 [ 127 -128] 0\n",
      "579: 0 [ 127 -128] 0\n",
      "580: 0 [ 127 -128] 0\n",
      "581: 0 [ 127 -128] 0\n",
      "582: 0 [ 115 -115] 0\n",
      "583: 0 [ 127 -128] 0\n",
      "584: 0 [ 127 -128] 0\n",
      "585: 0 [ 121 -121] 0\n",
      "586: 0 [ 127 -128] 0\n",
      "587: 0 [ 126 -126] 0\n",
      "588: 0 [ 127 -128] 0\n",
      "589: 0 [ 127 -128] 0\n",
      "590: 0 [ 127 -128] 0\n",
      "591: 0 [ 121 -121] 0\n",
      "592: 0 [ 127 -127] 0\n",
      "593: 0 [ 127 -127] 0\n",
      "594: 0 [ 127 -128] 0\n",
      "595: 0 [ 126 -126] 0\n",
      "596: 0 [ 127 -127] 0\n",
      "597: 0 [ 127 -128] 0\n",
      "598: 0 [-121  121] 1\n",
      "599: 0 [ 127 -128] 0\n",
      "600: 0 [ 127 -128] 0\n",
      "601: 0 [-128  127] 1\n",
      "602: 0 [ 127 -128] 0\n",
      "603: 0 [ 127 -128] 0\n",
      "604: 0 [ 127 -128] 0\n",
      "605: 0 [ 126 -126] 0\n",
      "606: 0 [ 127 -128] 0\n",
      "607: 0 [ 127 -128] 0\n",
      "608: 0 [ 127 -128] 0\n",
      "609: 0 [ 127 -128] 0\n",
      "610: 0 [ 127 -128] 0\n",
      "611: 0 [ 127 -128] 0\n",
      "612: 0 [ 127 -128] 0\n",
      "613: 0 [ 127 -128] 0\n",
      "614: 0 [ 127 -128] 0\n",
      "615: 0 [ 127 -128] 0\n",
      "616: 0 [ 127 -128] 0\n",
      "617: 0 [ 127 -128] 0\n",
      "618: 0 [ 127 -128] 0\n",
      "619: 0 [ 127 -128] 0\n",
      "620: 0 [ 126 -126] 0\n",
      "621: 0 [ 127 -127] 0\n",
      "622: 0 [ 71 -71] 0\n",
      "623: 0 [ 115 -115] 0\n",
      "624: 0 [ 126 -126] 0\n",
      "625: 0 [ 127 -127] 0\n",
      "626: 0 [ 75 -75] 0\n",
      "627: 0 [ 91 -91] 0\n",
      "628: 0 [ 113 -113] 0\n",
      "629: 0 [ 119 -119] 0\n",
      "630: 0 [ 97 -97] 0\n",
      "631: 0 [ 127 -128] 0\n",
      "632: 0 [ 127 -128] 0\n",
      "633: 0 [ 127 -128] 0\n",
      "634: 0 [ 127 -128] 0\n",
      "635: 0 [ 26 -26] 0\n",
      "636: 0 [ 110 -110] 0\n",
      "637: 0 [ 61 -61] 0\n",
      "638: 0 [ 127 -127] 0\n",
      "639: 0 [ 127 -128] 0\n",
      "640: 0 [ 127 -127] 0\n",
      "641: 0 [ 127 -127] 0\n",
      "642: 0 [ 127 -128] 0\n",
      "643: 0 [ 127 -128] 0\n",
      "644: 0 [ 127 -128] 0\n",
      "645: 0 [ 127 -128] 0\n",
      "646: 0 [ 124 -124] 0\n",
      "647: 0 [ 127 -128] 0\n",
      "648: 0 [ 127 -128] 0\n",
      "649: 0 [ 127 -128] 0\n",
      "650: 0 [ 127 -128] 0\n",
      "651: 0 [ 127 -128] 0\n",
      "652: 0 [ 126 -126] 0\n",
      "653: 0 [ 26 -26] 0\n",
      "654: 0 [ 127 -128] 0\n",
      "655: 0 [ 127 -128] 0\n",
      "656: 0 [ 127 -128] 0\n",
      "657: 0 [ 115 -115] 0\n",
      "658: 0 [ 127 -128] 0\n",
      "659: 0 [ 127 -128] 0\n",
      "660: 0 [ 127 -128] 0\n",
      "661: 0 [ 99 -99] 0\n",
      "662: 0 [ 112 -112] 0\n",
      "663: 0 [ 127 -128] 0\n",
      "664: 0 [ 127 -127] 0\n",
      "665: 0 [ 113 -113] 0\n",
      "666: 0 [ 127 -128] 0\n",
      "667: 0 [ 99 -99] 0\n",
      "668: 0 [-83  83] 1\n",
      "669: 0 [ 123 -123] 0\n",
      "670: 0 [ 127 -127] 0\n",
      "671: 0 [ 126 -126] 0\n",
      "672: 0 [ 127 -127] 0\n",
      "673: 0 [ 127 -127] 0\n",
      "674: 0 [ 127 -127] 0\n",
      "675: 0 [ 127 -128] 0\n",
      "676: 0 [ 127 -128] 0\n",
      "677: 0 [ 87 -87] 0\n",
      "678: 0 [ 104 -104] 0\n",
      "679: 0 [ 127 -128] 0\n",
      "680: 0 [ 102 -102] 0\n",
      "681: 0 [ 121 -121] 0\n",
      "682: 0 [-87  87] 1\n",
      "683: 0 [ 127 -128] 0\n",
      "684: 0 [ 127 -128] 0\n",
      "685: 0 [ 127 -128] 0\n",
      "686: 0 [ 127 -128] 0\n",
      "687: 0 [ 127 -128] 0\n",
      "688: 0 [ 121 -121] 0\n",
      "689: 0 [ 97 -97] 0\n",
      "690: 0 [ 127 -127] 0\n",
      "691: 0 [-56  56] 1\n",
      "692: 0 [ 127 -128] 0\n",
      "693: 0 [ 127 -128] 0\n",
      "694: 0 [ 127 -128] 0\n",
      "695: 0 [ 121 -121] 0\n",
      "696: 0 [ 127 -128] 0\n",
      "697: 0 [ 127 -128] 0\n",
      "698: 0 [ 120 -120] 0\n",
      "699: 0 [ 127 -128] 0\n",
      "700: 0 [ 127 -127] 0\n",
      "701: 0 [ 127 -128] 0\n",
      "702: 0 [ 127 -128] 0\n",
      "703: 0 [ 127 -127] 0\n",
      "704: 0 [ 126 -126] 0\n",
      "705: 0 [ 127 -128] 0\n",
      "706: 0 [ 127 -127] 0\n",
      "707: 0 [ 127 -128] 0\n",
      "708: 0 [ 124 -124] 0\n",
      "709: 0 [ 127 -128] 0\n",
      "710: 0 [ 127 -128] 0\n",
      "711: 0 [ 127 -128] 0\n",
      "712: 0 [ 127 -128] 0\n",
      "713: 0 [ 127 -128] 0\n",
      "714: 0 [ 127 -128] 0\n",
      "715: 0 [ 127 -128] 0\n",
      "716: 0 [ 127 -128] 0\n",
      "717: 0 [ 127 -128] 0\n",
      "718: 0 [ 127 -127] 0\n",
      "719: 0 [ 123 -123] 0\n",
      "720: 0 [ 127 -128] 0\n",
      "721: 0 [ 127 -128] 0\n",
      "722: 0 [ 127 -127] 0\n",
      "723: 0 [ 127 -128] 0\n",
      "724: 0 [ 102 -102] 0\n",
      "725: 0 [ 87 -87] 0\n",
      "726: 0 [-128  127] 1\n",
      "727: 0 [ 127 -128] 0\n",
      "728: 0 [ 79 -79] 0\n",
      "729: 0 [ 83 -83] 0\n",
      "730: 0 [0 0] 0\n",
      "731: 0 [ 127 -128] 0\n",
      "732: 0 [ 127 -127] 0\n",
      "733: 0 [ 97 -97] 0\n",
      "734: 0 [ 127 -128] 0\n",
      "735: 0 [ 45 -45] 0\n",
      "736: 0 [ 20 -20] 0\n",
      "737: 0 [ 50 -50] 0\n",
      "738: 0 [ 125 -125] 0\n",
      "739: 0 [ 127 -128] 0\n",
      "740: 0 [ 127 -128] 0\n",
      "741: 0 [ 127 -128] 0\n",
      "742: 0 [ 127 -128] 0\n",
      "743: 0 [ 126 -126] 0\n",
      "744: 0 [ 127 -128] 0\n",
      "745: 0 [ 120 -120] 0\n",
      "746: 0 [ 127 -128] 0\n",
      "747: 0 [ 116 -116] 0\n",
      "748: 0 [ 127 -128] 0\n",
      "749: 0 [ 127 -128] 0\n",
      "750: 0 [ 117 -117] 0\n",
      "751: 0 [ 127 -128] 0\n",
      "752: 0 [ 127 -128] 0\n",
      "753: 0 [ 127 -128] 0\n",
      "754: 0 [ 127 -128] 0\n",
      "755: 0 [ 119 -119] 0\n",
      "756: 0 [ 113 -113] 0\n",
      "757: 0 [ 75 -75] 0\n",
      "758: 0 [ 127 -128] 0\n",
      "759: 0 [ 115 -115] 0\n",
      "760: 0 [ 127 -128] 0\n",
      "761: 0 [ 127 -128] 0\n",
      "762: 0 [ 127 -127] 0\n",
      "763: 0 [ 124 -124] 0\n",
      "764: 0 [ 127 -128] 0\n",
      "765: 0 [ 91 -91] 0\n",
      "766: 0 [ 20 -20] 0\n",
      "767: 0 [ 122 -122] 0\n",
      "768: 0 [ 127 -128] 0\n",
      "769: 0 [ 127 -128] 0\n",
      "770: 0 [ 127 -128] 0\n",
      "771: 0 [ 127 -128] 0\n",
      "772: 0 [ 127 -128] 0\n",
      "773: 0 [ 127 -128] 0\n",
      "774: 0 [ 127 -128] 0\n",
      "775: 0 [ 127 -128] 0\n",
      "776: 0 [-106  106] 1\n",
      "777: 0 [ 127 -128] 0\n",
      "778: 0 [ 124 -124] 0\n",
      "779: 0 [ 127 -128] 0\n",
      "780: 0 [ 106 -106] 0\n",
      "781: 0 [ 127 -128] 0\n",
      "782: 0 [ 79 -79] 0\n",
      "783: 0 [ 123 -123] 0\n",
      "784: 0 [ 127 -127] 0\n",
      "785: 0 [-26  26] 1\n",
      "786: 0 [ 127 -127] 0\n",
      "787: 0 [ 56 -56] 0\n",
      "788: 0 [ 61 -61] 0\n",
      "789: 0 [ 127 -127] 0\n",
      "790: 0 [ 123 -123] 0\n",
      "791: 0 [ 127 -128] 0\n",
      "792: 0 [ 127 -128] 0\n",
      "793: 0 [ 127 -127] 0\n",
      "794: 0 [ 127 -128] 0\n",
      "795: 0 [ 127 -128] 0\n",
      "796: 0 [ 87 -87] 0\n",
      "797: 0 [ 127 -128] 0\n",
      "798: 0 [ 127 -128] 0\n",
      "799: 0 [ 125 -125] 0\n",
      "800: 0 [ 127 -128] 0\n",
      "801: 0 [ 126 -126] 0\n",
      "802: 0 [ 94 -94] 0\n",
      "803: 0 [ 122 -122] 0\n",
      "804: 0 [ 108 -108] 0\n",
      "805: 0 [ 126 -126] 0\n",
      "806: 0 [ 110 -110] 0\n",
      "807: 0 [ 45 -45] 0\n",
      "808: 0 [ 127 -128] 0\n",
      "809: 0 [ 127 -128] 0\n",
      "810: 0 [ 127 -128] 0\n",
      "811: 0 [ 127 -128] 0\n",
      "812: 0 [ 115 -115] 0\n",
      "813: 0 [ 124 -124] 0\n",
      "814: 0 [ 126 -126] 0\n",
      "815: 0 [ 127 -127] 0\n",
      "816: 0 [ 127 -128] 0\n",
      "817: 0 [ 113 -113] 0\n",
      "818: 0 [ 127 -128] 0\n",
      "819: 0 [ 127 -128] 0\n",
      "820: 0 [ 127 -128] 0\n",
      "821: 0 [ 127 -128] 0\n",
      "822: 0 [ 39 -39] 0\n",
      "823: 0 [ 32 -32] 0\n",
      "824: 0 [ 127 -128] 0\n",
      "825: 0 [ 83 -83] 0\n",
      "826: 0 [ 39 -39] 0\n",
      "827: 0 [ 126 -126] 0\n",
      "828: 0 [ 127 -128] 0\n",
      "829: 0 [ 116 -116] 0\n",
      "830: 0 [ 127 -127] 0\n",
      "831: 0 [ 127 -128] 0\n",
      "832: 0 [ 94 -94] 0\n",
      "833: 0 [ 127 -127] 0\n",
      "834: 0 [ 127 -128] 0\n",
      "835: 0 [ 127 -128] 0\n",
      "836: 0 [ 127 -127] 0\n",
      "837: 0 [ 127 -128] 0\n",
      "838: 0 [ 127 -128] 0\n",
      "839: 0 [ 127 -128] 0\n",
      "840: 0 [ 127 -127] 0\n",
      "841: 0 [-102  102] 1\n",
      "842: 0 [ 126 -126] 0\n",
      "843: 0 [-45  45] 1\n",
      "844: 0 [ 106 -106] 0\n",
      "845: 0 [ 125 -125] 0\n",
      "846: 0 [ 127 -128] 0\n",
      "847: 0 [ 127 -128] 0\n",
      "848: 0 [ 127 -127] 0\n",
      "849: 0 [ 127 -128] 0\n",
      "850: 0 [ 127 -127] 0\n",
      "851: 0 [ 127 -128] 0\n",
      "852: 0 [ 127 -128] 0\n",
      "853: 0 [ 66 -66] 0\n",
      "854: 0 [ 127 -128] 0\n",
      "855: 0 [ 127 -128] 0\n",
      "856: 0 [ 66 -66] 0\n",
      "857: 0 [ 127 -128] 0\n",
      "858: 0 [ 127 -128] 0\n",
      "859: 0 [ 127 -128] 0\n",
      "860: 0 [ 127 -128] 0\n",
      "861: 0 [ 127 -128] 0\n",
      "862: 0 [ 127 -128] 0\n",
      "863: 0 [ 94 -94] 0\n",
      "864: 0 [ 127 -128] 0\n",
      "865: 0 [ 127 -128] 0\n",
      "866: 0 [ 127 -128] 0\n",
      "867: 0 [ 127 -127] 0\n",
      "868: 0 [ 124 -124] 0\n",
      "869: 0 [ 127 -128] 0\n",
      "870: 0 [ 127 -128] 0\n",
      "871: 0 [ 127 -128] 0\n",
      "872: 0 [ 127 -128] 0\n",
      "873: 0 [ 127 -128] 0\n",
      "874: 0 [ 127 -128] 0\n",
      "875: 0 [ 127 -127] 0\n",
      "876: 0 [ 127 -128] 0\n",
      "877: 0 [ 127 -128] 0\n",
      "878: 0 [ 127 -128] 0\n",
      "879: 0 [ 127 -128] 0\n",
      "880: 0 [ 123 -123] 0\n",
      "881: 0 [ 87 -87] 0\n",
      "882: 0 [-117  117] 1\n",
      "883: 0 [ 115 -115] 0\n",
      "884: 0 [ 110 -110] 0\n",
      "885: 0 [ 121 -121] 0\n",
      "886: 0 [ 127 -128] 0\n",
      "887: 0 [ 127 -128] 0\n",
      "888: 0 [ 127 -128] 0\n",
      "889: 0 [ 125 -125] 0\n",
      "890: 0 [ 127 -128] 0\n",
      "891: 0 [ 127 -128] 0\n",
      "892: 0 [ 127 -127] 0\n",
      "893: 0 [ 127 -128] 0\n",
      "894: 0 [ 117 -117] 0\n",
      "895: 0 [ 127 -128] 0\n",
      "896: 0 [ 127 -128] 0\n",
      "897: 0 [ 113 -113] 0\n",
      "898: 0 [ 127 -127] 0\n",
      "899: 0 [ 127 -127] 0\n",
      "900: 0 [ 127 -128] 0\n",
      "901: 0 [ 123 -123] 0\n",
      "902: 0 [ 127 -127] 0\n",
      "903: 0 [ 118 -118] 0\n",
      "904: 0 [ 56 -56] 0\n",
      "905: 0 [ 127 -128] 0\n",
      "906: 0 [ 127 -128] 0\n",
      "907: 0 [ 127 -127] 0\n",
      "908: 0 [ 127 -128] 0\n",
      "909: 0 [ 121 -121] 0\n",
      "910: 0 [ 127 -128] 0\n",
      "911: 0 [ 127 -128] 0\n",
      "912: 0 [ 126 -126] 0\n",
      "913: 0 [ 127 -128] 0\n",
      "914: 0 [ 127 -128] 0\n",
      "915: 0 [ 127 -128] 0\n",
      "916: 0 [ 127 -128] 0\n",
      "917: 0 [ 127 -128] 0\n",
      "918: 0 [ 127 -128] 0\n",
      "919: 0 [ 127 -128] 0\n",
      "920: 0 [ 127 -127] 0\n",
      "921: 0 [ 127 -128] 0\n",
      "922: 0 [ 127 -127] 0\n",
      "923: 0 [ 127 -128] 0\n",
      "924: 0 [ 66 -66] 0\n",
      "925: 0 [ 124 -124] 0\n",
      "926: 0 [ 127 -128] 0\n",
      "927: 0 [ 127 -128] 0\n",
      "928: 0 [ 127 -128] 0\n",
      "929: 0 [ 126 -126] 0\n",
      "930: 0 [ 127 -127] 0\n",
      "931: 0 [ 124 -124] 0\n",
      "932: 0 [ 127 -128] 0\n",
      "933: 0 [ 127 -127] 0\n",
      "934: 0 [ 127 -128] 0\n",
      "935: 0 [ 127 -128] 0\n",
      "936: 0 [ 127 -128] 0\n",
      "937: 0 [ 127 -128] 0\n",
      "938: 0 [ 127 -127] 0\n",
      "939: 0 [ 124 -124] 0\n",
      "940: 0 [ 127 -128] 0\n",
      "941: 0 [ 127 -128] 0\n",
      "942: 0 [ 127 -127] 0\n",
      "943: 0 [ 127 -128] 0\n",
      "944: 0 [ 119 -119] 0\n",
      "945: 0 [ 127 -128] 0\n",
      "946: 0 [ 127 -128] 0\n",
      "947: 0 [ 127 -127] 0\n",
      "948: 0 [ 127 -128] 0\n",
      "949: 0 [ 127 -128] 0\n",
      "950: 0 [ 127 -128] 0\n",
      "951: 0 [ 127 -128] 0\n",
      "952: 0 [ 122 -122] 0\n",
      "953: 0 [ 127 -128] 0\n",
      "954: 0 [ 127 -127] 0\n",
      "955: 0 [ 39 -39] 0\n",
      "956: 0 [ 127 -128] 0\n",
      "957: 0 [ 127 -128] 0\n",
      "958: 0 [ 127 -128] 0\n",
      "959: 0 [ 127 -128] 0\n",
      "960: 0 [ 127 -128] 0\n",
      "961: 0 [ 127 -128] 0\n",
      "962: 0 [ 127 -128] 0\n",
      "963: 0 [ 127 -127] 0\n",
      "964: 0 [ 127 -127] 0\n",
      "965: 0 [ 127 -128] 0\n",
      "966: 0 [ 127 -128] 0\n",
      "967: 0 [ 127 -127] 0\n",
      "968: 0 [ 127 -128] 0\n",
      "969: 0 [ 127 -128] 0\n",
      "970: 0 [ 127 -128] 0\n",
      "971: 0 [ 127 -128] 0\n",
      "972: 0 [ 127 -128] 0\n",
      "973: 0 [ 127 -128] 0\n",
      "974: 0 [ 127 -128] 0\n",
      "975: 0 [ 127 -128] 0\n",
      "976: 0 [ 127 -128] 0\n",
      "977: 0 [ 127 -128] 0\n",
      "978: 0 [ 127 -128] 0\n",
      "979: 0 [ 127 -127] 0\n",
      "model accuracy is 97.040816% (Number of test samples=980)\n"
     ]
    }
   ],
   "source": [
    "TFLITE_MODEL_FILE = 'models/KWS_op.tflite'\n",
    "interpreter = tf.lite.Interpreter(model_path = TFLITE_MODEL_FILE)\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()[0]\n",
    "output_details = interpreter.get_output_details()[0]\n",
    "\n",
    "test_ds = np.expand_dims(test_ds, axis=1).astype(np.float32)\n",
    "\n",
    "input_scale, input_zero_point = input_details['quantization']\n",
    "test_ds = test_ds / input_scale + input_zero_point\n",
    "test_ds = test_ds.astype(input_details['dtype'])\n",
    "print(input_scale)\n",
    "print(input_zero_point)\n",
    "print(len(test_ds[3].tolist()))\n",
    "print(test_ds[3].tolist())\n",
    "\n",
    "correct_predictions = 0\n",
    "for i in range(len(test_ds)):\n",
    "    interpreter.set_tensor(input_details[\"index\"], test_ds[i])\n",
    "    interpreter.invoke()\n",
    "    output = interpreter.get_tensor(output_details[\"index\"])[0]\n",
    "    top_prediction = output.argmax()\n",
    "    correct_predictions += (top_prediction == y_test[i])\n",
    "    print(str(i)+': '+str(y_test[i])+' '+str(output)+' '+str(top_prediction))\n",
    "\n",
    "print('model accuracy is %f%% (Number of test samples=%d)' % (\n",
    "    (correct_predictions * 100) / len(test_ds), len(test_ds)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9e1a5e6c-75a9-4854-a27b-d48f37b36504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving './models/KWS_op.tflite' at http://localhost:8080\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('localhost', 8080)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import netron\n",
    "netron.start(R'./models/KWS_op.tflite')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357a8978-d451-4d7a-a165-a84d44c2f5ed",
   "metadata": {},
   "source": [
    "### Create binary file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "57721568-4147-4fbe-999e-442aa3c25db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_TFLITE = './models/KWS_op.tflite'\n",
    "MODEL_TFLITE_MICRO = 'kws_yes_no.cc'\n",
    "!xxd -i {MODEL_TFLITE} > {MODEL_TFLITE_MICRO}\n",
    "REPLACE_TEXT = MODEL_TFLITE.replace('/', '_').replace('.', '_')\n",
    "!sed -i 's/'{REPLACE_TEXT}'/g_model/g' {MODEL_TFLITE_MICRO}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5084a1a1-cbbd-40d5-947e-7c6431b58feb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unsigned char g_model[] = {\n",
      "  0x20, 0x00, 0x00, 0x00, 0x54, 0x46, 0x4c, 0x33, 0x00, 0x00, 0x00, 0x00,\n",
      "  0x14, 0x00, 0x20, 0x00, 0x1c, 0x00, 0x18, 0x00, 0x14, 0x00, 0x10, 0x00,\n",
      "  0x0c, 0x00, 0x00, 0x00, 0x08, 0x00, 0x04, 0x00, 0x14, 0x00, 0x00, 0x00,\n",
      "  0x1c, 0x00, 0x00, 0x00, 0x1c, 0x00, 0x00, 0x00, 0x9c, 0x00, 0x00, 0x00,\n",
      "  0x24, 0x19, 0x00, 0x00, 0x34, 0x19, 0x00, 0x00, 0x18, 0x28, 0x00, 0x00,\n",
      "  0x03, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x03, 0x00, 0x00, 0x00,\n",
      "  0x5c, 0x00, 0x00, 0x00, 0x2c, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00,\n",
      "  0xb8, 0xff, 0xff, 0xff, 0x16, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00,\n",
      "  0x13, 0x00, 0x00, 0x00, 0x43, 0x4f, 0x4e, 0x56, 0x45, 0x52, 0x53, 0x49,\n",
      "  0x4f, 0x4e, 0x5f, 0x4d, 0x45, 0x54, 0x41, 0x44, 0x41, 0x54, 0x41, 0x00,\n",
      "  0xdc, 0xff, 0xff, 0xff, 0x15, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00,\n",
      "  0x13, 0x00, 0x00, 0x00, 0x6d, 0x69, 0x6e, 0x5f, 0x72, 0x75, 0x6e, 0x74,\n",
      "  0x69, 0x6d, 0x65, 0x5f, 0x76, 0x65, 0x72, 0x73, 0x69, 0x6f, 0x6e, 0x00,\n",
      "  0x08, 0x00, 0x0c, 0x00, 0x08, 0x00, 0x04, 0x00, 0x08, 0x00, 0x00, 0x00,\n",
      "  0x14, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0x13, 0x00, 0x00, 0x00,\n",
      "  0x6d, 0x69, 0x6e, 0x5f, 0x72, 0x75, 0x6e, 0x74, 0x69, 0x6d, 0x65, 0x5f,\n",
      "  0x76, 0x65, 0x72, 0x73, 0x69, 0x6f, 0x6e, 0x00, 0x17, 0x00, 0x00, 0x00,\n",
      "  0x84, 0x18, 0x00, 0x00, 0x7c, 0x18, 0x00, 0x00, 0x68, 0x18, 0x00, 0x00,\n",
      "  0x54, 0x18, 0x00, 0x00, 0x40, 0x18, 0x00, 0x00, 0x2c, 0x18, 0x00, 0x00,\n",
      "  0x24, 0x18, 0x00, 0x00, 0x0c, 0x18, 0x00, 0x00, 0xf4, 0x17, 0x00, 0x00,\n",
      "  0x8c, 0x01, 0x00, 0x00, 0x50, 0x01, 0x00, 0x00, 0xdc, 0x00, 0x00, 0x00,\n",
      "  0xd4, 0x00, 0x00, 0x00, 0xcc, 0x00, 0x00, 0x00, 0xc4, 0x00, 0x00, 0x00,\n",
      "  0xbc, 0x00, 0x00, 0x00, 0xb4, 0x00, 0x00, 0x00, 0xac, 0x00, 0x00, 0x00,\n",
      "  0xa4, 0x00, 0x00, 0x00, 0x9c, 0x00, 0x00, 0x00, 0x7c, 0x00, 0x00, 0x00,\n",
      "  0x5c, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0x3e, 0xe6, 0xff, 0xff,\n",
      "  0x04, 0x00, 0x00, 0x00, 0x48, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00,\n",
      "  0xdc, 0xff, 0xff, 0xff, 0x10, 0x00, 0x00, 0x00, 0x24, 0x00, 0x00, 0x00,\n",
      "  0x00, 0x00, 0x06, 0x00, 0x08, 0x00, 0x04, 0x00, 0x06, 0x00, 0x00, 0x00,\n",
      "  0x04, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0xeb, 0x03, 0x00, 0x00,\n",
      "  0x08, 0x00, 0x0c, 0x00, 0x08, 0x00, 0x04, 0x00, 0x08, 0x00, 0x00, 0x00,\n",
      "  0x01, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0x06, 0x00, 0x00, 0x00,\n",
      "  0x32, 0x2e, 0x31, 0x36, 0x2e, 0x31, 0x00, 0x00, 0x92, 0xe6, 0xff, 0xff,\n",
      "  0x04, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
      "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
      "  0xae, 0xe6, 0xff, 0xff, 0x04, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00,\n",
      "  0x31, 0x2e, 0x31, 0x34, 0x2e, 0x30, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
      "  0x00, 0x00, 0x00, 0x00, 0x28, 0xda, 0xff, 0xff, 0x2c, 0xda, 0xff, 0xff,\n",
      "  0x30, 0xda, 0xff, 0xff, 0x34, 0xda, 0xff, 0xff, 0x38, 0xda, 0xff, 0xff,\n",
      "  0x3c, 0xda, 0xff, 0xff, 0x40, 0xda, 0xff, 0xff, 0x44, 0xda, 0xff, 0xff,\n",
      "  0xea, 0xe6, 0xff, 0xff, 0x04, 0x00, 0x00, 0x00, 0x63, 0x00, 0x00, 0x00,\n",
      "  0x06, 0xfd, 0x39, 0xcd, 0x3f, 0xe5, 0xc7, 0x7f, 0xbe, 0x7f, 0xee, 0x29,\n",
      "  0x33, 0x3e, 0x3d, 0xc6, 0xbf, 0x00, 0xec, 0x02, 0x7f, 0xd5, 0xf5, 0x30,\n",
      "  0xc1, 0xef, 0xf4, 0x81, 0xa4, 0x71, 0x35, 0x6a, 0x5c, 0x53, 0xc6, 0xbe,\n",
      "  0xba, 0xdb, 0x7f, 0x0b, 0x33, 0xf4, 0x61, 0xfd, 0x95, 0x09, 0xe2, 0xda,\n",
      "  0x62, 0x9c, 0xd5, 0xbe, 0x7f, 0xde, 0xc7, 0xfa, 0xff, 0xb9, 0xf8, 0x7f,\n",
      "  0x22, 0x67, 0xcc, 0xe7, 0x81, 0x5c, 0x07, 0xbc, 0x52, 0x13, 0x1b, 0x5d,\n",
      "  0x30, 0x55, 0x12, 0x25, 0x33, 0x91, 0x7f, 0xa4, 0xa0, 0x49, 0x8d, 0xa4,\n",
      "  0x5f, 0x9d, 0x1c, 0x7f, 0x78, 0x05, 0xef, 0xfd, 0xb5, 0xb2, 0x27, 0x56,\n",
      "  0xec, 0xda, 0x7f, 0x00, 0x5a, 0xe7, 0xff, 0xff, 0x04, 0x00, 0x00, 0x00,\n",
      "  0x2c, 0x00, 0x00, 0x00, 0x3b, 0x08, 0x00, 0x00, 0xdc, 0x03, 0x00, 0x00,\n",
      "  0xa9, 0x01, 0x00, 0x00, 0x5e, 0x07, 0x00, 0x00, 0xc1, 0x0a, 0x00, 0x00,\n",
      "  0x95, 0xd9, 0xff, 0xff, 0xc0, 0x0a, 0x00, 0x00, 0xc9, 0x0c, 0x00, 0x00,\n",
      "  0x5b, 0x0a, 0x00, 0x00, 0xc2, 0x00, 0x00, 0x00, 0xd2, 0x06, 0x00, 0x00,\n",
      "  0x92, 0xe7, 0xff, 0xff, 0x04, 0x00, 0x00, 0x00, 0x58, 0x16, 0x00, 0x00,\n",
      "  0xfa, 0x76, 0xff, 0xff, 0x0f, 0x06, 0xf8, 0x03, 0x04, 0x04, 0xfb, 0xf9,\n",
      "  0x14, 0xfa, 0x01, 0xfc, 0x07, 0xfb, 0xfc, 0x02, 0x03, 0xff, 0x0b, 0x17,\n",
      "  0xff, 0xff, 0xff, 0x01, 0x0d, 0xff, 0xfd, 0x03, 0x00, 0x00, 0x19, 0xf9,\n",
      "  0x1c, 0x03, 0x04, 0x02, 0x18, 0xff, 0x03, 0xfe, 0x13, 0x34, 0xfc, 0xf3,\n",
      "  0x03, 0xfd, 0xef, 0xf2, 0xf7, 0x02, 0x03, 0xec, 0x0e, 0xff, 0xf4, 0xe6,\n",
      "  0x03, 0x0e, 0xce, 0x11, 0xfb, 0x08, 0x01, 0x0f, 0xff, 0xf2, 0xed, 0x02,\n",
      "  0xf2, 0x08, 0xf4, 0xd1, 0xfc, 0xec, 0x17, 0xf9, 0xfa, 0xf5, 0xfe, 0x18,\n",
      "  0xe6, 0xeb, 0xf5, 0x08, 0xf5, 0x14, 0x02, 0xfa, 0x09, 0x00, 0x16, 0xf1,\n",
      "  0xef, 0x02, 0x03, 0xfd, 0x0d, 0xff, 0x02, 0xd1, 0xfa, 0xfd, 0xf7, 0x05,\n",
      "  0x00, 0x03, 0x12, 0x16, 0x03, 0xff, 0xc0, 0xfd, 0xf2, 0xf1, 0x07, 0xfc,\n",
      "  0x00, 0xe1, 0x13, 0xfd, 0xf5, 0xf8, 0x00, 0xe3, 0xf6, 0x15, 0xff, 0xfc,\n",
      "  0x1f, 0x34, 0xfd, 0xfe, 0xda, 0x01, 0xf8, 0xeb, 0x0f, 0x0e, 0xf8, 0x08,\n",
      "  0x00, 0x04, 0x03, 0x08, 0xff, 0xfe, 0x07, 0x00, 0x09, 0xfc, 0x01, 0xfb,\n",
      "  0xff, 0xf6, 0xf6, 0x05, 0x05, 0x02, 0xfb, 0x05, 0xfa, 0x03, 0xe9, 0x01,\n",
      "  0xff, 0xfb, 0x02, 0x01, 0x05, 0xf8, 0xf7, 0xff, 0xfb, 0x4b, 0x03, 0x19,\n",
      "  0x03, 0x00, 0x06, 0x10, 0x00, 0xfd, 0xfa, 0xff, 0x04, 0xff, 0xfe, 0x0e,\n",
      "  0x02, 0xff, 0xff, 0x0d, 0xfd, 0xfb, 0x0a, 0xff, 0x02, 0xec, 0x07, 0xfd,\n",
      "  0x09, 0xee, 0x05, 0xf4, 0x05, 0xf1, 0xfd, 0xfe, 0xe6, 0xdb, 0xff, 0xfe,\n",
      "  0xf7, 0xf4, 0x08, 0xf8, 0xf9, 0x06, 0x01, 0x07, 0x15, 0xfd, 0x03, 0x0c,\n",
      "  0xfc, 0x0c, 0xfe, 0xe8, 0x00, 0x05, 0x1d, 0x09, 0xfd, 0x0c, 0x06, 0xfe,\n",
      "  0x05, 0x02, 0x04, 0xf9, 0x01, 0x09, 0x03, 0xf8, 0xfc, 0x00, 0x0d, 0x10,\n",
      "  0xfc, 0xe7, 0xb3, 0x00, 0xe5, 0xe6, 0xfb, 0xee, 0xf3, 0xf5, 0xff, 0x01,\n",
      "  0xd3, 0x00, 0x04, 0xf8, 0xe7, 0xf8, 0xec, 0xf4, 0x03, 0x03, 0x00, 0x08,\n",
      "  0xfd, 0xfe, 0x11, 0xfb, 0xfc, 0x01, 0xf7, 0xff, 0xfb, 0xff, 0x05, 0xfe,\n",
      "  0x01, 0xfc, 0xfd, 0x04, 0x06, 0x05, 0xfe, 0x00, 0xfe, 0x03, 0x23, 0xff,\n",
      "  0x07, 0xfa, 0xfc, 0x09, 0x09, 0x01, 0xfa, 0xff, 0xfd, 0xaf, 0xfd, 0xfa,\n",
      "  0xff, 0xfe, 0xff, 0x00, 0xfa, 0xfb, 0xfc, 0x02, 0x1c, 0xff, 0xef, 0x08,\n",
      "  0xff, 0x04, 0x01, 0x04, 0x00, 0x04, 0x06, 0xae, 0xff, 0x10, 0x07, 0x06,\n",
      "  0x02, 0x02, 0xfe, 0xfe, 0xfe, 0x09, 0xfc, 0xf9, 0xfc, 0x01, 0x03, 0xf6,\n",
      "  0xfb, 0x03, 0x06, 0xfd, 0x11, 0xfd, 0xf5, 0x19, 0x1b, 0x02, 0x10, 0x13,\n",
      "  0x00, 0x01, 0x01, 0x02, 0xfd, 0xfd, 0x14, 0x0c, 0x01, 0x11, 0x0a, 0x0d,\n",
      "  0x09, 0xfb, 0xeb, 0xdd, 0x02, 0xfd, 0xf0, 0x02, 0xf5, 0xef, 0x05, 0x15,\n",
      "  0xfe, 0x05, 0x04, 0xfe, 0xf3, 0xf4, 0xf9, 0xfa, 0xfb, 0xf9, 0xf0, 0x00,\n",
      "  0xf2, 0xb0, 0x0a, 0xfe, 0xe2, 0xfa, 0xf9, 0xf2, 0xfe, 0x09, 0xfb, 0xfb,\n",
      "  0xc4, 0x04, 0x01, 0xe7, 0xf8, 0xfc, 0x04, 0x03, 0x0f, 0x01, 0x05, 0xda,\n",
      "  0x03, 0x12, 0x14, 0xfa, 0x00, 0xfe, 0xf6, 0x08, 0xfc, 0xfd, 0x23, 0x02,\n",
      "  0x08, 0xff, 0x04, 0x01, 0x05, 0x03, 0x07, 0x01, 0x05, 0x25, 0x07, 0x05,\n",
      "  0x01, 0x02, 0xff, 0x00, 0xff, 0xfc, 0xfe, 0xfc, 0x9b, 0x00, 0xfd, 0x00,\n",
      "  0x02, 0xff, 0xff, 0x01, 0xfe, 0xf9, 0x01, 0xac, 0xfe, 0x03, 0xf6, 0x02,\n",
      "  0x05, 0x07, 0xfe, 0xfd, 0x00, 0x04, 0x89, 0xfc, 0xf2, 0xf7, 0x08, 0x05,\n",
      "  0x00, 0x00, 0x08, 0x03, 0x01, 0x03, 0xfc, 0x16, 0xf2, 0xff, 0x0f, 0xfb,\n",
      "  0x04, 0x03, 0xfd, 0xfc, 0x01, 0xfe, 0x1e, 0x11, 0x03, 0x0f, 0x16, 0x09,\n",
      "  0xfd, 0x00, 0x1f, 0x01, 0x04, 0x3f, 0x22, 0xff, 0x13, 0x0a, 0x16, 0x21,\n",
      "  0x02, 0xfe, 0xa5, 0x01, 0x0c, 0x01, 0x01, 0x03, 0xff, 0x06, 0x0e, 0x06,\n",
      "  0xe2, 0xcf, 0x03, 0xf5, 0xf3, 0xfd, 0xeb, 0xf6, 0x0c, 0x07, 0xfc, 0x0d,\n",
      "  0xce, 0x00, 0xf2, 0xe1, 0xfd, 0xf7, 0xf4, 0xf0, 0xff, 0x00, 0x08, 0xf4,\n",
      "  0x08, 0x03, 0x01, 0xff, 0xf5, 0xff, 0x02, 0x0e, 0xf9, 0x18, 0x07, 0x01,\n",
      "  0x1d, 0x01, 0xfd, 0x0a, 0x03, 0x02, 0x05, 0xfc, 0x02, 0x16, 0xff, 0x06,\n",
      "  0x04, 0x00, 0x04, 0x00, 0x05, 0x06, 0x01, 0x04, 0xa9, 0xfd, 0xfd, 0x00,\n",
      "  0x04, 0xfe, 0x00, 0xff, 0x05, 0x03, 0x02, 0xa2, 0xf6, 0xf6, 0xfd, 0x01,\n",
      "  0xfd, 0xfe, 0x02, 0xff, 0x01, 0x00, 0xec, 0xfa, 0xf3, 0xf9, 0x05, 0x03,\n",
      "  0x05, 0xfc, 0xfa, 0x07, 0x03, 0xee, 0x03, 0x03, 0x03, 0xfe, 0xfc, 0x02,\n",
      "  0x00, 0x03, 0xfe, 0x08, 0xf9, 0xfc, 0x02, 0x02, 0x00, 0x00, 0x07, 0x07,\n",
      "  0x08, 0x03, 0xff, 0x12, 0xff, 0x16, 0x0b, 0xfe, 0x0c, 0x0e, 0x04, 0xec,\n",
      "  0x00, 0xfe, 0xfd, 0x03, 0x2d, 0x1b, 0xf9, 0x14, 0x0f, 0x1d, 0xf8, 0x04,\n",
      "  0xfd, 0xae, 0xfa, 0x04, 0x07, 0x02, 0xfd, 0xf9, 0x0c, 0x1e, 0x05, 0xf4,\n",
      "  0xd0, 0x00, 0xf4, 0xf5, 0xf9, 0xf5, 0xfb, 0xf1, 0x0d, 0xfa, 0x0b, 0xe8,\n",
      "  0x06, 0x01, 0xf1, 0x00, 0xfb, 0xf3, 0xfa, 0x0b, 0xf8, 0x0d, 0xea, 0x03,\n",
      "  0xf3, 0xe4, 0xfe, 0xf2, 0xf8, 0xfe, 0x08, 0x00, 0x12, 0xeb, 0x03, 0xee,\n",
      "  0xfb, 0x00, 0xf7, 0x02, 0x05, 0x09, 0xfd, 0x05, 0x49, 0xfc, 0xfa, 0xf9,\n",
      "  0x03, 0xff, 0x09, 0x05, 0x07, 0xfc, 0x00, 0x09, 0x01, 0x00, 0xff, 0x00,\n",
      "  0x04, 0xff, 0xff, 0x05, 0x00, 0x00, 0x92, 0xfd, 0xf8, 0x01, 0xfc, 0x00,\n",
      "  0xfd, 0x00, 0xfe, 0x00, 0xfc, 0xf6, 0x01, 0x02, 0xfd, 0x00, 0x01, 0x09,\n",
      "  0xfe, 0x00, 0xff, 0x06, 0x04, 0xfe, 0x04, 0x05, 0xff, 0x07, 0x06, 0x01,\n",
      "  0x01, 0x00, 0x02, 0xf8, 0xff, 0x0b, 0x02, 0x08, 0x09, 0x02, 0x08, 0x04,\n",
      "  0xfb, 0x08, 0x35, 0xf7, 0x21, 0x1e, 0x02, 0x12, 0x12, 0x05, 0x20, 0xff,\n",
      "  0x06, 0x17, 0xf8, 0x02, 0x11, 0x08, 0x17, 0x03, 0x19, 0x05, 0x02, 0xfb,\n",
      "  0xd6, 0xfa, 0x05, 0x05, 0x02, 0x04, 0xfa, 0x01, 0x0b, 0xfe, 0xef, 0xdc,\n",
      "  0x02, 0xfa, 0xe3, 0x02, 0xf9, 0xfc, 0xf5, 0x03, 0x01, 0xf7, 0xb6, 0x00,\n",
      "  0xdf, 0xe5, 0x04, 0xf9, 0xfb, 0xf5, 0x0a, 0xff, 0x08, 0xc5, 0x05, 0xee,\n",
      "  0xf2, 0x04, 0xf9, 0xfe, 0xff, 0x09, 0xfe, 0x0a, 0xbf, 0x03, 0xfe, 0x02,\n",
      "  0xff, 0x00, 0xf7, 0xfc, 0x0b, 0x01, 0x09, 0xe1, 0x02, 0xff, 0xff, 0xfa,\n",
      "  0x02, 0x01, 0x00, 0x05, 0x01, 0x01, 0xfa, 0x00, 0xfb, 0xf9, 0xff, 0x06,\n",
      "  0x05, 0x01, 0x00, 0xfd, 0x01, 0x81, 0x05, 0xff, 0x00, 0xf4, 0xfe, 0x01,\n",
      "  0xfa, 0xfd, 0x00, 0x08, 0xf2, 0x02, 0x01, 0xff, 0x02, 0x06, 0x06, 0x02,\n",
      "  0xf8, 0x03, 0x04, 0xb1, 0x06, 0x05, 0x05, 0xfd, 0x00, 0xfe, 0x01, 0xfb,\n",
      "  0x00, 0x07, 0x0d, 0xfe, 0x0d, 0x07, 0x02, 0xf8, 0xff, 0x00, 0xff, 0x05,\n",
      "  0x06, 0x42, 0xfe, 0x04, 0x07, 0xff, 0x08, 0x0c, 0x06, 0x08, 0xff, 0x06,\n",
      "  0xff, 0xfd, 0x0a, 0x14, 0x03, 0x08, 0x0c, 0x19, 0x15, 0x00, 0xff, 0x05,\n",
      "  0xfa, 0x0e, 0x02, 0xfd, 0x03, 0xf9, 0x00, 0x0c, 0xfe, 0xf3, 0xc4, 0xff,\n",
      "  0xff, 0xf3, 0xfc, 0xf3, 0xf4, 0xe7, 0x0c, 0xf7, 0x04, 0xf7, 0xff, 0xfe,\n",
      "  0xef, 0x04, 0xfb, 0xf0, 0x03, 0xfa, 0xfa, 0x08, 0xfe, 0x07, 0xfe, 0xfe,\n",
      "  0x00, 0xfa, 0x02, 0xfe, 0x0a, 0xff, 0xfd, 0xcb, 0x02, 0x1b, 0x00, 0x04,\n",
      "  0x00, 0xfe, 0x04, 0x05, 0xff, 0x07, 0xf8, 0x03, 0xff, 0xfe, 0xff, 0x05,\n",
      "  0x05, 0xfd, 0x02, 0xfe, 0x0a, 0x02, 0x01, 0xf6, 0x00, 0xfa, 0x08, 0x03,\n",
      "  0x05, 0x01, 0x03, 0x01, 0xe6, 0xfd, 0xf7, 0x00, 0xff, 0x00, 0xff, 0xfe,\n",
      "  0xfd, 0x02, 0x00, 0xe7, 0xfd, 0xf5, 0xfd, 0xfd, 0x00, 0x07, 0x05, 0xf8,\n",
      "  0x05, 0xff, 0xaa, 0xfc, 0xfa, 0x02, 0x03, 0x05, 0x05, 0xfd, 0x04, 0xff,\n",
      "  0x03, 0x1a, 0x01, 0xe9, 0xfb, 0xf9, 0x03, 0x01, 0xfa, 0xf9, 0x01, 0x05,\n",
      "  0x3d, 0x03, 0x0c, 0x13, 0xfd, 0x08, 0x05, 0x09, 0xf0, 0x04, 0x0c, 0xfa,\n",
      "  0xfb, 0x24, 0x21, 0xfc, 0x15, 0x07, 0x19, 0x07, 0xfb, 0xf4, 0xfc, 0xf9,\n",
      "  0x0c, 0x04, 0xff, 0x09, 0xf6, 0x04, 0x0f, 0xfa, 0xf3, 0xbb, 0x05, 0xfa,\n",
      "  0xf0, 0xfb, 0xf4, 0xfb, 0xed, 0x07, 0x03, 0x07, 0xcc, 0x03, 0xe7, 0xef,\n",
      "  0xff, 0xfc, 0x00, 0xfb, 0x05, 0xf8, 0x0c, 0xce, 0x01, 0xe7, 0xf0, 0x02,\n",
      "  0x01, 0xff, 0xfc, 0x10, 0xfe, 0xfd, 0xde, 0x05, 0x06, 0xf0, 0x05, 0xfe,\n",
      "  0x11, 0x03, 0x13, 0x01, 0x05, 0xc2, 0xff, 0x05, 0x01, 0xff, 0x05, 0x03,\n",
      "  0x03, 0x05, 0x03, 0x06, 0x25, 0x02, 0x02, 0x03, 0xfb, 0x01, 0x04, 0x04,\n",
      "  0x08, 0x01, 0x04, 0xa3, 0xff, 0xf7, 0xff, 0xfb, 0xfd, 0xff, 0xff, 0x05,\n",
      "  0xfc, 0x06, 0xe2, 0xfe, 0xfe, 0x00, 0x00, 0x03, 0x09, 0x04, 0xfd, 0x00,\n",
      "  0x02, 0xc7, 0x01, 0x01, 0xfe, 0xfe, 0x06, 0x01, 0xff, 0xfd, 0x00, 0x07,\n",
      "  0x17, 0xfe, 0xf1, 0x04, 0xfb, 0x03, 0x07, 0x05, 0xfa, 0x03, 0x00, 0x12,\n",
      "  0xff, 0xff, 0x0e, 0xfa, 0x00, 0x09, 0x06, 0x0c, 0x00, 0x07, 0x29, 0xfc,\n",
      "  0x1d, 0x15, 0x02, 0x10, 0x0f, 0x18, 0x03, 0x01, 0xfc, 0x3c, 0xfd, 0x0f,\n",
      "  0xfa, 0x08, 0x04, 0xfc, 0x08, 0x19, 0xff, 0xf6, 0xcf, 0x02, 0xf8, 0xe8,\n",
      "  0x04, 0xe8, 0xef, 0xeb, 0x0e, 0xff, 0x00, 0xd3, 0x03, 0xf2, 0xec, 0x03,\n",
      "  0xf9, 0x02, 0x01, 0xfc, 0x01, 0xfd, 0x8e, 0x09, 0xfc, 0xf6, 0x06, 0xfe,\n",
      "  0x03, 0x05, 0x09, 0xfc, 0xfd, 0xd3, 0x00, 0x06, 0xfe, 0x04, 0xf7, 0xfe,\n",
      "  0xff, 0x10, 0x02, 0x08, 0x05, 0xfb, 0x02, 0x04, 0xf8, 0x05, 0x06, 0x03,\n",
      "  0x09, 0xfe, 0x09, 0x0e, 0x05, 0x03, 0x01, 0xf8, 0x05, 0x09, 0xfe, 0xff,\n",
      "  0x02, 0x02, 0x00, 0xfa, 0xfa, 0x06, 0xf8, 0xfa, 0x07, 0x06, 0xfd, 0xfc,\n",
      "  0x00, 0xf6, 0xfb, 0x09, 0xff, 0xff, 0xff, 0x07, 0x06, 0xff, 0x00, 0x00,\n",
      "  0x01, 0x01, 0x03, 0x01, 0xff, 0x05, 0x03, 0x00, 0xff, 0xfd, 0xf9, 0x00,\n",
      "  0xfd, 0x06, 0x00, 0xf8, 0xf7, 0x0e, 0x01, 0x02, 0xfa, 0x05, 0x01, 0xfc,\n",
      "  0x13, 0x16, 0x03, 0x08, 0x0c, 0x08, 0xf7, 0x09, 0x0f, 0x11, 0xf7, 0x18,\n",
      "  0x18, 0x05, 0x13, 0x05, 0x1a, 0xf7, 0x02, 0xfe, 0xf9, 0xfa, 0x0b, 0xfa,\n",
      "  0x02, 0xfb, 0x00, 0x02, 0x0f, 0xfc, 0xfd, 0xb6, 0x06, 0xfd, 0xf1, 0x03,\n",
      "  0xf9, 0xef, 0xf3, 0x07, 0xf6, 0x05, 0xe5, 0x00, 0xf7, 0xf3, 0x03, 0xf0,\n",
      "  0xf6, 0xfb, 0x06, 0xfc, 0x07, 0x02, 0x09, 0x01, 0xf0, 0x05, 0xff, 0x04,\n",
      "  0xf7, 0x0f, 0xf7, 0x04, 0xd5, 0xfd, 0x0f, 0xfb, 0x09, 0x00, 0xfd, 0x02,\n",
      "  0x11, 0xfc, 0x02, 0x07, 0xff, 0x04, 0x00, 0xfa, 0x05, 0x00, 0x00, 0x02,\n",
      "  0xfb, 0x08, 0x07, 0xfe, 0xff, 0x00, 0xf5, 0xfe, 0x06, 0xfb, 0xff, 0x03,\n",
      "  0x02, 0xf9, 0xfb, 0xf7, 0x05, 0xfc, 0xfd, 0x04, 0x04, 0xff, 0xfd, 0xfd,\n",
      "  0xf9, 0xfa, 0x04, 0x05, 0xfb, 0x02, 0x06, 0x00, 0xf6, 0x01, 0x01, 0xff,\n",
      "  0x05, 0xff, 0xfe, 0x04, 0xfc, 0x00, 0x01, 0x01, 0xfb, 0x04, 0x07, 0x00,\n",
      "  0xfe, 0x03, 0x01, 0xfc, 0x03, 0x02, 0x01, 0x07, 0x0d, 0x23, 0xfa, 0x0f,\n",
      "  0x04, 0x00, 0x12, 0x05, 0x04, 0xf7, 0x00, 0x07, 0x16, 0xf9, 0x26, 0x1b,\n",
      "  0x00, 0x16, 0x0a, 0x18, 0x1f, 0x05, 0xfe, 0x06, 0xfb, 0xf7, 0x00, 0x03,\n",
      "  0x07, 0x07, 0x00, 0x18, 0x01, 0xef, 0x02, 0xfb, 0xfa, 0xe8, 0x06, 0xf1,\n",
      "  0xf7, 0xed, 0x0d, 0xfb, 0x01, 0x02, 0xfd, 0xf8, 0xeb, 0x02, 0xee, 0xfb,\n",
      "  0xf4, 0x07, 0xff, 0x08, 0xfd, 0xfa, 0x0e, 0xee, 0x08, 0x04, 0x07, 0xf9,\n",
      "  0xff, 0xf9, 0x04, 0x04, 0xfa, 0x05, 0xfe, 0x0e, 0x01, 0xff, 0x01, 0x0f,\n",
      "  0xff, 0xff, 0xfe, 0xfd, 0xff, 0xff, 0xf7, 0xff, 0x05, 0x04, 0x04, 0xfd,\n",
      "  0x06, 0xff, 0x00, 0x03, 0x05, 0xf6, 0xfc, 0x03, 0xfb, 0x03, 0xfb, 0x00,\n",
      "  0xfc, 0x00, 0xf3, 0x02, 0xf9, 0x00, 0x09, 0x00, 0xfc, 0x00, 0x05, 0xfc,\n",
      "  0xfd, 0x04, 0xfc, 0x01, 0x00, 0x07, 0x00, 0xf3, 0x02, 0x05, 0xfe, 0x00,\n",
      "  0xfb, 0xff, 0xfe, 0x05, 0x02, 0x02, 0x04, 0x02, 0xfd, 0x02, 0xfe, 0x0f,\n",
      "  0x02, 0xf6, 0x00, 0x08, 0x02, 0x00, 0x01, 0x09, 0x0a, 0x01, 0x18, 0x09,\n",
      "  0xfb, 0x0e, 0x01, 0x0b, 0x0d, 0x01, 0xfe, 0x20, 0x00, 0x22, 0x2a, 0xfa,\n",
      "  0x0e, 0x06, 0x1a, 0x1a, 0xfd, 0xf4, 0x0d, 0xf8, 0x0c, 0x03, 0x08, 0x06,\n",
      "  0x01, 0x08, 0x1d, 0xfe, 0xef, 0x08, 0x01, 0xff, 0xf6, 0x01, 0xf4, 0xf2,\n",
      "  0xf8, 0x05, 0x00, 0x02, 0xf5, 0xfb, 0xef, 0xe6, 0x05, 0xf3, 0xfb, 0x00,\n",
      "  0x15, 0xfc, 0x08, 0x03, 0x02, 0xf5, 0x02, 0x0d, 0xf7, 0xfe, 0xfc, 0x0d,\n",
      "  0xf9, 0x00, 0xff, 0xfe, 0x0e, 0x05, 0x0d, 0x01, 0x04, 0xff, 0x16, 0xf5,\n",
      "  0x06, 0xff, 0xfe, 0x03, 0x01, 0xf8, 0xfc, 0x02, 0x03, 0x0a, 0x00, 0xff,\n",
      "  0xfa, 0xfc, 0xfd, 0x02, 0xff, 0xf9, 0x04, 0xff, 0x06, 0x01, 0x0b, 0x02,\n",
      "  0xfb, 0xf4, 0x01, 0xff, 0x03, 0xfd, 0xfc, 0xf9, 0x02, 0x02, 0x05, 0x00,\n",
      "  0xfc, 0x02, 0xff, 0x06, 0x0a, 0x01, 0x00, 0x02, 0x04, 0x02, 0xfe, 0x06,\n",
      "  0x00, 0xfb, 0xff, 0x07, 0x05, 0x02, 0xfc, 0x05, 0x05, 0xfd, 0xee, 0x01,\n",
      "  0xf9, 0xf5, 0xf8, 0x00, 0xfc, 0x03, 0x06, 0x06, 0x04, 0x0c, 0x11, 0x01,\n",
      "  0x07, 0x14, 0x0d, 0xf4, 0x06, 0x08, 0x0b, 0xfb, 0x18, 0x18, 0x00, 0x10,\n",
      "  0x0c, 0x10, 0x21, 0xfd, 0x06, 0x04, 0xf7, 0x00, 0xff, 0x0a, 0x04, 0x01,\n",
      "  0x07, 0x25, 0xfb, 0xe5, 0xf8, 0xfc, 0x09, 0xec, 0xff, 0xf1, 0xef, 0xfb,\n",
      "  0x15, 0xfe, 0x01, 0x01, 0x03, 0xe4, 0xe6, 0xff, 0xee, 0xf6, 0xf8, 0x09,\n",
      "  0xfd, 0x0b, 0xfc, 0x00, 0x09, 0x00, 0x08, 0xff, 0x06, 0x00, 0x0b, 0xff,\n",
      "  0xfc, 0x03, 0xfa, 0x19, 0x02, 0x0e, 0xef, 0xfa, 0xfb, 0x12, 0xf9, 0x01,\n",
      "  0x00, 0x01, 0xff, 0xfd, 0xf9, 0x04, 0x04, 0xff, 0x05, 0xfd, 0x01, 0x00,\n",
      "  0x00, 0xf4, 0xfc, 0xfb, 0x00, 0x07, 0x00, 0x00, 0xff, 0xff, 0x02, 0xff,\n",
      "  0x01, 0xff, 0xf9, 0x03, 0x04, 0x00, 0xfa, 0xfd, 0x05, 0x05, 0xfd, 0xf7,\n",
      "  0x08, 0xff, 0xff, 0x07, 0xfe, 0xfe, 0xfd, 0x04, 0xf9, 0x04, 0x03, 0xfe,\n",
      "  0x03, 0x07, 0x02, 0x03, 0xfd, 0x01, 0x06, 0xff, 0x07, 0x02, 0xfd, 0x00,\n",
      "  0xfd, 0x06, 0x02, 0xfa, 0xff, 0x09, 0x11, 0xfe, 0x39, 0x1f, 0xfc, 0x12,\n",
      "  0x0f, 0x0a, 0x15, 0x05, 0x09, 0x06, 0xfa, 0x22, 0x1a, 0xfe, 0x10, 0x13,\n",
      "  0x0e, 0x21, 0xfe, 0xf0, 0x15, 0xf2, 0x07, 0x07, 0x05, 0x07, 0x05, 0x08,\n",
      "  0x12, 0x00, 0xd3, 0x37, 0x04, 0xff, 0xd5, 0x0b, 0xf9, 0xf2, 0xf6, 0x11,\n",
      "  0xfa, 0x00, 0xf7, 0x02, 0xf0, 0xdf, 0x05, 0xf5, 0xea, 0x00, 0xf0, 0x00,\n",
      "  0xfe, 0xfb, 0xfc, 0xe1, 0xee, 0x08, 0xfb, 0x04, 0xfb, 0x1c, 0xfd, 0xfc,\n",
      "  0xf4, 0xfe, 0x0b, 0xf1, 0x0c, 0xfe, 0x01, 0xfe, 0x17, 0xf7, 0x0a, 0x02,\n",
      "  0x02, 0x00, 0x06, 0xfe, 0x02, 0xff, 0x04, 0x03, 0xfc, 0x05, 0x09, 0x02,\n",
      "  0xfc, 0x00, 0xf9, 0xf9, 0x09, 0xfb, 0x03, 0x02, 0x03, 0xf8, 0x00, 0x03,\n",
      "  0xff, 0xf8, 0x02, 0xfd, 0x01, 0xfe, 0xfc, 0x03, 0x02, 0x02, 0x05, 0x05,\n",
      "  0xff, 0x08, 0x07, 0x00, 0xf8, 0x03, 0xfd, 0xfb, 0x04, 0x08, 0x07, 0x04,\n",
      "  0x08, 0xfd, 0x04, 0x05, 0xfd, 0xfe, 0x05, 0x03, 0xfc, 0x06, 0xfc, 0x03,\n",
      "  0x03, 0xfc, 0x00, 0x00, 0x04, 0x02, 0xfc, 0x2b, 0x15, 0x02, 0x0e, 0x14,\n",
      "  0x06, 0xdd, 0x04, 0x08, 0xfa, 0xf8, 0x25, 0x10, 0x01, 0x14, 0x0f, 0x09,\n",
      "  0x10, 0xfb, 0xf5, 0xed, 0xf6, 0x1c, 0xf9, 0x04, 0x0c, 0x0c, 0x04, 0x15,\n",
      "  0xf1, 0xe4, 0xef, 0x00, 0x07, 0xf4, 0x06, 0xf9, 0xed, 0xf7, 0x1e, 0xfb,\n",
      "  0x05, 0x05, 0x02, 0x01, 0xe8, 0xff, 0xef, 0xf4, 0xfc, 0xfe, 0x00, 0x03,\n",
      "  0x13, 0x03, 0x07, 0xe8, 0x02, 0xfa, 0x0b, 0x01, 0x04, 0x03, 0x03, 0x15,\n",
      "  0xf9, 0x0e, 0xf2, 0x0e, 0x03, 0x0d, 0x02, 0xfb, 0xf7, 0x00, 0x01, 0x03,\n",
      "  0xff, 0xfa, 0xff, 0xfe, 0x0a, 0xfc, 0x08, 0xff, 0x05, 0x06, 0xfe, 0x00,\n",
      "  0x01, 0xff, 0x08, 0x10, 0xff, 0x07, 0xff, 0x04, 0x01, 0x01, 0xf1, 0xfd,\n",
      "  0xfb, 0x01, 0x0a, 0x03, 0x08, 0x05, 0x00, 0x02, 0xfc, 0x0c, 0x07, 0x00,\n",
      "  0xfe, 0x0c, 0x03, 0xf6, 0xfd, 0x03, 0x0a, 0xfe, 0x0d, 0x04, 0xfd, 0x02,\n",
      "  0x04, 0xfb, 0xf4, 0x03, 0xff, 0x07, 0xfd, 0xfd, 0x01, 0xfa, 0x07, 0xfc,\n",
      "  0xfd, 0xf7, 0xfe, 0x07, 0x08, 0x01, 0x0a, 0x15, 0x05, 0x0e, 0xfe, 0x10,\n",
      "  0xaa, 0x04, 0x19, 0x00, 0x03, 0x19, 0x1b, 0xff, 0x1c, 0x0e, 0x0f, 0xf4,\n",
      "  0x02, 0x04, 0xfa, 0xf9, 0x0b, 0x0a, 0x09, 0x16, 0xfd, 0x08, 0x07, 0xfa,\n",
      "  0xf8, 0xf2, 0x04, 0xf3, 0xfd, 0x05, 0xf3, 0xf3, 0xf7, 0x07, 0xf9, 0x04,\n",
      "  0xf2, 0x01, 0xf9, 0xee, 0x00, 0xec, 0xe6, 0x04, 0xfd, 0x05, 0xfb, 0xfc,\n",
      "  0x06, 0xec, 0x08, 0x05, 0xf4, 0x0a, 0xfc, 0x16, 0xfe, 0x07, 0x07, 0xf8,\n",
      "  0x12, 0x03, 0x0a, 0xf9, 0xec, 0xfa, 0x1a, 0xf9, 0x07, 0x02, 0x09, 0xfb,\n",
      "  0xff, 0xfb, 0x01, 0x02, 0x04, 0xff, 0x01, 0x04, 0x3b, 0x05, 0x0c, 0x02,\n",
      "  0xfb, 0xf8, 0x0e, 0x02, 0x06, 0x06, 0x04, 0x29, 0x04, 0xf4, 0x04, 0xfc,\n",
      "  0x02, 0x07, 0x00, 0x03, 0x00, 0x07, 0x27, 0xfd, 0xf8, 0x07, 0x05, 0x02,\n",
      "  0x01, 0x03, 0xfb, 0x01, 0x05, 0xeb, 0x06, 0xf7, 0xfb, 0xfb, 0x01, 0xf4,\n",
      "  0x02, 0xf4, 0xff, 0xfd, 0xe4, 0x02, 0x01, 0xfe, 0xff, 0x01, 0xff, 0x00,\n",
      "  0xff, 0xff, 0x0b, 0xec, 0x00, 0x04, 0x19, 0x07, 0x09, 0x11, 0x09, 0xf2,\n",
      "  0xf6, 0x08, 0xb5, 0xfa, 0x0e, 0x0d, 0xfd, 0x1f, 0x05, 0x11, 0x59, 0xf5,\n",
      "  0xef, 0xe9, 0xf3, 0x09, 0xfc, 0x03, 0x12, 0xfd, 0xff, 0x2a, 0xf7, 0xea,\n",
      "  0xd3, 0xfd, 0xc8, 0xe5, 0x07, 0xdc, 0xe7, 0xfb, 0x11, 0xff, 0xf8, 0xd4,\n",
      "  0x03, 0xd7, 0xd4, 0x03, 0xda, 0x02, 0xfb, 0xe1, 0xfc, 0xf8, 0xfe, 0xfd,\n",
      "  0xbb, 0xf6, 0x03, 0x01, 0xfe, 0x07, 0x34, 0xf5, 0x15, 0x22, 0xf8, 0x01,\n",
      "  0xdf, 0x05, 0xfd, 0xf6, 0x01, 0x19, 0xf2, 0x0d, 0xf7, 0x06, 0xf6, 0x02,\n",
      "  0xfb, 0x04, 0xff, 0x03, 0x02, 0xfb, 0xfb, 0x04, 0x09, 0xfc, 0xf5, 0xfa,\n",
      "  0x03, 0xff, 0xff, 0x15, 0x03, 0x04, 0x00, 0xfe, 0xf3, 0x06, 0xfa, 0xf1,\n",
      "  0xfe, 0xff, 0x02, 0xfd, 0x09, 0xfa, 0x02, 0xed, 0xfb, 0xfe, 0x0d, 0x17,\n",
      "  0x05, 0x03, 0xff, 0x03, 0xf3, 0x00, 0xee, 0x0d, 0xfb, 0x10, 0xf9, 0x06,\n",
      "  0xf6, 0x04, 0x12, 0xff, 0x04, 0xfc, 0x05, 0x00, 0x1d, 0xfe, 0xfd, 0xf0,\n",
      "  0x05, 0x06, 0xf7, 0x00, 0x6b, 0x24, 0xff, 0x26, 0x29, 0x11, 0xff, 0xf9,\n",
      "  0x12, 0xeb, 0xf7, 0x52, 0x1b, 0x01, 0x28, 0x17, 0x09, 0x03, 0x01, 0xf1,\n",
      "  0x03, 0xfb, 0x09, 0xff, 0x03, 0x0d, 0xff, 0x05, 0x17, 0xfc, 0x06, 0xd5,\n",
      "  0xfc, 0x15, 0xfb, 0x00, 0xdd, 0xef, 0xfe, 0x0a, 0xfe, 0x06, 0xdc, 0x00,\n",
      "  0xde, 0xdf, 0x00, 0xf5, 0xf9, 0xf3, 0x2b, 0x02, 0x00, 0xe7, 0xfe, 0xfb,\n",
      "  0xea, 0x02, 0xfe, 0x10, 0x00, 0x1b, 0x00, 0x07, 0xe4, 0xf9, 0x20, 0xb9,\n",
      "  0x04, 0xf9, 0xdb, 0x0d, 0x3a, 0xf7, 0x05, 0xfc, 0x04, 0xfa, 0xf6, 0xfd,\n",
      "  0xf5, 0x02, 0x04, 0x05, 0xfd, 0x06, 0x02, 0x02, 0xf6, 0xf9, 0xfa, 0x07,\n",
      "  0x06, 0x02, 0x0d, 0x01, 0x08, 0xf8, 0x02, 0xfc, 0xfa, 0xfe, 0x03, 0xfb,\n",
      "  0x01, 0x02, 0x01, 0x05, 0xfb, 0x02, 0xfd, 0xf3, 0x01, 0x08, 0x09, 0x07,\n",
      "  0x03, 0x01, 0xf2, 0xff, 0x02, 0x00, 0xff, 0x04, 0xf6, 0x08, 0x00, 0xfc,\n",
      "  0xff, 0x14, 0xfc, 0x00, 0xf6, 0xfd, 0xfe, 0x22, 0xff, 0x02, 0x0a, 0x01,\n",
      "  0xfb, 0x02, 0xfd, 0xed, 0x08, 0x02, 0x11, 0x01, 0x0b, 0x0f, 0xff, 0xf7,\n",
      "  0x11, 0x02, 0x10, 0x21, 0xfc, 0x2a, 0x07, 0x0d, 0x1a, 0x01, 0xd3, 0x0a,\n",
      "  0xfe, 0x16, 0xed, 0xfd, 0x12, 0xfd, 0xfb, 0x1d, 0xff, 0xe1, 0xff, 0x00,\n",
      "  0xf7, 0xcb, 0xfe, 0xe4, 0xe1, 0xf6, 0x15, 0xfc, 0x15, 0xfd, 0xfc, 0x09,\n",
      "  0xe4, 0x02, 0x03, 0x09, 0xfb, 0x23, 0x00, 0xf8, 0x0c, 0xfe, 0xf3, 0xab,\n",
      "  0x00, 0xf3, 0xfd, 0x01, 0xf3, 0x01, 0xf9, 0x0e, 0xf7, 0x16, 0xca, 0x05,\n",
      "  0x1c, 0xeb, 0xff, 0x2f, 0xf7, 0xf9, 0x00, 0xff, 0xf7, 0xfe, 0xf6, 0x06,\n",
      "  0x12, 0x07, 0x0e, 0xf8, 0x03, 0x06, 0x04, 0x17, 0x07, 0x00, 0x02, 0x14,\n",
      "  0x00, 0x0c, 0x09, 0x0e, 0xfd, 0x00, 0xe4, 0x03, 0x00, 0x03, 0x0c, 0x02,\n",
      "  0xf9, 0x03, 0x03, 0xfe, 0xfe, 0xef, 0xfe, 0xfe, 0x0a, 0x0c, 0x00, 0xfa,\n",
      "  0x00, 0x08, 0x04, 0x06, 0x13, 0xfa, 0x00, 0xf8, 0x02, 0xfe, 0x03, 0x01,\n",
      "  0xff, 0x03, 0xfc, 0xf7, 0x02, 0x00, 0x10, 0x0a, 0x03, 0x1f, 0x01, 0xfe,\n",
      "  0x0b, 0x01, 0x09, 0x17, 0x01, 0x18, 0xf7, 0x09, 0x01, 0x01, 0xed, 0x0f,\n",
      "  0x00, 0x2a, 0xfd, 0xff, 0x1d, 0x0a, 0x0a, 0x9d, 0xfe, 0xe7, 0x0e, 0xf8,\n",
      "  0x21, 0x25, 0xfb, 0x08, 0x1e, 0xfa, 0x0a, 0xfe, 0xea, 0x01, 0x03, 0xff,\n",
      "  0xe4, 0xff, 0xfb, 0xe4, 0xf3, 0x34, 0xfe, 0x2a, 0x00, 0xfc, 0xdd, 0xff,\n",
      "  0xff, 0xec, 0xf6, 0xfd, 0xdb, 0xff, 0x03, 0x03, 0xfe, 0xea, 0xe9, 0xfa,\n",
      "  0x08, 0xe7, 0xf4, 0x1a, 0x03, 0x0b, 0x04, 0xfa, 0x1f, 0xfb, 0x03, 0x08,\n",
      "  0xfc, 0x06, 0x0b, 0xf3, 0xff, 0x89, 0x05, 0x06, 0xfc, 0x02, 0x02, 0xf2,\n",
      "  0xff, 0x02, 0xfd, 0xfe, 0xe5, 0x00, 0xf6, 0x02, 0x05, 0x05, 0x05, 0x03,\n",
      "  0xf8, 0x04, 0xf6, 0xeb, 0xfc, 0xff, 0xfe, 0x00, 0xf6, 0x01, 0x07, 0x0a,\n",
      "  0xfc, 0x09, 0xeb, 0x08, 0xe2, 0xfa, 0x00, 0x06, 0xea, 0x05, 0x03, 0x02,\n",
      "  0xf2, 0xd1, 0xff, 0x04, 0xf2, 0xfe, 0x16, 0x0d, 0x09, 0xfb, 0x00, 0x1b,\n",
      "  0xeb, 0x04, 0x0a, 0x0c, 0x01, 0xfb, 0x33, 0xe9, 0x10, 0x05, 0xfd, 0xec,\n",
      "  0x05, 0x10, 0x1d, 0xff, 0x0e, 0x00, 0x08, 0x2d, 0x01, 0x12, 0xf2, 0xfe,\n",
      "  0x07, 0x12, 0xfd, 0xed, 0x16, 0x12, 0x03, 0xfa, 0x06, 0xed, 0xfa, 0xff,\n",
      "  0xf8, 0x03, 0xe7, 0x19, 0x12, 0xfb, 0xfa, 0xfe, 0xf0, 0xf6, 0x02, 0x29,\n",
      "  0xfe, 0x0b, 0x0a, 0xfd, 0xff, 0x02, 0xed, 0xe8, 0xf8, 0x02, 0x40, 0x05,\n",
      "  0x0d, 0x13, 0xf8, 0xff, 0x00, 0x21, 0xe8, 0xfb, 0x01, 0x07, 0x02, 0x23,\n",
      "  0x09, 0xea, 0xf9, 0x05, 0xe3, 0xc6, 0x05, 0x08, 0x2a, 0x07, 0x0a, 0x0e,\n",
      "  0xe5, 0xfc, 0x01, 0xff, 0x00, 0x05, 0xfe, 0xff, 0xfe, 0xf8, 0xfb, 0x02,\n",
      "  0x04, 0xfd, 0x00, 0x04, 0xfd, 0xff, 0x04, 0x05, 0x05, 0x02, 0xfc, 0xfe,\n",
      "  0xfd, 0x02, 0x0c, 0xfd, 0xfd, 0xfe, 0x03, 0x05, 0xfb, 0xfc, 0x01, 0x01,\n",
      "  0x03, 0xb0, 0x04, 0xe6, 0xff, 0x00, 0xfc, 0xe9, 0x04, 0xff, 0x02, 0x04,\n",
      "  0xff, 0x06, 0x0d, 0xf2, 0x03, 0xfc, 0x01, 0xf7, 0x02, 0xff, 0xf6, 0x07,\n",
      "  0x00, 0x11, 0xfa, 0xfe, 0xef, 0x17, 0xfb, 0x06, 0x05, 0x0c, 0xff, 0xfa,\n",
      "  0x18, 0x1e, 0x00, 0x06, 0x09, 0x07, 0xf7, 0x00, 0x13, 0x04, 0xfb, 0xfc,\n",
      "  0xe9, 0x00, 0x00, 0xfd, 0x04, 0xf2, 0xfa, 0x13, 0x06, 0x03, 0xe7, 0xf0,\n",
      "  0x01, 0xf8, 0x01, 0x03, 0xf8, 0x09, 0x02, 0x05, 0xfd, 0xf6, 0xfd, 0xff,\n",
      "  0x0c, 0x02, 0xfd, 0xf5, 0x04, 0x17, 0x4f, 0xf4, 0x1a, 0x19, 0x01, 0x0e,\n",
      "  0x17, 0x01, 0xfc, 0x02, 0x2f, 0x08, 0x01, 0x07, 0x17, 0xfe, 0x0d, 0x11,\n",
      "  0xf9, 0xfa, 0x05, 0xf9, 0xff, 0xfd, 0xf8, 0x06, 0x02, 0x03, 0x08, 0x04,\n",
      "  0x06, 0x03, 0xfb, 0xfa, 0x00, 0xfd, 0x03, 0x02, 0x02, 0xfe, 0xfd, 0xfe,\n",
      "  0x01, 0xff, 0xdc, 0x00, 0xfb, 0x06, 0xfa, 0xfb, 0xfe, 0x03, 0xfb, 0x00,\n",
      "  0x03, 0x4b, 0x05, 0x0b, 0x04, 0xfb, 0x08, 0xff, 0x00, 0x00, 0x01, 0xfd,\n",
      "  0xe7, 0x06, 0x10, 0xfc, 0x00, 0x01, 0xf3, 0x02, 0x01, 0x03, 0xff, 0x55,\n",
      "  0xfc, 0xf5, 0xf8, 0x08, 0xfa, 0x02, 0x02, 0x03, 0x02, 0xf4, 0xfe, 0x05,\n",
      "  0x06, 0xfc, 0x02, 0x07, 0x03, 0xfd, 0x03, 0x00, 0xec, 0xfb, 0xfe, 0xed,\n",
      "  0xf0, 0x03, 0xf4, 0xf3, 0xfe, 0x03, 0xf8, 0xf3, 0x04, 0xf9, 0xe9, 0xee,\n",
      "  0x05, 0xec, 0xf4, 0xed, 0xfe, 0xfa, 0x12, 0x1f, 0xfd, 0x06, 0x0f, 0x03,\n",
      "  0x0f, 0x0f, 0x06, 0xef, 0x04, 0xfc, 0x06, 0xfb, 0x0a, 0x11, 0x00, 0x08,\n",
      "  0x05, 0x01, 0x0e, 0x03, 0x05, 0x52, 0xfd, 0xff, 0x20, 0x00, 0x0c, 0x05,\n",
      "  0x02, 0xfb, 0x02, 0xf9, 0x3e, 0xfa, 0x03, 0x1b, 0xfe, 0x0a, 0x01, 0xfd,\n",
      "  0xf9, 0x08, 0xfb, 0x28, 0xfb, 0xef, 0xef, 0xfc, 0x06, 0x04, 0x01, 0xf7,\n",
      "  0xfb, 0xf6, 0xd7, 0x04, 0xfc, 0xf9, 0xfd, 0xff, 0xfb, 0x02, 0x02, 0x03,\n",
      "  0x00, 0xd8, 0x00, 0xff, 0x08, 0xff, 0xf8, 0xff, 0xff, 0xf8, 0x00, 0xfd,\n",
      "  0x60, 0x09, 0x0d, 0x03, 0xff, 0x03, 0xfa, 0x00, 0x01, 0xfe, 0x01, 0x56,\n",
      "  0xff, 0x08, 0x05, 0xfb, 0x00, 0xf5, 0x01, 0x04, 0xfd, 0xfb, 0x75, 0x02,\n",
      "  0x10, 0x07, 0x04, 0x00, 0xfb, 0x02, 0xfe, 0x05, 0xf4, 0xfb, 0x04, 0xf0,\n",
      "  0x03, 0x01, 0xf9, 0x06, 0x06, 0x05, 0x01, 0xfb, 0x00, 0xfe, 0xe5, 0xf5,\n",
      "  0x02, 0xf5, 0xe1, 0xf8, 0x03, 0xfd, 0xee, 0xfc, 0x03, 0xbb, 0xd8, 0x01,\n",
      "  0xec, 0xfa, 0xf1, 0xec, 0x01, 0x01, 0x5c, 0xfb, 0xfb, 0xf7, 0x06, 0x04,\n",
      "  0x01, 0xf4, 0xf2, 0x07, 0x21, 0x30, 0xff, 0x10, 0x09, 0xfe, 0x15, 0x0d,\n",
      "  0xff, 0xff, 0x04, 0xf7, 0x34, 0xfc, 0x06, 0x29, 0x00, 0x0a, 0x01, 0x1d,\n",
      "  0xfc, 0x06, 0xec, 0x14, 0xf9, 0xfb, 0x01, 0x02, 0x01, 0x00, 0x04, 0xed,\n",
      "  0xfe, 0xef, 0xee, 0xfe, 0xe9, 0x03, 0xfe, 0xfd, 0xfe, 0x02, 0xf1, 0xfb,\n",
      "  0xf9, 0xe8, 0xff, 0xfb, 0x06, 0xfc, 0xfe, 0xf4, 0x05, 0xff, 0x00, 0x04,\n",
      "  0x5e, 0xfa, 0x01, 0x00, 0x01, 0xfa, 0xf6, 0xfe, 0xf9, 0x01, 0xff, 0x54,\n",
      "  0x00, 0x0b, 0x00, 0xfe, 0xfd, 0x05, 0x03, 0xff, 0x04, 0x01, 0x17, 0x02,\n",
      "  0x06, 0x06, 0x04, 0xf8, 0xfb, 0xfd, 0x05, 0x00, 0xfd, 0x0c, 0x06, 0xf6,\n",
      "  0xfe, 0xfe, 0xfb, 0xfc, 0x04, 0x04, 0x06, 0x05, 0x0f, 0x06, 0x02, 0xff,\n",
      "  0xff, 0xfb, 0xfa, 0x00, 0x01, 0x02, 0xf7, 0xed, 0x07, 0xe3, 0xf2, 0xff,\n",
      "  0xeb, 0xf6, 0xf7, 0x0f, 0xf8, 0xf7, 0xff, 0x08, 0xd1, 0xea, 0x00, 0xe8,\n",
      "  0xef, 0xe4, 0x04, 0xfa, 0xfd, 0x5a, 0xfa, 0xfd, 0xfd, 0x05, 0x02, 0x0b,\n",
      "  0xf4, 0xe3, 0x07, 0x0e, 0x37, 0xf5, 0x0e, 0x0c, 0xfb, 0x0b, 0x07, 0x0d,\n",
      "  0xf3, 0xfe, 0xfb, 0x18, 0xfe, 0x04, 0x0d, 0x03, 0x04, 0x08, 0x0e, 0xf4,\n",
      "  0x01, 0xf2, 0x0f, 0xf7, 0x07, 0x19, 0xfd, 0x14, 0x08, 0x05, 0xf2, 0x07,\n",
      "  0xf7, 0x18, 0x00, 0x10, 0x00, 0x01, 0xff, 0xff, 0x05, 0xf7, 0x04, 0xfa,\n",
      "  0xb1, 0xfc, 0xff, 0xff, 0xfe, 0xf9, 0x02, 0x06, 0xfd, 0xfe, 0xfb, 0xfb,\n",
      "  0x02, 0x05, 0xff, 0x01, 0x04, 0xf6, 0xfe, 0xfe, 0x02, 0xfd, 0x76, 0x09,\n",
      "  0x07, 0x04, 0x01, 0xfe, 0xfe, 0x03, 0x05, 0x03, 0xfc, 0x03, 0x06, 0xf8,\n",
      "  0xff, 0xfd, 0xfb, 0xff, 0xfe, 0x09, 0x01, 0xff, 0xfb, 0x07, 0x01, 0xfb,\n",
      "  0x00, 0x04, 0xfa, 0x00, 0xfd, 0x01, 0x09, 0x0a, 0x08, 0xf6, 0xfd, 0x03,\n",
      "  0xfe, 0xfb, 0x03, 0x00, 0xfc, 0xf5, 0xd2, 0xfd, 0xd8, 0xea, 0x02, 0xe8,\n",
      "  0xf1, 0xf9, 0xe1, 0xfd, 0xf7, 0xe6, 0x03, 0xf9, 0xf2, 0x05, 0xf1, 0xf5,\n",
      "  0xe1, 0xfa, 0x01, 0x01, 0x2b, 0x06, 0xf3, 0xf5, 0x03, 0xfb, 0x06, 0xf5,\n",
      "  0xf9, 0x04, 0x0c, 0x28, 0xfe, 0x0b, 0x1d, 0x02, 0x0b, 0x08, 0x09, 0xfd,\n",
      "  0x04, 0x13, 0x45, 0xfd, 0x21, 0x1f, 0x02, 0x0b, 0x08, 0x05, 0xfa, 0x00,\n",
      "  0xff, 0x3c, 0xf8, 0x13, 0x10, 0x01, 0x01, 0x03, 0xfe, 0x01, 0x06, 0xf9,\n",
      "  0x36, 0xff, 0xfb, 0xf7, 0xff, 0x01, 0xfd, 0x05, 0xf7, 0x07, 0x02, 0x18,\n",
      "  0x04, 0xfd, 0x01, 0x02, 0xfe, 0x00, 0x01, 0x04, 0xfe, 0xfb, 0x11, 0xff,\n",
      "  0xfe, 0xfd, 0x02, 0x01, 0xfe, 0x01, 0x02, 0xfc, 0xfa, 0x75, 0x08, 0x07,\n",
      "  0xfe, 0xfe, 0xff, 0x00, 0xfb, 0x01, 0x01, 0x01, 0x12, 0x07, 0x0c, 0x02,\n",
      "  0x04, 0xff, 0xfc, 0xfb, 0x01, 0x03, 0xfe, 0x59, 0x06, 0xfa, 0xfc, 0x04,\n",
      "  0xfa, 0xfe, 0xfe, 0x05, 0x03, 0xfe, 0xf7, 0x01, 0xf0, 0xf4, 0x04, 0xfe,\n",
      "  0xfa, 0xfd, 0xfd, 0xfc, 0xfc, 0xc7, 0x02, 0xf4, 0xf3, 0xfb, 0xf4, 0xf5,\n",
      "  0xf9, 0xfe, 0xfd, 0xf6, 0x07, 0x04, 0xf5, 0xf6, 0x05, 0xfc, 0xf8, 0xe4,\n",
      "  0xef, 0xfb, 0x03, 0xf2, 0x07, 0xf1, 0xff, 0xfd, 0xff, 0x03, 0xfb, 0xf7,\n",
      "  0x01, 0x07, 0x38, 0xfb, 0xf8, 0x12, 0xfa, 0x0c, 0x06, 0x0d, 0xfb, 0x00,\n",
      "  0xfc, 0x05, 0x01, 0x03, 0x06, 0x00, 0x00, 0x04, 0xfd, 0x04, 0xfc, 0xf8,\n",
      "  0x04, 0xff, 0x07, 0xff, 0xfb, 0x11, 0x0a, 0x05, 0xf6, 0x08, 0x00, 0x38,\n",
      "  0x05, 0xed, 0xf7, 0x00, 0xfe, 0x01, 0x02, 0xef, 0x02, 0xfe, 0x13, 0x02,\n",
      "  0xfb, 0xff, 0x04, 0xfc, 0x06, 0xfd, 0x01, 0xfe, 0xfc, 0x04, 0xfe, 0x01,\n",
      "  0x01, 0xfe, 0xfb, 0xfe, 0x06, 0xfa, 0x01, 0xfa, 0x19, 0x03, 0x07, 0x03,\n",
      "  0x07, 0xfe, 0xff, 0xff, 0x04, 0xff, 0xfd, 0x15, 0x04, 0x07, 0xfc, 0x00,\n",
      "  0xf9, 0xfa, 0xfe, 0x01, 0x02, 0xfe, 0x58, 0x00, 0x07, 0xfc, 0x05, 0x00,\n",
      "  0x02, 0xfc, 0xef, 0x00, 0xff, 0xed, 0x05, 0x16, 0x04, 0x01, 0xfc, 0xfc,\n",
      "  0xfa, 0x01, 0xfd, 0xfe, 0xc7, 0x03, 0xf6, 0xea, 0xfc, 0xfc, 0xf6, 0xf5,\n",
      "  0x0f, 0xfd, 0xfe, 0x05, 0x05, 0xe3, 0xe1, 0xfd, 0xec, 0xf9, 0xe8, 0xfb,\n",
      "  0xf9, 0x07, 0xfe, 0x0b, 0xf3, 0xfb, 0x00, 0x03, 0x05, 0xfa, 0xf3, 0xfe,\n",
      "  0x02, 0x42, 0x00, 0x07, 0x17, 0xf9, 0x14, 0x02, 0x0c, 0xf4, 0x08, 0x04,\n",
      "  0x36, 0x03, 0x12, 0x07, 0xfa, 0x02, 0x05, 0x05, 0xfc, 0xfe, 0xfe, 0x33,\n",
      "  0xf9, 0x1b, 0x14, 0xfa, 0x06, 0x08, 0x02, 0xf7, 0x04, 0x03, 0x1f, 0x06,\n",
      "  0xf3, 0x0f, 0xfe, 0x08, 0xf0, 0x06, 0xf8, 0x03, 0x00, 0x44, 0x00, 0xfc,\n",
      "  0xff, 0x08, 0x00, 0xfb, 0x00, 0xfa, 0x01, 0xf4, 0xda, 0x01, 0x01, 0x04,\n",
      "  0x0c, 0xfd, 0xfd, 0x02, 0x03, 0xfc, 0xff, 0x63, 0x02, 0x0a, 0x00, 0x07,\n",
      "  0x05, 0xf7, 0xff, 0x07, 0x06, 0x02, 0x22, 0x04, 0x0b, 0xfb, 0x00, 0xf8,\n",
      "  0xfc, 0xfe, 0x05, 0xff, 0xfc, 0x3e, 0x05, 0x01, 0xfa, 0x05, 0x02, 0x08,\n",
      "  0x00, 0x01, 0xfe, 0xfe, 0xea, 0x00, 0x0e, 0xff, 0x04, 0x00, 0x05, 0xfb,\n",
      "  0x07, 0xfd, 0x02, 0xf5, 0xfe, 0xfb, 0xe9, 0x02, 0xfc, 0xf3, 0xf7, 0xf1,\n",
      "  0xff, 0xf8, 0xd4, 0xff, 0xde, 0xea, 0x00, 0xe9, 0xf4, 0xf0, 0xfc, 0xfc,\n",
      "  0x00, 0xcd, 0x05, 0xf2, 0xff, 0x01, 0x01, 0xfa, 0x03, 0xe6, 0x02, 0x0b,\n",
      "  0x36, 0x00, 0x06, 0x12, 0xfc, 0x0a, 0x08, 0x0e, 0xf0, 0x0a, 0xf9, 0x24,\n",
      "  0x01, 0x0c, 0x16, 0xf7, 0xfe, 0x07, 0xf9, 0xfc, 0x07, 0x04, 0x75, 0x01,\n",
      "  0x03, 0xfd, 0xf7, 0x07, 0x06, 0x08, 0xf7, 0x03, 0x07, 0x2c, 0x05, 0x00,\n",
      "  0x01, 0xf9, 0x04, 0x00, 0x03, 0xf7, 0x0a, 0x01, 0xee, 0xfb, 0xfb, 0x05,\n",
      "  0x06, 0xff, 0xfd, 0x02, 0x02, 0xfe, 0xff, 0xf0, 0x05, 0x00, 0xfc, 0x05,\n",
      "  0xfe, 0xf9, 0xfd, 0x00, 0x02, 0xfc, 0x03, 0x02, 0x03, 0x08, 0x01, 0xfc,\n",
      "  0xfe, 0x07, 0x02, 0x01, 0xfd, 0x08, 0x01, 0xf6, 0x01, 0x0a, 0xfe, 0xf7,\n",
      "  0x00, 0x08, 0xfe, 0xfa, 0xfa, 0x03, 0x06, 0x00, 0x02, 0x01, 0xf8, 0xff,\n",
      "  0x05, 0xfc, 0xfb, 0x01, 0xfd, 0xf9, 0x06, 0xff, 0x01, 0xfa, 0x01, 0xfe,\n",
      "  0xfc, 0xff, 0xf4, 0xfa, 0xf1, 0xf3, 0x06, 0x01, 0xff, 0xf9, 0x09, 0x01,\n",
      "  0xf8, 0xec, 0x01, 0xe7, 0xe6, 0xff, 0xf1, 0xf5, 0xf0, 0x0a, 0xff, 0x04,\n",
      "  0x04, 0x08, 0xfb, 0x04, 0xfd, 0xfe, 0x05, 0xf8, 0xec, 0x03, 0x06, 0x49,\n",
      "  0x02, 0x02, 0x14, 0xf5, 0x0c, 0x0b, 0x07, 0xff, 0x05, 0x03, 0x1c, 0xff,\n",
      "  0x09, 0x18, 0xf9, 0x07, 0x0b, 0xfb, 0xfc, 0x07, 0xfe, 0x06, 0x03, 0x07,\n",
      "  0x07, 0xf3, 0x01, 0xfb, 0x06, 0xfc, 0x02, 0x05, 0x24, 0x05, 0xf3, 0x05,\n",
      "  0xfb, 0x07, 0x04, 0x09, 0xef, 0x0a, 0xff, 0x00, 0x04, 0x02, 0x03, 0x07,\n",
      "  0x02, 0x00, 0xff, 0xfc, 0xfe, 0xfc, 0x02, 0xfb, 0xfe, 0x03, 0x0a, 0xf9,\n",
      "  0xfb, 0xfd, 0xfa, 0xff, 0xfc, 0x0e, 0x02, 0x0a, 0x02, 0x0b, 0x02, 0x03,\n",
      "  0x02, 0x05, 0x02, 0xfa, 0x01, 0xff, 0xfc, 0xfa, 0x00, 0xfa, 0xfb, 0xfc,\n",
      "  0x04, 0xfe, 0xfc, 0x00, 0x04, 0xf9, 0xf8, 0x07, 0xfe, 0xfd, 0x05, 0x05,\n",
      "  0xfd, 0xfe, 0xfe, 0x01, 0x0d, 0xfc, 0x0b, 0x0a, 0x05, 0xfe, 0x05, 0xfe,\n",
      "  0xf8, 0xe1, 0xfa, 0xf8, 0xf3, 0x01, 0xec, 0xf2, 0xf9, 0x05, 0xfd, 0xfa,\n",
      "  0xe9, 0x01, 0xd2, 0xdf, 0x03, 0xf5, 0xf4, 0xeb, 0xe1, 0x03, 0xff, 0x03,\n",
      "  0x0a, 0x01, 0x07, 0xf8, 0xf9, 0x00, 0xfc, 0xe6, 0x05, 0x17, 0x06, 0xf9,\n",
      "  0x05, 0x11, 0xfd, 0x09, 0x07, 0x10, 0xf4, 0x06, 0x01, 0xfb, 0xfc, 0x07,\n",
      "  0x13, 0xfa, 0x10, 0x09, 0x01, 0xf2, 0x05, 0xfa, 0x01, 0xfc, 0xe8, 0x16,\n",
      "  0xf6, 0x02, 0xfa, 0xfb, 0xfb, 0xff, 0xff, 0x01, 0xfd, 0x01, 0x06, 0xfb,\n",
      "  0xf5, 0x08, 0x05, 0xf1, 0x05, 0xf7, 0x01, 0xfd, 0x04, 0xfd, 0x0e, 0xfd,\n",
      "  0xfb, 0xfe, 0xfe, 0xfe, 0xfd, 0xff, 0xff, 0xfc, 0x04, 0x0b, 0xfa, 0xfa,\n",
      "  0xfd, 0xfd, 0xf9, 0xf9, 0x06, 0xff, 0x0c, 0x04, 0x05, 0x02, 0xfd, 0xfe,\n",
      "  0xfa, 0x01, 0x00, 0x02, 0xfc, 0xfe, 0x01, 0x09, 0xf9, 0xff, 0xfd, 0x08,\n",
      "  0xfc, 0x00, 0xfe, 0xff, 0x06, 0xfd, 0x01, 0xfa, 0xfd, 0x00, 0xfd, 0x02,\n",
      "  0xfd, 0xfa, 0x00, 0xf3, 0xff, 0x01, 0xfc, 0xff, 0xfb, 0x00, 0xf8, 0x00,\n",
      "  0xf2, 0x03, 0xe5, 0xf7, 0xfb, 0xfc, 0x00, 0xfe, 0xee, 0xff, 0xfa, 0xdf,\n",
      "  0x05, 0xd4, 0xd2, 0xfc, 0xf3, 0xfa, 0xe4, 0xe3, 0xfd, 0x01, 0xed, 0x09,\n",
      "  0xfa, 0xfb, 0xfb, 0x00, 0x00, 0x00, 0xe0, 0x06, 0x10, 0xfd, 0xfb, 0x09,\n",
      "  0x0b, 0xfb, 0x10, 0x0a, 0x09, 0xf7, 0x04, 0xf9, 0x01, 0xfc, 0x0d, 0x1d,\n",
      "  0xff, 0x0e, 0x08, 0x02, 0xf2, 0x00, 0x01, 0xff, 0x00, 0x0b, 0x07, 0xf5,\n",
      "  0x02, 0x0c, 0xfa, 0xee, 0x01, 0xfe, 0x01, 0x04, 0xf2, 0x02, 0xf4, 0x05,\n",
      "  0xf2, 0x02, 0xf1, 0x09, 0x00, 0xff, 0xfe, 0xfc, 0x03, 0x06, 0xf7, 0xfc,\n",
      "  0x05, 0x00, 0xff, 0xf9, 0xfd, 0xf9, 0xf7, 0xfe, 0x08, 0xfc, 0xf8, 0xfd,\n",
      "  0xf9, 0x02, 0x00, 0x01, 0xfd, 0x0b, 0x01, 0x0a, 0x01, 0x02, 0xfb, 0xfe,\n",
      "  0x02, 0xff, 0x04, 0x04, 0xf9, 0xfc, 0xfd, 0x00, 0xfc, 0xfe, 0x0b, 0xff,\n",
      "  0xfe, 0xf8, 0xfe, 0xfd, 0x01, 0x02, 0xfb, 0x03, 0xfe, 0x01, 0xfc, 0x00,\n",
      "  0xf8, 0xff, 0x09, 0xf3, 0x02, 0x07, 0xff, 0xfd, 0x02, 0x01, 0x02, 0xf7,\n",
      "  0x09, 0xfd, 0xf0, 0x03, 0xf8, 0xf8, 0xf4, 0x04, 0x00, 0xfb, 0xf7, 0x04,\n",
      "  0xea, 0xe9, 0x00, 0xe8, 0xf1, 0xf7, 0xe9, 0xff, 0xfc, 0xfd, 0x08, 0xff,\n",
      "  0xf9, 0xfd, 0xfb, 0xfb, 0xfe, 0xdc, 0x04, 0x14, 0x09, 0xfc, 0xfd, 0x16,\n",
      "  0xf6, 0x15, 0x07, 0x09, 0xe3, 0x09, 0xfc, 0x07, 0x02, 0x1c, 0x16, 0xfa,\n",
      "  0x0a, 0x04, 0xfe, 0xf9, 0x01, 0xfc, 0x05, 0x02, 0xfa, 0x09, 0xf1, 0x03,\n",
      "  0xf3, 0x04, 0xf1, 0x02, 0xfe, 0x04, 0x03, 0xe6, 0xfc, 0xf7, 0x0b, 0x08,\n",
      "  0xfe, 0xef, 0x0d, 0xf5, 0xf7, 0x03, 0x01, 0x03, 0x05, 0x03, 0xfd, 0xfe,\n",
      "  0x00, 0xfe, 0xf9, 0xf8, 0xff, 0x05, 0x09, 0x07, 0xff, 0xfa, 0xfe, 0x00,\n",
      "  0xfe, 0xf4, 0x00, 0x04, 0xfb, 0xfb, 0x07, 0xfc, 0xfc, 0x00, 0x07, 0xff,\n",
      "  0xfe, 0xf7, 0xff, 0x00, 0x01, 0x04, 0xfb, 0xfb, 0xf9, 0x06, 0xfd, 0xfd,\n",
      "  0xff, 0x05, 0xfb, 0xf6, 0x04, 0xfe, 0x03, 0x05, 0x06, 0xfe, 0x04, 0xf5,\n",
      "  0x04, 0xf6, 0x03, 0x02, 0x02, 0x00, 0x05, 0x03, 0x00, 0xfc, 0xf3, 0xff,\n",
      "  0xc3, 0xe0, 0xfe, 0xf2, 0xee, 0xf0, 0xee, 0x02, 0xf2, 0xf8, 0x02, 0xdc,\n",
      "  0xde, 0xf9, 0xf0, 0xe9, 0xec, 0xe6, 0xfe, 0x0c, 0xf4, 0x04, 0x01, 0xf8,\n",
      "  0xfb, 0xfd, 0x05, 0x00, 0xf6, 0x05, 0x2a, 0xcf, 0x00, 0x00, 0x25, 0xfe,\n",
      "  0x0f, 0x0c, 0x0b, 0xe8, 0x08, 0xfd, 0x02, 0xff, 0x06, 0x23, 0xfe, 0x12,\n",
      "  0x0d, 0x05, 0x06, 0x02, 0xfe, 0x08, 0xfe, 0x18, 0x14, 0xf5, 0x04, 0xfc,\n",
      "  0x03, 0xe3, 0x08, 0x0d, 0x10, 0x0a, 0xfa, 0x11, 0xf8, 0x02, 0x03, 0x02,\n",
      "  0xe7, 0x05, 0xfd, 0x00, 0x04, 0x05, 0xfb, 0x09, 0x03, 0xf9, 0xfe, 0xfd,\n",
      "  0xfe, 0x02, 0x00, 0xfc, 0x09, 0xfc, 0x09, 0x01, 0xf9, 0xfa, 0xfa, 0x02,\n",
      "  0xff, 0x01, 0x02, 0x0a, 0xf9, 0xfd, 0xfe, 0xfc, 0x00, 0x03, 0x01, 0xfc,\n",
      "  0x03, 0x04, 0xfd, 0xff, 0x00, 0xff, 0x01, 0xfd, 0x06, 0x04, 0xf7, 0x06,\n",
      "  0x01, 0xf6, 0x02, 0x06, 0x01, 0xfd, 0xfd, 0x00, 0xff, 0x02, 0x01, 0x02,\n",
      "  0x05, 0x00, 0x02, 0xf1, 0xf3, 0xf9, 0x04, 0x02, 0xfb, 0xfb, 0x03, 0xdb,\n",
      "  0xe7, 0x06, 0xea, 0xe6, 0xf9, 0x1c, 0x01, 0xed, 0x13, 0x05, 0xda, 0xe6,\n",
      "  0xfa, 0xe9, 0xf5, 0xee, 0xf6, 0x00, 0x0b, 0x12, 0x02, 0xe7, 0x02, 0xf9,\n",
      "  0xf0, 0xfb, 0x02, 0xe7, 0x09, 0x10, 0x09, 0xfe, 0xf3, 0x11, 0xfe, 0x08,\n",
      "  0x09, 0x08, 0xe9, 0x09, 0xfc, 0xfa, 0x00, 0x04, 0x20, 0xf6, 0x0f, 0x08,\n",
      "  0x05, 0xfc, 0xff, 0xff, 0xe7, 0x04, 0xf8, 0x22, 0xfa, 0xfe, 0xf4, 0x03,\n",
      "  0xf9, 0x01, 0x02, 0xe4, 0x02, 0xed, 0x06, 0xfd, 0xff, 0xf7, 0x08, 0x04,\n",
      "  0x0e, 0xfd, 0xfd, 0x03, 0xf8, 0x00, 0x05, 0x03, 0xf1, 0xfa, 0xfe, 0xfb,\n",
      "  0xf8, 0x05, 0xfd, 0xfd, 0xfc, 0x04, 0xff, 0xf9, 0xf9, 0xfb, 0x01, 0xf8,\n",
      "  0x03, 0x01, 0x0a, 0x06, 0xfe, 0x08, 0xfc, 0xfe, 0x03, 0x07, 0xfb, 0xfe,\n",
      "  0xff, 0xe9, 0xf5, 0x00, 0xf8, 0xf9, 0xf9, 0x0a, 0xff, 0xfd, 0xfb, 0xfc,\n",
      "  0xfc, 0x01, 0xfe, 0xf7, 0xf2, 0xf8, 0x07, 0xff, 0xf9, 0xfe, 0xfc, 0x01,\n",
      "  0xf8, 0xfd, 0x06, 0x05, 0xfe, 0x0c, 0xff, 0xfc, 0x02, 0x03, 0xf1, 0xe9,\n",
      "  0x00, 0xe8, 0xfd, 0xf7, 0x57, 0xfd, 0xee, 0x02, 0x09, 0xeb, 0xe8, 0xf8,\n",
      "  0xdd, 0xef, 0xf2, 0x02, 0xfb, 0x02, 0x08, 0x0b, 0xfc, 0xf9, 0xfd, 0xed,\n",
      "  0x08, 0xf8, 0xed, 0x05, 0xff, 0x06, 0x00, 0x0e, 0x02, 0xfe, 0x01, 0x0f,\n",
      "  0x10, 0x03, 0x0a, 0x05, 0x0a, 0x00, 0x07, 0x0f, 0xfa, 0x11, 0x17, 0x02,\n",
      "  0x0e, 0x03, 0x02, 0x0c, 0x06, 0x11, 0xf5, 0xfa, 0x07, 0xfc, 0xfe, 0xe4,\n",
      "  0x03, 0xf8, 0xfd, 0x03, 0xf9, 0x00, 0xfe, 0xfe, 0x19, 0x05, 0xe8, 0x08,\n",
      "  0xfb, 0xfc, 0x01, 0x08, 0xfe, 0x03, 0xfb, 0xf6, 0x02, 0x00, 0xff, 0x02,\n",
      "  0xbc, 0x05, 0xfa, 0x06, 0xff, 0x06, 0xfb, 0x03, 0x03, 0x06, 0xf9, 0xd0,\n",
      "  0xfc, 0x07, 0x03, 0xfe, 0x06, 0x00, 0xfd, 0x03, 0xff, 0xfe, 0xd0, 0xfd,\n",
      "  0xff, 0x02, 0x06, 0xf6, 0xfb, 0xf8, 0x05, 0xff, 0xfb, 0x09, 0x01, 0x13,\n",
      "  0xf7, 0xfe, 0xfd, 0x07, 0xf6, 0x06, 0x03, 0xf9, 0x1c, 0xff, 0xff, 0xf8,\n",
      "  0xfd, 0x04, 0xfe, 0xfe, 0xfe, 0x00, 0xf5, 0x13, 0x01, 0xfc, 0xf0, 0x04,\n",
      "  0xf7, 0xf9, 0xf6, 0x06, 0x09, 0xf7, 0x4e, 0x03, 0xf4, 0xec, 0xfa, 0xe4,\n",
      "  0xfa, 0xf5, 0x9f, 0x00, 0x0d, 0x1c, 0x03, 0xf7, 0x00, 0xfc, 0xee, 0x01,\n",
      "  0xf6, 0xd2, 0x03, 0x14, 0x2b, 0xfe, 0x30, 0x25, 0x05, 0x27, 0x1f, 0x10,\n",
      "  0xf7, 0x08, 0x04, 0x26, 0x01, 0x2e, 0x2e, 0xfd, 0x26, 0xf9, 0x0d, 0x18,\n",
      "  0x05, 0x07, 0xfa, 0x02, 0x3c, 0x10, 0x00, 0x04, 0x08, 0xf8, 0xd8, 0x01,\n",
      "  0xee, 0xdd, 0x02, 0xff, 0x1b, 0xff, 0x00, 0xfc, 0xff, 0xea, 0x0d, 0x00,\n",
      "  0xfc, 0x04, 0x0a, 0x04, 0xff, 0xfb, 0xf9, 0x02, 0xfe, 0xfe, 0x01, 0x07,\n",
      "  0x05, 0x04, 0x03, 0x01, 0xf7, 0x00, 0xfe, 0xed, 0xfb, 0xf9, 0xff, 0xff,\n",
      "  0x11, 0xf9, 0xfc, 0x06, 0x01, 0xfd, 0xf9, 0x06, 0x03, 0x00, 0x04, 0x0b,\n",
      "  0x0a, 0xfb, 0xef, 0xf0, 0xfb, 0x04, 0xfd, 0x03, 0x0a, 0xfe, 0x19, 0x00,\n",
      "  0x00, 0xfd, 0x10, 0xf3, 0x12, 0x08, 0xf4, 0xf9, 0x08, 0x00, 0xff, 0x04,\n",
      "  0xe8, 0x0a, 0xfe, 0x0d, 0x04, 0xf5, 0x05, 0xfd, 0x95, 0xd9, 0x00, 0xd6,\n",
      "  0xd8, 0xf5, 0x0c, 0x04, 0xe9, 0x19, 0xfd, 0xab, 0xe0, 0xfe, 0xd1, 0xdd,\n",
      "  0xf2, 0x06, 0xfd, 0x0d, 0x02, 0x00, 0x01, 0xf5, 0xfd, 0xf6, 0xf6, 0xf8,\n",
      "  0xf5, 0x0b, 0x03, 0x35, 0xfb, 0xf3, 0x06, 0xfe, 0x26, 0x14, 0x0e, 0xf7,\n",
      "  0xff, 0xf8, 0x22, 0xfd, 0x1d, 0x25, 0xfe, 0x03, 0xfc, 0x0a, 0xd5, 0x07,\n",
      "  0xf9, 0x16, 0x05, 0x08, 0x11, 0xff, 0x0d, 0xec, 0x09, 0xe6, 0x01, 0xf3,\n",
      "  0x21, 0x01, 0xe3, 0x4c, 0x02, 0x06, 0x2e, 0xfe, 0xc1, 0x0f, 0x03, 0x05,\n",
      "  0x01, 0x06, 0x0a, 0xfc, 0x08, 0x05, 0x03, 0xf8, 0x00, 0x02, 0xf3, 0xfc,\n",
      "  0x01, 0x09, 0xfc, 0xfe, 0xfc, 0x01, 0xf1, 0xfc, 0xf9, 0x04, 0x01, 0x05,\n",
      "  0x02, 0x01, 0x01, 0x07, 0xfc, 0x05, 0x03, 0x00, 0xff, 0xfe, 0xfc, 0x09,\n",
      "  0x01, 0xfc, 0xfe, 0xfe, 0xfe, 0x06, 0x01, 0x01, 0x00, 0xff, 0xfb, 0x02,\n",
      "  0x05, 0xf8, 0xf9, 0x07, 0xfb, 0xeb, 0x03, 0x00, 0x0b, 0x0b, 0xfb, 0xe3,\n",
      "  0x02, 0x06, 0xf4, 0xf7, 0x0f, 0xff, 0x01, 0x0a, 0xf8, 0xfd, 0xef, 0xfd,\n",
      "  0xf3, 0xef, 0x07, 0x02, 0xf1, 0x05, 0xe7, 0xdf, 0xf8, 0xd3, 0xf4, 0xec,\n",
      "  0xe6, 0x04, 0x32, 0xf9, 0x01, 0xe3, 0x16, 0xf9, 0xee, 0xfc, 0xfa, 0xea,\n",
      "  0xfb, 0x20, 0x02, 0xff, 0xfd, 0x2b, 0xff, 0x1a, 0x1e, 0x0a, 0xeb, 0x05,\n",
      "  0xec, 0xfa, 0xfb, 0xee, 0x15, 0x02, 0xf6, 0xf9, 0x00, 0xe2, 0xfb, 0x0d,\n",
      "  0xfd, 0x05, 0x0f, 0x5e, 0xfa, 0x13, 0x00, 0xfd, 0x0f, 0xff, 0x02, 0xef,\n",
      "  0x04, 0xe3, 0x3e, 0x00, 0xe0, 0x16, 0xff, 0xd1, 0x09, 0x08, 0xf7, 0x01,\n",
      "  0x04, 0x0d, 0xfd, 0xfe, 0xf6, 0x05, 0xf2, 0x00, 0xf2, 0xfb, 0x05, 0xe4,\n",
      "  0xfe, 0x00, 0x08, 0xf3, 0xfd, 0xf9, 0xff, 0xf4, 0xfd, 0xfa, 0x22, 0x01,\n",
      "  0x00, 0xf9, 0xf6, 0xfd, 0x04, 0x01, 0xfa, 0x03, 0xfe, 0x10, 0xff, 0xf6,\n",
      "  0x01, 0xee, 0xfc, 0xfb, 0xfe, 0x04, 0xfe, 0x02, 0xed, 0x0d, 0xfc, 0x09,\n",
      "  0xfe, 0x03, 0xf7, 0x06, 0x00, 0xf9, 0x00, 0x04, 0xfd, 0x02, 0xf8, 0xff,\n",
      "  0xfc, 0xe0, 0xff, 0xfe, 0xf5, 0xfd, 0xf6, 0xe8, 0xff, 0xef, 0x09, 0xfc,\n",
      "  0xf9, 0x06, 0x08, 0xf3, 0x03, 0xcf, 0x08, 0xfe, 0xe3, 0xf6, 0xf3, 0x5d,\n",
      "  0xfc, 0x15, 0xfd, 0x05, 0xde, 0xd5, 0xf9, 0xf6, 0xe8, 0x05, 0xf1, 0x04,\n",
      "  0x19, 0x01, 0x00, 0xfa, 0x19, 0x01, 0x07, 0x16, 0x05, 0xce, 0xfe, 0xda,\n",
      "  0x03, 0xfe, 0x25, 0xff, 0xfe, 0x16, 0x0f, 0xfd, 0x2c, 0xfc, 0xfc, 0x08,\n",
      "  0x03, 0x11, 0x17, 0xfa, 0xfb, 0x1d, 0x0b, 0xe7, 0x09, 0xf9, 0xfd, 0x05,\n",
      "  0xe1, 0x05, 0x02, 0x03, 0x08, 0xfc, 0xf5, 0x07, 0xf6, 0xfd, 0xff, 0xff,\n",
      "  0x04, 0x00, 0x00, 0x00, 0x08, 0x00, 0x00, 0x00, 0x9c, 0xfb, 0xff, 0xff,\n",
      "  0x64, 0x04, 0x00, 0x00, 0x0a, 0xfe, 0xff, 0xff, 0x04, 0x00, 0x00, 0x00,\n",
      "  0x08, 0x00, 0x00, 0x00, 0xff, 0xff, 0xff, 0xff, 0x2c, 0x0b, 0x00, 0x00,\n",
      "  0x7c, 0xf1, 0xff, 0xff, 0x22, 0xfe, 0xff, 0xff, 0x04, 0x00, 0x00, 0x00,\n",
      "  0x04, 0x00, 0x00, 0x00, 0x28, 0x00, 0x00, 0x00, 0x32, 0xfe, 0xff, 0xff,\n",
      "  0x04, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0x3c, 0x00, 0x00, 0x00,\n",
      "  0x42, 0xfe, 0xff, 0xff, 0x04, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00,\n",
      "  0x01, 0x00, 0x00, 0x00, 0x52, 0xfe, 0xff, 0xff, 0x04, 0x00, 0x00, 0x00,\n",
      "  0x04, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0xc0, 0xf1, 0xff, 0xff,\n",
      "  0xc4, 0xf1, 0xff, 0xff, 0x0f, 0x00, 0x00, 0x00, 0x4d, 0x4c, 0x49, 0x52,\n",
      "  0x20, 0x43, 0x6f, 0x6e, 0x76, 0x65, 0x72, 0x74, 0x65, 0x64, 0x2e, 0x00,\n",
      "  0x01, 0x00, 0x00, 0x00, 0x14, 0x00, 0x00, 0x00, 0x00, 0x00, 0x0e, 0x00,\n",
      "  0x18, 0x00, 0x14, 0x00, 0x10, 0x00, 0x0c, 0x00, 0x08, 0x00, 0x04, 0x00,\n",
      "  0x0e, 0x00, 0x00, 0x00, 0x14, 0x00, 0x00, 0x00, 0x1c, 0x00, 0x00, 0x00,\n",
      "  0x28, 0x02, 0x00, 0x00, 0x2c, 0x02, 0x00, 0x00, 0x30, 0x02, 0x00, 0x00,\n",
      "  0x04, 0x00, 0x00, 0x00, 0x6d, 0x61, 0x69, 0x6e, 0x00, 0x00, 0x00, 0x00,\n",
      "  0x08, 0x00, 0x00, 0x00, 0xd8, 0x01, 0x00, 0x00, 0x78, 0x01, 0x00, 0x00,\n",
      "  0x20, 0x01, 0x00, 0x00, 0xf8, 0x00, 0x00, 0x00, 0x98, 0x00, 0x00, 0x00,\n",
      "  0x70, 0x00, 0x00, 0x00, 0x38, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00,\n",
      "  0xb2, 0xfe, 0xff, 0xff, 0x14, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x09,\n",
      "  0x14, 0x00, 0x00, 0x00, 0x18, 0x00, 0x00, 0x00, 0x06, 0x00, 0x00, 0x00,\n",
      "  0xf6, 0xfe, 0xff, 0xff, 0x00, 0x00, 0x80, 0x3f, 0x01, 0x00, 0x00, 0x00,\n",
      "  0x12, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x11, 0x00, 0x00, 0x00,\n",
      "  0xe2, 0xfe, 0xff, 0xff, 0x14, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x08,\n",
      "  0x10, 0x00, 0x00, 0x00, 0x14, 0x00, 0x00, 0x00, 0x05, 0x00, 0x00, 0x00,\n",
      "  0x84, 0xf2, 0xff, 0xff, 0x01, 0x00, 0x00, 0x00, 0x11, 0x00, 0x00, 0x00,\n",
      "  0x03, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00, 0x08, 0x00, 0x00, 0x00,\n",
      "  0x07, 0x00, 0x00, 0x00, 0x8a, 0xff, 0xff, 0xff, 0x0c, 0x00, 0x00, 0x00,\n",
      "  0x10, 0x00, 0x00, 0x00, 0x03, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
      "  0x10, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00, 0x0f, 0x00, 0x00, 0x00,\n",
      "  0x06, 0x00, 0x00, 0x00, 0x3a, 0xff, 0xff, 0xff, 0x20, 0x00, 0x00, 0x00,\n",
      "  0x00, 0x00, 0x00, 0x01, 0x2c, 0x00, 0x00, 0x00, 0x30, 0x00, 0x00, 0x00,\n",
      "  0x04, 0x00, 0x00, 0x00, 0x0c, 0x00, 0x14, 0x00, 0x13, 0x00, 0x0c, 0x00,\n",
      "  0x08, 0x00, 0x07, 0x00, 0x0c, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01,\n",
      "  0x03, 0x00, 0x00, 0x00, 0x03, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01,\n",
      "  0x01, 0x00, 0x00, 0x00, 0x0f, 0x00, 0x00, 0x00, 0x03, 0x00, 0x00, 0x00,\n",
      "  0x0e, 0x00, 0x00, 0x00, 0x0a, 0x00, 0x00, 0x00, 0x09, 0x00, 0x00, 0x00,\n",
      "  0x00, 0x00, 0x0a, 0x00, 0x10, 0x00, 0x0c, 0x00, 0x08, 0x00, 0x04, 0x00,\n",
      "  0x0a, 0x00, 0x00, 0x00, 0x0c, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00,\n",
      "  0x03, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x0e, 0x00, 0x00, 0x00,\n",
      "  0x02, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x0d, 0x00, 0x00, 0x00,\n",
      "  0xba, 0xff, 0xff, 0xff, 0x1c, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x3b,\n",
      "  0x1c, 0x00, 0x00, 0x00, 0x20, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00,\n",
      "  0x00, 0x00, 0x06, 0x00, 0x08, 0x00, 0x04, 0x00, 0x06, 0x00, 0x00, 0x00,\n",
      "  0x04, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x0d, 0x00, 0x00, 0x00,\n",
      "  0x04, 0x00, 0x00, 0x00, 0x0c, 0x00, 0x00, 0x00, 0x03, 0x00, 0x00, 0x00,\n",
      "  0x04, 0x00, 0x00, 0x00, 0x05, 0x00, 0x00, 0x00, 0x00, 0x00, 0x0e, 0x00,\n",
      "  0x1a, 0x00, 0x14, 0x00, 0x10, 0x00, 0x0c, 0x00, 0x0b, 0x00, 0x04, 0x00,\n",
      "  0x0e, 0x00, 0x00, 0x00, 0x24, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x20,\n",
      "  0x24, 0x00, 0x00, 0x00, 0x28, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
      "  0x00, 0x00, 0x0e, 0x00, 0x08, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
      "  0x00, 0x00, 0x04, 0x00, 0x0e, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
      "  0x01, 0x00, 0x00, 0x00, 0x0c, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00,\n",
      "  0x0b, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00,\n",
      "  0x02, 0x00, 0x00, 0x00, 0x00, 0x00, 0x0e, 0x00, 0x16, 0x00, 0x00, 0x00,\n",
      "  0x10, 0x00, 0x0c, 0x00, 0x0b, 0x00, 0x04, 0x00, 0x0e, 0x00, 0x00, 0x00,\n",
      "  0x18, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x37, 0x18, 0x00, 0x00, 0x00,\n",
      "  0x1c, 0x00, 0x00, 0x00, 0x00, 0x00, 0x06, 0x00, 0x08, 0x00, 0x07, 0x00,\n",
      "  0x06, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02, 0x01, 0x00, 0x00, 0x00,\n",
      "  0x0b, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
      "  0x01, 0x00, 0x00, 0x00, 0x12, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
      "  0x00, 0x00, 0x00, 0x00, 0x13, 0x00, 0x00, 0x00, 0x00, 0x0c, 0x00, 0x00,\n",
      "  0xa4, 0x0b, 0x00, 0x00, 0x4c, 0x0b, 0x00, 0x00, 0x10, 0x0b, 0x00, 0x00,\n",
      "  0xd4, 0x0a, 0x00, 0x00, 0x98, 0x0a, 0x00, 0x00, 0x58, 0x0a, 0x00, 0x00,\n",
      "  0xf8, 0x09, 0x00, 0x00, 0x94, 0x09, 0x00, 0x00, 0xb8, 0x08, 0x00, 0x00,\n",
      "  0xd4, 0x07, 0x00, 0x00, 0x30, 0x07, 0x00, 0x00, 0x80, 0x06, 0x00, 0x00,\n",
      "  0xcc, 0x05, 0x00, 0x00, 0xe4, 0x04, 0x00, 0x00, 0xa0, 0x02, 0x00, 0x00,\n",
      "  0xc4, 0x01, 0x00, 0x00, 0x80, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00,\n",
      "  0x62, 0xf4, 0xff, 0xff, 0x00, 0x00, 0x00, 0x01, 0x18, 0x00, 0x00, 0x00,\n",
      "  0x20, 0x00, 0x00, 0x00, 0x3c, 0x00, 0x00, 0x00, 0x13, 0x00, 0x00, 0x00,\n",
      "  0x00, 0x00, 0x00, 0x09, 0x50, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00,\n",
      "  0xff, 0xff, 0xff, 0xff, 0x02, 0x00, 0x00, 0x00, 0x4c, 0xf4, 0xff, 0xff,\n",
      "  0x08, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
      "  0x80, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0x01, 0x00, 0x00, 0x00,\n",
      "  0x00, 0x00, 0x80, 0x3b, 0x19, 0x00, 0x00, 0x00, 0x53, 0x74, 0x61, 0x74,\n",
      "  0x65, 0x66, 0x75, 0x6c, 0x50, 0x61, 0x72, 0x74, 0x69, 0x74, 0x69, 0x6f,\n",
      "  0x6e, 0x65, 0x64, 0x43, 0x61, 0x6c, 0x6c, 0x5f, 0x31, 0x00, 0x00, 0x00,\n",
      "  0x02, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00,\n",
      "  0xda, 0xf4, 0xff, 0xff, 0x00, 0x00, 0x00, 0x01, 0x18, 0x00, 0x00, 0x00,\n",
      "  0x20, 0x00, 0x00, 0x00, 0x40, 0x00, 0x00, 0x00, 0x12, 0x00, 0x00, 0x00,\n",
      "  0x00, 0x00, 0x00, 0x09, 0x18, 0x01, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00,\n",
      "  0xff, 0xff, 0xff, 0xff, 0x02, 0x00, 0x00, 0x00, 0xc4, 0xf4, 0xff, 0xff,\n",
      "  0x08, 0x00, 0x00, 0x00, 0x14, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
      "  0xfa, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0x00, 0x00, 0x00, 0x00,\n",
      "  0x01, 0x00, 0x00, 0x00, 0x78, 0x5c, 0xd4, 0x3d, 0xdd, 0x00, 0x00, 0x00,\n",
      "  0x73, 0x65, 0x71, 0x75, 0x65, 0x6e, 0x74, 0x69, 0x61, 0x6c, 0x5f, 0x36,\n",
      "  0x5f, 0x31, 0x2f, 0x64, 0x65, 0x6e, 0x73, 0x65, 0x5f, 0x36, 0x5f, 0x31,\n",
      "  0x2f, 0x4d, 0x61, 0x74, 0x4d, 0x75, 0x6c, 0x3b, 0x53, 0x74, 0x61, 0x74,\n",
      "  0x65, 0x66, 0x75, 0x6c, 0x50, 0x61, 0x72, 0x74, 0x69, 0x74, 0x69, 0x6f,\n",
      "  0x6e, 0x65, 0x64, 0x43, 0x61, 0x6c, 0x6c, 0x5f, 0x31, 0x2f, 0x53, 0x74,\n",
      "  0x61, 0x74, 0x65, 0x66, 0x75, 0x6c, 0x50, 0x61, 0x72, 0x74, 0x69, 0x74,\n",
      "  0x69, 0x6f, 0x6e, 0x65, 0x64, 0x43, 0x61, 0x6c, 0x6c, 0x2f, 0x73, 0x65,\n",
      "  0x71, 0x75, 0x65, 0x6e, 0x74, 0x69, 0x61, 0x6c, 0x5f, 0x36, 0x5f, 0x31,\n",
      "  0x2f, 0x64, 0x65, 0x6e, 0x73, 0x65, 0x5f, 0x36, 0x5f, 0x31, 0x2f, 0x4d,\n",
      "  0x61, 0x74, 0x4d, 0x75, 0x6c, 0x3b, 0x73, 0x65, 0x71, 0x75, 0x65, 0x6e,\n",
      "  0x74, 0x69, 0x61, 0x6c, 0x5f, 0x36, 0x5f, 0x31, 0x2f, 0x64, 0x65, 0x6e,\n",
      "  0x73, 0x65, 0x5f, 0x36, 0x5f, 0x31, 0x2f, 0x41, 0x64, 0x64, 0x3b, 0x53,\n",
      "  0x74, 0x61, 0x74, 0x65, 0x66, 0x75, 0x6c, 0x50, 0x61, 0x72, 0x74, 0x69,\n",
      "  0x74, 0x69, 0x6f, 0x6e, 0x65, 0x64, 0x43, 0x61, 0x6c, 0x6c, 0x5f, 0x31,\n",
      "  0x2f, 0x53, 0x74, 0x61, 0x74, 0x65, 0x66, 0x75, 0x6c, 0x50, 0x61, 0x72,\n",
      "  0x74, 0x69, 0x74, 0x69, 0x6f, 0x6e, 0x65, 0x64, 0x43, 0x61, 0x6c, 0x6c,\n",
      "  0x2f, 0x73, 0x65, 0x71, 0x75, 0x65, 0x6e, 0x74, 0x69, 0x61, 0x6c, 0x5f,\n",
      "  0x36, 0x5f, 0x31, 0x2f, 0x64, 0x65, 0x6e, 0x73, 0x65, 0x5f, 0x36, 0x5f,\n",
      "  0x31, 0x2f, 0x41, 0x64, 0x64, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00,\n",
      "  0x01, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00, 0x1a, 0xf6, 0xff, 0xff,\n",
      "  0x00, 0x00, 0x00, 0x01, 0x18, 0x00, 0x00, 0x00, 0x20, 0x00, 0x00, 0x00,\n",
      "  0x40, 0x00, 0x00, 0x00, 0x11, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x09,\n",
      "  0xb0, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00, 0xff, 0xff, 0xff, 0xff,\n",
      "  0x2c, 0x0b, 0x00, 0x00, 0x04, 0xf6, 0xff, 0xff, 0x08, 0x00, 0x00, 0x00,\n",
      "  0x14, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x80, 0xff, 0xff, 0xff,\n",
      "  0xff, 0xff, 0xff, 0xff, 0x00, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
      "  0x11, 0xe7, 0xcf, 0x3d, 0x77, 0x00, 0x00, 0x00, 0x73, 0x65, 0x71, 0x75,\n",
      "  0x65, 0x6e, 0x74, 0x69, 0x61, 0x6c, 0x5f, 0x36, 0x5f, 0x31, 0x2f, 0x66,\n",
      "  0x6c, 0x61, 0x74, 0x74, 0x65, 0x6e, 0x5f, 0x36, 0x5f, 0x31, 0x2f, 0x52,\n",
      "  0x65, 0x73, 0x68, 0x61, 0x70, 0x65, 0x3b, 0x53, 0x74, 0x61, 0x74, 0x65,\n",
      "  0x66, 0x75, 0x6c, 0x50, 0x61, 0x72, 0x74, 0x69, 0x74, 0x69, 0x6f, 0x6e,\n",
      "  0x65, 0x64, 0x43, 0x61, 0x6c, 0x6c, 0x5f, 0x31, 0x2f, 0x53, 0x74, 0x61,\n",
      "  0x74, 0x65, 0x66, 0x75, 0x6c, 0x50, 0x61, 0x72, 0x74, 0x69, 0x74, 0x69,\n",
      "  0x6f, 0x6e, 0x65, 0x64, 0x43, 0x61, 0x6c, 0x6c, 0x2f, 0x73, 0x65, 0x71,\n",
      "  0x75, 0x65, 0x6e, 0x74, 0x69, 0x61, 0x6c, 0x5f, 0x36, 0x5f, 0x31, 0x2f,\n",
      "  0x66, 0x6c, 0x61, 0x74, 0x74, 0x65, 0x6e, 0x5f, 0x36, 0x5f, 0x31, 0x2f,\n",
      "  0x52, 0x65, 0x73, 0x68, 0x61, 0x70, 0x65, 0x00, 0x02, 0x00, 0x00, 0x00,\n",
      "  0x01, 0x00, 0x00, 0x00, 0x2c, 0x0b, 0x00, 0x00, 0xf2, 0xf6, 0xff, 0xff,\n",
      "  0x00, 0x00, 0x00, 0x01, 0x18, 0x00, 0x00, 0x00, 0x28, 0x00, 0x00, 0x00,\n",
      "  0x44, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x09,\n",
      "  0x10, 0x02, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0xff, 0xff, 0xff, 0xff,\n",
      "  0x14, 0x00, 0x00, 0x00, 0x0d, 0x00, 0x00, 0x00, 0x0b, 0x00, 0x00, 0x00,\n",
      "  0xe4, 0xf6, 0xff, 0xff, 0x08, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00,\n",
      "  0x01, 0x00, 0x00, 0x00, 0x80, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,\n",
      "  0x01, 0x00, 0x00, 0x00, 0x11, 0xe7, 0xcf, 0x3d, 0xd1, 0x01, 0x00, 0x00,\n",
      "  0x73, 0x65, 0x71, 0x75, 0x65, 0x6e, 0x74, 0x69, 0x61, 0x6c, 0x5f, 0x36,\n",
      "  0x5f, 0x31, 0x2f, 0x63, 0x6f, 0x6e, 0x76, 0x32, 0x64, 0x5f, 0x36, 0x5f,\n",
      "  0x31, 0x2f, 0x52, 0x65, 0x6c, 0x75, 0x3b, 0x53, 0x74, 0x61, 0x74, 0x65,\n",
      "  0x66, 0x75, 0x6c, 0x50, 0x61, 0x72, 0x74, 0x69, 0x74, 0x69, 0x6f, 0x6e,\n",
      "  0x65, 0x64, 0x43, 0x61, 0x6c, 0x6c, 0x5f, 0x31, 0x2f, 0x53, 0x74, 0x61,\n",
      "  0x74, 0x65, 0x66, 0x75, 0x6c, 0x50, 0x61, 0x72, 0x74, 0x69, 0x74, 0x69,\n",
      "  0x6f, 0x6e, 0x65, 0x64, 0x43, 0x61, 0x6c, 0x6c, 0x2f, 0x73, 0x65, 0x71,\n",
      "  0x75, 0x65, 0x6e, 0x74, 0x69, 0x61, 0x6c, 0x5f, 0x36, 0x5f, 0x31, 0x2f,\n",
      "  0x63, 0x6f, 0x6e, 0x76, 0x32, 0x64, 0x5f, 0x36, 0x5f, 0x31, 0x2f, 0x52,\n",
      "  0x65, 0x6c, 0x75, 0x3b, 0x73, 0x65, 0x71, 0x75, 0x65, 0x6e, 0x74, 0x69,\n",
      "  0x61, 0x6c, 0x5f, 0x36, 0x5f, 0x31, 0x2f, 0x63, 0x6f, 0x6e, 0x76, 0x32,\n",
      "  0x64, 0x5f, 0x36, 0x5f, 0x31, 0x2f, 0x61, 0x64, 0x64, 0x3b, 0x53, 0x74,\n",
      "  0x61, 0x74, 0x65, 0x66, 0x75, 0x6c, 0x50, 0x61, 0x72, 0x74, 0x69, 0x74,\n",
      "  0x69, 0x6f, 0x6e, 0x65, 0x64, 0x43, 0x61, 0x6c, 0x6c, 0x5f, 0x31, 0x2f,\n",
      "  0x53, 0x74, 0x61, 0x74, 0x65, 0x66, 0x75, 0x6c, 0x50, 0x61, 0x72, 0x74,\n",
      "  0x69, 0x74, 0x69, 0x6f, 0x6e, 0x65, 0x64, 0x43, 0x61, 0x6c, 0x6c, 0x2f,\n",
      "  0x73, 0x65, 0x71, 0x75, 0x65, 0x6e, 0x74, 0x69, 0x61, 0x6c, 0x5f, 0x36,\n",
      "  0x5f, 0x31, 0x2f, 0x63, 0x6f, 0x6e, 0x76, 0x32, 0x64, 0x5f, 0x36, 0x5f,\n",
      "  0x31, 0x2f, 0x61, 0x64, 0x64, 0x3b, 0x73, 0x65, 0x71, 0x75, 0x65, 0x6e,\n",
      "  0x74, 0x69, 0x61, 0x6c, 0x5f, 0x36, 0x5f, 0x31, 0x2f, 0x63, 0x6f, 0x6e,\n",
      "  0x76, 0x32, 0x64, 0x5f, 0x36, 0x5f, 0x31, 0x2f, 0x63, 0x6f, 0x6e, 0x76,\n",
      "  0x6f, 0x6c, 0x75, 0x74, 0x69, 0x6f, 0x6e, 0x3b, 0x53, 0x74, 0x61, 0x74,\n",
      "  0x65, 0x66, 0x75, 0x6c, 0x50, 0x61, 0x72, 0x74, 0x69, 0x74, 0x69, 0x6f,\n",
      "  0x6e, 0x65, 0x64, 0x43, 0x61, 0x6c, 0x6c, 0x5f, 0x31, 0x2f, 0x53, 0x74,\n",
      "  0x61, 0x74, 0x65, 0x66, 0x75, 0x6c, 0x50, 0x61, 0x72, 0x74, 0x69, 0x74,\n",
      "  0x69, 0x6f, 0x6e, 0x65, 0x64, 0x43, 0x61, 0x6c, 0x6c, 0x2f, 0x73, 0x65,\n",
      "  0x71, 0x75, 0x65, 0x6e, 0x74, 0x69, 0x61, 0x6c, 0x5f, 0x36, 0x5f, 0x31,\n",
      "  0x2f, 0x63, 0x6f, 0x6e, 0x76, 0x32, 0x64, 0x5f, 0x36, 0x5f, 0x31, 0x2f,\n",
      "  0x63, 0x6f, 0x6e, 0x76, 0x6f, 0x6c, 0x75, 0x74, 0x69, 0x6f, 0x6e, 0x3b,\n",
      "  0x73, 0x65, 0x71, 0x75, 0x65, 0x6e, 0x74, 0x69, 0x61, 0x6c, 0x5f, 0x36,\n",
      "  0x5f, 0x31, 0x2f, 0x63, 0x6f, 0x6e, 0x76, 0x32, 0x64, 0x5f, 0x36, 0x5f,\n",
      "  0x31, 0x2f, 0x52, 0x65, 0x73, 0x68, 0x61, 0x70, 0x65, 0x3b, 0x53, 0x74,\n",
      "  0x61, 0x74, 0x65, 0x66, 0x75, 0x6c, 0x50, 0x61, 0x72, 0x74, 0x69, 0x74,\n",
      "  0x69, 0x6f, 0x6e, 0x65, 0x64, 0x43, 0x61, 0x6c, 0x6c, 0x5f, 0x31, 0x2f,\n",
      "  0x53, 0x74, 0x61, 0x74, 0x65, 0x66, 0x75, 0x6c, 0x50, 0x61, 0x72, 0x74,\n",
      "  0x69, 0x74, 0x69, 0x6f, 0x6e, 0x65, 0x64, 0x43, 0x61, 0x6c, 0x6c, 0x2f,\n",
      "  0x73, 0x65, 0x71, 0x75, 0x65, 0x6e, 0x74, 0x69, 0x61, 0x6c, 0x5f, 0x36,\n",
      "  0x5f, 0x31, 0x2f, 0x63, 0x6f, 0x6e, 0x76, 0x32, 0x64, 0x5f, 0x36, 0x5f,\n",
      "  0x31, 0x2f, 0x52, 0x65, 0x73, 0x68, 0x61, 0x70, 0x65, 0x00, 0x00, 0x00,\n",
      "  0x04, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x14, 0x00, 0x00, 0x00,\n",
      "  0x0d, 0x00, 0x00, 0x00, 0x0b, 0x00, 0x00, 0x00, 0x32, 0xf9, 0xff, 0xff,\n",
      "  0x00, 0x00, 0x00, 0x01, 0x18, 0x00, 0x00, 0x00, 0x28, 0x00, 0x00, 0x00,\n",
      "  0x44, 0x00, 0x00, 0x00, 0x0f, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x09,\n",
      "  0xb4, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0xff, 0xff, 0xff, 0xff,\n",
      "  0x3c, 0x00, 0x00, 0x00, 0x28, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
      "  0x24, 0xf9, 0xff, 0xff, 0x08, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00,\n",
      "  0x01, 0x00, 0x00, 0x00, 0x7f, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
      "  0x01, 0x00, 0x00, 0x00, 0xa1, 0xa0, 0xa0, 0x3e, 0x77, 0x00, 0x00, 0x00,\n",
      "  0x73, 0x65, 0x71, 0x75, 0x65, 0x6e, 0x74, 0x69, 0x61, 0x6c, 0x5f, 0x36,\n",
      "  0x5f, 0x31, 0x2f, 0x72, 0x65, 0x73, 0x68, 0x61, 0x70, 0x65, 0x5f, 0x36,\n",
      "  0x5f, 0x31, 0x2f, 0x52, 0x65, 0x73, 0x68, 0x61, 0x70, 0x65, 0x3b, 0x53,\n",
      "  0x74, 0x61, 0x74, 0x65, 0x66, 0x75, 0x6c, 0x50, 0x61, 0x72, 0x74, 0x69,\n",
      "  0x74, 0x69, 0x6f, 0x6e, 0x65, 0x64, 0x43, 0x61, 0x6c, 0x6c, 0x5f, 0x31,\n",
      "  0x2f, 0x53, 0x74, 0x61, 0x74, 0x65, 0x66, 0x75, 0x6c, 0x50, 0x61, 0x72,\n",
      "  0x74, 0x69, 0x74, 0x69, 0x6f, 0x6e, 0x65, 0x64, 0x43, 0x61, 0x6c, 0x6c,\n",
      "  0x2f, 0x73, 0x65, 0x71, 0x75, 0x65, 0x6e, 0x74, 0x69, 0x61, 0x6c, 0x5f,\n",
      "  0x36, 0x5f, 0x31, 0x2f, 0x72, 0x65, 0x73, 0x68, 0x61, 0x70, 0x65, 0x5f,\n",
      "  0x36, 0x5f, 0x31, 0x2f, 0x52, 0x65, 0x73, 0x68, 0x61, 0x70, 0x65, 0x00,\n",
      "  0x04, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x3c, 0x00, 0x00, 0x00,\n",
      "  0x28, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x6e, 0xfa, 0xff, 0xff,\n",
      "  0x00, 0x00, 0x00, 0x01, 0x14, 0x00, 0x00, 0x00, 0x14, 0x00, 0x00, 0x00,\n",
      "  0x0e, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02, 0x90, 0x00, 0x00, 0x00,\n",
      "  0x58, 0xfa, 0xff, 0xff, 0x83, 0x00, 0x00, 0x00, 0x73, 0x65, 0x71, 0x75,\n",
      "  0x65, 0x6e, 0x74, 0x69, 0x61, 0x6c, 0x5f, 0x36, 0x5f, 0x31, 0x2f, 0x72,\n",
      "  0x65, 0x73, 0x68, 0x61, 0x70, 0x65, 0x5f, 0x36, 0x5f, 0x31, 0x2f, 0x52,\n",
      "  0x65, 0x73, 0x68, 0x61, 0x70, 0x65, 0x2f, 0x73, 0x68, 0x61, 0x70, 0x65,\n",
      "  0x3b, 0x53, 0x74, 0x61, 0x74, 0x65, 0x66, 0x75, 0x6c, 0x50, 0x61, 0x72,\n",
      "  0x74, 0x69, 0x74, 0x69, 0x6f, 0x6e, 0x65, 0x64, 0x43, 0x61, 0x6c, 0x6c,\n",
      "  0x5f, 0x31, 0x2f, 0x53, 0x74, 0x61, 0x74, 0x65, 0x66, 0x75, 0x6c, 0x50,\n",
      "  0x61, 0x72, 0x74, 0x69, 0x74, 0x69, 0x6f, 0x6e, 0x65, 0x64, 0x43, 0x61,\n",
      "  0x6c, 0x6c, 0x2f, 0x73, 0x65, 0x71, 0x75, 0x65, 0x6e, 0x74, 0x69, 0x61,\n",
      "  0x6c, 0x5f, 0x36, 0x5f, 0x31, 0x2f, 0x72, 0x65, 0x73, 0x68, 0x61, 0x70,\n",
      "  0x65, 0x5f, 0x36, 0x5f, 0x31, 0x2f, 0x52, 0x65, 0x73, 0x68, 0x61, 0x70,\n",
      "  0x65, 0x2f, 0x73, 0x68, 0x61, 0x70, 0x65, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
      "  0x04, 0x00, 0x00, 0x00, 0x1e, 0xfb, 0xff, 0xff, 0x00, 0x00, 0x00, 0x01,\n",
      "  0x14, 0x00, 0x00, 0x00, 0x14, 0x00, 0x00, 0x00, 0x0d, 0x00, 0x00, 0x00,\n",
      "  0x00, 0x00, 0x00, 0x02, 0x90, 0x00, 0x00, 0x00, 0x08, 0xfb, 0xff, 0xff,\n",
      "  0x83, 0x00, 0x00, 0x00, 0x73, 0x65, 0x71, 0x75, 0x65, 0x6e, 0x74, 0x69,\n",
      "  0x61, 0x6c, 0x5f, 0x36, 0x5f, 0x31, 0x2f, 0x72, 0x65, 0x73, 0x68, 0x61,\n",
      "  0x70, 0x65, 0x5f, 0x36, 0x5f, 0x31, 0x2f, 0x73, 0x74, 0x72, 0x69, 0x64,\n",
      "  0x65, 0x64, 0x5f, 0x73, 0x6c, 0x69, 0x63, 0x65, 0x3b, 0x53, 0x74, 0x61,\n",
      "  0x74, 0x65, 0x66, 0x75, 0x6c, 0x50, 0x61, 0x72, 0x74, 0x69, 0x74, 0x69,\n",
      "  0x6f, 0x6e, 0x65, 0x64, 0x43, 0x61, 0x6c, 0x6c, 0x5f, 0x31, 0x2f, 0x53,\n",
      "  0x74, 0x61, 0x74, 0x65, 0x66, 0x75, 0x6c, 0x50, 0x61, 0x72, 0x74, 0x69,\n",
      "  0x74, 0x69, 0x6f, 0x6e, 0x65, 0x64, 0x43, 0x61, 0x6c, 0x6c, 0x2f, 0x73,\n",
      "  0x65, 0x71, 0x75, 0x65, 0x6e, 0x74, 0x69, 0x61, 0x6c, 0x5f, 0x36, 0x5f,\n",
      "  0x31, 0x2f, 0x72, 0x65, 0x73, 0x68, 0x61, 0x70, 0x65, 0x5f, 0x36, 0x5f,\n",
      "  0x31, 0x2f, 0x73, 0x74, 0x72, 0x69, 0x64, 0x65, 0x64, 0x5f, 0x73, 0x6c,\n",
      "  0x69, 0x63, 0x65, 0x00, 0x00, 0x00, 0x00, 0x00, 0xca, 0xfb, 0xff, 0xff,\n",
      "  0x00, 0x00, 0x00, 0x01, 0x14, 0x00, 0x00, 0x00, 0x14, 0x00, 0x00, 0x00,\n",
      "  0x0c, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02, 0x80, 0x00, 0x00, 0x00,\n",
      "  0xb4, 0xfb, 0xff, 0xff, 0x73, 0x00, 0x00, 0x00, 0x73, 0x65, 0x71, 0x75,\n",
      "  0x65, 0x6e, 0x74, 0x69, 0x61, 0x6c, 0x5f, 0x36, 0x5f, 0x31, 0x2f, 0x72,\n",
      "  0x65, 0x73, 0x68, 0x61, 0x70, 0x65, 0x5f, 0x36, 0x5f, 0x31, 0x2f, 0x53,\n",
      "  0x68, 0x61, 0x70, 0x65, 0x3b, 0x53, 0x74, 0x61, 0x74, 0x65, 0x66, 0x75,\n",
      "  0x6c, 0x50, 0x61, 0x72, 0x74, 0x69, 0x74, 0x69, 0x6f, 0x6e, 0x65, 0x64,\n",
      "  0x43, 0x61, 0x6c, 0x6c, 0x5f, 0x31, 0x2f, 0x53, 0x74, 0x61, 0x74, 0x65,\n",
      "  0x66, 0x75, 0x6c, 0x50, 0x61, 0x72, 0x74, 0x69, 0x74, 0x69, 0x6f, 0x6e,\n",
      "  0x65, 0x64, 0x43, 0x61, 0x6c, 0x6c, 0x2f, 0x73, 0x65, 0x71, 0x75, 0x65,\n",
      "  0x6e, 0x74, 0x69, 0x61, 0x6c, 0x5f, 0x36, 0x5f, 0x31, 0x2f, 0x72, 0x65,\n",
      "  0x73, 0x68, 0x61, 0x70, 0x65, 0x5f, 0x36, 0x5f, 0x31, 0x2f, 0x53, 0x68,\n",
      "  0x61, 0x70, 0x65, 0x00, 0x01, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00,\n",
      "  0x6a, 0xfc, 0xff, 0xff, 0x00, 0x00, 0x00, 0x01, 0x14, 0x00, 0x00, 0x00,\n",
      "  0xa8, 0x00, 0x00, 0x00, 0x0b, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x09,\n",
      "  0xb4, 0x00, 0x00, 0x00, 0xec, 0xfb, 0xff, 0xff, 0x08, 0x00, 0x00, 0x00,\n",
      "  0x60, 0x00, 0x00, 0x00, 0x0b, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
      "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
      "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
      "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
      "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
      "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
      "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
      "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
      "  0x0b, 0x00, 0x00, 0x00, 0x72, 0x4b, 0x13, 0x3b, 0x1c, 0x21, 0x61, 0x3b,\n",
      "  0xb5, 0xaa, 0xf7, 0x3a, 0x16, 0x8a, 0xd2, 0x3a, 0xed, 0xf4, 0xf1, 0x3a,\n",
      "  0x18, 0x7e, 0x18, 0x3a, 0x95, 0xa4, 0xe5, 0x3a, 0x6e, 0x95, 0xdb, 0x3a,\n",
      "  0x82, 0xb8, 0xc1, 0x3a, 0x43, 0x7d, 0xfc, 0x3a, 0xa9, 0x55, 0xd1, 0x3a,\n",
      "  0x12, 0x00, 0x00, 0x00, 0x74, 0x66, 0x6c, 0x2e, 0x70, 0x73, 0x65, 0x75,\n",
      "  0x64, 0x6f, 0x5f, 0x71, 0x63, 0x6f, 0x6e, 0x73, 0x74, 0x33, 0x00, 0x00,\n",
      "  0x04, 0x00, 0x00, 0x00, 0x0b, 0x00, 0x00, 0x00, 0x03, 0x00, 0x00, 0x00,\n",
      "  0x03, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x4a, 0xfd, 0xff, 0xff,\n",
      "  0x00, 0x00, 0x00, 0x01, 0x14, 0x00, 0x00, 0x00, 0xac, 0x00, 0x00, 0x00,\n",
      "  0x0a, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02, 0xb8, 0x00, 0x00, 0x00,\n",
      "  0xcc, 0xfc, 0xff, 0xff, 0x08, 0x00, 0x00, 0x00, 0x64, 0x00, 0x00, 0x00,\n",
      "  0x0b, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
      "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
      "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
      "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
      "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
      "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
      "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
      "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
      "  0x0b, 0x00, 0x00, 0x00, 0x26, 0xd7, 0x38, 0x3a, 0xf4, 0x41, 0x8d, 0x3a,\n",
      "  0x18, 0x66, 0x1b, 0x3a, 0x68, 0x1a, 0x04, 0x3a, 0xe5, 0xd0, 0x17, 0x3a,\n",
      "  0xfb, 0x5c, 0x3f, 0x39, 0xf4, 0x16, 0x10, 0x3a, 0x2c, 0xc7, 0x09, 0x3a,\n",
      "  0xbd, 0x19, 0xf3, 0x39, 0xb7, 0x6c, 0x1e, 0x3a, 0xe3, 0x58, 0x03, 0x3a,\n",
      "  0x12, 0x00, 0x00, 0x00, 0x74, 0x66, 0x6c, 0x2e, 0x70, 0x73, 0x65, 0x75,\n",
      "  0x64, 0x6f, 0x5f, 0x71, 0x63, 0x6f, 0x6e, 0x73, 0x74, 0x32, 0x00, 0x00,\n",
      "  0x01, 0x00, 0x00, 0x00, 0x0b, 0x00, 0x00, 0x00, 0x22, 0xfe, 0xff, 0xff,\n",
      "  0x00, 0x00, 0x00, 0x01, 0x14, 0x00, 0x00, 0x00, 0x30, 0x00, 0x00, 0x00,\n",
      "  0x09, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x09, 0x3c, 0x00, 0x00, 0x00,\n",
      "  0xa4, 0xfd, 0xff, 0xff, 0x08, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00,\n",
      "  0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
      "  0x01, 0x00, 0x00, 0x00, 0x43, 0xf5, 0xd2, 0x3b, 0x12, 0x00, 0x00, 0x00,\n",
      "  0x74, 0x66, 0x6c, 0x2e, 0x70, 0x73, 0x65, 0x75, 0x64, 0x6f, 0x5f, 0x71,\n",
      "  0x63, 0x6f, 0x6e, 0x73, 0x74, 0x31, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00,\n",
      "  0x02, 0x00, 0x00, 0x00, 0x2c, 0x0b, 0x00, 0x00, 0x82, 0xfe, 0xff, 0xff,\n",
      "  0x00, 0x00, 0x00, 0x01, 0x14, 0x00, 0x00, 0x00, 0x30, 0x00, 0x00, 0x00,\n",
      "  0x08, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02, 0x3c, 0x00, 0x00, 0x00,\n",
      "  0x04, 0xfe, 0xff, 0xff, 0x08, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00,\n",
      "  0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
      "  0x01, 0x00, 0x00, 0x00, 0xba, 0x52, 0x2b, 0x3a, 0x11, 0x00, 0x00, 0x00,\n",
      "  0x74, 0x66, 0x6c, 0x2e, 0x70, 0x73, 0x65, 0x75, 0x64, 0x6f, 0x5f, 0x71,\n",
      "  0x63, 0x6f, 0x6e, 0x73, 0x74, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
      "  0x02, 0x00, 0x00, 0x00, 0xde, 0xfe, 0xff, 0xff, 0x00, 0x00, 0x00, 0x01,\n",
      "  0x14, 0x00, 0x00, 0x00, 0x14, 0x00, 0x00, 0x00, 0x07, 0x00, 0x00, 0x00,\n",
      "  0x00, 0x00, 0x00, 0x02, 0x1c, 0x00, 0x00, 0x00, 0xc8, 0xfe, 0xff, 0xff,\n",
      "  0x0f, 0x00, 0x00, 0x00, 0x61, 0x72, 0x69, 0x74, 0x68, 0x2e, 0x63, 0x6f,\n",
      "  0x6e, 0x73, 0x74, 0x61, 0x6e, 0x74, 0x35, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
      "  0x02, 0x00, 0x00, 0x00, 0x1a, 0xff, 0xff, 0xff, 0x00, 0x00, 0x00, 0x01,\n",
      "  0x14, 0x00, 0x00, 0x00, 0x14, 0x00, 0x00, 0x00, 0x03, 0x00, 0x00, 0x00,\n",
      "  0x00, 0x00, 0x00, 0x02, 0x1c, 0x00, 0x00, 0x00, 0x04, 0xff, 0xff, 0xff,\n",
      "  0x0f, 0x00, 0x00, 0x00, 0x61, 0x72, 0x69, 0x74, 0x68, 0x2e, 0x63, 0x6f,\n",
      "  0x6e, 0x73, 0x74, 0x61, 0x6e, 0x74, 0x34, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
      "  0x52, 0xff, 0xff, 0xff, 0x00, 0x00, 0x00, 0x01, 0x14, 0x00, 0x00, 0x00,\n",
      "  0x14, 0x00, 0x00, 0x00, 0x05, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02,\n",
      "  0x1c, 0x00, 0x00, 0x00, 0x3c, 0xff, 0xff, 0xff, 0x0f, 0x00, 0x00, 0x00,\n",
      "  0x61, 0x72, 0x69, 0x74, 0x68, 0x2e, 0x63, 0x6f, 0x6e, 0x73, 0x74, 0x61,\n",
      "  0x6e, 0x74, 0x33, 0x00, 0x00, 0x00, 0x00, 0x00, 0x8a, 0xff, 0xff, 0xff,\n",
      "  0x00, 0x00, 0x00, 0x01, 0x14, 0x00, 0x00, 0x00, 0x14, 0x00, 0x00, 0x00,\n",
      "  0x04, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02, 0x1c, 0x00, 0x00, 0x00,\n",
      "  0x74, 0xff, 0xff, 0xff, 0x0f, 0x00, 0x00, 0x00, 0x61, 0x72, 0x69, 0x74,\n",
      "  0x68, 0x2e, 0x63, 0x6f, 0x6e, 0x73, 0x74, 0x61, 0x6e, 0x74, 0x32, 0x00,\n",
      "  0x00, 0x00, 0x00, 0x00, 0xc2, 0xff, 0xff, 0xff, 0x00, 0x00, 0x00, 0x01,\n",
      "  0x14, 0x00, 0x00, 0x00, 0x14, 0x00, 0x00, 0x00, 0x03, 0x00, 0x00, 0x00,\n",
      "  0x00, 0x00, 0x00, 0x02, 0x1c, 0x00, 0x00, 0x00, 0xac, 0xff, 0xff, 0xff,\n",
      "  0x0f, 0x00, 0x00, 0x00, 0x61, 0x72, 0x69, 0x74, 0x68, 0x2e, 0x63, 0x6f,\n",
      "  0x6e, 0x73, 0x74, 0x61, 0x6e, 0x74, 0x31, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
      "  0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x16, 0x00, 0x1c, 0x00, 0x18, 0x00,\n",
      "  0x17, 0x00, 0x10, 0x00, 0x0c, 0x00, 0x08, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
      "  0x00, 0x00, 0x07, 0x00, 0x16, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01,\n",
      "  0x18, 0x00, 0x00, 0x00, 0x18, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00,\n",
      "  0x00, 0x00, 0x00, 0x02, 0x20, 0x00, 0x00, 0x00, 0x04, 0x00, 0x04, 0x00,\n",
      "  0x04, 0x00, 0x00, 0x00, 0x0e, 0x00, 0x00, 0x00, 0x61, 0x72, 0x69, 0x74,\n",
      "  0x68, 0x2e, 0x63, 0x6f, 0x6e, 0x73, 0x74, 0x61, 0x6e, 0x74, 0x00, 0x00,\n",
      "  0x01, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x16, 0x00,\n",
      "  0x20, 0x00, 0x1c, 0x00, 0x1b, 0x00, 0x14, 0x00, 0x10, 0x00, 0x0c, 0x00,\n",
      "  0x00, 0x00, 0x00, 0x00, 0x08, 0x00, 0x07, 0x00, 0x16, 0x00, 0x00, 0x00,\n",
      "  0x00, 0x00, 0x00, 0x01, 0x18, 0x00, 0x00, 0x00, 0x2c, 0x00, 0x00, 0x00,\n",
      "  0x48, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x09,\n",
      "  0x60, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00, 0xff, 0xff, 0xff, 0xff,\n",
      "  0x60, 0x09, 0x00, 0x00, 0x0c, 0x00, 0x0c, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
      "  0x08, 0x00, 0x04, 0x00, 0x0c, 0x00, 0x00, 0x00, 0x08, 0x00, 0x00, 0x00,\n",
      "  0x10, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x7f, 0x00, 0x00, 0x00,\n",
      "  0x00, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0xa1, 0xa0, 0xa0, 0x3e,\n",
      "  0x1f, 0x00, 0x00, 0x00, 0x73, 0x65, 0x72, 0x76, 0x69, 0x6e, 0x67, 0x5f,\n",
      "  0x64, 0x65, 0x66, 0x61, 0x75, 0x6c, 0x74, 0x5f, 0x6b, 0x65, 0x72, 0x61,\n",
      "  0x73, 0x5f, 0x74, 0x65, 0x6e, 0x73, 0x6f, 0x72, 0x5f, 0x33, 0x30, 0x00,\n",
      "  0x02, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x60, 0x09, 0x00, 0x00,\n",
      "  0x07, 0x00, 0x00, 0x00, 0x88, 0x00, 0x00, 0x00, 0x6c, 0x00, 0x00, 0x00,\n",
      "  0x5c, 0x00, 0x00, 0x00, 0x4c, 0x00, 0x00, 0x00, 0x38, 0x00, 0x00, 0x00,\n",
      "  0x18, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0xe0, 0xff, 0xff, 0xff,\n",
      "  0x19, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x19,\n",
      "  0xf0, 0xff, 0xff, 0xff, 0x09, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00,\n",
      "  0x00, 0x00, 0x00, 0x09, 0x0c, 0x00, 0x10, 0x00, 0x0f, 0x00, 0x00, 0x00,\n",
      "  0x08, 0x00, 0x04, 0x00, 0x0c, 0x00, 0x00, 0x00, 0x03, 0x00, 0x00, 0x00,\n",
      "  0x03, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x03, 0xdc, 0xff, 0xff, 0xff,\n",
      "  0x16, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x16, 0xe8, 0xff, 0xff, 0xff,\n",
      "  0x53, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x53, 0xf4, 0xff, 0xff, 0xff,\n",
      "  0x2d, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x2d, 0x0c, 0x00, 0x0c, 0x00,\n",
      "  0x0b, 0x00, 0x00, 0x00, 0x00, 0x00, 0x04, 0x00, 0x0c, 0x00, 0x00, 0x00,\n",
      "  0x4d, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x4d\n",
      "};\n",
      "unsigned int g_model_len = 10472;\n"
     ]
    }
   ],
   "source": [
    "!cat {MODEL_TFLITE_MICRO}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea651213-3bd3-42de-bb8c-74426ded1665",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
