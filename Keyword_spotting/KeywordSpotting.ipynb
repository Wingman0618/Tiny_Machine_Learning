{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9304d1ad-73f9-41c5-b925-3c70fa85b239",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "from scipy.io import wavfile\n",
    "import librosa\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "import tensorflow_io as tfio\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69103891-afbe-4c47-9a73-8c764f05a324",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "016097b5-d4fd-4b7c-afb5-5ad4d469b1dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load done\n"
     ]
    }
   ],
   "source": [
    "## Building the data tensor set\n",
    "## Using 3400 audios for each classes\n",
    "## for counting number of data in the dataset through file system;\n",
    "## Reference method: image_count = len(list(DATASETPATH.glob('./*.wav')))\n",
    "## Padding the data with zeros to length 15872\n",
    "data_tensor_yes = []\n",
    "data_tensor_no = []\n",
    "data_tensor_test_yes = []\n",
    "data_tensor_test_no = []\n",
    "for i in range(3400):\n",
    "    filename = './Dataset/yes/yes' + str(i+1) + '.wav'\n",
    "    data_rate, data_audio_tensor = wavfile.read(filename)\n",
    "    if len(data_audio_tensor)>15872:\n",
    "        data_audio_tensor = data_audio_tensor[:15872]\n",
    "    else:\n",
    "        for j in range(15872-len(data_audio_tensor)):\n",
    "            data_audio_tensor = np.append(data_audio_tensor,[0])\n",
    "    data_tensor_yes.append(data_audio_tensor)\n",
    "    \n",
    "for i in range(3400):\n",
    "    filename = './Dataset/no/no' + str(i+1) + '.wav'\n",
    "    data_rate, data_audio_tensor = wavfile.read(filename)\n",
    "    if len(data_audio_tensor)>15872:\n",
    "        data_audio_tensor = data_audio_tensor[:15872]\n",
    "    else:\n",
    "        for j in range(15872-len(data_audio_tensor)):\n",
    "            data_audio_tensor = np.append(data_audio_tensor,[0])\n",
    "    data_tensor_no.append(data_audio_tensor)\n",
    "    \n",
    "## load test dataset\n",
    "for i in range(490):\n",
    "    filename = './test_set/yes/yes' + str(i+1) + '.wav'\n",
    "    data_rate, data_audio_tensor = wavfile.read(filename)\n",
    "    if len(data_audio_tensor)>15872:\n",
    "        data_audio_tensor = data_audio_tensor[:15872]\n",
    "    else:\n",
    "        for j in range(15872-len(data_audio_tensor)):\n",
    "            data_audio_tensor = np.append(data_audio_tensor,[0])\n",
    "    data_tensor_test_yes.append(data_audio_tensor)\n",
    "    \n",
    "for i in range(490):\n",
    "    filename = './test_set/no/no' + str(i+1) + '.wav'\n",
    "    data_rate, data_audio_tensor = wavfile.read(filename)\n",
    "    if len(data_audio_tensor)>=15872:\n",
    "        data_audio_tensor = data_audio_tensor[:15872]\n",
    "    else:\n",
    "        for j in range(15872-len(data_audio_tensor)):\n",
    "            data_audio_tensor = np.append(data_audio_tensor,[0])\n",
    "    data_tensor_test_no.append(data_audio_tensor)\n",
    "##print(data_tensor_yes[0])\n",
    "print(\"load done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b99f0e-c9f2-4714-b650-4ba346a18fe9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Data pre-process by the librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "108a7dbd-8077-47d0-8683-5e90b378136f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Construct the mfcc set\n",
    "'''\n",
    "mfcc_set_yes = []\n",
    "mfcc_set_no = []\n",
    "\n",
    "mfcc_test_set_yes = []\n",
    "mfcc_test_set_no = []\n",
    "\n",
    "mfcc_train_labels = []\n",
    "mfcc_test_labels = []\n",
    "for i in data_tensor_yes:\n",
    "    mfcc_audio = librosa.power_to_db(librosa.feature.melspectrogram(y=np.float32(i),\n",
    "                                                               sr=16000,\n",
    "                                                               n_fft=512,\n",
    "                                                               hop_length=256,\n",
    "                                                               n_mels=40))\n",
    "    mfcc_set_yes.append(mfcc_audio)\n",
    "    mfcc_train_labels.append(1)\n",
    "    \n",
    "for i in data_tensor_no:\n",
    "    mfcc_audio = librosa.power_to_db(librosa.feature.melspectrogram(y=np.float32(i),\n",
    "                                                               sr=16000,\n",
    "                                                               n_fft=512,\n",
    "                                                               hop_length=256,\n",
    "                                                               n_mels=40))\n",
    "    mfcc_set_no.append(mfcc_audio)\n",
    "    mfcc_train_labels.append(0)\n",
    "\n",
    "\n",
    "## load test mfccs\n",
    "for i in data_tensor_test_yes:\n",
    "    mfcc_audio = librosa.power_to_db(librosa.feature.melspectrogram(y=np.float32(i),\n",
    "                                                               sr=16000,\n",
    "                                                               n_fft=512,\n",
    "                                                               hop_length=256,\n",
    "                                                               n_mels=40))\n",
    "    mfcc_test_set_yes.append(mfcc_audio)\n",
    "    mfcc_test_labels.append(1)\n",
    "\n",
    "for i in data_tensor_test_no:\n",
    "    mfcc_audio = librosa.power_to_db(librosa.feature.melspectrogram(y=np.float32(i),\n",
    "                                                               sr=16000,\n",
    "                                                               n_fft=512,\n",
    "                                                               hop_length=256,\n",
    "                                                               n_mels=40))\n",
    "    mfcc_test_set_no.append(mfcc_audio)\n",
    "    mfcc_test_labels.append(0)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99b9082-581c-4b46-91cc-4ff7fa299d6e",
   "metadata": {},
   "source": [
    "## Mel_spectrogram generating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "db75b420-d843-4463-9072-59d762b204af",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the functions\n",
    "import sys\n",
    "\n",
    "def hamming(length):\n",
    "    weight = []\n",
    "    for i in range(length):\n",
    "        weight.append(0.56-0.46*np.cos((2.*np.pi*float(i))/(float(length)-1.)))\n",
    "    max_x = np.max(weight)\n",
    "    min_x = np.min(weight)\n",
    "    for i in range(length):\n",
    "        weight[i] = (weight[i]-min_x)/(max_x - min_x)\n",
    "    return weight\n",
    "\n",
    "def stft(data, num_of_inputs, window_size, hop_length):\n",
    "    num_of_ffts = (num_of_inputs - window_size)/hop_length\n",
    "    n_fft = (window_size/2)+1\n",
    "    fft_arr = []\n",
    "    counter = 0\n",
    "    pointer = 0\n",
    "    while(counter != num_of_ffts):\n",
    "        window = data[pointer:(pointer+window_size)]\n",
    "        weight = hamming(window_size)\n",
    "        fft_ = np.fft.fft(window*weight)\n",
    "        fft_arr.append(np.abs(fft_[:int(n_fft)]))\n",
    "        pointer+=hop_length\n",
    "        counter+=1\n",
    "    return fft_arr\n",
    "\n",
    "def mel_spec(data, num_of_inputs, window_size, hop_length, n_mels, sample_rate):\n",
    "    num_of_ffts = (num_of_inputs - window_size)/hop_length\n",
    "    n_ffts = (window_size/2)+1\n",
    "\n",
    "    lower_freq = 300\n",
    "    upper_freq = 8000\n",
    "\n",
    "    mel_lower_freq = 1125*np.log(1+lower_freq/700)\n",
    "    mel_upper_freq = 1125*np.log(1+upper_freq/700)\n",
    "    mel_gap = (mel_upper_freq - mel_lower_freq)/(n_mels+1)\n",
    "\n",
    "    ## Define the filterbank\n",
    "    mel_value = mel_lower_freq\n",
    "    fbin = []\n",
    "    counter = 0\n",
    "    while(counter<n_mels+2):\n",
    "        mel_to_hz = 700*(np.exp(mel_value/1125)-1)\n",
    "\n",
    "        rounding_freq = np.floor((n_ffts*mel_to_hz)/sample_rate)\n",
    "        fbin.append(rounding_freq)\n",
    "        mel_value+=mel_gap\n",
    "\n",
    "        counter+=1\n",
    "\n",
    "    filterbank = np.zeros((n_mels, int(n_ffts)))\n",
    "    for m in range(1, n_mels+1):\n",
    "        f_min = int(fbin[m-1])\n",
    "        f_mid = int(fbin[m])\n",
    "        f_max = int(fbin[m+1])\n",
    "\n",
    "        for k in range(f_min, f_mid):\n",
    "            filterbank[m-1, k] = (k - fbin[m-1])/(fbin[m] - fbin[m-1])\n",
    "        for k in range(f_mid, f_max):\n",
    "            filterbank[m-1, k] = (fbin[m+1] - k)/(fbin[m+1] - fbin[m])\n",
    "    \n",
    "    stft_arr = stft(data, num_of_inputs, window_size, hop_length)\n",
    "    mel_spec_arr = np.dot(np.array(stft_arr), filterbank.T)\n",
    "    \n",
    "\n",
    "    return mel_spec_arr\n",
    "\n",
    "def amplitude_to_db(mel_spec_arr):\n",
    "    ref_value = np.max(mel_spec_arr)\n",
    "    mel_spec_arr = np.square(mel_spec_arr)\n",
    "    ref_value = ref_value**2\n",
    "    mel_spec_arr_db = 10*np.log10(np.maximum(sys.float_info.min, mel_spec_arr))\n",
    "    mel_spec_arr_db -= 10*np.log10(np.maximum(sys.float_info.min, ref_value))\n",
    "    mel_spec_arr_db = np.maximum(mel_spec_arr_db, mel_spec_arr_db.max()-80)\n",
    "\n",
    "    return mel_spec_arr_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2383cde5-50ea-47b5-974d-cf0454a01080",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 40)\n",
      "[[-80.         -80.         -80.         -80.         -80.\n",
      "  -80.         -80.         -80.         -80.         -80.\n",
      "  -80.         -80.         -80.         -78.97969468 -80.\n",
      "  -80.         -80.         -80.         -80.         -80.\n",
      "  -80.         -80.         -80.         -80.         -80.\n",
      "  -80.         -80.         -80.         -80.         -80.\n",
      "  -78.64563495 -80.         -74.1480606  -70.36661866 -67.5225434\n",
      "  -75.67403686 -77.29147045 -74.19117969 -80.         -79.13420895]\n",
      " [-80.         -80.         -79.48334978 -80.         -80.\n",
      "  -80.         -80.         -79.87234044 -80.         -80.\n",
      "  -80.         -80.         -80.         -80.         -80.\n",
      "  -80.         -80.         -80.         -80.         -80.\n",
      "  -80.         -80.         -80.         -80.         -80.\n",
      "  -80.         -80.         -80.         -80.         -76.37778465\n",
      "  -79.01255835 -79.42314436 -71.10043184 -70.95889082 -61.07290572\n",
      "  -56.25906793 -45.21187992 -37.37273998 -50.16971052 -64.16402019]\n",
      " [-80.         -80.         -79.19506178 -80.         -80.\n",
      "  -80.         -80.         -80.         -80.         -80.\n",
      "  -80.         -80.         -80.         -80.         -78.14415022\n",
      "  -80.         -80.         -80.         -80.         -77.74638956\n",
      "  -80.         -80.         -80.         -80.         -80.\n",
      "  -80.         -80.         -80.         -79.49820078 -69.3325811\n",
      "  -74.25201886 -78.97832507 -75.49110336 -64.80644438 -57.87310076\n",
      "  -50.67168917 -38.13662425 -34.39765155 -46.26189008 -57.02767302]\n",
      " [-80.         -80.         -80.         -80.         -78.97812571\n",
      "  -80.         -80.         -80.         -80.         -80.\n",
      "  -80.         -80.         -80.         -80.         -78.45824441\n",
      "  -80.         -80.         -80.         -80.         -80.\n",
      "  -80.         -80.         -80.         -79.01119785 -80.\n",
      "  -80.         -80.         -80.         -75.62296485 -72.19553666\n",
      "  -71.33936758 -78.04061191 -76.55061816 -71.1583216  -66.03565202\n",
      "  -60.48274555 -44.00571432 -35.03253984 -46.46611267 -57.1214453 ]\n",
      " [-78.30451204 -77.46086839 -80.         -69.70958514 -67.74937245\n",
      "  -80.         -70.65030201 -76.9267302  -80.         -80.\n",
      "  -80.         -80.         -80.         -80.         -74.58800084\n",
      "  -80.         -80.         -80.         -80.         -80.\n",
      "  -80.         -80.         -80.         -77.92288547 -77.94780332\n",
      "  -75.43280564 -78.41971849 -71.70051115 -74.24043356 -68.74785215\n",
      "  -66.00000206 -74.43948191 -72.84293387 -76.48576234 -74.4763713\n",
      "  -66.68660011 -52.09424242 -37.00467014 -50.72946456 -57.87696586]\n",
      " [-76.76997333 -80.         -77.87721282 -74.48393785 -74.09071701\n",
      "  -68.72492529 -65.42017007 -74.11840476 -80.         -80.\n",
      "  -79.07451705 -80.         -80.         -78.90768413 -67.43995209\n",
      "  -71.09980761 -78.93056275 -75.79672447 -80.         -80.\n",
      "  -80.         -80.         -80.         -77.33516086 -80.\n",
      "  -79.1721144  -72.73470749 -70.72571538 -73.73608857 -67.18647444\n",
      "  -62.18366568 -71.14138608 -74.85313421 -76.54848454 -70.33040721\n",
      "  -64.41687085 -47.66836073 -37.7075149  -47.84581186 -44.70139857]\n",
      " [-65.17571652 -73.26570638 -65.72799624 -59.8554439  -63.86271375\n",
      "  -63.49775078 -60.22500516 -67.31438093 -71.0892753  -63.84965671\n",
      "  -69.74988927 -77.01805098 -79.30151157 -73.51029768 -65.14480312\n",
      "  -64.66240093 -80.         -80.         -80.         -77.36159444\n",
      "  -79.50691637 -80.         -80.         -76.75182267 -70.51494973\n",
      "  -75.36403041 -70.8445679  -66.43952751 -63.01695403 -54.07085514\n",
      "  -54.14777195 -60.61498581 -62.42940533 -61.43958886 -52.6944669\n",
      "  -46.32773203 -33.09444848 -30.45048026 -28.72517519 -31.91957964]\n",
      " [-35.48777844 -40.24760388 -40.49438609 -35.62484201 -35.84082679\n",
      "  -42.77464951 -38.39542487 -47.16090178 -53.82936798 -48.59256397\n",
      "  -50.4574232  -59.54773769 -67.32871088 -69.84118042 -63.18222986\n",
      "  -62.1625456  -66.77279748 -66.47868901 -69.20607091 -79.56643773\n",
      "  -68.0123446  -69.18474071 -78.19741979 -67.72208882 -68.04246364\n",
      "  -71.75726445 -66.85151017 -65.53761482 -58.89099654 -48.25575199\n",
      "  -38.31834584 -39.33994028 -46.41683919 -51.10300042 -35.48665046\n",
      "  -29.71455284 -24.33528461 -21.52660548 -25.34458319 -29.17924932]\n",
      " [-20.93224617 -28.45306327 -24.57665375 -24.02664104 -25.23625776\n",
      "  -23.50880645 -16.41076376 -14.63922618 -28.35548117 -32.47821555\n",
      "  -30.63880543 -35.27734961 -36.44473076 -43.87760183 -42.18773401\n",
      "  -44.49193329 -53.22671056 -51.25733603 -55.8747007  -55.94782742\n",
      "  -57.57878618 -64.88353509 -63.58485563 -60.27418177 -61.68810977\n",
      "  -57.44341204 -52.64884037 -49.75844259 -47.31139786 -29.02930807\n",
      "  -22.59321892 -29.19601662 -29.5605107  -30.6894606  -24.95757723\n",
      "  -20.76068351 -19.2841423  -19.70353237 -23.43463671 -27.28948182]\n",
      " [-24.6656814  -21.79007261 -16.04714921 -16.33134356 -19.77651796\n",
      "  -24.01102962  -5.18375397  -6.1521371  -20.25126692 -19.01141709\n",
      "  -28.04342609 -32.53264532 -37.27787376 -35.41723508 -39.09452097\n",
      "  -38.42927491 -47.26861285 -53.01113123 -56.01663018 -54.43015625\n",
      "  -47.92745902 -49.03073211 -55.10684274 -48.7431839  -43.55046379\n",
      "  -40.50524186 -34.0095207  -32.51944097 -19.18424606 -12.37894063\n",
      "  -18.42733665 -21.08085099 -20.22012005 -21.94719814 -15.42929476\n",
      "  -16.08006739 -17.16057568 -15.67032419 -15.01669931 -20.07700932]\n",
      " [-36.62701763 -21.02551258 -14.25189409 -16.87149002 -27.52494894\n",
      "  -18.53782068 -15.56267921 -11.84090645  -8.26348046  -6.61053336\n",
      "  -17.50243845 -24.41981694 -29.08836659 -25.23126115 -35.819131\n",
      "  -39.14281726 -42.80945741 -43.6559728  -43.2214596  -45.6193345\n",
      "  -43.48128404 -42.04379534 -47.20610145 -45.57910255 -34.92920307\n",
      "  -27.78869844 -26.48100482 -21.57692726 -14.01483671  -8.62145975\n",
      "  -13.80724101 -22.62495651 -15.45075868 -13.69327281 -17.14979885\n",
      "  -18.4756148  -14.8712332  -16.91248984 -22.63623015 -22.4039373 ]\n",
      " [-38.98927424 -21.43993839 -14.93689136 -19.78999645 -36.30341527\n",
      "  -26.19007837 -17.59916892 -17.13162126  -4.02886503   0.\n",
      "  -12.1061901  -20.40704235 -25.30477826 -22.44085301 -36.08115724\n",
      "  -37.01173079 -34.07993585 -37.36635308 -45.08323172 -43.15275685\n",
      "  -38.33270734 -34.95519824 -40.45680107 -40.47218581 -35.80628816\n",
      "  -27.5863386  -21.48316227 -14.82134908  -8.94069815 -12.32936785\n",
      "  -20.70937324 -19.04427105 -16.16970506 -15.63323458 -23.21142343\n",
      "  -22.88828186 -22.15656587 -16.7581031  -19.18572277 -24.32662965]\n",
      " [-35.83575673 -23.06030212 -15.84712878 -20.43584235 -27.05860785\n",
      "  -20.04331341 -18.60313908 -13.64170989  -4.84747921  -6.67147343\n",
      "   -7.68035234 -12.67281675 -23.72220659 -22.96847457 -31.38715678\n",
      "  -38.61929965 -33.97760844 -39.66878033 -39.91834105 -44.39526006\n",
      "  -35.23465683 -35.34545963 -40.89606044 -34.04311627 -31.08512455\n",
      "  -27.63052225 -17.62948753  -9.2637713  -12.45213352 -14.32199495\n",
      "  -19.6208283  -19.5423229  -14.34259733 -15.91362464 -21.29889738\n",
      "  -20.47515133 -19.92439549 -16.10624878 -18.03329889 -19.53008359]\n",
      " [-46.37944961 -22.22111214 -17.3896389  -23.77484461 -27.85086352\n",
      "  -19.60969309 -19.29444394  -9.1533912   -7.6165655  -11.89102165\n",
      "   -4.24641293 -13.87440376 -19.99473362 -24.19871293 -22.85426783\n",
      "  -30.90023926 -34.14998371 -36.46137    -36.97852274 -40.62485284\n",
      "  -34.60011199 -39.58890631 -35.29674042 -30.92723691 -33.21078264\n",
      "  -25.88371418 -15.63073685 -10.13086969 -17.67408629 -23.34678938\n",
      "  -30.20221442 -26.75891666 -24.15963463 -25.46866837 -28.792374\n",
      "  -26.50373508 -21.68491533 -16.90127202 -16.06034901 -17.23899126]\n",
      " [-41.89412252 -20.51162773 -17.78965045 -27.83180502 -25.42136199\n",
      "  -17.7590013  -15.92333227  -9.68197789 -11.28414647 -13.92141548\n",
      "   -3.28193277 -17.92119926 -20.12811149 -22.84270862 -25.44495276\n",
      "  -31.92047814 -31.78961612 -30.68284794 -35.65112331 -39.93827426\n",
      "  -32.02368659 -32.57586767 -34.53067544 -34.04913039 -29.43241378\n",
      "  -22.47506467 -19.89451135 -19.83429545 -23.25439781 -23.92512868\n",
      "  -27.34272894 -29.25562785 -23.28308359 -23.92758074 -27.87872214\n",
      "  -27.13555456 -27.08996665 -19.40498043 -24.46666298 -27.08765898]\n",
      " [-33.55198282 -21.394465   -19.88864953 -28.713354   -21.30815815\n",
      "  -16.95601686 -18.31905129  -8.779288   -14.50511125  -8.1878501\n",
      "   -5.94665025 -21.41886611 -19.80784678 -21.57702106 -27.51835364\n",
      "  -25.57026934 -33.1046698  -31.75276097 -30.99121191 -34.01955962\n",
      "  -35.05159657 -33.48573521 -31.20796827 -34.11476746 -27.59004382\n",
      "  -20.11284207 -20.59100705 -23.23047865 -25.72452785 -27.14878571\n",
      "  -32.98602116 -34.79706405 -27.30765202 -25.92596413 -26.96995736\n",
      "  -33.79634088 -29.9834884  -23.20720901 -24.0248956  -29.59770245]\n",
      " [-32.22291935 -26.42143731 -27.7914681  -30.39957885 -23.35874685\n",
      "  -17.66559348 -17.33961922 -15.80099524 -23.67499614 -15.60688466\n",
      "  -15.21863583 -22.6590169  -25.39391215 -25.36153109 -30.02091831\n",
      "  -39.74792549 -37.27626111 -38.90598529 -36.77107892 -37.4618494\n",
      "  -40.22598503 -42.48044246 -36.66241963 -29.10641725 -31.29843252\n",
      "  -28.51701304 -24.17559323 -24.05115423 -31.45330533 -35.37373401\n",
      "  -37.16176795 -36.39549834 -28.93314822 -19.34749465 -25.35625408\n",
      "  -29.72321616 -35.17910345 -22.40344891 -22.22440713 -31.91205572]\n",
      " [-25.67594533 -33.3858986  -34.00738704 -24.52382233 -23.08410844\n",
      "  -26.75230494 -20.02967007 -20.33572931 -26.53511772 -19.16779068\n",
      "  -25.52361688 -32.98575754 -30.19543582 -36.65557699 -34.4528509\n",
      "  -37.55589521 -38.0788482  -38.70446057 -46.44690416 -47.33631759\n",
      "  -45.75569643 -44.48076009 -43.74554351 -36.53972019 -34.30213168\n",
      "  -27.37714515 -27.64963018 -28.87309793 -36.67470709 -38.01896742\n",
      "  -37.92480596 -37.70334722 -30.64725792 -28.67083863 -34.84471293\n",
      "  -33.16294169 -29.87358749 -23.32087981 -22.63203535 -31.16395235]\n",
      " [-29.80307233 -33.06214849 -37.4416598  -44.49044404 -29.6632185\n",
      "  -31.57715382 -29.6151563  -30.94868061 -36.46078082 -27.46647395\n",
      "  -36.00108331 -36.58221576 -37.86614623 -31.76006581 -44.94613541\n",
      "  -46.01690669 -48.68874606 -44.16351757 -49.60026366 -51.17407235\n",
      "  -43.8515868  -47.54746436 -41.4848921  -34.50625983 -32.58267499\n",
      "  -29.04483505 -29.42249456 -35.81280508 -33.17253233 -36.76407781\n",
      "  -42.821821   -40.46169587 -31.36022216 -26.09703284 -30.72608835\n",
      "  -33.32537988 -27.92218586 -20.97353933 -20.59375996 -20.23896783]\n",
      " [-36.76751123 -38.45513529 -45.61251503 -47.89645429 -40.86700803\n",
      "  -40.86274598 -45.93320493 -46.74687449 -44.24602944 -40.07242757\n",
      "  -41.79520166 -44.59953671 -40.43850821 -41.14204178 -45.7759393\n",
      "  -50.20921227 -48.89798787 -50.56821832 -55.82652861 -54.83373569\n",
      "  -46.04192346 -44.48497295 -43.0972952  -34.5517694  -36.19493488\n",
      "  -30.1829085  -34.67734798 -34.200342   -38.549221   -38.13665712\n",
      "  -45.7582685  -42.54728114 -35.35529114 -35.46223445 -32.85573804\n",
      "  -32.80899742 -26.3430173  -20.59563601 -15.04989274 -13.78535594]\n",
      " [-60.96763622 -44.43854777 -47.63084389 -51.21144707 -43.75406684\n",
      "  -45.19435196 -53.13395958 -46.98621711 -43.33312062 -39.05117866\n",
      "  -39.24250518 -45.58924459 -42.96090709 -46.65957927 -46.84346204\n",
      "  -47.3507886  -50.23738165 -50.01347294 -54.51992127 -48.40019598\n",
      "  -49.16319546 -45.22656371 -55.35981203 -51.60739965 -42.14922474\n",
      "  -36.36419782 -39.30643583 -40.06760619 -41.63749389 -42.62282237\n",
      "  -51.32908032 -44.4925007  -35.76213328 -33.98973652 -31.28851753\n",
      "  -27.92346278 -22.67616172 -18.36725336 -17.78339707 -14.08609294]\n",
      " [-59.40831788 -60.11749699 -59.90905098 -45.6986299  -43.75134995\n",
      "  -45.41999148 -41.43370093 -39.60171178 -41.84975906 -42.67932279\n",
      "  -44.03835421 -56.54419952 -50.4214799  -42.72142332 -50.32514736\n",
      "  -55.49165325 -59.66069478 -63.82588742 -62.14145663 -53.13805464\n",
      "  -50.14788464 -50.5134243  -54.74045905 -46.70486297 -44.42284065\n",
      "  -36.1830124  -38.81840235 -39.42544989 -37.28704936 -45.33637776\n",
      "  -51.02266502 -43.54041932 -36.46426188 -32.09101671 -32.17938884\n",
      "  -28.41594405 -24.0615429  -17.45579188 -16.28724422 -15.81672162]\n",
      " [-61.13133437 -63.21659738 -60.33072554 -53.41570104 -56.63745399\n",
      "  -59.07136442 -50.33286352 -50.74533877 -50.63866216 -42.94376674\n",
      "  -38.7738631  -44.65278562 -51.09422896 -43.41226267 -53.33793545\n",
      "  -48.78131165 -55.62536951 -56.92910384 -60.86288888 -58.76916444\n",
      "  -56.30390475 -54.80112075 -53.860194   -52.82742289 -43.74378192\n",
      "  -40.91667383 -46.93446512 -44.39893146 -40.59208545 -45.72181424\n",
      "  -53.38044739 -45.73478325 -34.59393844 -28.56332199 -30.08750438\n",
      "  -23.48460109 -23.72789814 -10.06936364 -12.12526383 -11.69294905]\n",
      " [-58.15813871 -62.77716773 -68.99171777 -69.01260887 -73.19262445\n",
      "  -60.00772191 -57.50532242 -53.57333906 -51.99659196 -46.18280162\n",
      "  -48.38606058 -48.36710132 -61.14767424 -52.17334238 -56.93959918\n",
      "  -62.82082949 -59.3635165  -58.95238709 -62.34081738 -64.38358181\n",
      "  -59.27568958 -58.19607698 -53.55678131 -53.25069468 -50.43644284\n",
      "  -44.71716146 -43.23227106 -46.19876614 -43.79180329 -50.65135958\n",
      "  -51.62675217 -51.37076038 -37.02604839 -30.65404374 -26.19766115\n",
      "  -25.59869752 -25.99437037 -14.35583375 -13.72729396 -11.54918729]\n",
      " [-59.26696077 -62.84181278 -62.77878744 -61.21487501 -57.07967388\n",
      "  -52.783786   -53.40092257 -48.93710149 -56.79356562 -58.86465863\n",
      "  -51.628506   -59.21855627 -58.4357607  -55.11497434 -52.55682896\n",
      "  -57.63483419 -59.56165352 -65.51063937 -64.05081921 -59.62128854\n",
      "  -58.70133348 -57.26603952 -55.45012091 -58.93329899 -56.27330708\n",
      "  -45.81491963 -46.64372725 -46.77971789 -50.23562406 -54.21168637\n",
      "  -50.40914152 -49.50816819 -35.26236309 -31.93227371 -31.85175608\n",
      "  -27.10893941 -26.65443329 -14.89677033  -5.574531   -11.45603281]\n",
      " [-60.67468794 -80.         -66.4115162  -66.8077979  -67.91748185\n",
      "  -54.08812455 -50.64867461 -55.07157777 -60.67997966 -56.09476352\n",
      "  -51.33108217 -56.60007767 -62.94749052 -56.04593686 -58.87131171\n",
      "  -56.6108203  -56.07832476 -60.44750375 -58.52792838 -65.2673494\n",
      "  -60.56928757 -54.92100945 -60.69539485 -58.6007164  -60.44760377\n",
      "  -54.53609591 -53.13044192 -51.57534962 -49.79877766 -47.72099469\n",
      "  -51.94326123 -47.56924463 -39.66920266 -40.42901048 -31.85224836\n",
      "  -27.32745784 -25.1369344  -16.01580511  -6.55710797 -10.1555192 ]\n",
      " [-65.56121405 -62.32240036 -72.84284093 -65.23102964 -62.87544443\n",
      "  -58.40431958 -49.48700992 -49.25630723 -51.65364304 -50.8766864\n",
      "  -51.70090222 -65.4103035  -65.39010916 -56.78983996 -58.46819474\n",
      "  -62.17384473 -69.60497626 -68.67547572 -59.82987174 -62.27387493\n",
      "  -62.56443551 -59.7709169  -57.27608661 -59.31853158 -56.78414562\n",
      "  -47.79704097 -50.7386517  -48.41825813 -50.06621764 -50.65705295\n",
      "  -57.05689338 -48.67754634 -39.49492646 -37.64537769 -36.37538786\n",
      "  -31.02476639 -24.5250601  -18.80573395 -15.50815803 -14.38422496]\n",
      " [-63.80160456 -62.85447425 -66.22309994 -55.57732217 -52.06699646\n",
      "  -51.77434396 -48.81717433 -49.74057443 -59.05099944 -66.07475632\n",
      "  -53.65479188 -54.64373061 -51.07822138 -54.88461133 -64.38631788\n",
      "  -72.10522428 -72.94722937 -63.31446706 -62.77220531 -70.67980544\n",
      "  -65.3304452  -61.86781358 -59.77993529 -60.6455082  -54.86249926\n",
      "  -51.40682305 -50.83253793 -48.88255139 -52.35009372 -50.99772526\n",
      "  -57.38831758 -45.751664   -37.47139042 -34.70373057 -32.61486249\n",
      "  -26.96162653 -24.7728478  -18.35007115 -13.03538382 -14.20789292]\n",
      " [-58.82775614 -66.41436904 -62.73028167 -62.24578339 -71.18891249\n",
      "  -60.0560708  -58.04177749 -59.55701654 -59.80859426 -59.15347101\n",
      "  -55.36201729 -60.63673079 -59.33586081 -60.37570191 -65.61769465\n",
      "  -67.63003866 -74.42689029 -71.30087679 -59.87011564 -58.21336047\n",
      "  -65.95146969 -58.1808808  -59.74703291 -65.50260542 -51.96812683\n",
      "  -49.61111388 -53.70349134 -46.3103414  -49.3413205  -54.07284769\n",
      "  -53.80893165 -50.89763363 -43.32958323 -36.83416504 -35.19289554\n",
      "  -26.78218658 -22.54074737 -18.66751627 -18.73658293 -20.85608481]\n",
      " [-69.94470205 -63.19470147 -73.35657726 -73.92374842 -64.15208573\n",
      "  -55.23722901 -51.24220435 -57.87554261 -80.         -58.15500241\n",
      "  -49.68647314 -60.09694732 -68.58923824 -69.00596604 -66.40494214\n",
      "  -64.68044593 -66.28640974 -63.77319462 -65.1427195  -60.57846923\n",
      "  -64.00110204 -67.01946553 -71.04230732 -62.23418056 -57.41582265\n",
      "  -52.19546867 -50.67338291 -52.66841891 -55.17719739 -53.65424711\n",
      "  -59.14946635 -54.54953613 -46.12861143 -39.53952971 -31.98440124\n",
      "  -29.52279318 -22.44762645 -14.14535687 -11.09530777 -13.87079433]\n",
      " [-62.68113532 -60.09296051 -63.25286675 -67.29065313 -64.27160029\n",
      "  -60.67384768 -54.95459423 -51.04907292 -66.44428173 -67.30758347\n",
      "  -57.5324989  -65.8587845  -64.51243349 -58.60375447 -54.26112412\n",
      "  -52.85310499 -63.88939955 -64.28902492 -59.96506914 -61.16108242\n",
      "  -62.53183271 -69.66638602 -59.90149479 -60.98874419 -61.87041265\n",
      "  -66.26478391 -53.7057536  -52.24705804 -56.18552908 -55.49879523\n",
      "  -57.08452849 -49.43509175 -42.62108491 -36.95046021 -34.30501712\n",
      "  -31.48476722 -23.91082002 -21.46976409 -17.48227902 -20.85750989]\n",
      " [-69.19440524 -65.03367982 -66.35310413 -63.1252754  -59.89384032\n",
      "  -57.98021823 -62.3970506  -59.60432175 -56.88514753 -65.10826243\n",
      "  -69.027703   -68.18304227 -69.76384687 -65.12938315 -54.88513763\n",
      "  -58.66926565 -65.59625222 -70.87247946 -65.42538322 -68.24805805\n",
      "  -60.95820616 -66.09128392 -69.62149382 -67.15109872 -58.58629012\n",
      "  -57.76240376 -52.10524056 -52.92075535 -54.68375342 -54.67633428\n",
      "  -56.89972634 -55.48217866 -47.01238026 -40.87972097 -44.30781587\n",
      "  -33.61545296 -29.59101624 -20.06411897 -18.6630136  -19.86246249]\n",
      " [-68.71902236 -68.05256967 -62.64750174 -58.01898271 -62.96016488\n",
      "  -57.12123374 -57.80925357 -52.68274188 -56.32702238 -54.66847305\n",
      "  -55.82176451 -65.691572   -70.6362465  -66.15803671 -56.77029607\n",
      "  -55.26650758 -62.43487724 -68.09173825 -71.36748689 -65.20199241\n",
      "  -65.70406533 -67.65336003 -72.54561728 -64.62452745 -57.21886795\n",
      "  -54.17051141 -55.95470134 -54.49422717 -53.61225713 -52.64577826\n",
      "  -58.12934473 -52.97551391 -45.10041426 -42.01743805 -35.59450517\n",
      "  -30.56331654 -27.59314776 -22.87022482 -18.8860608  -23.09918669]\n",
      " [-58.62461173 -54.80087439 -58.81585454 -65.22256838 -60.59711514\n",
      "  -65.40455945 -51.36487309 -51.05391157 -56.73324531 -62.44892901\n",
      "  -64.87591215 -64.17561491 -68.86547051 -65.00222714 -55.53370652\n",
      "  -57.6992189  -71.69969759 -78.22364927 -75.14371563 -64.95840138\n",
      "  -60.04126446 -54.26950166 -59.44847095 -64.99137236 -60.29103648\n",
      "  -54.60011335 -50.33712406 -50.31949846 -52.66399511 -52.5234707\n",
      "  -55.03604017 -55.06808139 -45.92479016 -43.64291966 -43.42739657\n",
      "  -37.78548822 -29.62891805 -24.68598627 -21.20332929 -24.10398758]\n",
      " [-55.04679571 -55.31601457 -54.99466363 -59.11342915 -61.88107569\n",
      "  -61.24204007 -59.11990052 -64.61013486 -61.36078905 -63.53406066\n",
      "  -57.30756229 -62.29254499 -61.81071118 -65.68085791 -56.35324371\n",
      "  -54.23271465 -66.57938296 -70.1482038  -61.6714776  -68.39941702\n",
      "  -63.39548394 -54.81187499 -58.89395009 -60.03357191 -64.24710395\n",
      "  -58.33482842 -53.0716163  -50.49096713 -56.00936814 -55.83749555\n",
      "  -56.30554526 -57.41199259 -55.0492668  -50.21877768 -47.58212558\n",
      "  -45.18013231 -36.12784152 -28.22767652 -17.38231839 -27.76919965]\n",
      " [-59.10272306 -61.20667267 -67.9348948  -71.36453876 -61.84384822\n",
      "  -57.8211688  -55.80972321 -55.73013678 -61.06434464 -59.62779717\n",
      "  -51.12394885 -52.70274703 -64.59941148 -60.88193153 -57.3867455\n",
      "  -57.084615   -68.98452426 -70.40849614 -67.27344136 -69.20473493\n",
      "  -65.0308062  -69.44206883 -63.95734431 -62.20726088 -57.22221363\n",
      "  -50.73719687 -58.27621961 -54.45223604 -59.90368364 -58.1586845\n",
      "  -62.03916449 -69.21000195 -58.46880133 -52.55023939 -50.09524047\n",
      "  -45.73359967 -36.61420328 -31.18753439 -26.03871682 -31.32514056]\n",
      " [-64.43901408 -75.36286503 -67.59525203 -59.52013673 -57.00245024\n",
      "  -54.64121832 -52.09189844 -50.15126617 -59.01598798 -66.05418087\n",
      "  -60.83591087 -62.85046089 -60.39260006 -63.8648445  -60.89117552\n",
      "  -57.4326208  -63.95584457 -66.49880354 -67.79066799 -67.70307527\n",
      "  -73.94551446 -71.91246211 -70.47149123 -65.14497327 -53.81264922\n",
      "  -52.5012694  -57.13727041 -55.06643911 -62.21498221 -59.02546947\n",
      "  -59.28941603 -62.1088266  -56.52280609 -58.04159282 -63.28824119\n",
      "  -50.3478093  -45.0295188  -37.24061222 -33.53135328 -44.58873195]\n",
      " [-68.9396882  -73.90983933 -71.65644442 -58.02666953 -54.24484334\n",
      "  -54.2928802  -55.09657766 -52.89471941 -67.66218584 -63.24765926\n",
      "  -59.57255982 -66.19557712 -68.43134155 -68.18181506 -70.61423799\n",
      "  -65.89160541 -68.14105739 -66.52030224 -62.98564534 -57.47557201\n",
      "  -62.65006492 -67.0968885  -72.08016945 -62.83122583 -54.86070643\n",
      "  -51.37223842 -58.18085583 -60.67533065 -68.01607686 -57.85128188\n",
      "  -64.77137163 -74.7290756  -67.31181029 -63.92407012 -68.81700842\n",
      "  -60.13070762 -49.02832208 -44.89400711 -38.26422973 -44.92583944]\n",
      " [-80.         -79.45145424 -71.31255455 -65.62939733 -65.38319221\n",
      "  -58.90056511 -55.14361758 -55.2822469  -55.71920864 -56.97425791\n",
      "  -57.08317929 -59.96168053 -62.86376177 -67.33699998 -68.71502996\n",
      "  -60.85376445 -70.00438951 -69.431659   -66.96318197 -55.32181587\n",
      "  -60.3522521  -64.16924588 -62.32103392 -57.08982102 -57.7058957\n",
      "  -59.58736236 -61.11861444 -57.92199544 -66.77631895 -62.21557905\n",
      "  -65.12776305 -65.57906402 -66.538924   -60.78909701 -69.51768939\n",
      "  -62.65866679 -56.10706681 -53.27037972 -49.69849891 -50.59179721]\n",
      " [-70.26805266 -70.59731817 -67.16922704 -62.38315951 -64.94850863\n",
      "  -65.30255328 -65.11288603 -57.69224098 -53.29036568 -58.27034684\n",
      "  -56.60996948 -60.36308364 -64.40503635 -62.21969693 -63.18303825\n",
      "  -64.75750553 -75.27263379 -63.87191878 -61.49806129 -61.02597323\n",
      "  -61.38147591 -58.05351459 -52.80833266 -50.04210962 -57.33554381\n",
      "  -61.09659718 -63.97834461 -54.68707988 -58.57831856 -59.09150988\n",
      "  -62.73800174 -66.3883709  -65.3373843  -66.3730699  -66.5654255\n",
      "  -63.40217168 -60.11938734 -56.59121572 -57.99095182 -57.56229289]\n",
      " [-67.25061434 -73.11727029 -70.21079392 -64.24113073 -58.62325385\n",
      "  -59.41875196 -57.2177487  -59.01918673 -63.18317385 -60.68870415\n",
      "  -56.54820068 -60.52978967 -61.80092285 -64.98409171 -63.62452416\n",
      "  -68.46284207 -67.05255354 -69.53362679 -62.63205449 -58.32160027\n",
      "  -52.35021351 -56.85051324 -53.57374672 -55.31266628 -56.27368863\n",
      "  -63.56703757 -62.79927442 -57.45751593 -53.29542475 -58.54554074\n",
      "  -60.80521612 -70.87946935 -66.61220425 -72.23984945 -72.01565438\n",
      "  -69.2130858  -62.18091791 -59.15613176 -59.365818   -61.08268811]\n",
      " [-75.78729104 -75.33244967 -67.1893834  -58.6249111  -59.48662099\n",
      "  -72.06539517 -65.71202457 -72.27314434 -75.12685301 -73.33357231\n",
      "  -57.74853636 -58.538834   -67.08953209 -67.36466885 -67.64028686\n",
      "  -65.2973412  -66.32690353 -61.99118734 -66.84246967 -63.45678597\n",
      "  -60.31986538 -60.28819862 -62.59015843 -62.76588455 -64.1985982\n",
      "  -64.64681596 -61.70124299 -61.94299826 -61.25364666 -61.98054865\n",
      "  -68.64742863 -68.28427836 -66.45643251 -68.231705   -70.19884525\n",
      "  -73.95507151 -65.12405669 -64.18088075 -61.94654752 -58.71984472]\n",
      " [-72.60596979 -66.85393029 -63.79209393 -68.26143291 -65.3996196\n",
      "  -57.50365365 -58.39559768 -68.87638247 -80.         -68.05273595\n",
      "  -64.23728534 -66.99876628 -67.61250099 -67.79108958 -60.39963683\n",
      "  -64.54204365 -66.52534106 -62.95648339 -66.66241603 -63.72672661\n",
      "  -66.72948088 -63.59787827 -63.65685615 -64.40900175 -63.47314093\n",
      "  -64.05741009 -59.76187873 -57.12270871 -64.236752   -61.23678403\n",
      "  -66.51657526 -68.40650407 -67.14472149 -67.32496303 -69.4509528\n",
      "  -68.63658114 -68.00238974 -65.62364766 -65.0715008  -65.24520575]\n",
      " [-64.39397212 -64.11594274 -68.87831667 -64.49095795 -67.18012359\n",
      "  -55.20313908 -54.15671223 -67.50345585 -78.12148341 -74.95817728\n",
      "  -66.89729302 -71.76012522 -66.07255103 -72.54177423 -69.25823735\n",
      "  -67.62814025 -67.27218413 -73.67370833 -76.11932863 -65.50011371\n",
      "  -69.45049767 -64.09530578 -64.92498921 -58.21628396 -60.46453892\n",
      "  -60.09696875 -63.74037343 -60.16029718 -60.33534333 -62.21999593\n",
      "  -69.48374897 -67.32022037 -69.01398144 -73.07449046 -72.15638499\n",
      "  -68.81293285 -69.22372376 -71.46616666 -71.40459339 -71.72493153]\n",
      " [-62.78917029 -63.60982905 -69.00732828 -60.57419716 -58.76019935\n",
      "  -58.244235   -67.86386625 -66.71007047 -69.82905989 -67.12307238\n",
      "  -61.4071729  -64.345919   -68.79128042 -67.93731092 -75.48743489\n",
      "  -72.26620356 -71.85438006 -72.76196757 -72.64919528 -68.85522253\n",
      "  -68.10245904 -65.13247301 -61.77075677 -61.67356153 -61.57680902\n",
      "  -62.54506273 -66.81982343 -60.8597202  -64.08331583 -62.87295499\n",
      "  -69.77779723 -66.91477276 -67.24417272 -72.76091671 -70.83920433\n",
      "  -72.68990484 -71.31184815 -75.08397476 -71.12533056 -64.85617121]\n",
      " [-62.3960217  -79.28460981 -67.19475241 -65.01528185 -61.41619784\n",
      "  -61.17276047 -66.02170524 -67.3742666  -69.8209524  -71.46332965\n",
      "  -69.60511286 -61.81195865 -63.27174679 -66.58524242 -66.26158872\n",
      "  -74.03885851 -66.15930613 -71.54607131 -78.3977421  -68.62794682\n",
      "  -64.89061286 -76.96694876 -72.43132052 -62.51643204 -60.98066346\n",
      "  -61.99204501 -64.73611978 -64.42104358 -63.06812396 -65.26394107\n",
      "  -71.46452748 -63.45609558 -63.35168779 -69.1739686  -71.07132964\n",
      "  -75.86697652 -68.92066865 -72.89312301 -73.9849585  -67.21346074]\n",
      " [-67.12647798 -71.84874668 -72.07573697 -76.49557835 -74.85603197\n",
      "  -69.56275372 -62.15090164 -65.98250679 -65.39340843 -62.67159947\n",
      "  -57.54388258 -64.74798296 -63.498001   -62.71174394 -68.43968663\n",
      "  -69.37898148 -69.23973086 -75.20347484 -78.65857368 -68.42519232\n",
      "  -74.35496998 -72.17069655 -66.38010897 -64.02257064 -70.11364396\n",
      "  -68.20705195 -65.87919059 -64.92256443 -59.66772454 -62.46725857\n",
      "  -67.80943937 -66.73830122 -66.09642332 -67.72368234 -68.30558857\n",
      "  -73.20108352 -68.55307303 -71.24917946 -68.70396809 -67.12957268]\n",
      " [-67.92857241 -72.13842411 -64.13778546 -65.11024029 -65.39814388\n",
      "  -66.91663121 -61.54967114 -59.451589   -64.64797341 -59.40181704\n",
      "  -64.9714562  -72.97966704 -62.70423487 -62.21755914 -70.53280241\n",
      "  -70.63284922 -68.34372452 -70.3115011  -71.19254895 -65.11446052\n",
      "  -65.18673333 -61.87631417 -67.74792244 -68.90807408 -73.07062574\n",
      "  -71.26043603 -65.41396681 -61.15967182 -63.29487612 -64.20682465\n",
      "  -70.23275002 -75.46936471 -76.48029194 -68.76566302 -70.62698963\n",
      "  -73.09428669 -69.41699203 -72.88706177 -73.44946073 -70.22685117]\n",
      " [-60.57637758 -66.92078218 -67.16557653 -56.98835154 -57.46733802\n",
      "  -71.98466615 -71.44960028 -65.40488279 -63.37127593 -59.71133316\n",
      "  -59.47501003 -66.74477336 -58.85924998 -67.10784773 -73.44793621\n",
      "  -68.90349941 -66.44262792 -76.14972452 -69.76677758 -63.55005928\n",
      "  -62.94722368 -65.89776641 -76.25600977 -79.91108943 -80.\n",
      "  -72.15276157 -66.98456431 -62.20521753 -57.54510588 -63.27354786\n",
      "  -67.38568341 -69.65786392 -71.57247997 -73.87344605 -73.90717468\n",
      "  -71.6230802  -70.031561   -72.4937941  -69.66022741 -70.13596554]\n",
      " [-60.11511765 -63.81798922 -66.34469348 -61.36671299 -62.28014751\n",
      "  -67.33398283 -65.28063134 -69.13650477 -71.57719848 -68.27898579\n",
      "  -67.09363114 -75.9084191  -72.52879002 -68.53802528 -68.30433236\n",
      "  -65.20416661 -73.48745246 -73.2086888  -68.03023787 -62.34574868\n",
      "  -69.38259994 -66.40084053 -76.24199228 -76.36215931 -75.6650756\n",
      "  -74.64411406 -67.37549233 -63.18579818 -64.24969374 -68.91389314\n",
      "  -66.57890983 -67.25516454 -70.41821345 -76.56945034 -76.28708999\n",
      "  -75.4546772  -76.08807854 -74.77904479 -69.80469319 -67.23250592]\n",
      " [-72.30750021 -77.82650027 -76.67880248 -67.23652028 -69.30942166\n",
      "  -80.         -80.         -74.66725225 -69.58687876 -63.37411387\n",
      "  -60.81863927 -72.8163905  -69.85428927 -65.71403625 -70.45899094\n",
      "  -67.44968857 -72.21863491 -71.35467678 -75.15771209 -73.46903237\n",
      "  -76.66236874 -80.         -77.56767753 -77.93918339 -74.40986173\n",
      "  -80.         -72.59173475 -69.75017795 -72.67723579 -71.04654653\n",
      "  -65.44236602 -67.61954325 -70.4632448  -74.20475309 -79.85017313\n",
      "  -75.10670874 -71.4974069  -68.44525433 -68.87301601 -69.54415386]\n",
      " [-76.85017368 -80.         -68.76270667 -74.36727623 -80.\n",
      "  -80.         -70.25145325 -67.49580277 -80.         -72.72632225\n",
      "  -65.65175041 -66.71077517 -69.67753652 -70.57244582 -70.8393502\n",
      "  -71.59066826 -70.93288283 -70.27482256 -68.28689093 -69.97902736\n",
      "  -72.67881104 -78.73869946 -80.         -80.         -77.93204453\n",
      "  -76.65571297 -73.97126233 -66.21824475 -65.33131817 -67.57048398\n",
      "  -67.85593499 -71.6510275  -69.62541531 -71.8990565  -74.05523806\n",
      "  -74.3462892  -77.13357559 -71.00224393 -70.55285876 -69.09152985]\n",
      " [-79.10231136 -70.60117704 -75.54794096 -69.60858774 -66.01076455\n",
      "  -65.75361446 -68.24268602 -75.20963776 -75.83497086 -69.8432096\n",
      "  -69.503382   -66.3532339  -80.         -80.         -74.4683787\n",
      "  -73.95306682 -76.57501969 -76.12314562 -72.24145295 -76.20014483\n",
      "  -73.17211953 -76.61887361 -80.         -80.         -71.91439685\n",
      "  -69.35486686 -69.70379622 -67.38211134 -65.09695624 -69.30386203\n",
      "  -69.20434991 -73.70676094 -70.64905353 -68.60709553 -73.11125981\n",
      "  -77.44518558 -75.54892798 -75.84150944 -75.28297247 -73.34574046]\n",
      " [-74.30257636 -80.         -70.17638496 -76.75246016 -73.6895117\n",
      "  -73.77159391 -70.42018619 -68.34342188 -68.29490719 -67.97892765\n",
      "  -73.69398598 -80.         -66.70323507 -72.85589153 -76.27707966\n",
      "  -76.70846956 -80.         -73.91527825 -73.7357621  -70.25288152\n",
      "  -66.3687573  -79.10617007 -80.         -76.58989097 -72.80179626\n",
      "  -67.42922189 -74.37312745 -64.52874973 -59.30259288 -64.12087839\n",
      "  -65.1523435  -75.10828217 -73.16618638 -72.76347485 -77.45357691\n",
      "  -73.99670031 -75.67499073 -80.         -75.69345276 -69.82694009]\n",
      " [-77.7716458  -80.         -70.20287558 -66.09696452 -76.53859742\n",
      "  -73.53655618 -73.93075755 -65.32231283 -65.90946557 -66.37473683\n",
      "  -68.36843907 -67.21167366 -67.93299651 -75.90109918 -78.07138115\n",
      "  -71.01286189 -79.70055225 -73.02210862 -76.32164949 -71.77078698\n",
      "  -68.25610563 -77.39108216 -80.         -77.07348956 -70.28680619\n",
      "  -64.87804971 -66.52578826 -65.76720051 -60.97136515 -62.67374247\n",
      "  -66.39421021 -73.99958567 -73.28696807 -71.88363528 -74.22769798\n",
      "  -75.91464358 -77.68944353 -77.71879016 -70.11961224 -71.464144  ]\n",
      " [-73.87819634 -73.89109929 -80.         -70.87980857 -73.47341591\n",
      "  -77.8107306  -67.46547593 -65.85563068 -66.95565165 -66.04540327\n",
      "  -70.25172231 -70.67332455 -75.26267196 -73.74608895 -70.94929175\n",
      "  -75.76387344 -76.09505194 -80.         -73.05374007 -73.19413369\n",
      "  -66.90238962 -68.71424818 -77.79821287 -74.58721052 -74.17157837\n",
      "  -76.77197303 -68.04884992 -65.70910488 -60.0899463  -62.11832764\n",
      "  -72.54868583 -75.09793627 -73.43913321 -76.23240708 -73.96306837\n",
      "  -79.73441488 -80.         -80.         -72.30227043 -68.10383459]\n",
      " [-68.41109732 -73.03055905 -72.60073077 -72.46937459 -76.15591316\n",
      "  -78.51659302 -78.90598344 -77.74331399 -77.42089039 -64.24459131\n",
      "  -65.46859605 -71.92970832 -75.29577467 -70.48752124 -76.41467918\n",
      "  -76.13348124 -78.44750205 -78.90223671 -70.72598414 -68.50950266\n",
      "  -68.56084086 -73.18215714 -80.         -80.         -71.39819293\n",
      "  -70.98869946 -75.60850142 -76.27958206 -70.69552961 -67.41629603\n",
      "  -72.21798065 -75.20665964 -70.96911726 -78.94571086 -76.01542682\n",
      "  -79.19829737 -76.82440138 -77.23502867 -69.11866755 -70.56512025]\n",
      " [-80.         -72.66411027 -77.43462457 -80.         -80.\n",
      "  -80.         -75.60534023 -78.97079915 -77.94266983 -77.6570607\n",
      "  -80.         -72.49474386 -66.05119354 -64.20448956 -76.44368783\n",
      "  -80.         -80.         -80.         -69.74664005 -67.54050519\n",
      "  -66.13158355 -76.50737271 -76.70844638 -74.67518206 -79.25139601\n",
      "  -67.54626624 -74.21457214 -71.98514535 -75.13349098 -68.98773769\n",
      "  -68.25937067 -71.38755568 -72.92030021 -80.         -76.90905879\n",
      "  -76.89509054 -72.9250171  -76.66745902 -72.1221566  -74.37072851]\n",
      " [-78.18603854 -80.         -80.         -80.         -80.\n",
      "  -72.55387597 -66.90789434 -70.15394873 -80.         -80.\n",
      "  -76.61944354 -77.44179358 -71.68799258 -67.07974473 -80.\n",
      "  -80.         -80.         -80.         -79.48799189 -70.76624637\n",
      "  -70.78522702 -77.00800443 -72.32242716 -72.52251112 -70.21054825\n",
      "  -67.36951126 -67.80627234 -72.67565677 -77.55378145 -71.74773104\n",
      "  -76.69016772 -73.70101143 -77.08726279 -79.87331081 -80.\n",
      "  -78.7864415  -73.43261997 -75.24714821 -71.17722099 -76.22502038]\n",
      " [-75.48349288 -74.00784531 -78.80374475 -80.         -76.1081381\n",
      "  -69.1424043  -59.54920621 -62.6773378  -80.         -80.\n",
      "  -78.02124969 -78.41344671 -76.83807638 -72.23334063 -74.50430486\n",
      "  -80.         -80.         -80.         -80.         -77.65247874\n",
      "  -74.15565422 -71.24468279 -69.1143602  -69.02686127 -67.77532377\n",
      "  -68.6640339  -67.41328089 -69.30391739 -73.87442946 -72.37589129\n",
      "  -77.41208668 -78.03690776 -80.         -80.         -77.42476334\n",
      "  -77.54211905 -74.77780231 -77.98838817 -71.57845786 -75.38246149]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0, 11000.0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## testing the results\n",
    "mel_spec_arr = mel_spec(data_tensor_yes[0], 15872, 512, 256, 40, 16000)\n",
    "mel_spec_db = amplitude_to_db(mel_spec_arr)\n",
    "print(np.array(mel_spec_db).shape)\n",
    "print(np.array(mel_spec_db))\n",
    "fig, ax = plt.subplots(figsize=(6, 3))\n",
    "librosa.display.specshow(\n",
    "    mel_spec_db,\n",
    "    y_axis=\"hz\",\n",
    "    x_axis=\"time\",\n",
    "    ax=ax,\n",
    "    fmax=6000\n",
    ")\n",
    "plt.ylim([0, 11000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "199300c9-e7a4-4b3d-bdb4-74c89b0be537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 'yes': ##########\n",
      "train set 'yes' finished\n",
      "Loading 'no': ##########\n",
      "train set 'no' finished\n",
      "(3400, 60, 40)\n",
      "(3400, 60, 40)\n",
      "2024-05-27 11:28:21.314588\n"
     ]
    }
   ],
   "source": [
    "## Processing the data to mel_spectrogram\n",
    "import datetime\n",
    "\n",
    "melSpec_set_yes = []\n",
    "melSpec_set_no = []\n",
    "melSpec_train_labels = []\n",
    "\n",
    "window_size = 512\n",
    "step = 256\n",
    "num_of_inputs = 15872\n",
    "sample_rate = 16000\n",
    "\n",
    "count = 0\n",
    "print(\"Loading 'yes': \", end=\"\")\n",
    "for i in data_tensor_yes:\n",
    "    mel_spec_arr = mel_spec(i, num_of_inputs, window_size, step, 40, sample_rate)\n",
    "    ref_value = np.max(mel_spec_arr )\n",
    "    mel_spec_arr = np.square(mel_spec_arr)\n",
    "    ref_value = ref_value**2\n",
    "    mel_spec_db = 10*np.log10(np.maximum(sys.float_info.min, mel_spec_arr))\n",
    "    mel_spec_db -= 10*np.log10(np.maximum(sys.float_info.min, ref_value))\n",
    "    mel_spec_db = np.maximum(mel_spec_db, mel_spec_db.max()-80)\n",
    "\n",
    "    melSpec_set_yes.append(mel_spec_db)\n",
    "    melSpec_train_labels.append(1)\n",
    "    count += 1\n",
    "    if(count%340==0):\n",
    "        print(\"#\", end=\"\")\n",
    "\n",
    "print()\n",
    "print(\"train set 'yes' finished\")\n",
    "print(\"Loading 'no': \", end=\"\")\n",
    "count = 0\n",
    "for i in data_tensor_no:\n",
    "    mel_spec_arr = mel_spec(i, num_of_inputs, window_size, step, 40, sample_rate)\n",
    "    ref_value = np.max(mel_spec_arr )\n",
    "    mel_spec_arr = np.square(mel_spec_arr)\n",
    "    ref_value = ref_value**2\n",
    "    mel_spec_db = 10*np.log10(np.maximum(sys.float_info.min, mel_spec_arr))\n",
    "    mel_spec_db -= 10*np.log10(np.maximum(sys.float_info.min, ref_value))\n",
    "    mel_spec_db = np.maximum(mel_spec_db, mel_spec_db.max()-80)\n",
    "\n",
    "    melSpec_set_no.append(mel_spec_db)\n",
    "    melSpec_train_labels.append(0)\n",
    "    count += 1\n",
    "    if(count%340==0):\n",
    "        print(\"#\", end=\"\")\n",
    "print()\n",
    "print(\"train set 'no' finished\")    \n",
    "print(np.array(melSpec_set_yes).shape)\n",
    "print(np.array(melSpec_set_no).shape)\n",
    "## print the time finished\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "96c41705-f8af-4f79-aa6e-031186f56abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 'yes': ##########\n",
      "test set 'yes' finished\n",
      "Loading 'no': ##########\n",
      "train set 'no' finished\n",
      "(490, 60, 40)\n",
      "(490, 60, 40)\n",
      "2024-05-27 11:32:51.917257\n"
     ]
    }
   ],
   "source": [
    "window_size = 512\n",
    "step = 256\n",
    "num_of_inputs = 15872\n",
    "sample_rate = 16000\n",
    "\n",
    "melSpec_test_set_yes = []\n",
    "melSpec_test_set_no = []\n",
    "melSpec_test_labels = []\n",
    "\n",
    "counter = 0\n",
    "print(\"Loading 'yes': \", end=\"\")\n",
    "for i in data_tensor_test_yes:\n",
    "    mel_spec_arr = mel_spec(i, num_of_inputs, window_size, step, 40, sample_rate)\n",
    "    ref_value = np.max(mel_spec_arr )\n",
    "    mel_spec_arr = np.square(mel_spec_arr)\n",
    "    ref_value = ref_value**2\n",
    "    mel_spec_db = 10*np.log10(np.maximum(sys.float_info.min, mel_spec_arr))\n",
    "    mel_spec_db -= 10*np.log10(np.maximum(sys.float_info.min, ref_value))\n",
    "    mel_spec_db = np.maximum(mel_spec_db, mel_spec_db.max()-80)\n",
    "    \n",
    "    melSpec_test_set_yes.append(mel_spec_db)\n",
    "    melSpec_test_labels.append(1)\n",
    "    count += 1\n",
    "    if(count%49==0):\n",
    "        print(\"#\", end=\"\")\n",
    "\n",
    "print()\n",
    "print(\"test set 'yes' finished\")\n",
    "print(\"Loading 'no': \", end=\"\")\n",
    "count = 0\n",
    "for i in data_tensor_test_no:\n",
    "    mel_spec_arr = mel_spec(i, num_of_inputs, window_size, step, 40, sample_rate)\n",
    "    ref_value = np.max(mel_spec_arr )\n",
    "    mel_spec_arr = np.square(mel_spec_arr)\n",
    "    ref_value = ref_value**2\n",
    "    mel_spec_db = 10*np.log10(np.maximum(sys.float_info.min, mel_spec_arr))\n",
    "    mel_spec_db -= 10*np.log10(np.maximum(sys.float_info.min, ref_value))\n",
    "    mel_spec_db = np.maximum(mel_spec_db, mel_spec_db.max()-80)\n",
    "    \n",
    "    melSpec_test_set_no.append(mel_spec_db)\n",
    "    melSpec_test_labels.append(0)\n",
    "    count += 1\n",
    "    if(count%49==0):\n",
    "        print(\"#\", end=\"\")\n",
    "\n",
    "print()\n",
    "print(\"train set 'no' finished\") \n",
    "print(np.array(melSpec_test_set_yes).shape)\n",
    "print(np.array(melSpec_test_set_no).shape)\n",
    "## print the time finished\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3954b9f0-fb51-4822-9d4d-b12633306643",
   "metadata": {},
   "source": [
    "## Flatten the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7a0c116e-6e4c-4fb6-ae75-fa6831861438",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 40)\n",
      "(6800, 2400)\n",
      "(2400,)\n"
     ]
    }
   ],
   "source": [
    "train_ds = []\n",
    "test_ds = []\n",
    "print(melSpec_set_yes[0].shape)\n",
    "##print(melSpec_set_yes[0])\n",
    "\n",
    "## resize\n",
    "for i in melSpec_set_yes:\n",
    "    resized = np.resize(i, (60, 40))\n",
    "    resized = resized.flatten()\n",
    "    train_ds.append(resized)\n",
    "for i in melSpec_set_no:\n",
    "    resized = np.resize(i, (60, 40))\n",
    "    resized = resized.flatten()\n",
    "    train_ds.append(resized)\n",
    "\n",
    "for i in melSpec_test_set_yes:\n",
    "    resized = np.resize(i, (60, 40))\n",
    "    resized = resized.flatten()\n",
    "    test_ds.append(resized)\n",
    "for i in melSpec_test_set_no:\n",
    "    resized = np.resize(i, (60, 40))\n",
    "    resized = resized.flatten()\n",
    "    test_ds.append(resized)\n",
    "\n",
    "train_ds = np.array(train_ds)\n",
    "test_ds = np.array(test_ds)\n",
    "\n",
    "train_ds = train_ds.astype('float32')\n",
    "##train_ds = np.reshape(train_ds, (len(train_ds), 128, 32, 1))\n",
    "\n",
    "test_ds = test_ds.astype('float32')\n",
    "##test_ds = np.reshape(test_ds, (len(test_ds), 128, 32, 1))\n",
    "print(train_ds.shape)\n",
    "\n",
    "y_train = np.array(melSpec_train_labels)\n",
    "y_test = np.array(melSpec_test_labels)\n",
    "print(train_ds[0].shape)\n",
    "##print(y_test[0])\n",
    "##print(test_ds[0].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81998d4-99e9-4160-be15-fa2e738a5e6e",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9edbad41-b952-4292-aef6-3688410c60d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ reshape_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)             │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ reshape_6 (\u001b[38;5;33mReshape\u001b[0m)             │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_6 (\u001b[38;5;33mFlatten\u001b[0m)             │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_classes = 2\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Reshape((60, 40, 1)),\n",
    "##    tf.keras.layers.DepthwiseConv2D(3, activation='relu'),\n",
    "##    tf.keras.layers.MaxPooling2D(),\n",
    "##    tf.keras.layers.DepthwiseConv2D(3, activation='relu'),\n",
    "##    tf.keras.layers.MaxPooling2D(),\n",
    "##    tf.keras.layers.DepthwiseConv2D(3, activation='relu'),\n",
    "##    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(11, 3, 3, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.50),\n",
    "    tf.keras.layers.Flatten(),\n",
    "##    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax'),\n",
    "])\n",
    "model.summary()\n",
    "## Complie the model\n",
    "model.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5387a410-f398-4503-a268-feb12416a8fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5247 - loss: 10.2660 - val_accuracy: 0.7847 - val_loss: 0.9423\n",
      "Epoch 2/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6068 - loss: 4.9075 - val_accuracy: 0.7980 - val_loss: 0.6983\n",
      "Epoch 3/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6356 - loss: 2.8383 - val_accuracy: 0.7878 - val_loss: 0.6108\n",
      "Epoch 4/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6560 - loss: 1.6275 - val_accuracy: 0.7367 - val_loss: 0.5872\n",
      "Epoch 5/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6643 - loss: 1.0134 - val_accuracy: 0.7378 - val_loss: 0.5783\n",
      "Epoch 6/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6700 - loss: 0.8811 - val_accuracy: 0.7418 - val_loss: 0.5512\n",
      "Epoch 7/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6867 - loss: 0.7081 - val_accuracy: 0.7541 - val_loss: 0.5076\n",
      "Epoch 8/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7001 - loss: 0.6508 - val_accuracy: 0.7806 - val_loss: 0.4585\n",
      "Epoch 9/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7241 - loss: 0.5938 - val_accuracy: 0.7929 - val_loss: 0.4440\n",
      "Epoch 10/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7344 - loss: 0.5778 - val_accuracy: 0.8133 - val_loss: 0.4165\n",
      "Epoch 11/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7461 - loss: 0.5474 - val_accuracy: 0.8235 - val_loss: 0.4009\n",
      "Epoch 12/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7767 - loss: 0.5060 - val_accuracy: 0.8367 - val_loss: 0.3818\n",
      "Epoch 13/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7855 - loss: 0.4749 - val_accuracy: 0.8449 - val_loss: 0.3686\n",
      "Epoch 14/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7972 - loss: 0.4551 - val_accuracy: 0.8459 - val_loss: 0.3621\n",
      "Epoch 15/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7940 - loss: 0.4554 - val_accuracy: 0.8602 - val_loss: 0.3476\n",
      "Epoch 16/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8040 - loss: 0.4290 - val_accuracy: 0.8602 - val_loss: 0.3413\n",
      "Epoch 17/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8152 - loss: 0.4214 - val_accuracy: 0.8653 - val_loss: 0.3267\n",
      "Epoch 18/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8180 - loss: 0.4159 - val_accuracy: 0.8724 - val_loss: 0.3141\n",
      "Epoch 19/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8252 - loss: 0.4029 - val_accuracy: 0.8735 - val_loss: 0.3097\n",
      "Epoch 20/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8350 - loss: 0.3929 - val_accuracy: 0.8806 - val_loss: 0.2985\n",
      "Epoch 21/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8281 - loss: 0.3770 - val_accuracy: 0.8939 - val_loss: 0.2887\n",
      "Epoch 22/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8406 - loss: 0.3606 - val_accuracy: 0.8969 - val_loss: 0.2776\n",
      "Epoch 23/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8496 - loss: 0.3462 - val_accuracy: 0.8929 - val_loss: 0.2770\n",
      "Epoch 24/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.3540 - val_accuracy: 0.9000 - val_loss: 0.2678\n",
      "Epoch 25/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8536 - loss: 0.3401 - val_accuracy: 0.9010 - val_loss: 0.2622\n",
      "Epoch 26/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8570 - loss: 0.3399 - val_accuracy: 0.9020 - val_loss: 0.2498\n",
      "Epoch 27/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8607 - loss: 0.3386 - val_accuracy: 0.8969 - val_loss: 0.2562\n",
      "Epoch 28/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8604 - loss: 0.3382 - val_accuracy: 0.9010 - val_loss: 0.2438\n",
      "Epoch 29/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8714 - loss: 0.3052 - val_accuracy: 0.9071 - val_loss: 0.2420\n",
      "Epoch 30/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8714 - loss: 0.3168 - val_accuracy: 0.9092 - val_loss: 0.2315\n",
      "Epoch 31/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8708 - loss: 0.2926 - val_accuracy: 0.9112 - val_loss: 0.2367\n",
      "Epoch 32/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8775 - loss: 0.3116 - val_accuracy: 0.9102 - val_loss: 0.2277\n",
      "Epoch 33/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8849 - loss: 0.2828 - val_accuracy: 0.9173 - val_loss: 0.2260\n",
      "Epoch 34/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8838 - loss: 0.2808 - val_accuracy: 0.9163 - val_loss: 0.2194\n",
      "Epoch 35/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8821 - loss: 0.2828 - val_accuracy: 0.9194 - val_loss: 0.2180\n",
      "Epoch 36/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8873 - loss: 0.2743 - val_accuracy: 0.9194 - val_loss: 0.2074\n",
      "Epoch 37/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8897 - loss: 0.2714 - val_accuracy: 0.9163 - val_loss: 0.2087\n",
      "Epoch 38/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8958 - loss: 0.2642 - val_accuracy: 0.9245 - val_loss: 0.2083\n",
      "Epoch 39/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8937 - loss: 0.2512 - val_accuracy: 0.9153 - val_loss: 0.2126\n",
      "Epoch 40/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8925 - loss: 0.2560 - val_accuracy: 0.9235 - val_loss: 0.1980\n",
      "Epoch 41/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9009 - loss: 0.2562 - val_accuracy: 0.9276 - val_loss: 0.1921\n",
      "Epoch 42/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9077 - loss: 0.2396 - val_accuracy: 0.9194 - val_loss: 0.1971\n",
      "Epoch 43/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9016 - loss: 0.2523 - val_accuracy: 0.9286 - val_loss: 0.1913\n",
      "Epoch 44/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9055 - loss: 0.2354 - val_accuracy: 0.9286 - val_loss: 0.1816\n",
      "Epoch 45/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9010 - loss: 0.2396 - val_accuracy: 0.9296 - val_loss: 0.1768\n",
      "Epoch 46/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9084 - loss: 0.2259 - val_accuracy: 0.9327 - val_loss: 0.1765\n",
      "Epoch 47/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9073 - loss: 0.2281 - val_accuracy: 0.9367 - val_loss: 0.1703\n",
      "Epoch 48/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9007 - loss: 0.2412 - val_accuracy: 0.9367 - val_loss: 0.1712\n",
      "Epoch 49/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9116 - loss: 0.2147 - val_accuracy: 0.9378 - val_loss: 0.1724\n",
      "Epoch 50/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9112 - loss: 0.2238 - val_accuracy: 0.9429 - val_loss: 0.1643\n",
      "Epoch 51/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9229 - loss: 0.2016 - val_accuracy: 0.9429 - val_loss: 0.1643\n",
      "Epoch 52/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9185 - loss: 0.2064 - val_accuracy: 0.9429 - val_loss: 0.1592\n",
      "Epoch 53/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9133 - loss: 0.2136 - val_accuracy: 0.9469 - val_loss: 0.1589\n",
      "Epoch 54/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9139 - loss: 0.2180 - val_accuracy: 0.9418 - val_loss: 0.1574\n",
      "Epoch 55/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9154 - loss: 0.2045 - val_accuracy: 0.9418 - val_loss: 0.1586\n",
      "Epoch 56/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9186 - loss: 0.2020 - val_accuracy: 0.9418 - val_loss: 0.1582\n",
      "Epoch 57/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9188 - loss: 0.2041 - val_accuracy: 0.9408 - val_loss: 0.1569\n",
      "Epoch 58/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9238 - loss: 0.1961 - val_accuracy: 0.9398 - val_loss: 0.1575\n",
      "Epoch 59/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9237 - loss: 0.1977 - val_accuracy: 0.9459 - val_loss: 0.1563\n",
      "Epoch 60/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9194 - loss: 0.1999 - val_accuracy: 0.9490 - val_loss: 0.1513\n",
      "Epoch 61/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9243 - loss: 0.1889 - val_accuracy: 0.9459 - val_loss: 0.1493\n",
      "Epoch 62/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9250 - loss: 0.1811 - val_accuracy: 0.9459 - val_loss: 0.1524\n",
      "Epoch 63/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9186 - loss: 0.1912 - val_accuracy: 0.9459 - val_loss: 0.1502\n",
      "Epoch 64/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9266 - loss: 0.1800 - val_accuracy: 0.9490 - val_loss: 0.1463\n",
      "Epoch 65/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9297 - loss: 0.1836 - val_accuracy: 0.9490 - val_loss: 0.1486\n",
      "Epoch 66/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9242 - loss: 0.2014 - val_accuracy: 0.9520 - val_loss: 0.1444\n",
      "Epoch 67/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9290 - loss: 0.1862 - val_accuracy: 0.9480 - val_loss: 0.1438\n",
      "Epoch 68/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9324 - loss: 0.1776 - val_accuracy: 0.9439 - val_loss: 0.1513\n",
      "Epoch 69/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9251 - loss: 0.1881 - val_accuracy: 0.9490 - val_loss: 0.1451\n",
      "Epoch 70/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9351 - loss: 0.1781 - val_accuracy: 0.9459 - val_loss: 0.1437\n",
      "Epoch 71/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9368 - loss: 0.1686 - val_accuracy: 0.9429 - val_loss: 0.1451\n",
      "Epoch 72/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9292 - loss: 0.1869 - val_accuracy: 0.9520 - val_loss: 0.1408\n",
      "Epoch 73/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9348 - loss: 0.1770 - val_accuracy: 0.9469 - val_loss: 0.1470\n",
      "Epoch 74/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9415 - loss: 0.1646 - val_accuracy: 0.9541 - val_loss: 0.1417\n",
      "Epoch 75/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9229 - loss: 0.1799 - val_accuracy: 0.9480 - val_loss: 0.1475\n",
      "Epoch 76/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9285 - loss: 0.1814 - val_accuracy: 0.9469 - val_loss: 0.1423\n",
      "Epoch 77/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9302 - loss: 0.1863 - val_accuracy: 0.9480 - val_loss: 0.1408\n",
      "Epoch 78/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9316 - loss: 0.1762 - val_accuracy: 0.9480 - val_loss: 0.1437\n",
      "Epoch 79/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9403 - loss: 0.1609 - val_accuracy: 0.9429 - val_loss: 0.1378\n",
      "Epoch 80/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9300 - loss: 0.1849 - val_accuracy: 0.9459 - val_loss: 0.1389\n",
      "Epoch 81/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9327 - loss: 0.1720 - val_accuracy: 0.9520 - val_loss: 0.1370\n",
      "Epoch 82/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9386 - loss: 0.1617 - val_accuracy: 0.9510 - val_loss: 0.1370\n",
      "Epoch 83/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9342 - loss: 0.1704 - val_accuracy: 0.9531 - val_loss: 0.1378\n",
      "Epoch 84/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9316 - loss: 0.1685 - val_accuracy: 0.9541 - val_loss: 0.1362\n",
      "Epoch 85/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9317 - loss: 0.1753 - val_accuracy: 0.9541 - val_loss: 0.1351\n",
      "Epoch 86/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9345 - loss: 0.1620 - val_accuracy: 0.9510 - val_loss: 0.1313\n",
      "Epoch 87/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9354 - loss: 0.1670 - val_accuracy: 0.9571 - val_loss: 0.1339\n",
      "Epoch 88/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9362 - loss: 0.1722 - val_accuracy: 0.9510 - val_loss: 0.1334\n",
      "Epoch 89/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9368 - loss: 0.1610 - val_accuracy: 0.9582 - val_loss: 0.1305\n",
      "Epoch 90/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9347 - loss: 0.1669 - val_accuracy: 0.9531 - val_loss: 0.1303\n",
      "Epoch 91/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9353 - loss: 0.1637 - val_accuracy: 0.9551 - val_loss: 0.1316\n",
      "Epoch 92/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9348 - loss: 0.1625 - val_accuracy: 0.9622 - val_loss: 0.1260\n",
      "Epoch 93/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9351 - loss: 0.1623 - val_accuracy: 0.9500 - val_loss: 0.1364\n",
      "Epoch 94/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9404 - loss: 0.1576 - val_accuracy: 0.9500 - val_loss: 0.1289\n",
      "Epoch 95/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9429 - loss: 0.1504 - val_accuracy: 0.9500 - val_loss: 0.1334\n",
      "Epoch 96/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9369 - loss: 0.1622 - val_accuracy: 0.9469 - val_loss: 0.1311\n",
      "Epoch 97/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9369 - loss: 0.1628 - val_accuracy: 0.9571 - val_loss: 0.1306\n",
      "Epoch 98/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9418 - loss: 0.1590 - val_accuracy: 0.9510 - val_loss: 0.1317\n",
      "Epoch 99/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9373 - loss: 0.1574 - val_accuracy: 0.9541 - val_loss: 0.1325\n",
      "Epoch 100/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9316 - loss: 0.1622 - val_accuracy: 0.9510 - val_loss: 0.1263\n",
      "Epoch 101/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9337 - loss: 0.1680 - val_accuracy: 0.9490 - val_loss: 0.1320\n",
      "Epoch 102/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9396 - loss: 0.1524 - val_accuracy: 0.9561 - val_loss: 0.1317\n",
      "Epoch 103/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9381 - loss: 0.1570 - val_accuracy: 0.9582 - val_loss: 0.1296\n",
      "Epoch 104/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9401 - loss: 0.1616 - val_accuracy: 0.9459 - val_loss: 0.1267\n",
      "Epoch 105/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9393 - loss: 0.1614 - val_accuracy: 0.9561 - val_loss: 0.1265\n",
      "Epoch 106/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9373 - loss: 0.1566 - val_accuracy: 0.9571 - val_loss: 0.1242\n",
      "Epoch 107/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9432 - loss: 0.1498 - val_accuracy: 0.9592 - val_loss: 0.1267\n",
      "Epoch 108/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9380 - loss: 0.1580 - val_accuracy: 0.9592 - val_loss: 0.1271\n",
      "Epoch 109/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9362 - loss: 0.1533 - val_accuracy: 0.9551 - val_loss: 0.1263\n",
      "Epoch 110/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9409 - loss: 0.1587 - val_accuracy: 0.9561 - val_loss: 0.1333\n",
      "Epoch 111/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9394 - loss: 0.1537 - val_accuracy: 0.9520 - val_loss: 0.1301\n",
      "Epoch 112/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9479 - loss: 0.1458 - val_accuracy: 0.9561 - val_loss: 0.1268\n",
      "Epoch 113/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9431 - loss: 0.1483 - val_accuracy: 0.9561 - val_loss: 0.1236\n",
      "Epoch 114/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9401 - loss: 0.1559 - val_accuracy: 0.9602 - val_loss: 0.1237\n",
      "Epoch 115/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9497 - loss: 0.1403 - val_accuracy: 0.9541 - val_loss: 0.1213\n",
      "Epoch 116/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9421 - loss: 0.1408 - val_accuracy: 0.9582 - val_loss: 0.1219\n",
      "Epoch 117/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9466 - loss: 0.1377 - val_accuracy: 0.9612 - val_loss: 0.1228\n",
      "Epoch 118/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9390 - loss: 0.1574 - val_accuracy: 0.9602 - val_loss: 0.1207\n",
      "Epoch 119/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9480 - loss: 0.1476 - val_accuracy: 0.9551 - val_loss: 0.1210\n",
      "Epoch 120/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9436 - loss: 0.1465 - val_accuracy: 0.9622 - val_loss: 0.1203\n",
      "Epoch 121/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9345 - loss: 0.1571 - val_accuracy: 0.9541 - val_loss: 0.1200\n",
      "Epoch 122/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9432 - loss: 0.1454 - val_accuracy: 0.9602 - val_loss: 0.1209\n",
      "Epoch 123/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9423 - loss: 0.1465 - val_accuracy: 0.9582 - val_loss: 0.1206\n",
      "Epoch 124/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9424 - loss: 0.1479 - val_accuracy: 0.9551 - val_loss: 0.1247\n",
      "Epoch 125/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9425 - loss: 0.1549 - val_accuracy: 0.9582 - val_loss: 0.1272\n",
      "Epoch 126/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9411 - loss: 0.1424 - val_accuracy: 0.9571 - val_loss: 0.1259\n",
      "Epoch 127/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9434 - loss: 0.1426 - val_accuracy: 0.9571 - val_loss: 0.1231\n",
      "Epoch 128/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9500 - loss: 0.1352 - val_accuracy: 0.9571 - val_loss: 0.1223\n",
      "Epoch 129/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9364 - loss: 0.1608 - val_accuracy: 0.9571 - val_loss: 0.1204\n",
      "Epoch 130/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9396 - loss: 0.1525 - val_accuracy: 0.9612 - val_loss: 0.1205\n",
      "Epoch 131/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9467 - loss: 0.1439 - val_accuracy: 0.9571 - val_loss: 0.1269\n",
      "Epoch 132/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9407 - loss: 0.1537 - val_accuracy: 0.9469 - val_loss: 0.1259\n",
      "Epoch 133/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9447 - loss: 0.1472 - val_accuracy: 0.9592 - val_loss: 0.1218\n",
      "Epoch 134/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9452 - loss: 0.1436 - val_accuracy: 0.9571 - val_loss: 0.1209\n",
      "Epoch 135/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9454 - loss: 0.1407 - val_accuracy: 0.9602 - val_loss: 0.1213\n",
      "Epoch 136/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9424 - loss: 0.1489 - val_accuracy: 0.9602 - val_loss: 0.1219\n",
      "Epoch 137/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9433 - loss: 0.1495 - val_accuracy: 0.9551 - val_loss: 0.1268\n",
      "Epoch 138/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9368 - loss: 0.1629 - val_accuracy: 0.9602 - val_loss: 0.1197\n",
      "Epoch 139/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9494 - loss: 0.1305 - val_accuracy: 0.9500 - val_loss: 0.1230\n",
      "Epoch 140/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9497 - loss: 0.1329 - val_accuracy: 0.9561 - val_loss: 0.1151\n",
      "Epoch 141/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9476 - loss: 0.1405 - val_accuracy: 0.9531 - val_loss: 0.1202\n",
      "Epoch 142/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9489 - loss: 0.1382 - val_accuracy: 0.9592 - val_loss: 0.1229\n",
      "Epoch 143/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9503 - loss: 0.1342 - val_accuracy: 0.9592 - val_loss: 0.1230\n",
      "Epoch 144/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9397 - loss: 0.1464 - val_accuracy: 0.9561 - val_loss: 0.1231\n",
      "Epoch 145/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9471 - loss: 0.1473 - val_accuracy: 0.9592 - val_loss: 0.1208\n",
      "Epoch 146/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9415 - loss: 0.1520 - val_accuracy: 0.9551 - val_loss: 0.1185\n",
      "Epoch 147/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9387 - loss: 0.1451 - val_accuracy: 0.9612 - val_loss: 0.1225\n",
      "Epoch 148/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9454 - loss: 0.1412 - val_accuracy: 0.9551 - val_loss: 0.1284\n",
      "Epoch 149/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9454 - loss: 0.1355 - val_accuracy: 0.9571 - val_loss: 0.1201\n",
      "Epoch 150/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9504 - loss: 0.1330 - val_accuracy: 0.9582 - val_loss: 0.1204\n",
      "Epoch 151/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9513 - loss: 0.1300 - val_accuracy: 0.9612 - val_loss: 0.1210\n",
      "Epoch 152/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9444 - loss: 0.1413 - val_accuracy: 0.9531 - val_loss: 0.1156\n",
      "Epoch 153/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9459 - loss: 0.1431 - val_accuracy: 0.9602 - val_loss: 0.1175\n",
      "Epoch 154/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9499 - loss: 0.1313 - val_accuracy: 0.9582 - val_loss: 0.1156\n",
      "Epoch 155/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9514 - loss: 0.1345 - val_accuracy: 0.9592 - val_loss: 0.1227\n",
      "Epoch 156/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9412 - loss: 0.1494 - val_accuracy: 0.9582 - val_loss: 0.1175\n",
      "Epoch 157/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9437 - loss: 0.1500 - val_accuracy: 0.9582 - val_loss: 0.1159\n",
      "Epoch 158/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9437 - loss: 0.1413 - val_accuracy: 0.9582 - val_loss: 0.1164\n",
      "Epoch 159/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9505 - loss: 0.1299 - val_accuracy: 0.9561 - val_loss: 0.1180\n",
      "Epoch 160/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9439 - loss: 0.1375 - val_accuracy: 0.9582 - val_loss: 0.1150\n",
      "Epoch 161/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9433 - loss: 0.1445 - val_accuracy: 0.9561 - val_loss: 0.1233\n",
      "Epoch 162/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9428 - loss: 0.1408 - val_accuracy: 0.9602 - val_loss: 0.1163\n",
      "Epoch 163/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9480 - loss: 0.1294 - val_accuracy: 0.9592 - val_loss: 0.1177\n",
      "Epoch 164/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9456 - loss: 0.1414 - val_accuracy: 0.9571 - val_loss: 0.1166\n",
      "Epoch 165/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9449 - loss: 0.1341 - val_accuracy: 0.9582 - val_loss: 0.1171\n",
      "Epoch 166/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9489 - loss: 0.1408 - val_accuracy: 0.9582 - val_loss: 0.1232\n",
      "Epoch 167/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9492 - loss: 0.1412 - val_accuracy: 0.9602 - val_loss: 0.1154\n",
      "Epoch 168/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9495 - loss: 0.1343 - val_accuracy: 0.9592 - val_loss: 0.1141\n",
      "Epoch 169/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9444 - loss: 0.1398 - val_accuracy: 0.9602 - val_loss: 0.1155\n",
      "Epoch 170/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9367 - loss: 0.1503 - val_accuracy: 0.9592 - val_loss: 0.1170\n",
      "Epoch 171/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9415 - loss: 0.1456 - val_accuracy: 0.9592 - val_loss: 0.1164\n",
      "Epoch 172/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9366 - loss: 0.1512 - val_accuracy: 0.9561 - val_loss: 0.1230\n",
      "Epoch 173/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9462 - loss: 0.1442 - val_accuracy: 0.9612 - val_loss: 0.1122\n",
      "Epoch 174/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9472 - loss: 0.1325 - val_accuracy: 0.9633 - val_loss: 0.1120\n",
      "Epoch 175/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9489 - loss: 0.1272 - val_accuracy: 0.9612 - val_loss: 0.1181\n",
      "Epoch 176/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9467 - loss: 0.1359 - val_accuracy: 0.9602 - val_loss: 0.1162\n",
      "Epoch 177/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9478 - loss: 0.1311 - val_accuracy: 0.9612 - val_loss: 0.1231\n",
      "Epoch 178/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9429 - loss: 0.1412 - val_accuracy: 0.9622 - val_loss: 0.1176\n",
      "Epoch 179/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9469 - loss: 0.1308 - val_accuracy: 0.9531 - val_loss: 0.1202\n",
      "Epoch 180/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9472 - loss: 0.1337 - val_accuracy: 0.9633 - val_loss: 0.1165\n",
      "Epoch 181/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9474 - loss: 0.1385 - val_accuracy: 0.9561 - val_loss: 0.1231\n",
      "Epoch 182/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9480 - loss: 0.1404 - val_accuracy: 0.9571 - val_loss: 0.1141\n",
      "Epoch 183/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9495 - loss: 0.1363 - val_accuracy: 0.9582 - val_loss: 0.1176\n",
      "Epoch 184/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9432 - loss: 0.1358 - val_accuracy: 0.9633 - val_loss: 0.1140\n",
      "Epoch 185/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9511 - loss: 0.1354 - val_accuracy: 0.9643 - val_loss: 0.1128\n",
      "Epoch 186/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9424 - loss: 0.1449 - val_accuracy: 0.9582 - val_loss: 0.1163\n",
      "Epoch 187/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9474 - loss: 0.1346 - val_accuracy: 0.9622 - val_loss: 0.1150\n",
      "Epoch 188/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9505 - loss: 0.1375 - val_accuracy: 0.9592 - val_loss: 0.1229\n",
      "Epoch 189/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9465 - loss: 0.1378 - val_accuracy: 0.9622 - val_loss: 0.1151\n",
      "Epoch 190/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9410 - loss: 0.1472 - val_accuracy: 0.9592 - val_loss: 0.1176\n",
      "Epoch 191/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9452 - loss: 0.1428 - val_accuracy: 0.9622 - val_loss: 0.1139\n",
      "Epoch 192/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9534 - loss: 0.1293 - val_accuracy: 0.9582 - val_loss: 0.1167\n",
      "Epoch 193/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9515 - loss: 0.1366 - val_accuracy: 0.9602 - val_loss: 0.1131\n",
      "Epoch 194/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9573 - loss: 0.1192 - val_accuracy: 0.9612 - val_loss: 0.1139\n",
      "Epoch 195/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9452 - loss: 0.1414 - val_accuracy: 0.9633 - val_loss: 0.1091\n",
      "Epoch 196/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9519 - loss: 0.1290 - val_accuracy: 0.9622 - val_loss: 0.1134\n",
      "Epoch 197/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9490 - loss: 0.1272 - val_accuracy: 0.9612 - val_loss: 0.1132\n",
      "Epoch 198/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9531 - loss: 0.1237 - val_accuracy: 0.9602 - val_loss: 0.1140\n",
      "Epoch 199/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9446 - loss: 0.1409 - val_accuracy: 0.9592 - val_loss: 0.1121\n",
      "Epoch 200/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9460 - loss: 0.1453 - val_accuracy: 0.9622 - val_loss: 0.1131\n",
      "Epoch 201/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9506 - loss: 0.1317 - val_accuracy: 0.9612 - val_loss: 0.1119\n",
      "Epoch 202/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9547 - loss: 0.1220 - val_accuracy: 0.9602 - val_loss: 0.1110\n",
      "Epoch 203/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9517 - loss: 0.1296 - val_accuracy: 0.9592 - val_loss: 0.1109\n",
      "Epoch 204/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9511 - loss: 0.1377 - val_accuracy: 0.9622 - val_loss: 0.1145\n",
      "Epoch 205/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9471 - loss: 0.1309 - val_accuracy: 0.9582 - val_loss: 0.1104\n",
      "Epoch 206/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9492 - loss: 0.1365 - val_accuracy: 0.9633 - val_loss: 0.1141\n",
      "Epoch 207/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9524 - loss: 0.1313 - val_accuracy: 0.9643 - val_loss: 0.1117\n",
      "Epoch 208/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9503 - loss: 0.1360 - val_accuracy: 0.9602 - val_loss: 0.1125\n",
      "Epoch 209/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9510 - loss: 0.1275 - val_accuracy: 0.9571 - val_loss: 0.1161\n",
      "Epoch 210/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9491 - loss: 0.1292 - val_accuracy: 0.9592 - val_loss: 0.1151\n",
      "Epoch 211/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9530 - loss: 0.1226 - val_accuracy: 0.9622 - val_loss: 0.1170\n",
      "Epoch 212/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9519 - loss: 0.1357 - val_accuracy: 0.9592 - val_loss: 0.1165\n",
      "Epoch 213/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9503 - loss: 0.1262 - val_accuracy: 0.9592 - val_loss: 0.1157\n",
      "Epoch 214/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9572 - loss: 0.1231 - val_accuracy: 0.9582 - val_loss: 0.1136\n",
      "Epoch 215/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9510 - loss: 0.1237 - val_accuracy: 0.9582 - val_loss: 0.1154\n",
      "Epoch 216/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9424 - loss: 0.1426 - val_accuracy: 0.9571 - val_loss: 0.1159\n",
      "Epoch 217/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9525 - loss: 0.1284 - val_accuracy: 0.9612 - val_loss: 0.1161\n",
      "Epoch 218/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9512 - loss: 0.1278 - val_accuracy: 0.9622 - val_loss: 0.1184\n",
      "Epoch 219/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9490 - loss: 0.1276 - val_accuracy: 0.9571 - val_loss: 0.1159\n",
      "Epoch 220/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9547 - loss: 0.1241 - val_accuracy: 0.9592 - val_loss: 0.1146\n",
      "Epoch 221/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9535 - loss: 0.1218 - val_accuracy: 0.9592 - val_loss: 0.1162\n",
      "Epoch 222/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9491 - loss: 0.1289 - val_accuracy: 0.9633 - val_loss: 0.1150\n",
      "Epoch 223/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9506 - loss: 0.1276 - val_accuracy: 0.9602 - val_loss: 0.1155\n",
      "Epoch 224/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9508 - loss: 0.1246 - val_accuracy: 0.9633 - val_loss: 0.1139\n",
      "Epoch 225/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9535 - loss: 0.1288 - val_accuracy: 0.9592 - val_loss: 0.1168\n",
      "Epoch 226/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9524 - loss: 0.1293 - val_accuracy: 0.9622 - val_loss: 0.1109\n",
      "Epoch 227/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9508 - loss: 0.1327 - val_accuracy: 0.9612 - val_loss: 0.1116\n",
      "Epoch 228/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9500 - loss: 0.1275 - val_accuracy: 0.9633 - val_loss: 0.1133\n",
      "Epoch 229/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9524 - loss: 0.1185 - val_accuracy: 0.9612 - val_loss: 0.1110\n",
      "Epoch 230/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9463 - loss: 0.1390 - val_accuracy: 0.9653 - val_loss: 0.1083\n",
      "Epoch 231/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9498 - loss: 0.1279 - val_accuracy: 0.9622 - val_loss: 0.1123\n",
      "Epoch 232/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9532 - loss: 0.1258 - val_accuracy: 0.9643 - val_loss: 0.1070\n",
      "Epoch 233/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9446 - loss: 0.1424 - val_accuracy: 0.9622 - val_loss: 0.1113\n",
      "Epoch 234/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9542 - loss: 0.1226 - val_accuracy: 0.9602 - val_loss: 0.1085\n",
      "Epoch 235/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9529 - loss: 0.1266 - val_accuracy: 0.9622 - val_loss: 0.1081\n",
      "Epoch 236/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9530 - loss: 0.1263 - val_accuracy: 0.9592 - val_loss: 0.1132\n",
      "Epoch 237/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9481 - loss: 0.1342 - val_accuracy: 0.9602 - val_loss: 0.1155\n",
      "Epoch 238/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9501 - loss: 0.1301 - val_accuracy: 0.9633 - val_loss: 0.1131\n",
      "Epoch 239/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9567 - loss: 0.1161 - val_accuracy: 0.9582 - val_loss: 0.1122\n",
      "Epoch 240/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9523 - loss: 0.1231 - val_accuracy: 0.9633 - val_loss: 0.1139\n",
      "Epoch 241/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9412 - loss: 0.1500 - val_accuracy: 0.9643 - val_loss: 0.1116\n",
      "Epoch 242/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9541 - loss: 0.1199 - val_accuracy: 0.9643 - val_loss: 0.1090\n",
      "Epoch 243/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9474 - loss: 0.1258 - val_accuracy: 0.9643 - val_loss: 0.1121\n",
      "Epoch 244/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9469 - loss: 0.1331 - val_accuracy: 0.9592 - val_loss: 0.1078\n",
      "Epoch 245/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9519 - loss: 0.1222 - val_accuracy: 0.9653 - val_loss: 0.1121\n",
      "Epoch 246/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9526 - loss: 0.1214 - val_accuracy: 0.9633 - val_loss: 0.1125\n",
      "Epoch 247/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9530 - loss: 0.1223 - val_accuracy: 0.9612 - val_loss: 0.1102\n",
      "Epoch 248/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9519 - loss: 0.1213 - val_accuracy: 0.9582 - val_loss: 0.1140\n",
      "Epoch 249/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9542 - loss: 0.1207 - val_accuracy: 0.9612 - val_loss: 0.1110\n",
      "Epoch 250/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9513 - loss: 0.1259 - val_accuracy: 0.9592 - val_loss: 0.1117\n",
      "Epoch 251/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9572 - loss: 0.1153 - val_accuracy: 0.9602 - val_loss: 0.1187\n",
      "Epoch 252/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9483 - loss: 0.1291 - val_accuracy: 0.9602 - val_loss: 0.1158\n",
      "Epoch 253/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9527 - loss: 0.1277 - val_accuracy: 0.9571 - val_loss: 0.1150\n",
      "Epoch 254/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9510 - loss: 0.1376 - val_accuracy: 0.9612 - val_loss: 0.1116\n",
      "Epoch 255/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9509 - loss: 0.1227 - val_accuracy: 0.9582 - val_loss: 0.1108\n",
      "Epoch 256/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9489 - loss: 0.1336 - val_accuracy: 0.9643 - val_loss: 0.1130\n",
      "Epoch 257/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9492 - loss: 0.1211 - val_accuracy: 0.9612 - val_loss: 0.1117\n",
      "Epoch 258/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9498 - loss: 0.1258 - val_accuracy: 0.9612 - val_loss: 0.1130\n",
      "Epoch 259/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9563 - loss: 0.1153 - val_accuracy: 0.9592 - val_loss: 0.1111\n",
      "Epoch 260/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9546 - loss: 0.1228 - val_accuracy: 0.9582 - val_loss: 0.1156\n",
      "Epoch 261/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9531 - loss: 0.1267 - val_accuracy: 0.9622 - val_loss: 0.1091\n",
      "Epoch 262/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9478 - loss: 0.1359 - val_accuracy: 0.9612 - val_loss: 0.1107\n",
      "Epoch 263/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9526 - loss: 0.1226 - val_accuracy: 0.9582 - val_loss: 0.1127\n",
      "Epoch 264/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9491 - loss: 0.1317 - val_accuracy: 0.9622 - val_loss: 0.1059\n",
      "Epoch 265/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9533 - loss: 0.1304 - val_accuracy: 0.9592 - val_loss: 0.1119\n",
      "Epoch 266/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9519 - loss: 0.1313 - val_accuracy: 0.9582 - val_loss: 0.1105\n",
      "Epoch 267/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9523 - loss: 0.1166 - val_accuracy: 0.9602 - val_loss: 0.1091\n",
      "Epoch 268/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9497 - loss: 0.1285 - val_accuracy: 0.9633 - val_loss: 0.1104\n",
      "Epoch 269/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9539 - loss: 0.1193 - val_accuracy: 0.9612 - val_loss: 0.1114\n",
      "Epoch 270/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9551 - loss: 0.1187 - val_accuracy: 0.9612 - val_loss: 0.1088\n",
      "Epoch 271/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9534 - loss: 0.1222 - val_accuracy: 0.9592 - val_loss: 0.1116\n",
      "Epoch 272/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9515 - loss: 0.1323 - val_accuracy: 0.9622 - val_loss: 0.1083\n",
      "Epoch 273/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9468 - loss: 0.1390 - val_accuracy: 0.9592 - val_loss: 0.1133\n",
      "Epoch 274/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9501 - loss: 0.1298 - val_accuracy: 0.9582 - val_loss: 0.1148\n",
      "Epoch 275/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9534 - loss: 0.1255 - val_accuracy: 0.9612 - val_loss: 0.1110\n",
      "Epoch 276/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9530 - loss: 0.1259 - val_accuracy: 0.9643 - val_loss: 0.1072\n",
      "Epoch 277/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9511 - loss: 0.1265 - val_accuracy: 0.9541 - val_loss: 0.1118\n",
      "Epoch 278/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9558 - loss: 0.1266 - val_accuracy: 0.9643 - val_loss: 0.1071\n",
      "Epoch 279/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9540 - loss: 0.1261 - val_accuracy: 0.9592 - val_loss: 0.1086\n",
      "Epoch 280/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9512 - loss: 0.1197 - val_accuracy: 0.9612 - val_loss: 0.1102\n",
      "Epoch 281/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9558 - loss: 0.1179 - val_accuracy: 0.9582 - val_loss: 0.1166\n",
      "Epoch 282/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9464 - loss: 0.1250 - val_accuracy: 0.9602 - val_loss: 0.1044\n",
      "Epoch 283/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9512 - loss: 0.1267 - val_accuracy: 0.9643 - val_loss: 0.1102\n",
      "Epoch 284/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9538 - loss: 0.1208 - val_accuracy: 0.9592 - val_loss: 0.1167\n",
      "Epoch 285/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9477 - loss: 0.1318 - val_accuracy: 0.9602 - val_loss: 0.1145\n",
      "Epoch 286/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9555 - loss: 0.1218 - val_accuracy: 0.9612 - val_loss: 0.1086\n",
      "Epoch 287/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9540 - loss: 0.1196 - val_accuracy: 0.9622 - val_loss: 0.1080\n",
      "Epoch 288/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9528 - loss: 0.1193 - val_accuracy: 0.9622 - val_loss: 0.1075\n",
      "Epoch 289/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9604 - loss: 0.1085 - val_accuracy: 0.9622 - val_loss: 0.1053\n",
      "Epoch 290/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9533 - loss: 0.1224 - val_accuracy: 0.9571 - val_loss: 0.1116\n",
      "Epoch 291/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9591 - loss: 0.1055 - val_accuracy: 0.9612 - val_loss: 0.1092\n",
      "Epoch 292/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9529 - loss: 0.1221 - val_accuracy: 0.9612 - val_loss: 0.1093\n",
      "Epoch 293/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9570 - loss: 0.1219 - val_accuracy: 0.9612 - val_loss: 0.1113\n",
      "Epoch 294/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9531 - loss: 0.1282 - val_accuracy: 0.9612 - val_loss: 0.1064\n",
      "Epoch 295/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9492 - loss: 0.1272 - val_accuracy: 0.9612 - val_loss: 0.1058\n",
      "Epoch 296/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9573 - loss: 0.1132 - val_accuracy: 0.9643 - val_loss: 0.1103\n",
      "Epoch 297/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9564 - loss: 0.1164 - val_accuracy: 0.9612 - val_loss: 0.1095\n",
      "Epoch 298/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9535 - loss: 0.1357 - val_accuracy: 0.9653 - val_loss: 0.1085\n",
      "Epoch 299/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9542 - loss: 0.1171 - val_accuracy: 0.9622 - val_loss: 0.1112\n",
      "Epoch 300/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9495 - loss: 0.1279 - val_accuracy: 0.9612 - val_loss: 0.1077\n",
      "Epoch 301/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9547 - loss: 0.1226 - val_accuracy: 0.9643 - val_loss: 0.1071\n",
      "Epoch 302/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9544 - loss: 0.1249 - val_accuracy: 0.9622 - val_loss: 0.1108\n",
      "Epoch 303/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9591 - loss: 0.1060 - val_accuracy: 0.9622 - val_loss: 0.1084\n",
      "Epoch 304/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9600 - loss: 0.1076 - val_accuracy: 0.9622 - val_loss: 0.1088\n",
      "Epoch 305/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9560 - loss: 0.1138 - val_accuracy: 0.9571 - val_loss: 0.1205\n",
      "Epoch 306/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9468 - loss: 0.1302 - val_accuracy: 0.9622 - val_loss: 0.1071\n",
      "Epoch 307/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9564 - loss: 0.1178 - val_accuracy: 0.9602 - val_loss: 0.1077\n",
      "Epoch 308/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9591 - loss: 0.1103 - val_accuracy: 0.9612 - val_loss: 0.1076\n",
      "Epoch 309/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9495 - loss: 0.1241 - val_accuracy: 0.9622 - val_loss: 0.1100\n",
      "Epoch 310/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9556 - loss: 0.1121 - val_accuracy: 0.9622 - val_loss: 0.1112\n",
      "Epoch 311/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9528 - loss: 0.1239 - val_accuracy: 0.9612 - val_loss: 0.1096\n",
      "Epoch 312/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9493 - loss: 0.1286 - val_accuracy: 0.9622 - val_loss: 0.1088\n",
      "Epoch 313/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9578 - loss: 0.1154 - val_accuracy: 0.9643 - val_loss: 0.1115\n",
      "Epoch 314/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9553 - loss: 0.1191 - val_accuracy: 0.9633 - val_loss: 0.1072\n",
      "Epoch 315/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9479 - loss: 0.1365 - val_accuracy: 0.9592 - val_loss: 0.1152\n",
      "Epoch 316/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9503 - loss: 0.1205 - val_accuracy: 0.9643 - val_loss: 0.1085\n",
      "Epoch 317/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9534 - loss: 0.1212 - val_accuracy: 0.9633 - val_loss: 0.1019\n",
      "Epoch 318/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9600 - loss: 0.1046 - val_accuracy: 0.9673 - val_loss: 0.1057\n",
      "Epoch 319/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9596 - loss: 0.1147 - val_accuracy: 0.9612 - val_loss: 0.1064\n",
      "Epoch 320/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9471 - loss: 0.1427 - val_accuracy: 0.9633 - val_loss: 0.1115\n",
      "Epoch 321/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9538 - loss: 0.1133 - val_accuracy: 0.9633 - val_loss: 0.1102\n",
      "Epoch 322/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9528 - loss: 0.1332 - val_accuracy: 0.9612 - val_loss: 0.1084\n",
      "Epoch 323/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9535 - loss: 0.1187 - val_accuracy: 0.9653 - val_loss: 0.1106\n",
      "Epoch 324/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9545 - loss: 0.1147 - val_accuracy: 0.9643 - val_loss: 0.1076\n",
      "Epoch 325/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9532 - loss: 0.1194 - val_accuracy: 0.9592 - val_loss: 0.1071\n",
      "Epoch 326/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9559 - loss: 0.1104 - val_accuracy: 0.9622 - val_loss: 0.1066\n",
      "Epoch 327/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9516 - loss: 0.1274 - val_accuracy: 0.9622 - val_loss: 0.1066\n",
      "Epoch 328/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9520 - loss: 0.1217 - val_accuracy: 0.9602 - val_loss: 0.1081\n",
      "Epoch 329/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9539 - loss: 0.1205 - val_accuracy: 0.9622 - val_loss: 0.1097\n",
      "Epoch 330/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9510 - loss: 0.1248 - val_accuracy: 0.9612 - val_loss: 0.1060\n",
      "Epoch 331/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9523 - loss: 0.1230 - val_accuracy: 0.9612 - val_loss: 0.1074\n",
      "Epoch 332/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9520 - loss: 0.1245 - val_accuracy: 0.9612 - val_loss: 0.1031\n",
      "Epoch 333/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9587 - loss: 0.1139 - val_accuracy: 0.9622 - val_loss: 0.1029\n",
      "Epoch 334/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9530 - loss: 0.1152 - val_accuracy: 0.9653 - val_loss: 0.1069\n",
      "Epoch 335/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9538 - loss: 0.1241 - val_accuracy: 0.9643 - val_loss: 0.1064\n",
      "Epoch 336/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9482 - loss: 0.1302 - val_accuracy: 0.9653 - val_loss: 0.1044\n",
      "Epoch 337/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9589 - loss: 0.1107 - val_accuracy: 0.9643 - val_loss: 0.1049\n",
      "Epoch 338/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9569 - loss: 0.1188 - val_accuracy: 0.9663 - val_loss: 0.1058\n",
      "Epoch 339/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9548 - loss: 0.1270 - val_accuracy: 0.9602 - val_loss: 0.1056\n",
      "Epoch 340/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9516 - loss: 0.1242 - val_accuracy: 0.9622 - val_loss: 0.1075\n",
      "Epoch 341/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9525 - loss: 0.1173 - val_accuracy: 0.9633 - val_loss: 0.1043\n",
      "Epoch 342/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9566 - loss: 0.1178 - val_accuracy: 0.9602 - val_loss: 0.1129\n",
      "Epoch 343/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9512 - loss: 0.1285 - val_accuracy: 0.9622 - val_loss: 0.1107\n",
      "Epoch 344/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9481 - loss: 0.1290 - val_accuracy: 0.9622 - val_loss: 0.1122\n",
      "Epoch 345/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9569 - loss: 0.1190 - val_accuracy: 0.9633 - val_loss: 0.1126\n",
      "Epoch 346/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9474 - loss: 0.1224 - val_accuracy: 0.9633 - val_loss: 0.1073\n",
      "Epoch 347/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9561 - loss: 0.1197 - val_accuracy: 0.9622 - val_loss: 0.1124\n",
      "Epoch 348/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9536 - loss: 0.1238 - val_accuracy: 0.9612 - val_loss: 0.1081\n",
      "Epoch 349/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9587 - loss: 0.1089 - val_accuracy: 0.9684 - val_loss: 0.1049\n",
      "Epoch 350/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9564 - loss: 0.1115 - val_accuracy: 0.9612 - val_loss: 0.1094\n",
      "Epoch 351/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9596 - loss: 0.1096 - val_accuracy: 0.9663 - val_loss: 0.1030\n",
      "Epoch 352/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9547 - loss: 0.1163 - val_accuracy: 0.9622 - val_loss: 0.1080\n",
      "Epoch 353/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9522 - loss: 0.1232 - val_accuracy: 0.9653 - val_loss: 0.1068\n",
      "Epoch 354/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9524 - loss: 0.1190 - val_accuracy: 0.9582 - val_loss: 0.1095\n",
      "Epoch 355/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9559 - loss: 0.1127 - val_accuracy: 0.9643 - val_loss: 0.1078\n",
      "Epoch 356/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9586 - loss: 0.1089 - val_accuracy: 0.9622 - val_loss: 0.1102\n",
      "Epoch 357/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9588 - loss: 0.1098 - val_accuracy: 0.9622 - val_loss: 0.1061\n",
      "Epoch 358/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9540 - loss: 0.1206 - val_accuracy: 0.9643 - val_loss: 0.1063\n",
      "Epoch 359/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9545 - loss: 0.1174 - val_accuracy: 0.9643 - val_loss: 0.1064\n",
      "Epoch 360/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9529 - loss: 0.1321 - val_accuracy: 0.9571 - val_loss: 0.1127\n",
      "Epoch 361/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9597 - loss: 0.1134 - val_accuracy: 0.9622 - val_loss: 0.1152\n",
      "Epoch 362/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9566 - loss: 0.1094 - val_accuracy: 0.9663 - val_loss: 0.1050\n",
      "Epoch 363/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9499 - loss: 0.1263 - val_accuracy: 0.9602 - val_loss: 0.1141\n",
      "Epoch 364/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9536 - loss: 0.1209 - val_accuracy: 0.9571 - val_loss: 0.1173\n",
      "Epoch 365/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9616 - loss: 0.1045 - val_accuracy: 0.9653 - val_loss: 0.1047\n",
      "Epoch 366/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9531 - loss: 0.1232 - val_accuracy: 0.9622 - val_loss: 0.1084\n",
      "Epoch 367/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9525 - loss: 0.1232 - val_accuracy: 0.9622 - val_loss: 0.1097\n",
      "Epoch 368/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9556 - loss: 0.1186 - val_accuracy: 0.9633 - val_loss: 0.1111\n",
      "Epoch 369/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9534 - loss: 0.1136 - val_accuracy: 0.9633 - val_loss: 0.1069\n",
      "Epoch 370/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9531 - loss: 0.1225 - val_accuracy: 0.9633 - val_loss: 0.1097\n",
      "Epoch 371/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9469 - loss: 0.1333 - val_accuracy: 0.9622 - val_loss: 0.1077\n",
      "Epoch 372/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9653 - loss: 0.1044 - val_accuracy: 0.9653 - val_loss: 0.1082\n",
      "Epoch 373/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9574 - loss: 0.1097 - val_accuracy: 0.9633 - val_loss: 0.1072\n",
      "Epoch 374/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9563 - loss: 0.1114 - val_accuracy: 0.9622 - val_loss: 0.1084\n",
      "Epoch 375/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9562 - loss: 0.1092 - val_accuracy: 0.9622 - val_loss: 0.1107\n",
      "Epoch 376/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9533 - loss: 0.1108 - val_accuracy: 0.9592 - val_loss: 0.1163\n",
      "Epoch 377/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9594 - loss: 0.1081 - val_accuracy: 0.9592 - val_loss: 0.1108\n",
      "Epoch 378/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9571 - loss: 0.1140 - val_accuracy: 0.9622 - val_loss: 0.1082\n",
      "Epoch 379/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9555 - loss: 0.1141 - val_accuracy: 0.9633 - val_loss: 0.1096\n",
      "Epoch 380/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9560 - loss: 0.1102 - val_accuracy: 0.9622 - val_loss: 0.1089\n",
      "Epoch 381/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9524 - loss: 0.1167 - val_accuracy: 0.9571 - val_loss: 0.1096\n",
      "Epoch 382/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9540 - loss: 0.1179 - val_accuracy: 0.9633 - val_loss: 0.1063\n",
      "Epoch 383/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9577 - loss: 0.1178 - val_accuracy: 0.9653 - val_loss: 0.1126\n",
      "Epoch 384/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9576 - loss: 0.1128 - val_accuracy: 0.9602 - val_loss: 0.1149\n",
      "Epoch 385/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9612 - loss: 0.1028 - val_accuracy: 0.9622 - val_loss: 0.1142\n",
      "Epoch 386/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9600 - loss: 0.1045 - val_accuracy: 0.9643 - val_loss: 0.1074\n",
      "Epoch 387/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9534 - loss: 0.1199 - val_accuracy: 0.9612 - val_loss: 0.1099\n",
      "Epoch 388/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9597 - loss: 0.1097 - val_accuracy: 0.9622 - val_loss: 0.1118\n",
      "Epoch 389/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9551 - loss: 0.1147 - val_accuracy: 0.9643 - val_loss: 0.1098\n",
      "Epoch 390/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9548 - loss: 0.1143 - val_accuracy: 0.9622 - val_loss: 0.1091\n",
      "Epoch 391/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9535 - loss: 0.1248 - val_accuracy: 0.9643 - val_loss: 0.1084\n",
      "Epoch 392/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9558 - loss: 0.1141 - val_accuracy: 0.9633 - val_loss: 0.1110\n",
      "Epoch 393/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9601 - loss: 0.1138 - val_accuracy: 0.9643 - val_loss: 0.1088\n",
      "Epoch 394/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9571 - loss: 0.1102 - val_accuracy: 0.9622 - val_loss: 0.1106\n",
      "Epoch 395/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9552 - loss: 0.1094 - val_accuracy: 0.9663 - val_loss: 0.1108\n",
      "Epoch 396/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9592 - loss: 0.1112 - val_accuracy: 0.9663 - val_loss: 0.1099\n",
      "Epoch 397/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9524 - loss: 0.1268 - val_accuracy: 0.9622 - val_loss: 0.1076\n",
      "Epoch 398/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9531 - loss: 0.1272 - val_accuracy: 0.9653 - val_loss: 0.1094\n",
      "Epoch 399/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9571 - loss: 0.1145 - val_accuracy: 0.9633 - val_loss: 0.1059\n",
      "Epoch 400/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9533 - loss: 0.1162 - val_accuracy: 0.9663 - val_loss: 0.1115\n",
      "Epoch 401/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9542 - loss: 0.1123 - val_accuracy: 0.9643 - val_loss: 0.1074\n",
      "Epoch 402/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9519 - loss: 0.1238 - val_accuracy: 0.9622 - val_loss: 0.1074\n",
      "Epoch 403/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9565 - loss: 0.1176 - val_accuracy: 0.9663 - val_loss: 0.1075\n",
      "Epoch 404/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9501 - loss: 0.1197 - val_accuracy: 0.9653 - val_loss: 0.1095\n",
      "Epoch 405/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9565 - loss: 0.1088 - val_accuracy: 0.9653 - val_loss: 0.1080\n",
      "Epoch 406/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9555 - loss: 0.1114 - val_accuracy: 0.9643 - val_loss: 0.1089\n",
      "Epoch 407/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9579 - loss: 0.1086 - val_accuracy: 0.9653 - val_loss: 0.1054\n",
      "Epoch 408/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9523 - loss: 0.1193 - val_accuracy: 0.9622 - val_loss: 0.1108\n",
      "Epoch 409/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9520 - loss: 0.1223 - val_accuracy: 0.9643 - val_loss: 0.1095\n",
      "Epoch 410/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9566 - loss: 0.1131 - val_accuracy: 0.9663 - val_loss: 0.1066\n",
      "Epoch 411/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9538 - loss: 0.1171 - val_accuracy: 0.9622 - val_loss: 0.1111\n",
      "Epoch 412/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9591 - loss: 0.1095 - val_accuracy: 0.9663 - val_loss: 0.1094\n",
      "Epoch 413/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9581 - loss: 0.1117 - val_accuracy: 0.9653 - val_loss: 0.1102\n",
      "Epoch 414/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9590 - loss: 0.1067 - val_accuracy: 0.9643 - val_loss: 0.1110\n",
      "Epoch 415/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9601 - loss: 0.1107 - val_accuracy: 0.9684 - val_loss: 0.1074\n",
      "Epoch 416/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9577 - loss: 0.1054 - val_accuracy: 0.9694 - val_loss: 0.1095\n",
      "Epoch 417/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9582 - loss: 0.1052 - val_accuracy: 0.9663 - val_loss: 0.1055\n",
      "Epoch 418/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9555 - loss: 0.1090 - val_accuracy: 0.9663 - val_loss: 0.1078\n",
      "Epoch 419/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9607 - loss: 0.1028 - val_accuracy: 0.9653 - val_loss: 0.1094\n",
      "Epoch 420/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9559 - loss: 0.1185 - val_accuracy: 0.9643 - val_loss: 0.1106\n",
      "Epoch 421/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9540 - loss: 0.1215 - val_accuracy: 0.9663 - val_loss: 0.1050\n",
      "Epoch 422/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9628 - loss: 0.0994 - val_accuracy: 0.9673 - val_loss: 0.1065\n",
      "Epoch 423/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9597 - loss: 0.1099 - val_accuracy: 0.9653 - val_loss: 0.1088\n",
      "Epoch 424/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9531 - loss: 0.1287 - val_accuracy: 0.9653 - val_loss: 0.1074\n",
      "Epoch 425/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9614 - loss: 0.1011 - val_accuracy: 0.9673 - val_loss: 0.1074\n",
      "Epoch 426/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9623 - loss: 0.1015 - val_accuracy: 0.9653 - val_loss: 0.1092\n",
      "Epoch 427/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9538 - loss: 0.1138 - val_accuracy: 0.9663 - val_loss: 0.1093\n",
      "Epoch 428/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9597 - loss: 0.1083 - val_accuracy: 0.9643 - val_loss: 0.1121\n",
      "Epoch 429/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9572 - loss: 0.1038 - val_accuracy: 0.9684 - val_loss: 0.1097\n",
      "Epoch 430/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9573 - loss: 0.1094 - val_accuracy: 0.9633 - val_loss: 0.1097\n",
      "Epoch 431/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9560 - loss: 0.1142 - val_accuracy: 0.9643 - val_loss: 0.1165\n",
      "Epoch 432/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9612 - loss: 0.0998 - val_accuracy: 0.9653 - val_loss: 0.1123\n",
      "Epoch 433/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9565 - loss: 0.1148 - val_accuracy: 0.9643 - val_loss: 0.1102\n",
      "Epoch 434/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9524 - loss: 0.1189 - val_accuracy: 0.9643 - val_loss: 0.1122\n",
      "Epoch 435/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9518 - loss: 0.1239 - val_accuracy: 0.9612 - val_loss: 0.1105\n",
      "Epoch 436/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9588 - loss: 0.1069 - val_accuracy: 0.9663 - val_loss: 0.1110\n",
      "Epoch 437/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9539 - loss: 0.1088 - val_accuracy: 0.9622 - val_loss: 0.1105\n",
      "Epoch 438/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9593 - loss: 0.1072 - val_accuracy: 0.9622 - val_loss: 0.1152\n",
      "Epoch 439/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9551 - loss: 0.1161 - val_accuracy: 0.9643 - val_loss: 0.1117\n",
      "Epoch 440/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9530 - loss: 0.1172 - val_accuracy: 0.9622 - val_loss: 0.1117\n",
      "Epoch 441/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9625 - loss: 0.0997 - val_accuracy: 0.9643 - val_loss: 0.1086\n",
      "Epoch 442/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9596 - loss: 0.1157 - val_accuracy: 0.9612 - val_loss: 0.1105\n",
      "Epoch 443/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9605 - loss: 0.1015 - val_accuracy: 0.9633 - val_loss: 0.1113\n",
      "Epoch 444/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9535 - loss: 0.1213 - val_accuracy: 0.9633 - val_loss: 0.1094\n",
      "Epoch 445/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9601 - loss: 0.1058 - val_accuracy: 0.9633 - val_loss: 0.1093\n",
      "Epoch 446/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9508 - loss: 0.1231 - val_accuracy: 0.9653 - val_loss: 0.1121\n",
      "Epoch 447/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9581 - loss: 0.1121 - val_accuracy: 0.9633 - val_loss: 0.1073\n",
      "Epoch 448/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9576 - loss: 0.1186 - val_accuracy: 0.9653 - val_loss: 0.1103\n",
      "Epoch 449/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9582 - loss: 0.1148 - val_accuracy: 0.9633 - val_loss: 0.1095\n",
      "Epoch 450/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9559 - loss: 0.1150 - val_accuracy: 0.9663 - val_loss: 0.1104\n",
      "Epoch 451/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9601 - loss: 0.1044 - val_accuracy: 0.9663 - val_loss: 0.1065\n",
      "Epoch 452/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9650 - loss: 0.1049 - val_accuracy: 0.9663 - val_loss: 0.1066\n",
      "Epoch 453/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9561 - loss: 0.1108 - val_accuracy: 0.9643 - val_loss: 0.1092\n",
      "Epoch 454/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9590 - loss: 0.1042 - val_accuracy: 0.9633 - val_loss: 0.1082\n",
      "Epoch 455/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9575 - loss: 0.1126 - val_accuracy: 0.9633 - val_loss: 0.1106\n",
      "Epoch 456/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9613 - loss: 0.0961 - val_accuracy: 0.9633 - val_loss: 0.1073\n",
      "Epoch 457/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9563 - loss: 0.1147 - val_accuracy: 0.9612 - val_loss: 0.1099\n",
      "Epoch 458/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9549 - loss: 0.1146 - val_accuracy: 0.9602 - val_loss: 0.1131\n",
      "Epoch 459/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9549 - loss: 0.1126 - val_accuracy: 0.9612 - val_loss: 0.1126\n",
      "Epoch 460/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9572 - loss: 0.1208 - val_accuracy: 0.9612 - val_loss: 0.1100\n",
      "Epoch 461/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9574 - loss: 0.1062 - val_accuracy: 0.9633 - val_loss: 0.1095\n",
      "Epoch 462/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9578 - loss: 0.1110 - val_accuracy: 0.9643 - val_loss: 0.1063\n",
      "Epoch 463/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9612 - loss: 0.1032 - val_accuracy: 0.9622 - val_loss: 0.1100\n",
      "Epoch 464/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9643 - loss: 0.0956 - val_accuracy: 0.9643 - val_loss: 0.1118\n",
      "Epoch 465/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9621 - loss: 0.1084 - val_accuracy: 0.9643 - val_loss: 0.1085\n",
      "Epoch 466/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9587 - loss: 0.1083 - val_accuracy: 0.9663 - val_loss: 0.1088\n",
      "Epoch 467/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9574 - loss: 0.1153 - val_accuracy: 0.9643 - val_loss: 0.1101\n",
      "Epoch 468/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9570 - loss: 0.1136 - val_accuracy: 0.9653 - val_loss: 0.1071\n",
      "Epoch 469/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9572 - loss: 0.1052 - val_accuracy: 0.9653 - val_loss: 0.1065\n",
      "Epoch 470/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9623 - loss: 0.1156 - val_accuracy: 0.9663 - val_loss: 0.1121\n",
      "Epoch 471/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9578 - loss: 0.1106 - val_accuracy: 0.9684 - val_loss: 0.1084\n",
      "Epoch 472/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9530 - loss: 0.1213 - val_accuracy: 0.9673 - val_loss: 0.1056\n",
      "Epoch 473/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9524 - loss: 0.1210 - val_accuracy: 0.9673 - val_loss: 0.1065\n",
      "Epoch 474/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9592 - loss: 0.1091 - val_accuracy: 0.9684 - val_loss: 0.1109\n",
      "Epoch 475/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9595 - loss: 0.1134 - val_accuracy: 0.9633 - val_loss: 0.1108\n",
      "Epoch 476/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9616 - loss: 0.1018 - val_accuracy: 0.9622 - val_loss: 0.1126\n",
      "Epoch 477/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9617 - loss: 0.0974 - val_accuracy: 0.9622 - val_loss: 0.1071\n",
      "Epoch 478/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9609 - loss: 0.1070 - val_accuracy: 0.9653 - val_loss: 0.1094\n",
      "Epoch 479/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9580 - loss: 0.1075 - val_accuracy: 0.9602 - val_loss: 0.1138\n",
      "Epoch 480/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9588 - loss: 0.1093 - val_accuracy: 0.9633 - val_loss: 0.1115\n",
      "Epoch 481/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9617 - loss: 0.1060 - val_accuracy: 0.9643 - val_loss: 0.1085\n",
      "Epoch 482/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9571 - loss: 0.1069 - val_accuracy: 0.9653 - val_loss: 0.1098\n",
      "Epoch 483/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9574 - loss: 0.1094 - val_accuracy: 0.9643 - val_loss: 0.1134\n",
      "Epoch 484/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9521 - loss: 0.1250 - val_accuracy: 0.9602 - val_loss: 0.1138\n",
      "Epoch 485/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9578 - loss: 0.1145 - val_accuracy: 0.9673 - val_loss: 0.1102\n",
      "Epoch 486/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9581 - loss: 0.1107 - val_accuracy: 0.9643 - val_loss: 0.1051\n",
      "Epoch 487/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9611 - loss: 0.0998 - val_accuracy: 0.9673 - val_loss: 0.1117\n",
      "Epoch 488/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9616 - loss: 0.1002 - val_accuracy: 0.9663 - val_loss: 0.1090\n",
      "Epoch 489/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9592 - loss: 0.1052 - val_accuracy: 0.9643 - val_loss: 0.1109\n",
      "Epoch 490/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9601 - loss: 0.1092 - val_accuracy: 0.9684 - val_loss: 0.1072\n",
      "Epoch 491/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9554 - loss: 0.1089 - val_accuracy: 0.9643 - val_loss: 0.1094\n",
      "Epoch 492/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9590 - loss: 0.1198 - val_accuracy: 0.9673 - val_loss: 0.1061\n",
      "Epoch 493/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9570 - loss: 0.1153 - val_accuracy: 0.9622 - val_loss: 0.1110\n",
      "Epoch 494/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9559 - loss: 0.1099 - val_accuracy: 0.9673 - val_loss: 0.1049\n",
      "Epoch 495/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9553 - loss: 0.1190 - val_accuracy: 0.9673 - val_loss: 0.1045\n",
      "Epoch 496/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9541 - loss: 0.1173 - val_accuracy: 0.9673 - val_loss: 0.1051\n",
      "Epoch 497/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9516 - loss: 0.1193 - val_accuracy: 0.9663 - val_loss: 0.1046\n",
      "Epoch 498/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9617 - loss: 0.1034 - val_accuracy: 0.9673 - val_loss: 0.1091\n",
      "Epoch 499/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9632 - loss: 0.1121 - val_accuracy: 0.9653 - val_loss: 0.1099\n",
      "Epoch 500/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9665 - loss: 0.0952 - val_accuracy: 0.9673 - val_loss: 0.1090\n",
      "Epoch 501/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9557 - loss: 0.1100 - val_accuracy: 0.9633 - val_loss: 0.1080\n",
      "Epoch 502/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9555 - loss: 0.1118 - val_accuracy: 0.9653 - val_loss: 0.1053\n",
      "Epoch 503/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9584 - loss: 0.1083 - val_accuracy: 0.9684 - val_loss: 0.1055\n",
      "Epoch 504/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9571 - loss: 0.1129 - val_accuracy: 0.9653 - val_loss: 0.1079\n",
      "Epoch 505/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9504 - loss: 0.1174 - val_accuracy: 0.9653 - val_loss: 0.1076\n",
      "Epoch 506/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9566 - loss: 0.1183 - val_accuracy: 0.9643 - val_loss: 0.1094\n",
      "Epoch 507/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9547 - loss: 0.1072 - val_accuracy: 0.9622 - val_loss: 0.1117\n",
      "Epoch 508/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9579 - loss: 0.1127 - val_accuracy: 0.9673 - val_loss: 0.1058\n",
      "Epoch 509/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9611 - loss: 0.1028 - val_accuracy: 0.9663 - val_loss: 0.1118\n",
      "Epoch 510/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9568 - loss: 0.1111 - val_accuracy: 0.9633 - val_loss: 0.1074\n",
      "Epoch 511/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9596 - loss: 0.1028 - val_accuracy: 0.9694 - val_loss: 0.1063\n",
      "Epoch 512/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9615 - loss: 0.1013 - val_accuracy: 0.9633 - val_loss: 0.1054\n",
      "Epoch 513/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9599 - loss: 0.1056 - val_accuracy: 0.9663 - val_loss: 0.1103\n",
      "Epoch 514/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9540 - loss: 0.1127 - val_accuracy: 0.9684 - val_loss: 0.1073\n",
      "Epoch 515/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9555 - loss: 0.1108 - val_accuracy: 0.9663 - val_loss: 0.1078\n",
      "Epoch 516/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9580 - loss: 0.1127 - val_accuracy: 0.9633 - val_loss: 0.1088\n",
      "Epoch 517/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9613 - loss: 0.0993 - val_accuracy: 0.9643 - val_loss: 0.1099\n",
      "Epoch 518/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9551 - loss: 0.1130 - val_accuracy: 0.9653 - val_loss: 0.1082\n",
      "Epoch 519/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9572 - loss: 0.1131 - val_accuracy: 0.9633 - val_loss: 0.1078\n",
      "Epoch 520/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9568 - loss: 0.1171 - val_accuracy: 0.9633 - val_loss: 0.1100\n",
      "Epoch 521/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9633 - loss: 0.1028 - val_accuracy: 0.9653 - val_loss: 0.1094\n",
      "Epoch 522/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9566 - loss: 0.1108 - val_accuracy: 0.9633 - val_loss: 0.1099\n",
      "Epoch 523/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9639 - loss: 0.0961 - val_accuracy: 0.9633 - val_loss: 0.1099\n",
      "Epoch 524/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9591 - loss: 0.1014 - val_accuracy: 0.9592 - val_loss: 0.1136\n",
      "Epoch 525/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9600 - loss: 0.1079 - val_accuracy: 0.9633 - val_loss: 0.1146\n",
      "Epoch 526/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9610 - loss: 0.1040 - val_accuracy: 0.9633 - val_loss: 0.1108\n",
      "Epoch 527/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9608 - loss: 0.1011 - val_accuracy: 0.9653 - val_loss: 0.1098\n",
      "Epoch 528/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9614 - loss: 0.0972 - val_accuracy: 0.9643 - val_loss: 0.1126\n",
      "Epoch 529/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9603 - loss: 0.1091 - val_accuracy: 0.9643 - val_loss: 0.1104\n",
      "Epoch 530/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9579 - loss: 0.1150 - val_accuracy: 0.9622 - val_loss: 0.1102\n",
      "Epoch 531/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9573 - loss: 0.1087 - val_accuracy: 0.9622 - val_loss: 0.1132\n",
      "Epoch 532/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9527 - loss: 0.1144 - val_accuracy: 0.9622 - val_loss: 0.1136\n",
      "Epoch 533/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9625 - loss: 0.1064 - val_accuracy: 0.9622 - val_loss: 0.1114\n",
      "Epoch 534/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9611 - loss: 0.1026 - val_accuracy: 0.9633 - val_loss: 0.1145\n",
      "Epoch 535/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9555 - loss: 0.1194 - val_accuracy: 0.9633 - val_loss: 0.1093\n",
      "Epoch 536/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9597 - loss: 0.1093 - val_accuracy: 0.9643 - val_loss: 0.1112\n",
      "Epoch 537/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9621 - loss: 0.1006 - val_accuracy: 0.9653 - val_loss: 0.1082\n",
      "Epoch 538/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9584 - loss: 0.1047 - val_accuracy: 0.9633 - val_loss: 0.1174\n",
      "Epoch 539/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9582 - loss: 0.1086 - val_accuracy: 0.9633 - val_loss: 0.1105\n",
      "Epoch 540/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9640 - loss: 0.1028 - val_accuracy: 0.9643 - val_loss: 0.1100\n",
      "Epoch 541/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9600 - loss: 0.1056 - val_accuracy: 0.9612 - val_loss: 0.1102\n",
      "Epoch 542/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9629 - loss: 0.1062 - val_accuracy: 0.9653 - val_loss: 0.1105\n",
      "Epoch 543/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9583 - loss: 0.1076 - val_accuracy: 0.9622 - val_loss: 0.1134\n",
      "Epoch 544/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9620 - loss: 0.1037 - val_accuracy: 0.9643 - val_loss: 0.1106\n",
      "Epoch 545/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9634 - loss: 0.0981 - val_accuracy: 0.9633 - val_loss: 0.1122\n",
      "Epoch 546/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9590 - loss: 0.1023 - val_accuracy: 0.9633 - val_loss: 0.1097\n",
      "Epoch 547/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9601 - loss: 0.0978 - val_accuracy: 0.9663 - val_loss: 0.1098\n",
      "Epoch 548/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9580 - loss: 0.1032 - val_accuracy: 0.9653 - val_loss: 0.1081\n",
      "Epoch 549/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9577 - loss: 0.1143 - val_accuracy: 0.9653 - val_loss: 0.1149\n",
      "Epoch 550/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9653 - loss: 0.0899 - val_accuracy: 0.9633 - val_loss: 0.1180\n",
      "Epoch 551/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9604 - loss: 0.1058 - val_accuracy: 0.9622 - val_loss: 0.1095\n",
      "Epoch 552/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9580 - loss: 0.1121 - val_accuracy: 0.9622 - val_loss: 0.1076\n",
      "Epoch 553/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9542 - loss: 0.1087 - val_accuracy: 0.9633 - val_loss: 0.1070\n",
      "Epoch 554/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9589 - loss: 0.1097 - val_accuracy: 0.9663 - val_loss: 0.1102\n",
      "Epoch 555/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9576 - loss: 0.1036 - val_accuracy: 0.9643 - val_loss: 0.1115\n",
      "Epoch 556/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9546 - loss: 0.1172 - val_accuracy: 0.9653 - val_loss: 0.1082\n",
      "Epoch 557/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9634 - loss: 0.0949 - val_accuracy: 0.9643 - val_loss: 0.1086\n",
      "Epoch 558/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9558 - loss: 0.1143 - val_accuracy: 0.9633 - val_loss: 0.1082\n",
      "Epoch 559/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9584 - loss: 0.1128 - val_accuracy: 0.9633 - val_loss: 0.1108\n",
      "Epoch 560/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9598 - loss: 0.1133 - val_accuracy: 0.9643 - val_loss: 0.1122\n",
      "Epoch 561/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9617 - loss: 0.1074 - val_accuracy: 0.9643 - val_loss: 0.1131\n",
      "Epoch 562/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9602 - loss: 0.0973 - val_accuracy: 0.9612 - val_loss: 0.1119\n",
      "Epoch 563/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9557 - loss: 0.1156 - val_accuracy: 0.9643 - val_loss: 0.1123\n",
      "Epoch 564/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9586 - loss: 0.1142 - val_accuracy: 0.9633 - val_loss: 0.1129\n",
      "Epoch 565/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9623 - loss: 0.1018 - val_accuracy: 0.9582 - val_loss: 0.1113\n",
      "Epoch 566/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9638 - loss: 0.0952 - val_accuracy: 0.9622 - val_loss: 0.1168\n",
      "Epoch 567/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9589 - loss: 0.1068 - val_accuracy: 0.9653 - val_loss: 0.1114\n",
      "Epoch 568/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9595 - loss: 0.1031 - val_accuracy: 0.9663 - val_loss: 0.1116\n",
      "Epoch 569/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9571 - loss: 0.1079 - val_accuracy: 0.9622 - val_loss: 0.1119\n",
      "Epoch 570/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9560 - loss: 0.1142 - val_accuracy: 0.9612 - val_loss: 0.1166\n",
      "Epoch 571/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9620 - loss: 0.1035 - val_accuracy: 0.9602 - val_loss: 0.1144\n",
      "Epoch 572/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9535 - loss: 0.1132 - val_accuracy: 0.9684 - val_loss: 0.1113\n",
      "Epoch 573/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9606 - loss: 0.1057 - val_accuracy: 0.9643 - val_loss: 0.1168\n",
      "Epoch 574/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9627 - loss: 0.1013 - val_accuracy: 0.9643 - val_loss: 0.1141\n",
      "Epoch 575/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9594 - loss: 0.1102 - val_accuracy: 0.9633 - val_loss: 0.1161\n",
      "Epoch 576/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9567 - loss: 0.1149 - val_accuracy: 0.9622 - val_loss: 0.1148\n",
      "Epoch 577/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9582 - loss: 0.1168 - val_accuracy: 0.9643 - val_loss: 0.1117\n",
      "Epoch 578/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9572 - loss: 0.1107 - val_accuracy: 0.9622 - val_loss: 0.1169\n",
      "Epoch 579/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9588 - loss: 0.1113 - val_accuracy: 0.9633 - val_loss: 0.1138\n",
      "Epoch 580/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9605 - loss: 0.1029 - val_accuracy: 0.9612 - val_loss: 0.1124\n",
      "Epoch 581/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9585 - loss: 0.1135 - val_accuracy: 0.9643 - val_loss: 0.1132\n",
      "Epoch 582/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9602 - loss: 0.1071 - val_accuracy: 0.9592 - val_loss: 0.1081\n",
      "Epoch 583/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9610 - loss: 0.1132 - val_accuracy: 0.9643 - val_loss: 0.1071\n",
      "Epoch 584/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9503 - loss: 0.1237 - val_accuracy: 0.9663 - val_loss: 0.1084\n",
      "Epoch 585/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9625 - loss: 0.1011 - val_accuracy: 0.9653 - val_loss: 0.1068\n",
      "Epoch 586/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9645 - loss: 0.0943 - val_accuracy: 0.9643 - val_loss: 0.1070\n",
      "Epoch 587/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9598 - loss: 0.0992 - val_accuracy: 0.9643 - val_loss: 0.1077\n",
      "Epoch 588/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9593 - loss: 0.1096 - val_accuracy: 0.9643 - val_loss: 0.1093\n",
      "Epoch 589/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9661 - loss: 0.0887 - val_accuracy: 0.9653 - val_loss: 0.1072\n",
      "Epoch 590/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9624 - loss: 0.1081 - val_accuracy: 0.9633 - val_loss: 0.1101\n",
      "Epoch 591/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9642 - loss: 0.0887 - val_accuracy: 0.9653 - val_loss: 0.1140\n",
      "Epoch 592/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9579 - loss: 0.1059 - val_accuracy: 0.9653 - val_loss: 0.1142\n",
      "Epoch 593/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9647 - loss: 0.0932 - val_accuracy: 0.9633 - val_loss: 0.1112\n",
      "Epoch 594/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9611 - loss: 0.1021 - val_accuracy: 0.9663 - val_loss: 0.1092\n",
      "Epoch 595/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9577 - loss: 0.1114 - val_accuracy: 0.9653 - val_loss: 0.1025\n",
      "Epoch 596/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9618 - loss: 0.0990 - val_accuracy: 0.9684 - val_loss: 0.1069\n",
      "Epoch 597/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9576 - loss: 0.1150 - val_accuracy: 0.9684 - val_loss: 0.1078\n",
      "Epoch 598/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9657 - loss: 0.0931 - val_accuracy: 0.9673 - val_loss: 0.1073\n",
      "Epoch 599/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9580 - loss: 0.1111 - val_accuracy: 0.9694 - val_loss: 0.1116\n",
      "Epoch 600/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9526 - loss: 0.1140 - val_accuracy: 0.9663 - val_loss: 0.1063\n",
      "Epoch 601/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9609 - loss: 0.1034 - val_accuracy: 0.9653 - val_loss: 0.1101\n",
      "Epoch 602/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9608 - loss: 0.1090 - val_accuracy: 0.9684 - val_loss: 0.1097\n",
      "Epoch 603/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9650 - loss: 0.0946 - val_accuracy: 0.9663 - val_loss: 0.1051\n",
      "Epoch 604/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9637 - loss: 0.1065 - val_accuracy: 0.9663 - val_loss: 0.1076\n",
      "Epoch 605/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9626 - loss: 0.0998 - val_accuracy: 0.9673 - val_loss: 0.1069\n",
      "Epoch 606/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9567 - loss: 0.1159 - val_accuracy: 0.9633 - val_loss: 0.1069\n",
      "Epoch 607/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9629 - loss: 0.0980 - val_accuracy: 0.9643 - val_loss: 0.1072\n",
      "Epoch 608/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9638 - loss: 0.0999 - val_accuracy: 0.9653 - val_loss: 0.1063\n",
      "Epoch 609/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9585 - loss: 0.1041 - val_accuracy: 0.9612 - val_loss: 0.1092\n",
      "Epoch 610/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9596 - loss: 0.1011 - val_accuracy: 0.9653 - val_loss: 0.1095\n",
      "Epoch 611/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9569 - loss: 0.1131 - val_accuracy: 0.9633 - val_loss: 0.1064\n",
      "Epoch 612/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9613 - loss: 0.0986 - val_accuracy: 0.9673 - val_loss: 0.1046\n",
      "Epoch 613/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9642 - loss: 0.1086 - val_accuracy: 0.9663 - val_loss: 0.1101\n",
      "Epoch 614/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9616 - loss: 0.1075 - val_accuracy: 0.9643 - val_loss: 0.1070\n",
      "Epoch 615/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9580 - loss: 0.1140 - val_accuracy: 0.9673 - val_loss: 0.1075\n",
      "Epoch 616/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9582 - loss: 0.0997 - val_accuracy: 0.9673 - val_loss: 0.1059\n",
      "Epoch 617/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9602 - loss: 0.0978 - val_accuracy: 0.9643 - val_loss: 0.1043\n",
      "Epoch 618/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9602 - loss: 0.1046 - val_accuracy: 0.9663 - val_loss: 0.1066\n",
      "Epoch 619/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9637 - loss: 0.1003 - val_accuracy: 0.9663 - val_loss: 0.1067\n",
      "Epoch 620/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9647 - loss: 0.0905 - val_accuracy: 0.9653 - val_loss: 0.1073\n",
      "Epoch 621/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9628 - loss: 0.0897 - val_accuracy: 0.9622 - val_loss: 0.1145\n",
      "Epoch 622/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9638 - loss: 0.0970 - val_accuracy: 0.9673 - val_loss: 0.1074\n",
      "Epoch 623/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9650 - loss: 0.0947 - val_accuracy: 0.9684 - val_loss: 0.1111\n",
      "Epoch 624/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9545 - loss: 0.1217 - val_accuracy: 0.9663 - val_loss: 0.1059\n",
      "Epoch 625/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9634 - loss: 0.0949 - val_accuracy: 0.9663 - val_loss: 0.1091\n",
      "Epoch 626/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9608 - loss: 0.1005 - val_accuracy: 0.9663 - val_loss: 0.1105\n",
      "Epoch 627/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9555 - loss: 0.1161 - val_accuracy: 0.9633 - val_loss: 0.1121\n",
      "Epoch 628/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9595 - loss: 0.1069 - val_accuracy: 0.9673 - val_loss: 0.1105\n",
      "Epoch 629/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9534 - loss: 0.1243 - val_accuracy: 0.9673 - val_loss: 0.1083\n",
      "Epoch 630/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9572 - loss: 0.1086 - val_accuracy: 0.9653 - val_loss: 0.1145\n",
      "Epoch 631/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9618 - loss: 0.1052 - val_accuracy: 0.9653 - val_loss: 0.1095\n",
      "Epoch 632/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9669 - loss: 0.0909 - val_accuracy: 0.9643 - val_loss: 0.1051\n",
      "Epoch 633/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9611 - loss: 0.1067 - val_accuracy: 0.9653 - val_loss: 0.1056\n",
      "Epoch 634/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9632 - loss: 0.0950 - val_accuracy: 0.9653 - val_loss: 0.1071\n",
      "Epoch 635/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9642 - loss: 0.0998 - val_accuracy: 0.9663 - val_loss: 0.1086\n",
      "Epoch 636/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9589 - loss: 0.1029 - val_accuracy: 0.9653 - val_loss: 0.1068\n",
      "Epoch 637/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9572 - loss: 0.1039 - val_accuracy: 0.9673 - val_loss: 0.1117\n",
      "Epoch 638/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9621 - loss: 0.1079 - val_accuracy: 0.9653 - val_loss: 0.1083\n",
      "Epoch 639/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9618 - loss: 0.0955 - val_accuracy: 0.9663 - val_loss: 0.1098\n",
      "Epoch 640/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9573 - loss: 0.1070 - val_accuracy: 0.9633 - val_loss: 0.1133\n",
      "Epoch 641/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9618 - loss: 0.1001 - val_accuracy: 0.9694 - val_loss: 0.1111\n",
      "Epoch 642/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9628 - loss: 0.0992 - val_accuracy: 0.9663 - val_loss: 0.1062\n",
      "Epoch 643/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9649 - loss: 0.0936 - val_accuracy: 0.9663 - val_loss: 0.1090\n",
      "Epoch 644/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9565 - loss: 0.1149 - val_accuracy: 0.9663 - val_loss: 0.1036\n",
      "Epoch 645/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9628 - loss: 0.0970 - val_accuracy: 0.9663 - val_loss: 0.1094\n",
      "Epoch 646/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9565 - loss: 0.1045 - val_accuracy: 0.9684 - val_loss: 0.1096\n",
      "Epoch 647/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9640 - loss: 0.1024 - val_accuracy: 0.9663 - val_loss: 0.1102\n",
      "Epoch 648/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9656 - loss: 0.0909 - val_accuracy: 0.9704 - val_loss: 0.1103\n",
      "Epoch 649/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9586 - loss: 0.1117 - val_accuracy: 0.9673 - val_loss: 0.1071\n",
      "Epoch 650/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9591 - loss: 0.1047 - val_accuracy: 0.9663 - val_loss: 0.1102\n",
      "Epoch 651/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9551 - loss: 0.1079 - val_accuracy: 0.9704 - val_loss: 0.1119\n",
      "Epoch 652/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9590 - loss: 0.1033 - val_accuracy: 0.9663 - val_loss: 0.1102\n",
      "Epoch 653/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9601 - loss: 0.1035 - val_accuracy: 0.9653 - val_loss: 0.1122\n",
      "Epoch 654/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9601 - loss: 0.1023 - val_accuracy: 0.9653 - val_loss: 0.1076\n",
      "Epoch 655/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9597 - loss: 0.1095 - val_accuracy: 0.9673 - val_loss: 0.1093\n",
      "Epoch 656/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9609 - loss: 0.1029 - val_accuracy: 0.9673 - val_loss: 0.1077\n",
      "Epoch 657/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9611 - loss: 0.1066 - val_accuracy: 0.9663 - val_loss: 0.1063\n",
      "Epoch 658/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9624 - loss: 0.0979 - val_accuracy: 0.9673 - val_loss: 0.1063\n",
      "Epoch 659/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9603 - loss: 0.1056 - val_accuracy: 0.9684 - val_loss: 0.1050\n",
      "Epoch 660/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9619 - loss: 0.1020 - val_accuracy: 0.9673 - val_loss: 0.1087\n",
      "Epoch 661/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9637 - loss: 0.0981 - val_accuracy: 0.9694 - val_loss: 0.1071\n",
      "Epoch 662/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9611 - loss: 0.1092 - val_accuracy: 0.9684 - val_loss: 0.1093\n",
      "Epoch 663/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9614 - loss: 0.0999 - val_accuracy: 0.9684 - val_loss: 0.1061\n",
      "Epoch 664/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9615 - loss: 0.1113 - val_accuracy: 0.9663 - val_loss: 0.1047\n",
      "Epoch 665/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9592 - loss: 0.1022 - val_accuracy: 0.9673 - val_loss: 0.1076\n",
      "Epoch 666/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9618 - loss: 0.1032 - val_accuracy: 0.9673 - val_loss: 0.1078\n",
      "Epoch 667/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9599 - loss: 0.1059 - val_accuracy: 0.9653 - val_loss: 0.1091\n",
      "Epoch 668/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9617 - loss: 0.1033 - val_accuracy: 0.9673 - val_loss: 0.1082\n",
      "Epoch 669/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9583 - loss: 0.1132 - val_accuracy: 0.9663 - val_loss: 0.1108\n",
      "Epoch 670/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9658 - loss: 0.0929 - val_accuracy: 0.9622 - val_loss: 0.1112\n",
      "Epoch 671/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9652 - loss: 0.0974 - val_accuracy: 0.9673 - val_loss: 0.1078\n",
      "Epoch 672/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9651 - loss: 0.0942 - val_accuracy: 0.9694 - val_loss: 0.1084\n",
      "Epoch 673/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9617 - loss: 0.1103 - val_accuracy: 0.9663 - val_loss: 0.1075\n",
      "Epoch 674/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9592 - loss: 0.1006 - val_accuracy: 0.9653 - val_loss: 0.1117\n",
      "Epoch 675/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9623 - loss: 0.1006 - val_accuracy: 0.9653 - val_loss: 0.1094\n",
      "Epoch 676/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9611 - loss: 0.1058 - val_accuracy: 0.9684 - val_loss: 0.1061\n",
      "Epoch 677/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9596 - loss: 0.1131 - val_accuracy: 0.9684 - val_loss: 0.1103\n",
      "Epoch 678/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9642 - loss: 0.0950 - val_accuracy: 0.9673 - val_loss: 0.1047\n",
      "Epoch 679/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9596 - loss: 0.1098 - val_accuracy: 0.9643 - val_loss: 0.1041\n",
      "Epoch 680/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9641 - loss: 0.0993 - val_accuracy: 0.9633 - val_loss: 0.1178\n",
      "Epoch 681/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9582 - loss: 0.1062 - val_accuracy: 0.9653 - val_loss: 0.1075\n",
      "Epoch 682/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9624 - loss: 0.1091 - val_accuracy: 0.9653 - val_loss: 0.1047\n",
      "Epoch 683/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9613 - loss: 0.0915 - val_accuracy: 0.9653 - val_loss: 0.1044\n",
      "Epoch 684/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9641 - loss: 0.1020 - val_accuracy: 0.9673 - val_loss: 0.1037\n",
      "Epoch 685/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9604 - loss: 0.1091 - val_accuracy: 0.9673 - val_loss: 0.1046\n",
      "Epoch 686/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9656 - loss: 0.0974 - val_accuracy: 0.9663 - val_loss: 0.1028\n",
      "Epoch 687/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9635 - loss: 0.1043 - val_accuracy: 0.9684 - val_loss: 0.1042\n",
      "Epoch 688/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9577 - loss: 0.1094 - val_accuracy: 0.9643 - val_loss: 0.1075\n",
      "Epoch 689/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9596 - loss: 0.1023 - val_accuracy: 0.9643 - val_loss: 0.1033\n",
      "Epoch 690/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9598 - loss: 0.1068 - val_accuracy: 0.9694 - val_loss: 0.1006\n",
      "Epoch 691/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9613 - loss: 0.1073 - val_accuracy: 0.9694 - val_loss: 0.1008\n",
      "Epoch 692/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9628 - loss: 0.0963 - val_accuracy: 0.9704 - val_loss: 0.0982\n",
      "Epoch 693/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9569 - loss: 0.1061 - val_accuracy: 0.9694 - val_loss: 0.1036\n",
      "Epoch 694/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9626 - loss: 0.0999 - val_accuracy: 0.9714 - val_loss: 0.1046\n",
      "Epoch 695/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9576 - loss: 0.1084 - val_accuracy: 0.9673 - val_loss: 0.1009\n",
      "Epoch 696/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9627 - loss: 0.0954 - val_accuracy: 0.9694 - val_loss: 0.1027\n",
      "Epoch 697/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9609 - loss: 0.1062 - val_accuracy: 0.9653 - val_loss: 0.1042\n",
      "Epoch 698/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9612 - loss: 0.0961 - val_accuracy: 0.9653 - val_loss: 0.1053\n",
      "Epoch 699/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9612 - loss: 0.0997 - val_accuracy: 0.9643 - val_loss: 0.1070\n",
      "Epoch 700/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9591 - loss: 0.1086 - val_accuracy: 0.9684 - val_loss: 0.1035\n",
      "Epoch 701/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9591 - loss: 0.1134 - val_accuracy: 0.9684 - val_loss: 0.1050\n",
      "Epoch 702/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9536 - loss: 0.1228 - val_accuracy: 0.9694 - val_loss: 0.1057\n",
      "Epoch 703/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9627 - loss: 0.1037 - val_accuracy: 0.9663 - val_loss: 0.1044\n",
      "Epoch 704/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9643 - loss: 0.1046 - val_accuracy: 0.9653 - val_loss: 0.1098\n",
      "Epoch 705/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9598 - loss: 0.1021 - val_accuracy: 0.9663 - val_loss: 0.1049\n",
      "Epoch 706/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9600 - loss: 0.1002 - val_accuracy: 0.9653 - val_loss: 0.1088\n",
      "Epoch 707/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9572 - loss: 0.1048 - val_accuracy: 0.9622 - val_loss: 0.1150\n",
      "Epoch 708/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9658 - loss: 0.0934 - val_accuracy: 0.9653 - val_loss: 0.1042\n",
      "Epoch 709/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9623 - loss: 0.1037 - val_accuracy: 0.9643 - val_loss: 0.1078\n",
      "Epoch 710/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9615 - loss: 0.0988 - val_accuracy: 0.9633 - val_loss: 0.1124\n",
      "Epoch 711/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9611 - loss: 0.0963 - val_accuracy: 0.9684 - val_loss: 0.1071\n",
      "Epoch 712/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9622 - loss: 0.0986 - val_accuracy: 0.9643 - val_loss: 0.1037\n",
      "Epoch 713/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9598 - loss: 0.1038 - val_accuracy: 0.9643 - val_loss: 0.1123\n",
      "Epoch 714/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9632 - loss: 0.0990 - val_accuracy: 0.9673 - val_loss: 0.1070\n",
      "Epoch 715/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9581 - loss: 0.1033 - val_accuracy: 0.9694 - val_loss: 0.1087\n",
      "Epoch 716/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9624 - loss: 0.0996 - val_accuracy: 0.9663 - val_loss: 0.1079\n",
      "Epoch 717/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9657 - loss: 0.0921 - val_accuracy: 0.9663 - val_loss: 0.1064\n",
      "Epoch 718/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9620 - loss: 0.1056 - val_accuracy: 0.9673 - val_loss: 0.1043\n",
      "Epoch 719/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9604 - loss: 0.1097 - val_accuracy: 0.9663 - val_loss: 0.1035\n",
      "Epoch 720/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9577 - loss: 0.1139 - val_accuracy: 0.9653 - val_loss: 0.1089\n",
      "Epoch 721/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9610 - loss: 0.1075 - val_accuracy: 0.9653 - val_loss: 0.1148\n",
      "Epoch 722/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9603 - loss: 0.1086 - val_accuracy: 0.9633 - val_loss: 0.1036\n",
      "Epoch 723/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9626 - loss: 0.1053 - val_accuracy: 0.9653 - val_loss: 0.1105\n",
      "Epoch 724/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9617 - loss: 0.0994 - val_accuracy: 0.9673 - val_loss: 0.1072\n",
      "Epoch 725/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9649 - loss: 0.1011 - val_accuracy: 0.9643 - val_loss: 0.1072\n",
      "Epoch 726/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9589 - loss: 0.1056 - val_accuracy: 0.9653 - val_loss: 0.1084\n",
      "Epoch 727/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9633 - loss: 0.0965 - val_accuracy: 0.9673 - val_loss: 0.1045\n",
      "Epoch 728/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9579 - loss: 0.1111 - val_accuracy: 0.9663 - val_loss: 0.0997\n",
      "Epoch 729/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9625 - loss: 0.1006 - val_accuracy: 0.9653 - val_loss: 0.1044\n",
      "Epoch 730/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9589 - loss: 0.1106 - val_accuracy: 0.9673 - val_loss: 0.1048\n",
      "Epoch 731/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9615 - loss: 0.0999 - val_accuracy: 0.9653 - val_loss: 0.1063\n",
      "Epoch 732/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9569 - loss: 0.1121 - val_accuracy: 0.9612 - val_loss: 0.1203\n",
      "Epoch 733/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9603 - loss: 0.1097 - val_accuracy: 0.9653 - val_loss: 0.1065\n",
      "Epoch 734/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9599 - loss: 0.1037 - val_accuracy: 0.9643 - val_loss: 0.1091\n",
      "Epoch 735/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9580 - loss: 0.1067 - val_accuracy: 0.9643 - val_loss: 0.1137\n",
      "Epoch 736/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9628 - loss: 0.1018 - val_accuracy: 0.9653 - val_loss: 0.1029\n",
      "Epoch 737/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9641 - loss: 0.0989 - val_accuracy: 0.9633 - val_loss: 0.1041\n",
      "Epoch 738/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9618 - loss: 0.0986 - val_accuracy: 0.9673 - val_loss: 0.1077\n",
      "Epoch 739/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9641 - loss: 0.0914 - val_accuracy: 0.9663 - val_loss: 0.1100\n",
      "Epoch 740/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9642 - loss: 0.0958 - val_accuracy: 0.9653 - val_loss: 0.1078\n",
      "Epoch 741/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9589 - loss: 0.1079 - val_accuracy: 0.9612 - val_loss: 0.1095\n",
      "Epoch 742/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9646 - loss: 0.0969 - val_accuracy: 0.9653 - val_loss: 0.1095\n",
      "Epoch 743/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9623 - loss: 0.1077 - val_accuracy: 0.9633 - val_loss: 0.1078\n",
      "Epoch 744/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9626 - loss: 0.1025 - val_accuracy: 0.9653 - val_loss: 0.1052\n",
      "Epoch 745/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9646 - loss: 0.0942 - val_accuracy: 0.9663 - val_loss: 0.1050\n",
      "Epoch 746/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9593 - loss: 0.1025 - val_accuracy: 0.9663 - val_loss: 0.1085\n",
      "Epoch 747/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9634 - loss: 0.0924 - val_accuracy: 0.9673 - val_loss: 0.1080\n",
      "Epoch 748/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9649 - loss: 0.0969 - val_accuracy: 0.9663 - val_loss: 0.1097\n",
      "Epoch 749/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9589 - loss: 0.1067 - val_accuracy: 0.9653 - val_loss: 0.1120\n",
      "Epoch 750/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9601 - loss: 0.1071 - val_accuracy: 0.9653 - val_loss: 0.1114\n",
      "Epoch 751/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9603 - loss: 0.1113 - val_accuracy: 0.9633 - val_loss: 0.1058\n",
      "Epoch 752/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9537 - loss: 0.1275 - val_accuracy: 0.9643 - val_loss: 0.1099\n",
      "Epoch 753/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9601 - loss: 0.1104 - val_accuracy: 0.9633 - val_loss: 0.1078\n",
      "Epoch 754/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9634 - loss: 0.0948 - val_accuracy: 0.9663 - val_loss: 0.1074\n",
      "Epoch 755/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9583 - loss: 0.1098 - val_accuracy: 0.9643 - val_loss: 0.1102\n",
      "Epoch 756/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9632 - loss: 0.0959 - val_accuracy: 0.9653 - val_loss: 0.1077\n",
      "Epoch 757/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9664 - loss: 0.0880 - val_accuracy: 0.9673 - val_loss: 0.1115\n",
      "Epoch 758/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9634 - loss: 0.0893 - val_accuracy: 0.9633 - val_loss: 0.1101\n",
      "Epoch 759/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9615 - loss: 0.0948 - val_accuracy: 0.9612 - val_loss: 0.1099\n",
      "Epoch 760/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9633 - loss: 0.1015 - val_accuracy: 0.9643 - val_loss: 0.1124\n",
      "Epoch 761/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9644 - loss: 0.0994 - val_accuracy: 0.9592 - val_loss: 0.1217\n",
      "Epoch 762/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9562 - loss: 0.1075 - val_accuracy: 0.9643 - val_loss: 0.1125\n",
      "Epoch 763/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9621 - loss: 0.0977 - val_accuracy: 0.9633 - val_loss: 0.1080\n",
      "Epoch 764/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9638 - loss: 0.1049 - val_accuracy: 0.9643 - val_loss: 0.1111\n",
      "Epoch 765/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9616 - loss: 0.1055 - val_accuracy: 0.9663 - val_loss: 0.1056\n",
      "Epoch 766/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9626 - loss: 0.0993 - val_accuracy: 0.9653 - val_loss: 0.1065\n",
      "Epoch 767/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9592 - loss: 0.1020 - val_accuracy: 0.9653 - val_loss: 0.1072\n",
      "Epoch 768/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9635 - loss: 0.1004 - val_accuracy: 0.9663 - val_loss: 0.1076\n",
      "Epoch 769/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9644 - loss: 0.0973 - val_accuracy: 0.9663 - val_loss: 0.1074\n",
      "Epoch 770/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9597 - loss: 0.1063 - val_accuracy: 0.9633 - val_loss: 0.1080\n",
      "Epoch 771/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9616 - loss: 0.1075 - val_accuracy: 0.9673 - val_loss: 0.1094\n",
      "Epoch 772/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9613 - loss: 0.1021 - val_accuracy: 0.9673 - val_loss: 0.1084\n",
      "Epoch 773/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9565 - loss: 0.1135 - val_accuracy: 0.9602 - val_loss: 0.1085\n",
      "Epoch 774/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9627 - loss: 0.0946 - val_accuracy: 0.9653 - val_loss: 0.1073\n",
      "Epoch 775/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9670 - loss: 0.0965 - val_accuracy: 0.9663 - val_loss: 0.1075\n",
      "Epoch 776/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9597 - loss: 0.1127 - val_accuracy: 0.9684 - val_loss: 0.1070\n",
      "Epoch 777/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9549 - loss: 0.1134 - val_accuracy: 0.9643 - val_loss: 0.1065\n",
      "Epoch 778/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9626 - loss: 0.1057 - val_accuracy: 0.9643 - val_loss: 0.1058\n",
      "Epoch 779/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9608 - loss: 0.1012 - val_accuracy: 0.9653 - val_loss: 0.1069\n",
      "Epoch 780/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9573 - loss: 0.1172 - val_accuracy: 0.9663 - val_loss: 0.1071\n",
      "Epoch 781/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9663 - loss: 0.0943 - val_accuracy: 0.9663 - val_loss: 0.1084\n",
      "Epoch 782/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9585 - loss: 0.1112 - val_accuracy: 0.9673 - val_loss: 0.1117\n",
      "Epoch 783/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9624 - loss: 0.0985 - val_accuracy: 0.9663 - val_loss: 0.1081\n",
      "Epoch 784/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9577 - loss: 0.1070 - val_accuracy: 0.9663 - val_loss: 0.1084\n",
      "Epoch 785/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9588 - loss: 0.1075 - val_accuracy: 0.9643 - val_loss: 0.1085\n",
      "Epoch 786/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9588 - loss: 0.1048 - val_accuracy: 0.9694 - val_loss: 0.1069\n",
      "Epoch 787/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9666 - loss: 0.0933 - val_accuracy: 0.9673 - val_loss: 0.1082\n",
      "Epoch 788/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9629 - loss: 0.0984 - val_accuracy: 0.9663 - val_loss: 0.1096\n",
      "Epoch 789/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9651 - loss: 0.1033 - val_accuracy: 0.9653 - val_loss: 0.1110\n",
      "Epoch 790/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9658 - loss: 0.0966 - val_accuracy: 0.9684 - val_loss: 0.1086\n",
      "Epoch 791/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9577 - loss: 0.1098 - val_accuracy: 0.9673 - val_loss: 0.1092\n",
      "Epoch 792/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9669 - loss: 0.0912 - val_accuracy: 0.9612 - val_loss: 0.1152\n",
      "Epoch 793/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9591 - loss: 0.1097 - val_accuracy: 0.9663 - val_loss: 0.1047\n",
      "Epoch 794/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9686 - loss: 0.0838 - val_accuracy: 0.9643 - val_loss: 0.1109\n",
      "Epoch 795/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9594 - loss: 0.1038 - val_accuracy: 0.9643 - val_loss: 0.1072\n",
      "Epoch 796/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9548 - loss: 0.1055 - val_accuracy: 0.9663 - val_loss: 0.1056\n",
      "Epoch 797/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9639 - loss: 0.0958 - val_accuracy: 0.9673 - val_loss: 0.1055\n",
      "Epoch 798/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9600 - loss: 0.1068 - val_accuracy: 0.9673 - val_loss: 0.1057\n",
      "Epoch 799/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9585 - loss: 0.1047 - val_accuracy: 0.9643 - val_loss: 0.1052\n",
      "Epoch 800/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9609 - loss: 0.1038 - val_accuracy: 0.9663 - val_loss: 0.1038\n",
      "Epoch 801/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9621 - loss: 0.0998 - val_accuracy: 0.9663 - val_loss: 0.1069\n",
      "Epoch 802/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9611 - loss: 0.0981 - val_accuracy: 0.9653 - val_loss: 0.1091\n",
      "Epoch 803/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9660 - loss: 0.0896 - val_accuracy: 0.9663 - val_loss: 0.1090\n",
      "Epoch 804/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9562 - loss: 0.1175 - val_accuracy: 0.9704 - val_loss: 0.1036\n",
      "Epoch 805/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9639 - loss: 0.0964 - val_accuracy: 0.9653 - val_loss: 0.1066\n",
      "Epoch 806/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9595 - loss: 0.1043 - val_accuracy: 0.9663 - val_loss: 0.1106\n",
      "Epoch 807/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9607 - loss: 0.0979 - val_accuracy: 0.9653 - val_loss: 0.1047\n",
      "Epoch 808/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9659 - loss: 0.1020 - val_accuracy: 0.9663 - val_loss: 0.1031\n",
      "Epoch 809/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9625 - loss: 0.1074 - val_accuracy: 0.9633 - val_loss: 0.1162\n",
      "Epoch 810/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9625 - loss: 0.0979 - val_accuracy: 0.9643 - val_loss: 0.1088\n",
      "Epoch 811/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9531 - loss: 0.1162 - val_accuracy: 0.9643 - val_loss: 0.1061\n",
      "Epoch 812/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9666 - loss: 0.0893 - val_accuracy: 0.9663 - val_loss: 0.1105\n",
      "Epoch 813/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9652 - loss: 0.0979 - val_accuracy: 0.9663 - val_loss: 0.1115\n",
      "Epoch 814/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9633 - loss: 0.1004 - val_accuracy: 0.9704 - val_loss: 0.1048\n",
      "Epoch 815/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9548 - loss: 0.1195 - val_accuracy: 0.9653 - val_loss: 0.1090\n",
      "Epoch 816/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9658 - loss: 0.1009 - val_accuracy: 0.9673 - val_loss: 0.1118\n",
      "Epoch 817/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9611 - loss: 0.1027 - val_accuracy: 0.9653 - val_loss: 0.1079\n",
      "Epoch 818/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9610 - loss: 0.0999 - val_accuracy: 0.9694 - val_loss: 0.1100\n",
      "Epoch 819/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9624 - loss: 0.1012 - val_accuracy: 0.9653 - val_loss: 0.1110\n",
      "Epoch 820/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9611 - loss: 0.1003 - val_accuracy: 0.9663 - val_loss: 0.1116\n",
      "Epoch 821/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9632 - loss: 0.0999 - val_accuracy: 0.9653 - val_loss: 0.1074\n",
      "Epoch 822/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9594 - loss: 0.1105 - val_accuracy: 0.9633 - val_loss: 0.1072\n",
      "Epoch 823/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9659 - loss: 0.0925 - val_accuracy: 0.9673 - val_loss: 0.1097\n",
      "Epoch 824/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9644 - loss: 0.1050 - val_accuracy: 0.9673 - val_loss: 0.1093\n",
      "Epoch 825/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9632 - loss: 0.1042 - val_accuracy: 0.9653 - val_loss: 0.1107\n",
      "Epoch 826/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9622 - loss: 0.1009 - val_accuracy: 0.9612 - val_loss: 0.1097\n",
      "Epoch 827/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9633 - loss: 0.0971 - val_accuracy: 0.9663 - val_loss: 0.1087\n",
      "Epoch 828/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9647 - loss: 0.0921 - val_accuracy: 0.9643 - val_loss: 0.1137\n",
      "Epoch 829/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9571 - loss: 0.1106 - val_accuracy: 0.9673 - val_loss: 0.1083\n",
      "Epoch 830/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9613 - loss: 0.1059 - val_accuracy: 0.9673 - val_loss: 0.1122\n",
      "Epoch 831/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9640 - loss: 0.1001 - val_accuracy: 0.9643 - val_loss: 0.1122\n",
      "Epoch 832/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9601 - loss: 0.1008 - val_accuracy: 0.9633 - val_loss: 0.1091\n",
      "Epoch 833/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9661 - loss: 0.0911 - val_accuracy: 0.9684 - val_loss: 0.1060\n",
      "Epoch 834/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9589 - loss: 0.1069 - val_accuracy: 0.9663 - val_loss: 0.1103\n",
      "Epoch 835/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9607 - loss: 0.1077 - val_accuracy: 0.9653 - val_loss: 0.1090\n",
      "Epoch 836/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9560 - loss: 0.1026 - val_accuracy: 0.9653 - val_loss: 0.1079\n",
      "Epoch 837/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9652 - loss: 0.0977 - val_accuracy: 0.9684 - val_loss: 0.1109\n",
      "Epoch 838/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9626 - loss: 0.1044 - val_accuracy: 0.9673 - val_loss: 0.1093\n",
      "Epoch 839/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9665 - loss: 0.0971 - val_accuracy: 0.9633 - val_loss: 0.1111\n",
      "Epoch 840/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9660 - loss: 0.0887 - val_accuracy: 0.9653 - val_loss: 0.1065\n",
      "Epoch 841/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9644 - loss: 0.0989 - val_accuracy: 0.9653 - val_loss: 0.1055\n",
      "Epoch 842/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9671 - loss: 0.0917 - val_accuracy: 0.9684 - val_loss: 0.1081\n",
      "Epoch 843/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9571 - loss: 0.1100 - val_accuracy: 0.9673 - val_loss: 0.1102\n",
      "Epoch 844/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9570 - loss: 0.1105 - val_accuracy: 0.9663 - val_loss: 0.1067\n",
      "Epoch 845/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9619 - loss: 0.0960 - val_accuracy: 0.9673 - val_loss: 0.1059\n",
      "Epoch 846/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9602 - loss: 0.0987 - val_accuracy: 0.9653 - val_loss: 0.1128\n",
      "Epoch 847/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9638 - loss: 0.0994 - val_accuracy: 0.9653 - val_loss: 0.1109\n",
      "Epoch 848/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9613 - loss: 0.1059 - val_accuracy: 0.9643 - val_loss: 0.1110\n",
      "Epoch 849/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9615 - loss: 0.0989 - val_accuracy: 0.9673 - val_loss: 0.1148\n",
      "Epoch 850/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9633 - loss: 0.0972 - val_accuracy: 0.9673 - val_loss: 0.1090\n",
      "Epoch 851/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9628 - loss: 0.1053 - val_accuracy: 0.9684 - val_loss: 0.1101\n",
      "Epoch 852/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9575 - loss: 0.1095 - val_accuracy: 0.9653 - val_loss: 0.1078\n",
      "Epoch 853/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9596 - loss: 0.1125 - val_accuracy: 0.9663 - val_loss: 0.1070\n",
      "Epoch 854/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9619 - loss: 0.0979 - val_accuracy: 0.9643 - val_loss: 0.1102\n",
      "Epoch 855/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9613 - loss: 0.1064 - val_accuracy: 0.9643 - val_loss: 0.1099\n",
      "Epoch 856/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9616 - loss: 0.0991 - val_accuracy: 0.9663 - val_loss: 0.1045\n",
      "Epoch 857/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9629 - loss: 0.0921 - val_accuracy: 0.9673 - val_loss: 0.1087\n",
      "Epoch 858/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9627 - loss: 0.1002 - val_accuracy: 0.9694 - val_loss: 0.1082\n",
      "Epoch 859/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9615 - loss: 0.0985 - val_accuracy: 0.9633 - val_loss: 0.1086\n",
      "Epoch 860/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9570 - loss: 0.1020 - val_accuracy: 0.9663 - val_loss: 0.1068\n",
      "Epoch 861/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9577 - loss: 0.1029 - val_accuracy: 0.9704 - val_loss: 0.1112\n",
      "Epoch 862/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9579 - loss: 0.1101 - val_accuracy: 0.9684 - val_loss: 0.1049\n",
      "Epoch 863/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9608 - loss: 0.0948 - val_accuracy: 0.9663 - val_loss: 0.1050\n",
      "Epoch 864/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9644 - loss: 0.0978 - val_accuracy: 0.9684 - val_loss: 0.1040\n",
      "Epoch 865/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9618 - loss: 0.1000 - val_accuracy: 0.9663 - val_loss: 0.1105\n",
      "Epoch 866/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9656 - loss: 0.0938 - val_accuracy: 0.9684 - val_loss: 0.1077\n",
      "Epoch 867/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9583 - loss: 0.1041 - val_accuracy: 0.9643 - val_loss: 0.1061\n",
      "Epoch 868/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9592 - loss: 0.1143 - val_accuracy: 0.9673 - val_loss: 0.1076\n",
      "Epoch 869/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9605 - loss: 0.0970 - val_accuracy: 0.9673 - val_loss: 0.1021\n",
      "Epoch 870/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9630 - loss: 0.0972 - val_accuracy: 0.9653 - val_loss: 0.1087\n",
      "Epoch 871/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9659 - loss: 0.0875 - val_accuracy: 0.9633 - val_loss: 0.1053\n",
      "Epoch 872/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9676 - loss: 0.0925 - val_accuracy: 0.9673 - val_loss: 0.1058\n",
      "Epoch 873/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9599 - loss: 0.1019 - val_accuracy: 0.9684 - val_loss: 0.1095\n",
      "Epoch 874/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9668 - loss: 0.0863 - val_accuracy: 0.9653 - val_loss: 0.1067\n",
      "Epoch 875/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9610 - loss: 0.1065 - val_accuracy: 0.9653 - val_loss: 0.1046\n",
      "Epoch 876/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9625 - loss: 0.0963 - val_accuracy: 0.9684 - val_loss: 0.1083\n",
      "Epoch 877/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9642 - loss: 0.0996 - val_accuracy: 0.9653 - val_loss: 0.1083\n",
      "Epoch 878/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9627 - loss: 0.1094 - val_accuracy: 0.9673 - val_loss: 0.1053\n",
      "Epoch 879/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9632 - loss: 0.0998 - val_accuracy: 0.9673 - val_loss: 0.1031\n",
      "Epoch 880/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9675 - loss: 0.0906 - val_accuracy: 0.9653 - val_loss: 0.1065\n",
      "Epoch 881/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9652 - loss: 0.0946 - val_accuracy: 0.9663 - val_loss: 0.1077\n",
      "Epoch 882/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9609 - loss: 0.0919 - val_accuracy: 0.9673 - val_loss: 0.1077\n",
      "Epoch 883/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9642 - loss: 0.0943 - val_accuracy: 0.9673 - val_loss: 0.1082\n",
      "Epoch 884/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9671 - loss: 0.0883 - val_accuracy: 0.9643 - val_loss: 0.1090\n",
      "Epoch 885/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9592 - loss: 0.1004 - val_accuracy: 0.9663 - val_loss: 0.1074\n",
      "Epoch 886/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9624 - loss: 0.0909 - val_accuracy: 0.9653 - val_loss: 0.1052\n",
      "Epoch 887/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9693 - loss: 0.0923 - val_accuracy: 0.9663 - val_loss: 0.1088\n",
      "Epoch 888/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9647 - loss: 0.0910 - val_accuracy: 0.9663 - val_loss: 0.1069\n",
      "Epoch 889/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9612 - loss: 0.1036 - val_accuracy: 0.9643 - val_loss: 0.1056\n",
      "Epoch 890/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9664 - loss: 0.1032 - val_accuracy: 0.9673 - val_loss: 0.1065\n",
      "Epoch 891/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9598 - loss: 0.1061 - val_accuracy: 0.9653 - val_loss: 0.1073\n",
      "Epoch 892/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9594 - loss: 0.1045 - val_accuracy: 0.9622 - val_loss: 0.1047\n",
      "Epoch 893/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9670 - loss: 0.0891 - val_accuracy: 0.9633 - val_loss: 0.1049\n",
      "Epoch 894/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9643 - loss: 0.0980 - val_accuracy: 0.9643 - val_loss: 0.1026\n",
      "Epoch 895/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9651 - loss: 0.0964 - val_accuracy: 0.9622 - val_loss: 0.1073\n",
      "Epoch 896/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9620 - loss: 0.1035 - val_accuracy: 0.9673 - val_loss: 0.1056\n",
      "Epoch 897/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9632 - loss: 0.1022 - val_accuracy: 0.9663 - val_loss: 0.1043\n",
      "Epoch 898/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9675 - loss: 0.0931 - val_accuracy: 0.9653 - val_loss: 0.1065\n",
      "Epoch 899/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9586 - loss: 0.1024 - val_accuracy: 0.9653 - val_loss: 0.1066\n",
      "Epoch 900/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9595 - loss: 0.1097 - val_accuracy: 0.9633 - val_loss: 0.1058\n",
      "Epoch 901/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9594 - loss: 0.1026 - val_accuracy: 0.9663 - val_loss: 0.1014\n",
      "Epoch 902/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9570 - loss: 0.1114 - val_accuracy: 0.9673 - val_loss: 0.1012\n",
      "Epoch 903/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9643 - loss: 0.0982 - val_accuracy: 0.9643 - val_loss: 0.1062\n",
      "Epoch 904/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9654 - loss: 0.1005 - val_accuracy: 0.9633 - val_loss: 0.1115\n",
      "Epoch 905/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9614 - loss: 0.1001 - val_accuracy: 0.9633 - val_loss: 0.1063\n",
      "Epoch 906/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9640 - loss: 0.0981 - val_accuracy: 0.9643 - val_loss: 0.1054\n",
      "Epoch 907/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9680 - loss: 0.0826 - val_accuracy: 0.9653 - val_loss: 0.1060\n",
      "Epoch 908/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9608 - loss: 0.0942 - val_accuracy: 0.9673 - val_loss: 0.1075\n",
      "Epoch 909/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9680 - loss: 0.0904 - val_accuracy: 0.9663 - val_loss: 0.1106\n",
      "Epoch 910/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9619 - loss: 0.1013 - val_accuracy: 0.9663 - val_loss: 0.1074\n",
      "Epoch 911/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9692 - loss: 0.0905 - val_accuracy: 0.9643 - val_loss: 0.1069\n",
      "Epoch 912/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9658 - loss: 0.0936 - val_accuracy: 0.9653 - val_loss: 0.1071\n",
      "Epoch 913/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9597 - loss: 0.0928 - val_accuracy: 0.9643 - val_loss: 0.1075\n",
      "Epoch 914/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9666 - loss: 0.0913 - val_accuracy: 0.9694 - val_loss: 0.1081\n",
      "Epoch 915/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9630 - loss: 0.1004 - val_accuracy: 0.9663 - val_loss: 0.1126\n",
      "Epoch 916/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9578 - loss: 0.1109 - val_accuracy: 0.9653 - val_loss: 0.1079\n",
      "Epoch 917/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9611 - loss: 0.1080 - val_accuracy: 0.9633 - val_loss: 0.1103\n",
      "Epoch 918/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9640 - loss: 0.0933 - val_accuracy: 0.9633 - val_loss: 0.1079\n",
      "Epoch 919/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9648 - loss: 0.0954 - val_accuracy: 0.9673 - val_loss: 0.1101\n",
      "Epoch 920/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9581 - loss: 0.1108 - val_accuracy: 0.9643 - val_loss: 0.1077\n",
      "Epoch 921/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9639 - loss: 0.0904 - val_accuracy: 0.9633 - val_loss: 0.1071\n",
      "Epoch 922/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9665 - loss: 0.0951 - val_accuracy: 0.9663 - val_loss: 0.1098\n",
      "Epoch 923/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9652 - loss: 0.0953 - val_accuracy: 0.9643 - val_loss: 0.1081\n",
      "Epoch 924/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9645 - loss: 0.0943 - val_accuracy: 0.9673 - val_loss: 0.1142\n",
      "Epoch 925/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9586 - loss: 0.1069 - val_accuracy: 0.9643 - val_loss: 0.1133\n",
      "Epoch 926/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9639 - loss: 0.0958 - val_accuracy: 0.9653 - val_loss: 0.1068\n",
      "Epoch 927/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9605 - loss: 0.0992 - val_accuracy: 0.9684 - val_loss: 0.1067\n",
      "Epoch 928/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9619 - loss: 0.1015 - val_accuracy: 0.9633 - val_loss: 0.1113\n",
      "Epoch 929/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9662 - loss: 0.0837 - val_accuracy: 0.9643 - val_loss: 0.1093\n",
      "Epoch 930/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9656 - loss: 0.0981 - val_accuracy: 0.9643 - val_loss: 0.1094\n",
      "Epoch 931/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9572 - loss: 0.1114 - val_accuracy: 0.9663 - val_loss: 0.1106\n",
      "Epoch 932/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9635 - loss: 0.0975 - val_accuracy: 0.9673 - val_loss: 0.1086\n",
      "Epoch 933/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9617 - loss: 0.1013 - val_accuracy: 0.9643 - val_loss: 0.1123\n",
      "Epoch 934/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9649 - loss: 0.1004 - val_accuracy: 0.9653 - val_loss: 0.1117\n",
      "Epoch 935/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9632 - loss: 0.0926 - val_accuracy: 0.9694 - val_loss: 0.1124\n",
      "Epoch 936/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9642 - loss: 0.0903 - val_accuracy: 0.9684 - val_loss: 0.1105\n",
      "Epoch 937/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9571 - loss: 0.1081 - val_accuracy: 0.9643 - val_loss: 0.1137\n",
      "Epoch 938/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9602 - loss: 0.1026 - val_accuracy: 0.9673 - val_loss: 0.1103\n",
      "Epoch 939/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9670 - loss: 0.0979 - val_accuracy: 0.9673 - val_loss: 0.1125\n",
      "Epoch 940/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9651 - loss: 0.0926 - val_accuracy: 0.9663 - val_loss: 0.1115\n",
      "Epoch 941/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9633 - loss: 0.1022 - val_accuracy: 0.9643 - val_loss: 0.1086\n",
      "Epoch 942/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9642 - loss: 0.0972 - val_accuracy: 0.9663 - val_loss: 0.1139\n",
      "Epoch 943/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9577 - loss: 0.1102 - val_accuracy: 0.9673 - val_loss: 0.1090\n",
      "Epoch 944/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9664 - loss: 0.0934 - val_accuracy: 0.9622 - val_loss: 0.1086\n",
      "Epoch 945/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9653 - loss: 0.0942 - val_accuracy: 0.9633 - val_loss: 0.1126\n",
      "Epoch 946/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9623 - loss: 0.0987 - val_accuracy: 0.9643 - val_loss: 0.1118\n",
      "Epoch 947/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9631 - loss: 0.0956 - val_accuracy: 0.9643 - val_loss: 0.1090\n",
      "Epoch 948/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9653 - loss: 0.1019 - val_accuracy: 0.9663 - val_loss: 0.1095\n",
      "Epoch 949/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9574 - loss: 0.1136 - val_accuracy: 0.9633 - val_loss: 0.1079\n",
      "Epoch 950/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9639 - loss: 0.0968 - val_accuracy: 0.9673 - val_loss: 0.1110\n",
      "Epoch 951/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9628 - loss: 0.0949 - val_accuracy: 0.9643 - val_loss: 0.1060\n",
      "Epoch 952/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9637 - loss: 0.0902 - val_accuracy: 0.9643 - val_loss: 0.1058\n",
      "Epoch 953/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9597 - loss: 0.1150 - val_accuracy: 0.9724 - val_loss: 0.1071\n",
      "Epoch 954/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9638 - loss: 0.0941 - val_accuracy: 0.9633 - val_loss: 0.1050\n",
      "Epoch 955/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9641 - loss: 0.0956 - val_accuracy: 0.9643 - val_loss: 0.1083\n",
      "Epoch 956/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9647 - loss: 0.0897 - val_accuracy: 0.9673 - val_loss: 0.1046\n",
      "Epoch 957/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9604 - loss: 0.1017 - val_accuracy: 0.9653 - val_loss: 0.1117\n",
      "Epoch 958/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9663 - loss: 0.0885 - val_accuracy: 0.9653 - val_loss: 0.1045\n",
      "Epoch 959/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9661 - loss: 0.1035 - val_accuracy: 0.9633 - val_loss: 0.1101\n",
      "Epoch 960/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9650 - loss: 0.0879 - val_accuracy: 0.9643 - val_loss: 0.1077\n",
      "Epoch 961/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9663 - loss: 0.1007 - val_accuracy: 0.9663 - val_loss: 0.1094\n",
      "Epoch 962/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9630 - loss: 0.0986 - val_accuracy: 0.9694 - val_loss: 0.1105\n",
      "Epoch 963/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9565 - loss: 0.1071 - val_accuracy: 0.9643 - val_loss: 0.1066\n",
      "Epoch 964/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9646 - loss: 0.0946 - val_accuracy: 0.9673 - val_loss: 0.1042\n",
      "Epoch 965/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9649 - loss: 0.0946 - val_accuracy: 0.9673 - val_loss: 0.1049\n",
      "Epoch 966/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9600 - loss: 0.1012 - val_accuracy: 0.9694 - val_loss: 0.1074\n",
      "Epoch 967/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9595 - loss: 0.1092 - val_accuracy: 0.9694 - val_loss: 0.1085\n",
      "Epoch 968/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9615 - loss: 0.1042 - val_accuracy: 0.9673 - val_loss: 0.1062\n",
      "Epoch 969/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9645 - loss: 0.1028 - val_accuracy: 0.9673 - val_loss: 0.1073\n",
      "Epoch 970/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9639 - loss: 0.0999 - val_accuracy: 0.9663 - val_loss: 0.1069\n",
      "Epoch 971/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9682 - loss: 0.0909 - val_accuracy: 0.9653 - val_loss: 0.1084\n",
      "Epoch 972/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9695 - loss: 0.0863 - val_accuracy: 0.9643 - val_loss: 0.1071\n",
      "Epoch 973/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9674 - loss: 0.0893 - val_accuracy: 0.9673 - val_loss: 0.1054\n",
      "Epoch 974/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9593 - loss: 0.1068 - val_accuracy: 0.9694 - val_loss: 0.1081\n",
      "Epoch 975/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9631 - loss: 0.0981 - val_accuracy: 0.9694 - val_loss: 0.1080\n",
      "Epoch 976/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9631 - loss: 0.0979 - val_accuracy: 0.9653 - val_loss: 0.1039\n",
      "Epoch 977/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9647 - loss: 0.0945 - val_accuracy: 0.9653 - val_loss: 0.1109\n",
      "Epoch 978/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9657 - loss: 0.1019 - val_accuracy: 0.9704 - val_loss: 0.1069\n",
      "Epoch 979/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9602 - loss: 0.1045 - val_accuracy: 0.9673 - val_loss: 0.1053\n",
      "Epoch 980/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9673 - loss: 0.0940 - val_accuracy: 0.9663 - val_loss: 0.1061\n",
      "Epoch 981/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9641 - loss: 0.0906 - val_accuracy: 0.9663 - val_loss: 0.1077\n",
      "Epoch 982/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9613 - loss: 0.1074 - val_accuracy: 0.9663 - val_loss: 0.1063\n",
      "Epoch 983/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9614 - loss: 0.0997 - val_accuracy: 0.9663 - val_loss: 0.1050\n",
      "Epoch 984/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9632 - loss: 0.0954 - val_accuracy: 0.9653 - val_loss: 0.1026\n",
      "Epoch 985/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9631 - loss: 0.0930 - val_accuracy: 0.9673 - val_loss: 0.1031\n",
      "Epoch 986/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9610 - loss: 0.1026 - val_accuracy: 0.9663 - val_loss: 0.1042\n",
      "Epoch 987/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9660 - loss: 0.0935 - val_accuracy: 0.9663 - val_loss: 0.1064\n",
      "Epoch 988/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9667 - loss: 0.0922 - val_accuracy: 0.9633 - val_loss: 0.1089\n",
      "Epoch 989/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9627 - loss: 0.0965 - val_accuracy: 0.9653 - val_loss: 0.1060\n",
      "Epoch 990/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9697 - loss: 0.0919 - val_accuracy: 0.9633 - val_loss: 0.1070\n",
      "Epoch 991/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9655 - loss: 0.0949 - val_accuracy: 0.9663 - val_loss: 0.1057\n",
      "Epoch 992/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9639 - loss: 0.0969 - val_accuracy: 0.9684 - val_loss: 0.1059\n",
      "Epoch 993/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9667 - loss: 0.0879 - val_accuracy: 0.9653 - val_loss: 0.1062\n",
      "Epoch 994/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9601 - loss: 0.1071 - val_accuracy: 0.9643 - val_loss: 0.1070\n",
      "Epoch 995/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9619 - loss: 0.1094 - val_accuracy: 0.9694 - val_loss: 0.1071\n",
      "Epoch 996/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9634 - loss: 0.0970 - val_accuracy: 0.9694 - val_loss: 0.1057\n",
      "Epoch 997/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9597 - loss: 0.0976 - val_accuracy: 0.9704 - val_loss: 0.1076\n",
      "Epoch 998/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9659 - loss: 0.0958 - val_accuracy: 0.9663 - val_loss: 0.1068\n",
      "Epoch 999/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9636 - loss: 0.0989 - val_accuracy: 0.9694 - val_loss: 0.1056\n",
      "Epoch 1000/1000\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9629 - loss: 0.0950 - val_accuracy: 0.9694 - val_loss: 0.1058\n"
     ]
    }
   ],
   "source": [
    "## Train the model\n",
    "\n",
    "EPOCHS = 1000\n",
    "his = model.fit(\n",
    "    train_ds,\n",
    "    y_train,\n",
    "    validation_data=(test_ds, y_test),\n",
    "    epochs=EPOCHS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f9cd4923-36fc-4799-abb0-52acd470e6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 869us/step - accuracy: 0.9655 - loss: 0.1081\n",
      "\n",
      "Test score/loss: 0.10583625733852386\n",
      "Test accuracy: 0.9693877696990967\n",
      "dict_keys(['accuracy', 'loss', 'val_accuracy', 'val_loss'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Testing\n",
    "score = model.evaluate(test_ds, y_test, batch_size=32)\n",
    "print(\"\\nTest score/loss:\", score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "# list all data in history\n",
    "print(his.history.keys())\n",
    "\n",
    "# summarize history for accuracy\n",
    "#plt.plot(mo)\n",
    "fig= plt.figure(figsize=(4,3))\n",
    "plt.plot(his.history['accuracy'])\n",
    "plt.plot(his.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d12916-be37-4ce7-95df-f9689f870890",
   "metadata": {},
   "source": [
    "### Export the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0a7e568e-c2fd-4485-8ea6-652ea847782f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/KWS/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/KWS/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'models/KWS'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 2400), dtype=tf.float32, name='keras_tensor_30')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 2), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  130999255730304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  130999255736992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  130999255738224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  130999255914928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "export_dir = 'models/KWS'\n",
    "model.export(export_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "13a9fef0-d7ff-440d-a1ad-fb204190da42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/KWS/variables/variables\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/KWS/variables/variables\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:The given SavedModel MetaGraphDef contains SignatureDefs with the following keys: {'serving_default', '__saved_model_init_op', 'serve'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:The given SavedModel MetaGraphDef contains SignatureDefs with the following keys: {'serving_default', '__saved_model_init_op', 'serve'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/KWS/variables/variables\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/KWS/variables/variables\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/KWS/variables/variables\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-27 13:21:32.193430: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-27 13:21:32.193649: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2024-05-27 13:21:32.193722: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-05-27 13:21:32.193937: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-27 13:21:32.194096: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "INFO:tensorflow:Restoring parameters from models/KWS/variables/variables\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:The given SavedModel MetaGraphDef contains SignatureDefs with the following keys: {'serving_default', '__saved_model_init_op', 'serve'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:The given SavedModel MetaGraphDef contains SignatureDefs with the following keys: {'serving_default', '__saved_model_init_op', 'serve'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/KWS/variables/variables\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/KWS/variables/variables\n",
      "2024-05-27 13:21:32.302969: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-27 13:21:32.303201: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2024-05-27 13:21:32.303270: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-05-27 13:21:32.303535: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-27 13:21:32.303715: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "W0000 00:00:1716812492.335661    5666 tf_tfl_flatbuffer_helpers.cc:390] Ignored output_format.\n",
      "W0000 00:00:1716812492.335687    5666 tf_tfl_flatbuffer_helpers.cc:393] Ignored drop_control_dependency.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "27260"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "tflite_model_file = pathlib.Path('models/KWS.tflite')\n",
    "tflite_model_file.write_bytes(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8043c6-8eab-4e2b-b8b5-a21e0c9f8456",
   "metadata": {},
   "source": [
    "### Post-Quantisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "91e864e0-84b7-43b2-98e8-57a706c2d632",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/KWS/variables/variables\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/KWS/variables/variables\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:The given SavedModel MetaGraphDef contains SignatureDefs with the following keys: {'serving_default', '__saved_model_init_op', 'serve'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:The given SavedModel MetaGraphDef contains SignatureDefs with the following keys: {'serving_default', '__saved_model_init_op', 'serve'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/KWS/variables/variables\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/KWS/variables/variables\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/KWS/variables/variables\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-27 13:21:33.844529: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-27 13:21:33.844751: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2024-05-27 13:21:33.844821: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-05-27 13:21:33.845065: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-27 13:21:33.845227: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "INFO:tensorflow:Restoring parameters from models/KWS/variables/variables\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:The given SavedModel MetaGraphDef contains SignatureDefs with the following keys: {'serving_default', '__saved_model_init_op', 'serve'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:The given SavedModel MetaGraphDef contains SignatureDefs with the following keys: {'serving_default', '__saved_model_init_op', 'serve'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/KWS/variables/variables\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/KWS/variables/variables\n",
      "2024-05-27 13:21:33.959520: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-27 13:21:33.960000: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2024-05-27 13:21:33.960071: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-05-27 13:21:33.960313: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-27 13:21:33.960531: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "W0000 00:00:1716812493.994534    5666 tf_tfl_flatbuffer_helpers.cc:390] Ignored output_format.\n",
      "W0000 00:00:1716812493.994550    5666 tf_tfl_flatbuffer_helpers.cc:393] Ignored drop_control_dependency.\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: INT8, output_inference_type: INT8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10472"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def representative_dataset_gen(num_samples=100):\n",
    "    for data in train_ds[:num_samples]:\n",
    "        yield [data.reshape(1, 40, 60, 1)]\n",
    "##def representative_data_gen():\n",
    "##    for input_value, _ in y_test.take(100):\n",
    "##        yield [input_value]\n",
    "converter_op = tf.lite.TFLiteConverter.from_saved_model(export_dir)\n",
    "converter_op.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter_op.representative_dataset = representative_dataset_gen\n",
    "converter_op.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter_op.inference_input_type = tf.int8\n",
    "converter_op.inference_output_type = tf.int8\n",
    "\n",
    "tflite_model_file = pathlib.Path('models/KWS_op.tflite')\n",
    "tflite_model_file.write_bytes(converter_op.convert())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc64a8ac-2563-4599-b8c3-16a410b19023",
   "metadata": {},
   "source": [
    "## Test the accuracy of lite model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6c99560c-0fb7-49b1-abf1-ecfc04121e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load the dataset again\n",
    "test_ds = []\n",
    "\n",
    "for i in melSpec_test_set_yes:\n",
    "    resized = np.resize(i, (40,60))\n",
    "    resized = resized.flatten()\n",
    "    test_ds.append(resized)\n",
    "for i in melSpec_test_set_no:\n",
    "    resized = np.resize(i, (40,60))\n",
    "    resized = resized.flatten()\n",
    "    test_ds.append(resized)\n",
    "\n",
    "test_ds = np.array(test_ds)\n",
    "test_ds = test_ds.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f1b0ff6a-f8b0-4202-8d43-d9935b8ddb93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3137255012989044\n",
      "127\n",
      "[[-46, -14, -14, -33, -6, -8, -5, -20, -6, -27, -16, -10, 8, 4, -15, 0, 10, 0, 2, 4, 2, -32, -23, -14, -5, 6, -7, -17, -15, -16, -24, -33, -18, -25, -36, -23, -30, -24, -28, -43, 32, 26, -8, 6, 2, 4, -5, 7, -13, 0, 4, 5, -18, 2, 8, 6, 9, 15, 7, -11, 1, -9, -14, -17, 2, 6, -18, -28, 2, -8, -21, -12, -23, -45, -38, -25, -27, -15, -28, -39, -11, -8, 21, 22, 24, 2, 22, -12, -8, 13, -6, -17, -2, -8, 6, 12, 2, 2, -3, -7, -17, -5, -9, -2, -17, -29, -22, -16, -17, -10, -11, -17, -14, -37, -23, -27, -26, -29, -48, -33, 52, 55, 59, 59, 52, 34, 41, 31, 2, 7, 10, 4, 2, 1, 3, 10, 23, 28, 25, 36, 11, 2, 13, -8, -1, 1, -14, -23, -17, 1, -10, -2, -9, -8, -8, -11, 3, -6, -17, -32, 8, 53, 52, 27, 23, 23, 6, 18, 3, -18, -6, -17, -26, -1, -11, -17, -3, 18, 3, 0, -17, -29, -12, -27, -15, -28, -23, -12, -22, -16, -28, -27, -21, -17, -34, -20, -20, -21, -24, -22, 10, 61, 60, 12, 11, 23, 0, 19, -14, -5, -2, -26, -26, -33, -26, -7, -1, 12, -16, 2, -18, -32, -11, -12, -6, -2, -1, -20, -9, -8, 0, 3, -2, -17, -15, -10, -5, -12, -11, -29, 20, 65, 67, 29, 26, 34, 17, 27, 10, 0, 9, -1, 1, 16, 8, -1, 2, 16, -8, -7, 11, 2, -10, -3, 0, -9, -15, -21, -9, -20, -31, -6, -18, -24, -19, -29, -5, -10, -16, -30, 28, 71, 72, 37, 32, 45, 29, 24, 1, 11, 0, -40, -30, -8, -1, -8, -16, -21, -8, 0, 9, -10, -9, -4, -10, -7, 0, -18, -27, -7, -4, -3, -6, -19, -19, -19, -14, -2, -16, -37, 37, 85, 88, 58, 49, 64, 51, 44, 32, 0, -6, -11, -16, 0, 4, -20, 4, 24, -8, -6, 3, -5, -8, 4, -2, -7, -12, -26, 1, -2, 17, 9, -7, -12, -12, -6, 15, 0, -9, -21, 60, 100, 106, 76, 73, 95, 94, 78, 56, 42, 57, 24, 18, 28, 21, 4, 27, 50, 33, 37, 27, 3, -10, 10, 0, 1, 0, -12, -24, -1, 25, 18, 11, 6, 11, 2, 10, 6, 5, -8, 51, 102, 108, 74, 74, 103, 103, 93, 95, 73, 79, 35, 33, 37, 28, 33, 30, 24, 13, 27, 14, 9, 9, 5, 10, 10, -1, 2, 5, 38, 53, 32, 32, 41, 48, 41, 38, 38, 26, 2, 61, 101, 106, 70, 59, 91, 79, 113, 122, 102, 81, 29, 58, 51, 37, 43, 53, 46, 33, 42, 12, -2, 8, 24, 27, 24, 35, 46, 46, 49, 60, 51, 66, 81, 77, 46, 41, 45, 48, 19, 38, 98, 107, 75, 60, 78, 70, 118, 125, 109, 117, 83, 76, 70, 45, 37, 28, 15, 36, 31, 6, 17, 5, 20, 28, 27, 42, 58, 77, 77, 65, 64, 85, 90, 72, 56, 55, 50, 56, 37, 43, 91, 104, 75, 56, 78, 76, 109, 116, 96, 127, 96, 79, 57, 49, 32, 47, 59, 53, 42, 31, 29, 25, 39, 52, 52, 71, 90, 84, 76, 77, 75, 91, 88, 68, 49, 46, 43, 37, 14, 5, 86, 101, 79, 49, 84, 82, 91, 108, 86, 119, 110, 94, 91, 55, 52, 65, 57, 64, 61, 52, 32, 33, 49, 61, 66, 91, 106, 81, 78, 85, 78, 98, 89, 69, 51, 56, 60, 47, 23, 43, 70, 95, 76, 49, 86, 87, 89, 100, 81, 98, 84, 102, 108, 45, 52, 83, 59, 51, 62, 58, 47, 46, 61, 76, 73, 89, 91, 81, 80, 92, 83, 92, 80, 66, 49, 58, 57, 42, 21, 44, 89, 96, 65, 64, 73, 66, 92, 89, 75, 105, 96, 120, 111, 91, 89, 87, 71, 66, 73, 59, 56, 54, 64, 80, 82, 86, 86, 80, 81, 90, 77, 81, 71, 60, 45, 55, 49, 30, -4, 58, 94, 90, 34, 67, 73, 59, 65, 57, 93, 110, 111, 99, 80, 92, 84, 89, 89, 80, 74, 62, 63, 61, 80, 101, 94, 83, 86, 76, 79, 92, 80, 74, 66, 51, 38, 59, 57, 16, -7, 65, 89, 80, 55, 80, 66, 67, 62, 61, 90, 82, 65, 106, 112, 85, 74, 86, 69, 75, 75, 49, 48, 61, 88, 103, 80, 72, 69, 63, 66, 81, 70, 66, 55, 52, 36, 46, 56, 13, -14, 58, 10, 51, 69, 54, 48, 73, 76, 70, 82, 97, 92, 94, 92, 95, 77, 79, 75, 71, 80, 61, 65, 60, 90, 91, 74, 65, 79, 64, 74, 78, 60, 64, 53, 30, 24, 30, 24, -5, -28, 69, 34, 65, 65, 39, 56, 46, 67, 46, 82, 84, 65, 96, 94, 81, 81, 70, 72, 59, 64, 71, 58, 40, 71, 80, 72, 58, 45, 49, 51, 46, 46, 42, 17, 3, -4, -3, 3, -22, -28, 50, 45, 44, 52, 23, 44, 53, 56, 22, 61, 77, 50, 67, 66, 65, 60, 62, 47, 23, 55, 47, 37, 31, 42, 77, 53, 53, 64, 31, 38, 35, 27, 21, 1, -6, -1, -5, 0, -27, -34, 48, 46, 38, 22, 18, 23, 32, 34, 42, 46, 63, 61, 49, 29, 58, 55, 41, 52, 44, 37, 26, 16, 24, 42, 62, 41, 24, 25, 24, 12, -7, 11, 4, -15, -30, -14, -12, -16, -23, -34, 25, 13, -19, -19, -14, 2, 21, 21, 14, 26, 24, 24, 32, 33, 18, 18, 10, -8, 0, -5, -5, 8, 2, 16, 38, 31, -1, -8, -1, 1, 12, 4, -1, -24, -43, -34, -9, -8, -35, -52, -52, -45, -15, -16, -19, -18, 14, -10, -47, 1, 13, -61, 11, 1, -13, -4, -3, -25, 7, -4, -25, -16, -11, 1, 11, 9, 0, -13, -21, -14, 7, 2, -32, -47, -48, -29, -20, -13, -30, -47, -9, -9, -26, -33, -29, -36, -7, -14, -8, 15, 6, -20, -17, -16, 2, 1, 6, -21, -32, 0, 0, -19, -2, 5, -21, -6, 0, -16, -4, -6, -12, -29, -16, -27, -29, -29, -22, -24, -29, -37, -10, -29, -34, -31, -67, -25, 0, -13, -13, -12, 3, 7, -9, -20, -13, 0, -7, 3, -1, -8, -19, -9, 10, 7, -13, 10, 13, 0, -12, -24, 0, -8, -12, -23, -24, -21, -23, -23, -22, -37, 7, -3, -41, -20, -16, -40, -8, -30, -34, -17, 10, -2, -21, -8, 7, 1, 9, 10, -7, -16, -9, -12, -5, 3, 0, -3, -15, -11, -13, -17, -27, -18, -27, -41, -33, -16, -19, -22, -29, -40, -43, -25, -67, -55, -37, -9, 21, 12, 7, 9, -6, -14, -14, 3, -14, -6, -13, 0, 18, 12, -11, -23, 4, 5, 8, -9, -7, -18, -21, -11, -5, -15, -24, -25, -30, -28, -12, -12, -4, -24, -10, -17, -19, -31, -23, -18, 4, 5, -6, -13, 3, -17, -29, -2, -4, 3, -9, 0, -14, -21, -6, -16, -11, 0, -11, -10, -15, -13, -47, -23, -25, -16, -21, -21, -32, -28, -19, -24, -21, -38, -58, -71, -20, -6, -6, -10, -8, -10, -1, -3, -4, -17, -14, -23, 6, -2, 7, 5, -18, -17, -8, -4, -8, -9, -25, -10, -7, -17, -21, -15, -11, -13, -16, -18, -27, -28, -30, -20, -46, -38, -31, -15, -1, -14, -27, -49, -18, -9, -26, -5, -4, -41, -22, 7, -32, -18, 10, 23, -17, -28, -7, -12, 0, 1, -8, -12, -27, -32, -22, -16, -14, -2, -15, -27, -24, -23, -34, -24, -24, -30, 0, -38, -26, -61, -32, -57, -9, -2, -24, -18, 3, 2, -10, -3, 12, 13, 7, 1, 4, 6, -11, -23, -9, -22, -1, 0, -27, -18, -9, -11, -16, -16, -13, -33, -48, -28, -23, -26, -31, -38, -13, -18, -31, -39, -21, -15, -4, 6, -12, 7, -5, -11, 0, -2, 0, -1, -3, 12, 10, 8, 13, -1, -32, -13, -6, 2, -5, -8, 7, -7, -8, -7, -18, -20, -22, -18, -25, -26, -30, -35, -7, -19, -40, -17, -36, -16, 2, -2, -14, -13, -32, -13, -24, -13, 3, -10, -9, 7, -21, -5, 5, 7, -18, -8, 4, -1, -10, -7, 1, 4, 1, -7, -7, -8, -31, -30, -13, -18, -41, -50, -58, -17, -23, -36, -24, -32, -12, -15, -12, 5, 7, -8, -26, -27, -40, -21, -14, 18, 13, -1, -17, 6, -7, -23, -11, -3, -14, -14, -22, -13, -14, -18, -14, -24, -34, -32, -17, -18, -30, -45, -20, -25, -48, -13, -11, -9, 0, 11, -4, 0, -22, -15, -14, -14, -17, 12, 3, -9, -19, -10, -4, 2, -5, 1, 4, 2, -15, -19, -15, -8, -23, -5, 0, -19, -28, -52, -22, -21, -32, -41, 0, -24, -35, -33, -34, -12, -21, -9, -14, -22, -25, -42, -3, 1, -11, 4, -7, 1, -9, 1, 0, -14, -8, -3, -2, -6, -14, -21, -3, -19, -33, -30, -11, -32, -36, -30, -27, -26, -33, -30, -30, -44, -57, -23, 1, 3, -1, -3, -10, -19, -13, -39, -11, -5, -23, -15, -14, -5, 0, -19, -9, -5, 0, 2, -4, -2, -6, -5, -13, -10, -14, -21, -18, -27, -28, -42, -12, -22, -25, -24, 8, -13, -43, -35, -32, -34, -18, 3, 1, -1, -6, -1, -17, -14, -13, -11, 4, 1, -3, -13, -9, 1, 1, -14, -9, -5, -12, -19, -22, -8, -14, -20, -23, -14, -26, -32, -34, -24, -12, -25, -17, -22, -15, -11, -16, -49, 5, 3, -14, -5, -14, -16, -18, 5, 1, 12, 1, -19, -8, -5, 4, -10, -8, -10, -6, -3, -4, -20, -13, -6, -3, -26, -37, -20, -21, -35, -22, -22, -28, -31, -11, 11, 7, -46, -28, -43, -40, -13, 4, 3, -1, -15, -11, -9, 4, 1, -7, 9, 10, 16, 2, -6, -14, 4, -2, -3, -1, -13, -28, -5, -21, -20, 0, -1, -23, -15, -10, -11, 0, -1, -36, -32, -24, -48, -14, -22, -7, -9, -28, -19, 6, -7, -27, -5, 4, -11, -32, -21, 0, -6, 10, -9, 3, 10, 0, -14, -23, -28, -22, 7, -19, -29, -16, -8, -30, -39, -22, -30, -20, -1, -7, 0, -5, -22, -27, -18, -34, -1, -3, 13, -1, -18, -13, -22, -3, 7, 6, 5, -9, -6, -16, -24, -2, 8, 3, 1, -17, -14, -9, -10, -22, -32, -16, -22, -46, -34, -29, -35, -21, -29, 10, 4, -17, -35, -9, -18, -31, -21, -18, -4, -8, 2, -10, 1, 1, -7, 4, 10, -17, -10, -3, 0, 5, -10, -11, -6, -3, -12, -17, -24, -20, -18, -19, -19, -27, -23, -19, -26, -38, -32, -1, -54, -13, -26, -17, -12, -1, -1, 0, 1, 0, 2, -6, -1, -6, 6, 0, -17, -11, -11, -17, -6, -16, -16, -2, -2, -5, -18, -19, -22, -15, -27, -11, -13, -42, -30, -13, -26, -27, -22, -15, -8, -30, -30, -25, -31, -1, -26, -32, -7, -3, -42, -13, -1, 9, -3, -12, 7, 7, 15, -2, -9, -18, -10, -3, -12, -12, -15, -21, 3, -4, -15, -29, -19, -21, -29, -20, -25, -24, -38, -5, -14, -14, -13, -68, -22, -15, 0, 0, -9, -10, -13, -9, -9, -9, 0, -19, 12, -18, -15, 0, -23, -5, -11, -3, -4, -5, -26, -25, -8, -26, -16, -6, -25, -30, -35, -27, -28, -43, -48, 5, 6, -9, -17, -23, -15, -8, -26, -8, -1, 9, -23, -19, -4, -14, 3, -1, -9, -7, -18, -6, -4, -4, 2, 9, 4, -5, -10, -2, -7, -20, -10, -11, -29, -37, -23, -31, -21, -30, -43, -32, -25, -27, -27, -22, -25, -6, -5, -16, 0, -4, -32, -34, -19, -4, 0, -10, -10, -24, -5, 2, -4, -32, -6, -5, -16, -30, -17, 8, -5, -12, -14, -4, -19, -48, -33, -18, -14, -28, -50, -10, -23, -23, -10, -8, -20, 0, 1, 3, 2, -3, -7, -28, -9, -4, 15, 3, 20, 5, 9, 0, -31, -21, -6, -16, -13, -11, -7, -11, -15, -26, -12, -8, -21, -33, -26, -20, -28, -29, -44, 8, -63, -17, -42, -29, -9, -3, 0, -29, -7, -10, -41, -26, -3, 9, -2, -22, 3, 13, 6, 1, -5, -7, -2, 2, -3, -10, -18, -14, -17, -14, -25, -20, -28, -33, -21, -17, -26, -41, -45, -26, 0, -4, -2, -20, -38, -21, 6, -29, -45, -7, -4, -14, -13, 2, 1, -3, -17, -14, 17, 0, -3, -4, -1, 15, -2, -12, -12, -20, -15, -8, -22, -15, -25, -21, -26, -20, -26, -38, -50, -5, -33, -29, -63, -35, -11, 13, 9, -17, -5, -18, -26, -6, -1, 1, -11, 8, 3, -20, 0, -2, -23, -7, -4, -3, -8, -20, -24, -13, -5, -22, -16, -22, -23, -23, -15, -19, -24, -40, -45, 1, -27, -18, -21, -49, -35, -17, 10, 3, -15, -30, -23, -17, -4, 19, 1, 6, 15, 1, 4, 11, -12, -15, -19, -9, -1, -11, -10, -26, -12, -6, -9, -6, -29, -31, -21, -26, -35, -48, -38, -59, -15, -5, 1, -17, -2, -3, -4, 0, -9, -23, -28, -4, 22, -2, 13, 15, 12, -18, -4, 4, 1, 0, -2, -7, -8, -21, -26, -16, -19, -15, -10, -23, -25, -29, -19, -31, -23, -19, -40, -5, -14, -5, -28, -3, -9, -11, -23, -24, -24, -17, -48, -32, -23, -18, 13, 9, -12, -11, 4, -5, -17, -3, 2, -19, -16, -25, 5, -7, -10, -17, -15, -11, -16, -22, -24, -26, -26, -36, -40, -46, -38, -25, -20, -17, -28, -2, -2, -4, -19, 1, -35, -38, 7, 6, -11, -19, 3, 13, 9, -7, -13, -3, 12, 12, -12, -25, -24, -6, -2, -22, -13, -15, -29, -39, -39, -28, -20, -37, -56, -5, -9, -51, 0, 6, -6, -16, -10, -12, -12, -15, -33, -1, 0, -2, -3, 10, -4, -7, 17, 4, -7, -25, -3, 4, 0, -15, -23, -16, -29, -24, -16, -2, -16, -22, -14, -10, -34, -30, -41, -12, -16, -28, -10, 1, -2, 0, -6, -18, -16, 18, -10, -24, -22, -7, -8, -15, 7, 14, 0, 3, -7, 5, 12, 0, -15, -22, -15, -23, -15, -51, -17, -15, -22, -24, -27, -31, -30, -38, -41]]\n",
      "0: 1 [-128  127] 1\n",
      "1: 1 [-128  127] 1\n",
      "2: 1 [-128  127] 1\n",
      "3: 1 [-121  121] 1\n",
      "4: 1 [-110  110] 1\n",
      "5: 1 [-128  127] 1\n",
      "6: 1 [-79  79] 1\n",
      "7: 1 [-56  56] 1\n",
      "8: 1 [-116  116] 1\n",
      "9: 1 [-45  45] 1\n",
      "10: 1 [-83  83] 1\n",
      "11: 1 [-122  122] 1\n",
      "12: 1 [-104  104] 1\n",
      "13: 1 [-128  127] 1\n",
      "14: 1 [-128  127] 1\n",
      "15: 1 [-128  127] 1\n",
      "16: 1 [-32  32] 1\n",
      "17: 1 [-128  127] 1\n",
      "18: 1 [-128  127] 1\n",
      "19: 1 [-128  127] 1\n",
      "20: 1 [-128  127] 1\n",
      "21: 1 [-128  127] 1\n",
      "22: 1 [-128  127] 1\n",
      "23: 1 [-128  127] 1\n",
      "24: 1 [-128  127] 1\n",
      "25: 1 [-128  127] 1\n",
      "26: 1 [-127  127] 1\n",
      "27: 1 [-128  127] 1\n",
      "28: 1 [-128  127] 1\n",
      "29: 1 [-108  108] 1\n",
      "30: 1 [-79  79] 1\n",
      "31: 1 [-124  124] 1\n",
      "32: 1 [-127  127] 1\n",
      "33: 1 [-126  126] 1\n",
      "34: 1 [-128  127] 1\n",
      "35: 1 [-127  127] 1\n",
      "36: 1 [-127  127] 1\n",
      "37: 1 [-128  127] 1\n",
      "38: 1 [-128  127] 1\n",
      "39: 1 [-128  127] 1\n",
      "40: 1 [-128  127] 1\n",
      "41: 1 [-128  127] 1\n",
      "42: 1 [-121  121] 1\n",
      "43: 1 [-127  127] 1\n",
      "44: 1 [-128  127] 1\n",
      "45: 1 [-128  127] 1\n",
      "46: 1 [-110  110] 1\n",
      "47: 1 [-128  127] 1\n",
      "48: 1 [-127  127] 1\n",
      "49: 1 [-125  125] 1\n",
      "50: 1 [-128  127] 1\n",
      "51: 1 [-87  87] 1\n",
      "52: 1 [ 99 -99] 0\n",
      "53: 1 [-128  127] 1\n",
      "54: 1 [-124  124] 1\n",
      "55: 1 [-99  99] 1\n",
      "56: 1 [-112  112] 1\n",
      "57: 1 [-127  127] 1\n",
      "58: 1 [-104  104] 1\n",
      "59: 1 [-125  125] 1\n",
      "60: 1 [-128  127] 1\n",
      "61: 1 [-121  121] 1\n",
      "62: 1 [-128  127] 1\n",
      "63: 1 [-128  127] 1\n",
      "64: 1 [-128  127] 1\n",
      "65: 1 [-128  127] 1\n",
      "66: 1 [-128  127] 1\n",
      "67: 1 [ 123 -123] 0\n",
      "68: 1 [-110  110] 1\n",
      "69: 1 [-79  79] 1\n",
      "70: 1 [-120  120] 1\n",
      "71: 1 [-102  102] 1\n",
      "72: 1 [ 7 -7] 0\n",
      "73: 1 [-91  91] 1\n",
      "74: 1 [-26  26] 1\n",
      "75: 1 [-128  127] 1\n",
      "76: 1 [-128  127] 1\n",
      "77: 1 [-128  127] 1\n",
      "78: 1 [ 79 -79] 0\n",
      "79: 1 [-128  127] 1\n",
      "80: 1 [-126  126] 1\n",
      "81: 1 [-128  127] 1\n",
      "82: 1 [ 83 -83] 0\n",
      "83: 1 [-79  79] 1\n",
      "84: 1 [-128  127] 1\n",
      "85: 1 [-126  126] 1\n",
      "86: 1 [-120  120] 1\n",
      "87: 1 [-79  79] 1\n",
      "88: 1 [-128  127] 1\n",
      "89: 1 [-128  127] 1\n",
      "90: 1 [-126  126] 1\n",
      "91: 1 [-125  125] 1\n",
      "92: 1 [-127  127] 1\n",
      "93: 1 [-119  119] 1\n",
      "94: 1 [-127  127] 1\n",
      "95: 1 [-128  127] 1\n",
      "96: 1 [-127  127] 1\n",
      "97: 1 [-126  126] 1\n",
      "98: 1 [-128  127] 1\n",
      "99: 1 [-128  127] 1\n",
      "100: 1 [-128  127] 1\n",
      "101: 1 [-128  127] 1\n",
      "102: 1 [-127  127] 1\n",
      "103: 1 [-128  127] 1\n",
      "104: 1 [-128  127] 1\n",
      "105: 1 [-125  125] 1\n",
      "106: 1 [-123  123] 1\n",
      "107: 1 [-123  123] 1\n",
      "108: 1 [-128  127] 1\n",
      "109: 1 [-128  127] 1\n",
      "110: 1 [-123  123] 1\n",
      "111: 1 [-128  127] 1\n",
      "112: 1 [-128  127] 1\n",
      "113: 1 [-128  127] 1\n",
      "114: 1 [-128  127] 1\n",
      "115: 1 [-128  127] 1\n",
      "116: 1 [-128  127] 1\n",
      "117: 1 [-128  127] 1\n",
      "118: 1 [-127  127] 1\n",
      "119: 1 [-128  127] 1\n",
      "120: 1 [-128  127] 1\n",
      "121: 1 [-128  127] 1\n",
      "122: 1 [-128  127] 1\n",
      "123: 1 [-127  127] 1\n",
      "124: 1 [-128  127] 1\n",
      "125: 1 [-124  124] 1\n",
      "126: 1 [-128  127] 1\n",
      "127: 1 [-127  127] 1\n",
      "128: 1 [-127  127] 1\n",
      "129: 1 [-126  126] 1\n",
      "130: 1 [-128  127] 1\n",
      "131: 1 [-128  127] 1\n",
      "132: 1 [-128  127] 1\n",
      "133: 1 [-128  127] 1\n",
      "134: 1 [-128  127] 1\n",
      "135: 1 [-128  127] 1\n",
      "136: 1 [-128  127] 1\n",
      "137: 1 [-128  127] 1\n",
      "138: 1 [-126  126] 1\n",
      "139: 1 [-128  127] 1\n",
      "140: 1 [-124  124] 1\n",
      "141: 1 [-7  7] 1\n",
      "142: 1 [ 91 -91] 0\n",
      "143: 1 [-75  75] 1\n",
      "144: 1 [-127  127] 1\n",
      "145: 1 [-128  127] 1\n",
      "146: 1 [-128  127] 1\n",
      "147: 1 [-127  127] 1\n",
      "148: 1 [-128  127] 1\n",
      "149: 1 [-123  123] 1\n",
      "150: 1 [-126  126] 1\n",
      "151: 1 [-128  127] 1\n",
      "152: 1 [-126  126] 1\n",
      "153: 1 [-128  127] 1\n",
      "154: 1 [-128  127] 1\n",
      "155: 1 [-128  127] 1\n",
      "156: 1 [ 20 -20] 0\n",
      "157: 1 [-66  66] 1\n",
      "158: 1 [-7  7] 1\n",
      "159: 1 [-126  126] 1\n",
      "160: 1 [-110  110] 1\n",
      "161: 1 [-128  127] 1\n",
      "162: 1 [-128  127] 1\n",
      "163: 1 [-104  104] 1\n",
      "164: 1 [-121  121] 1\n",
      "165: 1 [-128  127] 1\n",
      "166: 1 [-123  123] 1\n",
      "167: 1 [-121  121] 1\n",
      "168: 1 [-128  127] 1\n",
      "169: 1 [-128  127] 1\n",
      "170: 1 [-128  127] 1\n",
      "171: 1 [-128  127] 1\n",
      "172: 1 [-122  122] 1\n",
      "173: 1 [-128  127] 1\n",
      "174: 1 [-128  127] 1\n",
      "175: 1 [-128  127] 1\n",
      "176: 1 [-128  127] 1\n",
      "177: 1 [-87  87] 1\n",
      "178: 1 [-127  127] 1\n",
      "179: 1 [-26  26] 1\n",
      "180: 1 [-118  118] 1\n",
      "181: 1 [-123  123] 1\n",
      "182: 1 [-127  127] 1\n",
      "183: 1 [-127  127] 1\n",
      "184: 1 [-128  127] 1\n",
      "185: 1 [-128  127] 1\n",
      "186: 1 [-128  127] 1\n",
      "187: 1 [-128  127] 1\n",
      "188: 1 [-128  127] 1\n",
      "189: 1 [-128  127] 1\n",
      "190: 1 [-128  127] 1\n",
      "191: 1 [-128  127] 1\n",
      "192: 1 [-128  127] 1\n",
      "193: 1 [-128  127] 1\n",
      "194: 1 [-128  127] 1\n",
      "195: 1 [-125  125] 1\n",
      "196: 1 [-127  127] 1\n",
      "197: 1 [-124  124] 1\n",
      "198: 1 [ 71 -71] 0\n",
      "199: 1 [0 0] 0\n",
      "200: 1 [-128  127] 1\n",
      "201: 1 [-127  127] 1\n",
      "202: 1 [-128  127] 1\n",
      "203: 1 [-128  127] 1\n",
      "204: 1 [-127  127] 1\n",
      "205: 1 [-128  127] 1\n",
      "206: 1 [-128  127] 1\n",
      "207: 1 [-128  127] 1\n",
      "208: 1 [-128  127] 1\n",
      "209: 1 [-128  127] 1\n",
      "210: 1 [-128  127] 1\n",
      "211: 1 [-128  127] 1\n",
      "212: 1 [-128  127] 1\n",
      "213: 1 [-112  112] 1\n",
      "214: 1 [-126  126] 1\n",
      "215: 1 [-115  115] 1\n",
      "216: 1 [-126  126] 1\n",
      "217: 1 [-126  126] 1\n",
      "218: 1 [-115  115] 1\n",
      "219: 1 [-128  127] 1\n",
      "220: 1 [-128  127] 1\n",
      "221: 1 [-128  127] 1\n",
      "222: 1 [-128  127] 1\n",
      "223: 1 [-128  127] 1\n",
      "224: 1 [-112  112] 1\n",
      "225: 1 [-128  127] 1\n",
      "226: 1 [-128  127] 1\n",
      "227: 1 [-128  127] 1\n",
      "228: 1 [-127  127] 1\n",
      "229: 1 [-125  125] 1\n",
      "230: 1 [-128  127] 1\n",
      "231: 1 [-110  110] 1\n",
      "232: 1 [-126  126] 1\n",
      "233: 1 [-127  127] 1\n",
      "234: 1 [-128  127] 1\n",
      "235: 1 [ 56 -56] 0\n",
      "236: 1 [-128  127] 1\n",
      "237: 1 [-127  127] 1\n",
      "238: 1 [-128  127] 1\n",
      "239: 1 [-128  127] 1\n",
      "240: 1 [-127  127] 1\n",
      "241: 1 [-128  127] 1\n",
      "242: 1 [-128  127] 1\n",
      "243: 1 [-128  127] 1\n",
      "244: 1 [-128  127] 1\n",
      "245: 1 [-128  127] 1\n",
      "246: 1 [-128  127] 1\n",
      "247: 1 [-94  94] 1\n",
      "248: 1 [-116  116] 1\n",
      "249: 1 [-128  127] 1\n",
      "250: 1 [-120  120] 1\n",
      "251: 1 [-45  45] 1\n",
      "252: 1 [-124  124] 1\n",
      "253: 1 [-128  127] 1\n",
      "254: 1 [-119  119] 1\n",
      "255: 1 [ 125 -125] 0\n",
      "256: 1 [-87  87] 1\n",
      "257: 1 [ 124 -124] 0\n",
      "258: 1 [-121  121] 1\n",
      "259: 1 [-127  127] 1\n",
      "260: 1 [-124  124] 1\n",
      "261: 1 [-91  91] 1\n",
      "262: 1 [-128  127] 1\n",
      "263: 1 [-128  127] 1\n",
      "264: 1 [-128  127] 1\n",
      "265: 1 [-128  127] 1\n",
      "266: 1 [-126  126] 1\n",
      "267: 1 [-128  127] 1\n",
      "268: 1 [-128  127] 1\n",
      "269: 1 [-91  91] 1\n",
      "270: 1 [-113  113] 1\n",
      "271: 1 [-39  39] 1\n",
      "272: 1 [-120  120] 1\n",
      "273: 1 [-128  127] 1\n",
      "274: 1 [-128  127] 1\n",
      "275: 1 [-128  127] 1\n",
      "276: 1 [-113  113] 1\n",
      "277: 1 [-112  112] 1\n",
      "278: 1 [-128  127] 1\n",
      "279: 1 [-97  97] 1\n",
      "280: 1 [-56  56] 1\n",
      "281: 1 [-94  94] 1\n",
      "282: 1 [-123  123] 1\n",
      "283: 1 [-128  127] 1\n",
      "284: 1 [-128  127] 1\n",
      "285: 1 [-125  125] 1\n",
      "286: 1 [-128  127] 1\n",
      "287: 1 [-124  124] 1\n",
      "288: 1 [-128  127] 1\n",
      "289: 1 [-128  127] 1\n",
      "290: 1 [-128  127] 1\n",
      "291: 1 [-128  127] 1\n",
      "292: 1 [-128  127] 1\n",
      "293: 1 [-126  126] 1\n",
      "294: 1 [-128  127] 1\n",
      "295: 1 [-124  124] 1\n",
      "296: 1 [-20  20] 1\n",
      "297: 1 [-128  127] 1\n",
      "298: 1 [-127  127] 1\n",
      "299: 1 [-127  127] 1\n",
      "300: 1 [ 106 -106] 0\n",
      "301: 1 [-125  125] 1\n",
      "302: 1 [-128  127] 1\n",
      "303: 1 [-128  127] 1\n",
      "304: 1 [-128  127] 1\n",
      "305: 1 [-128  127] 1\n",
      "306: 1 [-128  127] 1\n",
      "307: 1 [-124  124] 1\n",
      "308: 1 [-128  127] 1\n",
      "309: 1 [-128  127] 1\n",
      "310: 1 [-128  127] 1\n",
      "311: 1 [-128  127] 1\n",
      "312: 1 [-128  127] 1\n",
      "313: 1 [-128  127] 1\n",
      "314: 1 [-127  127] 1\n",
      "315: 1 [-128  127] 1\n",
      "316: 1 [-128  127] 1\n",
      "317: 1 [-128  127] 1\n",
      "318: 1 [-128  127] 1\n",
      "319: 1 [-128  127] 1\n",
      "320: 1 [-128  127] 1\n",
      "321: 1 [-128  127] 1\n",
      "322: 1 [-127  127] 1\n",
      "323: 1 [-127  127] 1\n",
      "324: 1 [-128  127] 1\n",
      "325: 1 [-128  127] 1\n",
      "326: 1 [-128  127] 1\n",
      "327: 1 [-128  127] 1\n",
      "328: 1 [-128  127] 1\n",
      "329: 1 [-127  127] 1\n",
      "330: 1 [-127  127] 1\n",
      "331: 1 [-127  127] 1\n",
      "332: 1 [-128  127] 1\n",
      "333: 1 [-124  124] 1\n",
      "334: 1 [-128  127] 1\n",
      "335: 1 [-128  127] 1\n",
      "336: 1 [-128  127] 1\n",
      "337: 1 [-128  127] 1\n",
      "338: 1 [-128  127] 1\n",
      "339: 1 [-128  127] 1\n",
      "340: 1 [-128  127] 1\n",
      "341: 1 [-128  127] 1\n",
      "342: 1 [-128  127] 1\n",
      "343: 1 [-128  127] 1\n",
      "344: 1 [-110  110] 1\n",
      "345: 1 [-128  127] 1\n",
      "346: 1 [-128  127] 1\n",
      "347: 1 [-127  127] 1\n",
      "348: 1 [-128  127] 1\n",
      "349: 1 [-128  127] 1\n",
      "350: 1 [-128  127] 1\n",
      "351: 1 [-128  127] 1\n",
      "352: 1 [-128  127] 1\n",
      "353: 1 [-125  125] 1\n",
      "354: 1 [-128  127] 1\n",
      "355: 1 [-124  124] 1\n",
      "356: 1 [-127  127] 1\n",
      "357: 1 [-128  127] 1\n",
      "358: 1 [-127  127] 1\n",
      "359: 1 [-127  127] 1\n",
      "360: 1 [-126  126] 1\n",
      "361: 1 [-127  127] 1\n",
      "362: 1 [-128  127] 1\n",
      "363: 1 [-128  127] 1\n",
      "364: 1 [-128  127] 1\n",
      "365: 1 [-128  127] 1\n",
      "366: 1 [-128  127] 1\n",
      "367: 1 [-126  126] 1\n",
      "368: 1 [-97  97] 1\n",
      "369: 1 [ 7 -7] 0\n",
      "370: 1 [-121  121] 1\n",
      "371: 1 [-127  127] 1\n",
      "372: 1 [-20  20] 1\n",
      "373: 1 [-117  117] 1\n",
      "374: 1 [-91  91] 1\n",
      "375: 1 [-128  127] 1\n",
      "376: 1 [-128  127] 1\n",
      "377: 1 [-128  127] 1\n",
      "378: 1 [-128  127] 1\n",
      "379: 1 [-127  127] 1\n",
      "380: 1 [-128  127] 1\n",
      "381: 1 [-104  104] 1\n",
      "382: 1 [-119  119] 1\n",
      "383: 1 [-127  127] 1\n",
      "384: 1 [-125  125] 1\n",
      "385: 1 [-128  127] 1\n",
      "386: 1 [-128  127] 1\n",
      "387: 1 [-127  127] 1\n",
      "388: 1 [-128  127] 1\n",
      "389: 1 [-128  127] 1\n",
      "390: 1 [-127  127] 1\n",
      "391: 1 [-66  66] 1\n",
      "392: 1 [-128  127] 1\n",
      "393: 1 [-102  102] 1\n",
      "394: 1 [ 61 -61] 0\n",
      "395: 1 [-106  106] 1\n",
      "396: 1 [-110  110] 1\n",
      "397: 1 [-113  113] 1\n",
      "398: 1 [-128  127] 1\n",
      "399: 1 [-128  127] 1\n",
      "400: 1 [-128  127] 1\n",
      "401: 1 [-128  127] 1\n",
      "402: 1 [-128  127] 1\n",
      "403: 1 [-115  115] 1\n",
      "404: 1 [-128  127] 1\n",
      "405: 1 [-119  119] 1\n",
      "406: 1 [-102  102] 1\n",
      "407: 1 [-120  120] 1\n",
      "408: 1 [-112  112] 1\n",
      "409: 1 [-7  7] 1\n",
      "410: 1 [-127  127] 1\n",
      "411: 1 [-128  127] 1\n",
      "412: 1 [-123  123] 1\n",
      "413: 1 [-128  127] 1\n",
      "414: 1 [-128  127] 1\n",
      "415: 1 [-128  127] 1\n",
      "416: 1 [-128  127] 1\n",
      "417: 1 [-128  127] 1\n",
      "418: 1 [-128  127] 1\n",
      "419: 1 [-128  127] 1\n",
      "420: 1 [-128  127] 1\n",
      "421: 1 [-121  121] 1\n",
      "422: 1 [-127  127] 1\n",
      "423: 1 [-83  83] 1\n",
      "424: 1 [-123  123] 1\n",
      "425: 1 [-126  126] 1\n",
      "426: 1 [-124  124] 1\n",
      "427: 1 [-128  127] 1\n",
      "428: 1 [-125  125] 1\n",
      "429: 1 [-122  122] 1\n",
      "430: 1 [-112  112] 1\n",
      "431: 1 [-128  127] 1\n",
      "432: 1 [-126  126] 1\n",
      "433: 1 [-128  127] 1\n",
      "434: 1 [-128  127] 1\n",
      "435: 1 [-128  127] 1\n",
      "436: 1 [-128  127] 1\n",
      "437: 1 [-128  127] 1\n",
      "438: 1 [-128  127] 1\n",
      "439: 1 [-128  127] 1\n",
      "440: 1 [-125  125] 1\n",
      "441: 1 [ 20 -20] 0\n",
      "442: 1 [-128  127] 1\n",
      "443: 1 [-128  127] 1\n",
      "444: 1 [-128  127] 1\n",
      "445: 1 [-128  127] 1\n",
      "446: 1 [-108  108] 1\n",
      "447: 1 [-118  118] 1\n",
      "448: 1 [-110  110] 1\n",
      "449: 1 [-127  127] 1\n",
      "450: 1 [-128  127] 1\n",
      "451: 1 [-127  127] 1\n",
      "452: 1 [-128  127] 1\n",
      "453: 1 [-128  127] 1\n",
      "454: 1 [-128  127] 1\n",
      "455: 1 [-125  125] 1\n",
      "456: 1 [-127  127] 1\n",
      "457: 1 [-127  127] 1\n",
      "458: 1 [-128  127] 1\n",
      "459: 1 [ 7 -7] 0\n",
      "460: 1 [-124  124] 1\n",
      "461: 1 [-128  127] 1\n",
      "462: 1 [-122  122] 1\n",
      "463: 1 [-124  124] 1\n",
      "464: 1 [-112  112] 1\n",
      "465: 1 [-127  127] 1\n",
      "466: 1 [-128  127] 1\n",
      "467: 1 [-127  127] 1\n",
      "468: 1 [-128  127] 1\n",
      "469: 1 [-128  127] 1\n",
      "470: 1 [-128  127] 1\n",
      "471: 1 [-128  127] 1\n",
      "472: 1 [-127  127] 1\n",
      "473: 1 [-127  127] 1\n",
      "474: 1 [-83  83] 1\n",
      "475: 1 [-121  121] 1\n",
      "476: 1 [-127  127] 1\n",
      "477: 1 [-97  97] 1\n",
      "478: 1 [-128  127] 1\n",
      "479: 1 [-126  126] 1\n",
      "480: 1 [-128  127] 1\n",
      "481: 1 [-123  123] 1\n",
      "482: 1 [-123  123] 1\n",
      "483: 1 [-83  83] 1\n",
      "484: 1 [-112  112] 1\n",
      "485: 1 [-87  87] 1\n",
      "486: 1 [-121  121] 1\n",
      "487: 1 [-106  106] 1\n",
      "488: 1 [-66  66] 1\n",
      "489: 1 [-128  127] 1\n",
      "490: 0 [ 127 -128] 0\n",
      "491: 0 [ 127 -128] 0\n",
      "492: 0 [ 127 -128] 0\n",
      "493: 0 [ 127 -128] 0\n",
      "494: 0 [ 124 -124] 0\n",
      "495: 0 [-66  66] 1\n",
      "496: 0 [ 32 -32] 0\n",
      "497: 0 [ 20 -20] 0\n",
      "498: 0 [ 120 -120] 0\n",
      "499: 0 [ 127 -128] 0\n",
      "500: 0 [ 127 -128] 0\n",
      "501: 0 [ 126 -126] 0\n",
      "502: 0 [ 126 -126] 0\n",
      "503: 0 [ 124 -124] 0\n",
      "504: 0 [ 127 -128] 0\n",
      "505: 0 [ 127 -128] 0\n",
      "506: 0 [ 127 -128] 0\n",
      "507: 0 [ 127 -128] 0\n",
      "508: 0 [ 127 -128] 0\n",
      "509: 0 [ 127 -128] 0\n",
      "510: 0 [ 127 -127] 0\n",
      "511: 0 [ 125 -125] 0\n",
      "512: 0 [ 108 -108] 0\n",
      "513: 0 [ 119 -119] 0\n",
      "514: 0 [ 126 -126] 0\n",
      "515: 0 [ 127 -128] 0\n",
      "516: 0 [ 117 -117] 0\n",
      "517: 0 [ 127 -128] 0\n",
      "518: 0 [ 104 -104] 0\n",
      "519: 0 [ 108 -108] 0\n",
      "520: 0 [ 121 -121] 0\n",
      "521: 0 [ 127 -128] 0\n",
      "522: 0 [ 127 -128] 0\n",
      "523: 0 [ 127 -128] 0\n",
      "524: 0 [ 127 -128] 0\n",
      "525: 0 [ 127 -128] 0\n",
      "526: 0 [ 125 -125] 0\n",
      "527: 0 [ 127 -128] 0\n",
      "528: 0 [ 127 -128] 0\n",
      "529: 0 [ 127 -128] 0\n",
      "530: 0 [ 127 -127] 0\n",
      "531: 0 [ 125 -125] 0\n",
      "532: 0 [ 127 -128] 0\n",
      "533: 0 [ 127 -128] 0\n",
      "534: 0 [ 127 -128] 0\n",
      "535: 0 [ 127 -127] 0\n",
      "536: 0 [ 127 -128] 0\n",
      "537: 0 [ 127 -128] 0\n",
      "538: 0 [ 127 -128] 0\n",
      "539: 0 [ 127 -128] 0\n",
      "540: 0 [ 127 -127] 0\n",
      "541: 0 [ 127 -128] 0\n",
      "542: 0 [ 127 -128] 0\n",
      "543: 0 [ 127 -127] 0\n",
      "544: 0 [ 127 -128] 0\n",
      "545: 0 [ 127 -128] 0\n",
      "546: 0 [ 126 -126] 0\n",
      "547: 0 [ 56 -56] 0\n",
      "548: 0 [ 125 -125] 0\n",
      "549: 0 [ 127 -128] 0\n",
      "550: 0 [ 120 -120] 0\n",
      "551: 0 [ 121 -121] 0\n",
      "552: 0 [ 113 -113] 0\n",
      "553: 0 [ 127 -128] 0\n",
      "554: 0 [ 127 -128] 0\n",
      "555: 0 [ 119 -119] 0\n",
      "556: 0 [ 127 -128] 0\n",
      "557: 0 [ 119 -119] 0\n",
      "558: 0 [ 127 -128] 0\n",
      "559: 0 [ 123 -123] 0\n",
      "560: 0 [ 127 -128] 0\n",
      "561: 0 [ 127 -128] 0\n",
      "562: 0 [ 127 -128] 0\n",
      "563: 0 [ 127 -127] 0\n",
      "564: 0 [ 79 -79] 0\n",
      "565: 0 [ 126 -126] 0\n",
      "566: 0 [ 120 -120] 0\n",
      "567: 0 [ 127 -128] 0\n",
      "568: 0 [ 97 -97] 0\n",
      "569: 0 [ 127 -128] 0\n",
      "570: 0 [ 127 -127] 0\n",
      "571: 0 [ 104 -104] 0\n",
      "572: 0 [ 127 -127] 0\n",
      "573: 0 [ 115 -115] 0\n",
      "574: 0 [ 124 -124] 0\n",
      "575: 0 [ 127 -127] 0\n",
      "576: 0 [ 102 -102] 0\n",
      "577: 0 [ 127 -128] 0\n",
      "578: 0 [ 127 -128] 0\n",
      "579: 0 [ 127 -128] 0\n",
      "580: 0 [ 127 -128] 0\n",
      "581: 0 [ 127 -128] 0\n",
      "582: 0 [ 115 -115] 0\n",
      "583: 0 [ 127 -128] 0\n",
      "584: 0 [ 127 -128] 0\n",
      "585: 0 [ 121 -121] 0\n",
      "586: 0 [ 127 -128] 0\n",
      "587: 0 [ 126 -126] 0\n",
      "588: 0 [ 127 -128] 0\n",
      "589: 0 [ 127 -128] 0\n",
      "590: 0 [ 127 -128] 0\n",
      "591: 0 [ 121 -121] 0\n",
      "592: 0 [ 127 -127] 0\n",
      "593: 0 [ 127 -127] 0\n",
      "594: 0 [ 127 -128] 0\n",
      "595: 0 [ 126 -126] 0\n",
      "596: 0 [ 127 -127] 0\n",
      "597: 0 [ 127 -128] 0\n",
      "598: 0 [-121  121] 1\n",
      "599: 0 [ 127 -128] 0\n",
      "600: 0 [ 127 -128] 0\n",
      "601: 0 [-128  127] 1\n",
      "602: 0 [ 127 -128] 0\n",
      "603: 0 [ 127 -128] 0\n",
      "604: 0 [ 127 -128] 0\n",
      "605: 0 [ 126 -126] 0\n",
      "606: 0 [ 127 -128] 0\n",
      "607: 0 [ 127 -128] 0\n",
      "608: 0 [ 127 -128] 0\n",
      "609: 0 [ 127 -128] 0\n",
      "610: 0 [ 127 -128] 0\n",
      "611: 0 [ 127 -128] 0\n",
      "612: 0 [ 127 -128] 0\n",
      "613: 0 [ 127 -128] 0\n",
      "614: 0 [ 127 -128] 0\n",
      "615: 0 [ 127 -128] 0\n",
      "616: 0 [ 127 -128] 0\n",
      "617: 0 [ 127 -128] 0\n",
      "618: 0 [ 127 -128] 0\n",
      "619: 0 [ 127 -128] 0\n",
      "620: 0 [ 126 -126] 0\n",
      "621: 0 [ 127 -127] 0\n",
      "622: 0 [ 71 -71] 0\n",
      "623: 0 [ 115 -115] 0\n",
      "624: 0 [ 126 -126] 0\n",
      "625: 0 [ 127 -127] 0\n",
      "626: 0 [ 75 -75] 0\n",
      "627: 0 [ 91 -91] 0\n",
      "628: 0 [ 113 -113] 0\n",
      "629: 0 [ 119 -119] 0\n",
      "630: 0 [ 97 -97] 0\n",
      "631: 0 [ 127 -128] 0\n",
      "632: 0 [ 127 -128] 0\n",
      "633: 0 [ 127 -128] 0\n",
      "634: 0 [ 127 -128] 0\n",
      "635: 0 [ 26 -26] 0\n",
      "636: 0 [ 110 -110] 0\n",
      "637: 0 [ 61 -61] 0\n",
      "638: 0 [ 127 -127] 0\n",
      "639: 0 [ 127 -128] 0\n",
      "640: 0 [ 127 -127] 0\n",
      "641: 0 [ 127 -127] 0\n",
      "642: 0 [ 127 -128] 0\n",
      "643: 0 [ 127 -128] 0\n",
      "644: 0 [ 127 -128] 0\n",
      "645: 0 [ 127 -128] 0\n",
      "646: 0 [ 124 -124] 0\n",
      "647: 0 [ 127 -128] 0\n",
      "648: 0 [ 127 -128] 0\n",
      "649: 0 [ 127 -128] 0\n",
      "650: 0 [ 127 -128] 0\n",
      "651: 0 [ 127 -128] 0\n",
      "652: 0 [ 126 -126] 0\n",
      "653: 0 [ 26 -26] 0\n",
      "654: 0 [ 127 -128] 0\n",
      "655: 0 [ 127 -128] 0\n",
      "656: 0 [ 127 -128] 0\n",
      "657: 0 [ 115 -115] 0\n",
      "658: 0 [ 127 -128] 0\n",
      "659: 0 [ 127 -128] 0\n",
      "660: 0 [ 127 -128] 0\n",
      "661: 0 [ 99 -99] 0\n",
      "662: 0 [ 112 -112] 0\n",
      "663: 0 [ 127 -128] 0\n",
      "664: 0 [ 127 -127] 0\n",
      "665: 0 [ 113 -113] 0\n",
      "666: 0 [ 127 -128] 0\n",
      "667: 0 [ 99 -99] 0\n",
      "668: 0 [-83  83] 1\n",
      "669: 0 [ 123 -123] 0\n",
      "670: 0 [ 127 -127] 0\n",
      "671: 0 [ 126 -126] 0\n",
      "672: 0 [ 127 -127] 0\n",
      "673: 0 [ 127 -127] 0\n",
      "674: 0 [ 127 -127] 0\n",
      "675: 0 [ 127 -128] 0\n",
      "676: 0 [ 127 -128] 0\n",
      "677: 0 [ 87 -87] 0\n",
      "678: 0 [ 104 -104] 0\n",
      "679: 0 [ 127 -128] 0\n",
      "680: 0 [ 102 -102] 0\n",
      "681: 0 [ 121 -121] 0\n",
      "682: 0 [-87  87] 1\n",
      "683: 0 [ 127 -128] 0\n",
      "684: 0 [ 127 -128] 0\n",
      "685: 0 [ 127 -128] 0\n",
      "686: 0 [ 127 -128] 0\n",
      "687: 0 [ 127 -128] 0\n",
      "688: 0 [ 121 -121] 0\n",
      "689: 0 [ 97 -97] 0\n",
      "690: 0 [ 127 -127] 0\n",
      "691: 0 [-56  56] 1\n",
      "692: 0 [ 127 -128] 0\n",
      "693: 0 [ 127 -128] 0\n",
      "694: 0 [ 127 -128] 0\n",
      "695: 0 [ 121 -121] 0\n",
      "696: 0 [ 127 -128] 0\n",
      "697: 0 [ 127 -128] 0\n",
      "698: 0 [ 120 -120] 0\n",
      "699: 0 [ 127 -128] 0\n",
      "700: 0 [ 127 -127] 0\n",
      "701: 0 [ 127 -128] 0\n",
      "702: 0 [ 127 -128] 0\n",
      "703: 0 [ 127 -127] 0\n",
      "704: 0 [ 126 -126] 0\n",
      "705: 0 [ 127 -128] 0\n",
      "706: 0 [ 127 -127] 0\n",
      "707: 0 [ 127 -128] 0\n",
      "708: 0 [ 124 -124] 0\n",
      "709: 0 [ 127 -128] 0\n",
      "710: 0 [ 127 -128] 0\n",
      "711: 0 [ 127 -128] 0\n",
      "712: 0 [ 127 -128] 0\n",
      "713: 0 [ 127 -128] 0\n",
      "714: 0 [ 127 -128] 0\n",
      "715: 0 [ 127 -128] 0\n",
      "716: 0 [ 127 -128] 0\n",
      "717: 0 [ 127 -128] 0\n",
      "718: 0 [ 127 -127] 0\n",
      "719: 0 [ 123 -123] 0\n",
      "720: 0 [ 127 -128] 0\n",
      "721: 0 [ 127 -128] 0\n",
      "722: 0 [ 127 -127] 0\n",
      "723: 0 [ 127 -128] 0\n",
      "724: 0 [ 102 -102] 0\n",
      "725: 0 [ 87 -87] 0\n",
      "726: 0 [-128  127] 1\n",
      "727: 0 [ 127 -128] 0\n",
      "728: 0 [ 79 -79] 0\n",
      "729: 0 [ 83 -83] 0\n",
      "730: 0 [0 0] 0\n",
      "731: 0 [ 127 -128] 0\n",
      "732: 0 [ 127 -127] 0\n",
      "733: 0 [ 97 -97] 0\n",
      "734: 0 [ 127 -128] 0\n",
      "735: 0 [ 45 -45] 0\n",
      "736: 0 [ 20 -20] 0\n",
      "737: 0 [ 50 -50] 0\n",
      "738: 0 [ 125 -125] 0\n",
      "739: 0 [ 127 -128] 0\n",
      "740: 0 [ 127 -128] 0\n",
      "741: 0 [ 127 -128] 0\n",
      "742: 0 [ 127 -128] 0\n",
      "743: 0 [ 126 -126] 0\n",
      "744: 0 [ 127 -128] 0\n",
      "745: 0 [ 120 -120] 0\n",
      "746: 0 [ 127 -128] 0\n",
      "747: 0 [ 116 -116] 0\n",
      "748: 0 [ 127 -128] 0\n",
      "749: 0 [ 127 -128] 0\n",
      "750: 0 [ 117 -117] 0\n",
      "751: 0 [ 127 -128] 0\n",
      "752: 0 [ 127 -128] 0\n",
      "753: 0 [ 127 -128] 0\n",
      "754: 0 [ 127 -128] 0\n",
      "755: 0 [ 119 -119] 0\n",
      "756: 0 [ 113 -113] 0\n",
      "757: 0 [ 75 -75] 0\n",
      "758: 0 [ 127 -128] 0\n",
      "759: 0 [ 115 -115] 0\n",
      "760: 0 [ 127 -128] 0\n",
      "761: 0 [ 127 -128] 0\n",
      "762: 0 [ 127 -127] 0\n",
      "763: 0 [ 124 -124] 0\n",
      "764: 0 [ 127 -128] 0\n",
      "765: 0 [ 91 -91] 0\n",
      "766: 0 [ 20 -20] 0\n",
      "767: 0 [ 122 -122] 0\n",
      "768: 0 [ 127 -128] 0\n",
      "769: 0 [ 127 -128] 0\n",
      "770: 0 [ 127 -128] 0\n",
      "771: 0 [ 127 -128] 0\n",
      "772: 0 [ 127 -128] 0\n",
      "773: 0 [ 127 -128] 0\n",
      "774: 0 [ 127 -128] 0\n",
      "775: 0 [ 127 -128] 0\n",
      "776: 0 [-106  106] 1\n",
      "777: 0 [ 127 -128] 0\n",
      "778: 0 [ 124 -124] 0\n",
      "779: 0 [ 127 -128] 0\n",
      "780: 0 [ 106 -106] 0\n",
      "781: 0 [ 127 -128] 0\n",
      "782: 0 [ 79 -79] 0\n",
      "783: 0 [ 123 -123] 0\n",
      "784: 0 [ 127 -127] 0\n",
      "785: 0 [-26  26] 1\n",
      "786: 0 [ 127 -127] 0\n",
      "787: 0 [ 56 -56] 0\n",
      "788: 0 [ 61 -61] 0\n",
      "789: 0 [ 127 -127] 0\n",
      "790: 0 [ 123 -123] 0\n",
      "791: 0 [ 127 -128] 0\n",
      "792: 0 [ 127 -128] 0\n",
      "793: 0 [ 127 -127] 0\n",
      "794: 0 [ 127 -128] 0\n",
      "795: 0 [ 127 -128] 0\n",
      "796: 0 [ 87 -87] 0\n",
      "797: 0 [ 127 -128] 0\n",
      "798: 0 [ 127 -128] 0\n",
      "799: 0 [ 125 -125] 0\n",
      "800: 0 [ 127 -128] 0\n",
      "801: 0 [ 126 -126] 0\n",
      "802: 0 [ 94 -94] 0\n",
      "803: 0 [ 122 -122] 0\n",
      "804: 0 [ 108 -108] 0\n",
      "805: 0 [ 126 -126] 0\n",
      "806: 0 [ 110 -110] 0\n",
      "807: 0 [ 45 -45] 0\n",
      "808: 0 [ 127 -128] 0\n",
      "809: 0 [ 127 -128] 0\n",
      "810: 0 [ 127 -128] 0\n",
      "811: 0 [ 127 -128] 0\n",
      "812: 0 [ 115 -115] 0\n",
      "813: 0 [ 124 -124] 0\n",
      "814: 0 [ 126 -126] 0\n",
      "815: 0 [ 127 -127] 0\n",
      "816: 0 [ 127 -128] 0\n",
      "817: 0 [ 113 -113] 0\n",
      "818: 0 [ 127 -128] 0\n",
      "819: 0 [ 127 -128] 0\n",
      "820: 0 [ 127 -128] 0\n",
      "821: 0 [ 127 -128] 0\n",
      "822: 0 [ 39 -39] 0\n",
      "823: 0 [ 32 -32] 0\n",
      "824: 0 [ 127 -128] 0\n",
      "825: 0 [ 83 -83] 0\n",
      "826: 0 [ 39 -39] 0\n",
      "827: 0 [ 126 -126] 0\n",
      "828: 0 [ 127 -128] 0\n",
      "829: 0 [ 116 -116] 0\n",
      "830: 0 [ 127 -127] 0\n",
      "831: 0 [ 127 -128] 0\n",
      "832: 0 [ 94 -94] 0\n",
      "833: 0 [ 127 -127] 0\n",
      "834: 0 [ 127 -128] 0\n",
      "835: 0 [ 127 -128] 0\n",
      "836: 0 [ 127 -127] 0\n",
      "837: 0 [ 127 -128] 0\n",
      "838: 0 [ 127 -128] 0\n",
      "839: 0 [ 127 -128] 0\n",
      "840: 0 [ 127 -127] 0\n",
      "841: 0 [-102  102] 1\n",
      "842: 0 [ 126 -126] 0\n",
      "843: 0 [-45  45] 1\n",
      "844: 0 [ 106 -106] 0\n",
      "845: 0 [ 125 -125] 0\n",
      "846: 0 [ 127 -128] 0\n",
      "847: 0 [ 127 -128] 0\n",
      "848: 0 [ 127 -127] 0\n",
      "849: 0 [ 127 -128] 0\n",
      "850: 0 [ 127 -127] 0\n",
      "851: 0 [ 127 -128] 0\n",
      "852: 0 [ 127 -128] 0\n",
      "853: 0 [ 66 -66] 0\n",
      "854: 0 [ 127 -128] 0\n",
      "855: 0 [ 127 -128] 0\n",
      "856: 0 [ 66 -66] 0\n",
      "857: 0 [ 127 -128] 0\n",
      "858: 0 [ 127 -128] 0\n",
      "859: 0 [ 127 -128] 0\n",
      "860: 0 [ 127 -128] 0\n",
      "861: 0 [ 127 -128] 0\n",
      "862: 0 [ 127 -128] 0\n",
      "863: 0 [ 94 -94] 0\n",
      "864: 0 [ 127 -128] 0\n",
      "865: 0 [ 127 -128] 0\n",
      "866: 0 [ 127 -128] 0\n",
      "867: 0 [ 127 -127] 0\n",
      "868: 0 [ 124 -124] 0\n",
      "869: 0 [ 127 -128] 0\n",
      "870: 0 [ 127 -128] 0\n",
      "871: 0 [ 127 -128] 0\n",
      "872: 0 [ 127 -128] 0\n",
      "873: 0 [ 127 -128] 0\n",
      "874: 0 [ 127 -128] 0\n",
      "875: 0 [ 127 -127] 0\n",
      "876: 0 [ 127 -128] 0\n",
      "877: 0 [ 127 -128] 0\n",
      "878: 0 [ 127 -128] 0\n",
      "879: 0 [ 127 -128] 0\n",
      "880: 0 [ 123 -123] 0\n",
      "881: 0 [ 87 -87] 0\n",
      "882: 0 [-117  117] 1\n",
      "883: 0 [ 115 -115] 0\n",
      "884: 0 [ 110 -110] 0\n",
      "885: 0 [ 121 -121] 0\n",
      "886: 0 [ 127 -128] 0\n",
      "887: 0 [ 127 -128] 0\n",
      "888: 0 [ 127 -128] 0\n",
      "889: 0 [ 125 -125] 0\n",
      "890: 0 [ 127 -128] 0\n",
      "891: 0 [ 127 -128] 0\n",
      "892: 0 [ 127 -127] 0\n",
      "893: 0 [ 127 -128] 0\n",
      "894: 0 [ 117 -117] 0\n",
      "895: 0 [ 127 -128] 0\n",
      "896: 0 [ 127 -128] 0\n",
      "897: 0 [ 113 -113] 0\n",
      "898: 0 [ 127 -127] 0\n",
      "899: 0 [ 127 -127] 0\n",
      "900: 0 [ 127 -128] 0\n",
      "901: 0 [ 123 -123] 0\n",
      "902: 0 [ 127 -127] 0\n",
      "903: 0 [ 118 -118] 0\n",
      "904: 0 [ 56 -56] 0\n",
      "905: 0 [ 127 -128] 0\n",
      "906: 0 [ 127 -128] 0\n",
      "907: 0 [ 127 -127] 0\n",
      "908: 0 [ 127 -128] 0\n",
      "909: 0 [ 121 -121] 0\n",
      "910: 0 [ 127 -128] 0\n",
      "911: 0 [ 127 -128] 0\n",
      "912: 0 [ 126 -126] 0\n",
      "913: 0 [ 127 -128] 0\n",
      "914: 0 [ 127 -128] 0\n",
      "915: 0 [ 127 -128] 0\n",
      "916: 0 [ 127 -128] 0\n",
      "917: 0 [ 127 -128] 0\n",
      "918: 0 [ 127 -128] 0\n",
      "919: 0 [ 127 -128] 0\n",
      "920: 0 [ 127 -127] 0\n",
      "921: 0 [ 127 -128] 0\n",
      "922: 0 [ 127 -127] 0\n",
      "923: 0 [ 127 -128] 0\n",
      "924: 0 [ 66 -66] 0\n",
      "925: 0 [ 124 -124] 0\n",
      "926: 0 [ 127 -128] 0\n",
      "927: 0 [ 127 -128] 0\n",
      "928: 0 [ 127 -128] 0\n",
      "929: 0 [ 126 -126] 0\n",
      "930: 0 [ 127 -127] 0\n",
      "931: 0 [ 124 -124] 0\n",
      "932: 0 [ 127 -128] 0\n",
      "933: 0 [ 127 -127] 0\n",
      "934: 0 [ 127 -128] 0\n",
      "935: 0 [ 127 -128] 0\n",
      "936: 0 [ 127 -128] 0\n",
      "937: 0 [ 127 -128] 0\n",
      "938: 0 [ 127 -127] 0\n",
      "939: 0 [ 124 -124] 0\n",
      "940: 0 [ 127 -128] 0\n",
      "941: 0 [ 127 -128] 0\n",
      "942: 0 [ 127 -127] 0\n",
      "943: 0 [ 127 -128] 0\n",
      "944: 0 [ 119 -119] 0\n",
      "945: 0 [ 127 -128] 0\n",
      "946: 0 [ 127 -128] 0\n",
      "947: 0 [ 127 -127] 0\n",
      "948: 0 [ 127 -128] 0\n",
      "949: 0 [ 127 -128] 0\n",
      "950: 0 [ 127 -128] 0\n",
      "951: 0 [ 127 -128] 0\n",
      "952: 0 [ 122 -122] 0\n",
      "953: 0 [ 127 -128] 0\n",
      "954: 0 [ 127 -127] 0\n",
      "955: 0 [ 39 -39] 0\n",
      "956: 0 [ 127 -128] 0\n",
      "957: 0 [ 127 -128] 0\n",
      "958: 0 [ 127 -128] 0\n",
      "959: 0 [ 127 -128] 0\n",
      "960: 0 [ 127 -128] 0\n",
      "961: 0 [ 127 -128] 0\n",
      "962: 0 [ 127 -128] 0\n",
      "963: 0 [ 127 -127] 0\n",
      "964: 0 [ 127 -127] 0\n",
      "965: 0 [ 127 -128] 0\n",
      "966: 0 [ 127 -128] 0\n",
      "967: 0 [ 127 -127] 0\n",
      "968: 0 [ 127 -128] 0\n",
      "969: 0 [ 127 -128] 0\n",
      "970: 0 [ 127 -128] 0\n",
      "971: 0 [ 127 -128] 0\n",
      "972: 0 [ 127 -128] 0\n",
      "973: 0 [ 127 -128] 0\n",
      "974: 0 [ 127 -128] 0\n",
      "975: 0 [ 127 -128] 0\n",
      "976: 0 [ 127 -128] 0\n",
      "977: 0 [ 127 -128] 0\n",
      "978: 0 [ 127 -128] 0\n",
      "979: 0 [ 127 -127] 0\n",
      "model accuracy is 97.040816% (Number of test samples=980)\n"
     ]
    }
   ],
   "source": [
    "TFLITE_MODEL_FILE = 'models/KWS_op.tflite'\n",
    "interpreter = tf.lite.Interpreter(model_path = TFLITE_MODEL_FILE)\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()[0]\n",
    "output_details = interpreter.get_output_details()[0]\n",
    "\n",
    "test_ds = np.expand_dims(test_ds, axis=1).astype(np.float32)\n",
    "\n",
    "input_scale, input_zero_point = input_details['quantization']\n",
    "test_ds = test_ds / input_scale + input_zero_point\n",
    "test_ds = test_ds.astype(input_details['dtype'])\n",
    "print(input_scale)\n",
    "print(input_zero_point)\n",
    "print(test_ds[3].tolist())\n",
    "\n",
    "correct_predictions = 0\n",
    "for i in range(len(test_ds)):\n",
    "    interpreter.set_tensor(input_details[\"index\"], test_ds[i])\n",
    "    interpreter.invoke()\n",
    "    output = interpreter.get_tensor(output_details[\"index\"])[0]\n",
    "    top_prediction = output.argmax()\n",
    "    correct_predictions += (top_prediction == y_test[i])\n",
    "    print(str(i)+': '+str(y_test[i])+' '+str(output)+' '+str(top_prediction))\n",
    "\n",
    "print('model accuracy is %f%% (Number of test samples=%d)' % (\n",
    "    (correct_predictions * 100) / len(test_ds), len(test_ds)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9e1a5e6c-75a9-4854-a27b-d48f37b36504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving './models/KWS_op.tflite' at http://localhost:8080\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('localhost', 8080)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import netron\n",
    "netron.start(R'./models/KWS_op.tflite')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357a8978-d451-4d7a-a165-a84d44c2f5ed",
   "metadata": {},
   "source": [
    "### Create binary file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "57721568-4147-4fbe-999e-442aa3c25db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_TFLITE = './models/KWS_op.tflite'\n",
    "MODEL_TFLITE_MICRO = 'kws_yes_no.cc'\n",
    "!xxd -i {MODEL_TFLITE} > {MODEL_TFLITE_MICRO}\n",
    "REPLACE_TEXT = MODEL_TFLITE.replace('/', '_').replace('.', '_')\n",
    "!sed -i 's/'{REPLACE_TEXT}'/g_model/g' {MODEL_TFLITE_MICRO}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5084a1a1-cbbd-40d5-947e-7c6431b58feb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unsigned char g_model[] = {\n",
      "  0x20, 0x00, 0x00, 0x00, 0x54, 0x46, 0x4c, 0x33, 0x00, 0x00, 0x00, 0x00,\n",
      "  0x14, 0x00, 0x20, 0x00, 0x1c, 0x00, 0x18, 0x00, 0x14, 0x00, 0x10, 0x00,\n",
      "  0x0c, 0x00, 0x00, 0x00, 0x08, 0x00, 0x04, 0x00, 0x14, 0x00, 0x00, 0x00,\n",
      "  0x1c, 0x00, 0x00, 0x00, 0x1c, 0x00, 0x00, 0x00, 0x9c, 0x00, 0x00, 0x00,\n",
      "  0x24, 0x19, 0x00, 0x00, 0x34, 0x19, 0x00, 0x00, 0x18, 0x28, 0x00, 0x00,\n",
      "  0x03, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x03, 0x00, 0x00, 0x00,\n",
      "  0x5c, 0x00, 0x00, 0x00, 0x2c, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00,\n",
      "  0xb8, 0xff, 0xff, 0xff, 0x16, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00,\n",
      "  0x13, 0x00, 0x00, 0x00, 0x43, 0x4f, 0x4e, 0x56, 0x45, 0x52, 0x53, 0x49,\n",
      "  0x4f, 0x4e, 0x5f, 0x4d, 0x45, 0x54, 0x41, 0x44, 0x41, 0x54, 0x41, 0x00,\n",
      "  0xdc, 0xff, 0xff, 0xff, 0x15, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00,\n",
      "  0x13, 0x00, 0x00, 0x00, 0x6d, 0x69, 0x6e, 0x5f, 0x72, 0x75, 0x6e, 0x74,\n",
      "  0x69, 0x6d, 0x65, 0x5f, 0x76, 0x65, 0x72, 0x73, 0x69, 0x6f, 0x6e, 0x00,\n",
      "  0x08, 0x00, 0x0c, 0x00, 0x08, 0x00, 0x04, 0x00, 0x08, 0x00, 0x00, 0x00,\n",
      "  0x14, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0x13, 0x00, 0x00, 0x00,\n",
      "  0x6d, 0x69, 0x6e, 0x5f, 0x72, 0x75, 0x6e, 0x74, 0x69, 0x6d, 0x65, 0x5f,\n",
      "  0x76, 0x65, 0x72, 0x73, 0x69, 0x6f, 0x6e, 0x00, 0x17, 0x00, 0x00, 0x00,\n",
      "  0x84, 0x18, 0x00, 0x00, 0x7c, 0x18, 0x00, 0x00, 0x68, 0x18, 0x00, 0x00,\n",
      "  0x54, 0x18, 0x00, 0x00, 0x40, 0x18, 0x00, 0x00, 0x2c, 0x18, 0x00, 0x00,\n",
      "  0x24, 0x18, 0x00, 0x00, 0x0c, 0x18, 0x00, 0x00, 0xf4, 0x17, 0x00, 0x00,\n",
      "  0x8c, 0x01, 0x00, 0x00, 0x50, 0x01, 0x00, 0x00, 0xdc, 0x00, 0x00, 0x00,\n",
      "  0xd4, 0x00, 0x00, 0x00, 0xcc, 0x00, 0x00, 0x00, 0xc4, 0x00, 0x00, 0x00,\n",
      "  0xbc, 0x00, 0x00, 0x00, 0xb4, 0x00, 0x00, 0x00, 0xac, 0x00, 0x00, 0x00,\n",
      "  0xa4, 0x00, 0x00, 0x00, 0x9c, 0x00, 0x00, 0x00, 0x7c, 0x00, 0x00, 0x00,\n",
      "  0x5c, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0x3e, 0xe6, 0xff, 0xff,\n",
      "  0x04, 0x00, 0x00, 0x00, 0x48, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00,\n",
      "  0xdc, 0xff, 0xff, 0xff, 0x10, 0x00, 0x00, 0x00, 0x24, 0x00, 0x00, 0x00,\n",
      "  0x00, 0x00, 0x06, 0x00, 0x08, 0x00, 0x04, 0x00, 0x06, 0x00, 0x00, 0x00,\n",
      "  0x04, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0xeb, 0x03, 0x00, 0x00,\n",
      "  0x08, 0x00, 0x0c, 0x00, 0x08, 0x00, 0x04, 0x00, 0x08, 0x00, 0x00, 0x00,\n",
      "  0x01, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0x06, 0x00, 0x00, 0x00,\n",
      "  0x32, 0x2e, 0x31, 0x36, 0x2e, 0x31, 0x00, 0x00, 0x92, 0xe6, 0xff, 0xff,\n",
      "  0x04, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
      "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
      "  0xae, 0xe6, 0xff, 0xff, 0x04, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00,\n",
      "  0x31, 0x2e, 0x31, 0x34, 0x2e, 0x30, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
      "  0x00, 0x00, 0x00, 0x00, 0x28, 0xda, 0xff, 0xff, 0x2c, 0xda, 0xff, 0xff,\n",
      "  0x30, 0xda, 0xff, 0xff, 0x34, 0xda, 0xff, 0xff, 0x38, 0xda, 0xff, 0xff,\n",
      "  0x3c, 0xda, 0xff, 0xff, 0x40, 0xda, 0xff, 0xff, 0x44, 0xda, 0xff, 0xff,\n",
      "  0xea, 0xe6, 0xff, 0xff, 0x04, 0x00, 0x00, 0x00, 0x63, 0x00, 0x00, 0x00,\n",
      "  0x06, 0xfd, 0x39, 0xcd, 0x3f, 0xe5, 0xc7, 0x7f, 0xbe, 0x7f, 0xee, 0x29,\n",
      "  0x33, 0x3e, 0x3d, 0xc6, 0xbf, 0x00, 0xec, 0x02, 0x7f, 0xd5, 0xf5, 0x30,\n",
      "  0xc1, 0xef, 0xf4, 0x81, 0xa4, 0x71, 0x35, 0x6a, 0x5c, 0x53, 0xc6, 0xbe,\n",
      "  0xba, 0xdb, 0x7f, 0x0b, 0x33, 0xf4, 0x61, 0xfd, 0x95, 0x09, 0xe2, 0xda,\n",
      "  0x62, 0x9c, 0xd5, 0xbe, 0x7f, 0xde, 0xc7, 0xfa, 0xff, 0xb9, 0xf8, 0x7f,\n",
      "  0x22, 0x67, 0xcc, 0xe7, 0x81, 0x5c, 0x07, 0xbc, 0x52, 0x13, 0x1b, 0x5d,\n",
      "  0x30, 0x55, 0x12, 0x25, 0x33, 0x91, 0x7f, 0xa4, 0xa0, 0x49, 0x8d, 0xa4,\n",
      "  0x5f, 0x9d, 0x1c, 0x7f, 0x78, 0x05, 0xef, 0xfd, 0xb5, 0xb2, 0x27, 0x56,\n",
      "  0xec, 0xda, 0x7f, 0x00, 0x5a, 0xe7, 0xff, 0xff, 0x04, 0x00, 0x00, 0x00,\n",
      "  0x2c, 0x00, 0x00, 0x00, 0x3b, 0x08, 0x00, 0x00, 0xdc, 0x03, 0x00, 0x00,\n",
      "  0xa9, 0x01, 0x00, 0x00, 0x5e, 0x07, 0x00, 0x00, 0xc1, 0x0a, 0x00, 0x00,\n",
      "  0x95, 0xd9, 0xff, 0xff, 0xc0, 0x0a, 0x00, 0x00, 0xc9, 0x0c, 0x00, 0x00,\n",
      "  0x5b, 0x0a, 0x00, 0x00, 0xc2, 0x00, 0x00, 0x00, 0xd2, 0x06, 0x00, 0x00,\n",
      "  0x92, 0xe7, 0xff, 0xff, 0x04, 0x00, 0x00, 0x00, 0x58, 0x16, 0x00, 0x00,\n",
      "  0xfa, 0x76, 0xff, 0xff, 0x0f, 0x06, 0xf8, 0x03, 0x04, 0x04, 0xfb, 0xf9,\n",
      "  0x14, 0xfa, 0x01, 0xfc, 0x07, 0xfb, 0xfc, 0x02, 0x03, 0xff, 0x0b, 0x17,\n",
      "  0xff, 0xff, 0xff, 0x01, 0x0d, 0xff, 0xfd, 0x03, 0x00, 0x00, 0x19, 0xf9,\n",
      "  0x1c, 0x03, 0x04, 0x02, 0x18, 0xff, 0x03, 0xfe, 0x13, 0x34, 0xfc, 0xf3,\n",
      "  0x03, 0xfd, 0xef, 0xf2, 0xf7, 0x02, 0x03, 0xec, 0x0e, 0xff, 0xf4, 0xe6,\n",
      "  0x03, 0x0e, 0xce, 0x11, 0xfb, 0x08, 0x01, 0x0f, 0xff, 0xf2, 0xed, 0x02,\n",
      "  0xf2, 0x08, 0xf4, 0xd1, 0xfc, 0xec, 0x17, 0xf9, 0xfa, 0xf5, 0xfe, 0x18,\n",
      "  0xe6, 0xeb, 0xf5, 0x08, 0xf5, 0x14, 0x02, 0xfa, 0x09, 0x00, 0x16, 0xf1,\n",
      "  0xef, 0x02, 0x03, 0xfd, 0x0d, 0xff, 0x02, 0xd1, 0xfa, 0xfd, 0xf7, 0x05,\n",
      "  0x00, 0x03, 0x12, 0x16, 0x03, 0xff, 0xc0, 0xfd, 0xf2, 0xf1, 0x07, 0xfc,\n",
      "  0x00, 0xe1, 0x13, 0xfd, 0xf5, 0xf8, 0x00, 0xe3, 0xf6, 0x15, 0xff, 0xfc,\n",
      "  0x1f, 0x34, 0xfd, 0xfe, 0xda, 0x01, 0xf8, 0xeb, 0x0f, 0x0e, 0xf8, 0x08,\n",
      "  0x00, 0x04, 0x03, 0x08, 0xff, 0xfe, 0x07, 0x00, 0x09, 0xfc, 0x01, 0xfb,\n",
      "  0xff, 0xf6, 0xf6, 0x05, 0x05, 0x02, 0xfb, 0x05, 0xfa, 0x03, 0xe9, 0x01,\n",
      "  0xff, 0xfb, 0x02, 0x01, 0x05, 0xf8, 0xf7, 0xff, 0xfb, 0x4b, 0x03, 0x19,\n",
      "  0x03, 0x00, 0x06, 0x10, 0x00, 0xfd, 0xfa, 0xff, 0x04, 0xff, 0xfe, 0x0e,\n",
      "  0x02, 0xff, 0xff, 0x0d, 0xfd, 0xfb, 0x0a, 0xff, 0x02, 0xec, 0x07, 0xfd,\n",
      "  0x09, 0xee, 0x05, 0xf4, 0x05, 0xf1, 0xfd, 0xfe, 0xe6, 0xdb, 0xff, 0xfe,\n",
      "  0xf7, 0xf4, 0x08, 0xf8, 0xf9, 0x06, 0x01, 0x07, 0x15, 0xfd, 0x03, 0x0c,\n",
      "  0xfc, 0x0c, 0xfe, 0xe8, 0x00, 0x05, 0x1d, 0x09, 0xfd, 0x0c, 0x06, 0xfe,\n",
      "  0x05, 0x02, 0x04, 0xf9, 0x01, 0x09, 0x03, 0xf8, 0xfc, 0x00, 0x0d, 0x10,\n",
      "  0xfc, 0xe7, 0xb3, 0x00, 0xe5, 0xe6, 0xfb, 0xee, 0xf3, 0xf5, 0xff, 0x01,\n",
      "  0xd3, 0x00, 0x04, 0xf8, 0xe7, 0xf8, 0xec, 0xf4, 0x03, 0x03, 0x00, 0x08,\n",
      "  0xfd, 0xfe, 0x11, 0xfb, 0xfc, 0x01, 0xf7, 0xff, 0xfb, 0xff, 0x05, 0xfe,\n",
      "  0x01, 0xfc, 0xfd, 0x04, 0x06, 0x05, 0xfe, 0x00, 0xfe, 0x03, 0x23, 0xff,\n",
      "  0x07, 0xfa, 0xfc, 0x09, 0x09, 0x01, 0xfa, 0xff, 0xfd, 0xaf, 0xfd, 0xfa,\n",
      "  0xff, 0xfe, 0xff, 0x00, 0xfa, 0xfb, 0xfc, 0x02, 0x1c, 0xff, 0xef, 0x08,\n",
      "  0xff, 0x04, 0x01, 0x04, 0x00, 0x04, 0x06, 0xae, 0xff, 0x10, 0x07, 0x06,\n",
      "  0x02, 0x02, 0xfe, 0xfe, 0xfe, 0x09, 0xfc, 0xf9, 0xfc, 0x01, 0x03, 0xf6,\n",
      "  0xfb, 0x03, 0x06, 0xfd, 0x11, 0xfd, 0xf5, 0x19, 0x1b, 0x02, 0x10, 0x13,\n",
      "  0x00, 0x01, 0x01, 0x02, 0xfd, 0xfd, 0x14, 0x0c, 0x01, 0x11, 0x0a, 0x0d,\n",
      "  0x09, 0xfb, 0xeb, 0xdd, 0x02, 0xfd, 0xf0, 0x02, 0xf5, 0xef, 0x05, 0x15,\n",
      "  0xfe, 0x05, 0x04, 0xfe, 0xf3, 0xf4, 0xf9, 0xfa, 0xfb, 0xf9, 0xf0, 0x00,\n",
      "  0xf2, 0xb0, 0x0a, 0xfe, 0xe2, 0xfa, 0xf9, 0xf2, 0xfe, 0x09, 0xfb, 0xfb,\n",
      "  0xc4, 0x04, 0x01, 0xe7, 0xf8, 0xfc, 0x04, 0x03, 0x0f, 0x01, 0x05, 0xda,\n",
      "  0x03, 0x12, 0x14, 0xfa, 0x00, 0xfe, 0xf6, 0x08, 0xfc, 0xfd, 0x23, 0x02,\n",
      "  0x08, 0xff, 0x04, 0x01, 0x05, 0x03, 0x07, 0x01, 0x05, 0x25, 0x07, 0x05,\n",
      "  0x01, 0x02, 0xff, 0x00, 0xff, 0xfc, 0xfe, 0xfc, 0x9b, 0x00, 0xfd, 0x00,\n",
      "  0x02, 0xff, 0xff, 0x01, 0xfe, 0xf9, 0x01, 0xac, 0xfe, 0x03, 0xf6, 0x02,\n",
      "  0x05, 0x07, 0xfe, 0xfd, 0x00, 0x04, 0x89, 0xfc, 0xf2, 0xf7, 0x08, 0x05,\n",
      "  0x00, 0x00, 0x08, 0x03, 0x01, 0x03, 0xfc, 0x16, 0xf2, 0xff, 0x0f, 0xfb,\n",
      "  0x04, 0x03, 0xfd, 0xfc, 0x01, 0xfe, 0x1e, 0x11, 0x03, 0x0f, 0x16, 0x09,\n",
      "  0xfd, 0x00, 0x1f, 0x01, 0x04, 0x3f, 0x22, 0xff, 0x13, 0x0a, 0x16, 0x21,\n",
      "  0x02, 0xfe, 0xa5, 0x01, 0x0c, 0x01, 0x01, 0x03, 0xff, 0x06, 0x0e, 0x06,\n",
      "  0xe2, 0xcf, 0x03, 0xf5, 0xf3, 0xfd, 0xeb, 0xf6, 0x0c, 0x07, 0xfc, 0x0d,\n",
      "  0xce, 0x00, 0xf2, 0xe1, 0xfd, 0xf7, 0xf4, 0xf0, 0xff, 0x00, 0x08, 0xf4,\n",
      "  0x08, 0x03, 0x01, 0xff, 0xf5, 0xff, 0x02, 0x0e, 0xf9, 0x18, 0x07, 0x01,\n",
      "  0x1d, 0x01, 0xfd, 0x0a, 0x03, 0x02, 0x05, 0xfc, 0x02, 0x16, 0xff, 0x06,\n",
      "  0x04, 0x00, 0x04, 0x00, 0x05, 0x06, 0x01, 0x04, 0xa9, 0xfd, 0xfd, 0x00,\n",
      "  0x04, 0xfe, 0x00, 0xff, 0x05, 0x03, 0x02, 0xa2, 0xf6, 0xf6, 0xfd, 0x01,\n",
      "  0xfd, 0xfe, 0x02, 0xff, 0x01, 0x00, 0xec, 0xfa, 0xf3, 0xf9, 0x05, 0x03,\n",
      "  0x05, 0xfc, 0xfa, 0x07, 0x03, 0xee, 0x03, 0x03, 0x03, 0xfe, 0xfc, 0x02,\n",
      "  0x00, 0x03, 0xfe, 0x08, 0xf9, 0xfc, 0x02, 0x02, 0x00, 0x00, 0x07, 0x07,\n",
      "  0x08, 0x03, 0xff, 0x12, 0xff, 0x16, 0x0b, 0xfe, 0x0c, 0x0e, 0x04, 0xec,\n",
      "  0x00, 0xfe, 0xfd, 0x03, 0x2d, 0x1b, 0xf9, 0x14, 0x0f, 0x1d, 0xf8, 0x04,\n",
      "  0xfd, 0xae, 0xfa, 0x04, 0x07, 0x02, 0xfd, 0xf9, 0x0c, 0x1e, 0x05, 0xf4,\n",
      "  0xd0, 0x00, 0xf4, 0xf5, 0xf9, 0xf5, 0xfb, 0xf1, 0x0d, 0xfa, 0x0b, 0xe8,\n",
      "  0x06, 0x01, 0xf1, 0x00, 0xfb, 0xf3, 0xfa, 0x0b, 0xf8, 0x0d, 0xea, 0x03,\n",
      "  0xf3, 0xe4, 0xfe, 0xf2, 0xf8, 0xfe, 0x08, 0x00, 0x12, 0xeb, 0x03, 0xee,\n",
      "  0xfb, 0x00, 0xf7, 0x02, 0x05, 0x09, 0xfd, 0x05, 0x49, 0xfc, 0xfa, 0xf9,\n",
      "  0x03, 0xff, 0x09, 0x05, 0x07, 0xfc, 0x00, 0x09, 0x01, 0x00, 0xff, 0x00,\n",
      "  0x04, 0xff, 0xff, 0x05, 0x00, 0x00, 0x92, 0xfd, 0xf8, 0x01, 0xfc, 0x00,\n",
      "  0xfd, 0x00, 0xfe, 0x00, 0xfc, 0xf6, 0x01, 0x02, 0xfd, 0x00, 0x01, 0x09,\n",
      "  0xfe, 0x00, 0xff, 0x06, 0x04, 0xfe, 0x04, 0x05, 0xff, 0x07, 0x06, 0x01,\n",
      "  0x01, 0x00, 0x02, 0xf8, 0xff, 0x0b, 0x02, 0x08, 0x09, 0x02, 0x08, 0x04,\n",
      "  0xfb, 0x08, 0x35, 0xf7, 0x21, 0x1e, 0x02, 0x12, 0x12, 0x05, 0x20, 0xff,\n",
      "  0x06, 0x17, 0xf8, 0x02, 0x11, 0x08, 0x17, 0x03, 0x19, 0x05, 0x02, 0xfb,\n",
      "  0xd6, 0xfa, 0x05, 0x05, 0x02, 0x04, 0xfa, 0x01, 0x0b, 0xfe, 0xef, 0xdc,\n",
      "  0x02, 0xfa, 0xe3, 0x02, 0xf9, 0xfc, 0xf5, 0x03, 0x01, 0xf7, 0xb6, 0x00,\n",
      "  0xdf, 0xe5, 0x04, 0xf9, 0xfb, 0xf5, 0x0a, 0xff, 0x08, 0xc5, 0x05, 0xee,\n",
      "  0xf2, 0x04, 0xf9, 0xfe, 0xff, 0x09, 0xfe, 0x0a, 0xbf, 0x03, 0xfe, 0x02,\n",
      "  0xff, 0x00, 0xf7, 0xfc, 0x0b, 0x01, 0x09, 0xe1, 0x02, 0xff, 0xff, 0xfa,\n",
      "  0x02, 0x01, 0x00, 0x05, 0x01, 0x01, 0xfa, 0x00, 0xfb, 0xf9, 0xff, 0x06,\n",
      "  0x05, 0x01, 0x00, 0xfd, 0x01, 0x81, 0x05, 0xff, 0x00, 0xf4, 0xfe, 0x01,\n",
      "  0xfa, 0xfd, 0x00, 0x08, 0xf2, 0x02, 0x01, 0xff, 0x02, 0x06, 0x06, 0x02,\n",
      "  0xf8, 0x03, 0x04, 0xb1, 0x06, 0x05, 0x05, 0xfd, 0x00, 0xfe, 0x01, 0xfb,\n",
      "  0x00, 0x07, 0x0d, 0xfe, 0x0d, 0x07, 0x02, 0xf8, 0xff, 0x00, 0xff, 0x05,\n",
      "  0x06, 0x42, 0xfe, 0x04, 0x07, 0xff, 0x08, 0x0c, 0x06, 0x08, 0xff, 0x06,\n",
      "  0xff, 0xfd, 0x0a, 0x14, 0x03, 0x08, 0x0c, 0x19, 0x15, 0x00, 0xff, 0x05,\n",
      "  0xfa, 0x0e, 0x02, 0xfd, 0x03, 0xf9, 0x00, 0x0c, 0xfe, 0xf3, 0xc4, 0xff,\n",
      "  0xff, 0xf3, 0xfc, 0xf3, 0xf4, 0xe7, 0x0c, 0xf7, 0x04, 0xf7, 0xff, 0xfe,\n",
      "  0xef, 0x04, 0xfb, 0xf0, 0x03, 0xfa, 0xfa, 0x08, 0xfe, 0x07, 0xfe, 0xfe,\n",
      "  0x00, 0xfa, 0x02, 0xfe, 0x0a, 0xff, 0xfd, 0xcb, 0x02, 0x1b, 0x00, 0x04,\n",
      "  0x00, 0xfe, 0x04, 0x05, 0xff, 0x07, 0xf8, 0x03, 0xff, 0xfe, 0xff, 0x05,\n",
      "  0x05, 0xfd, 0x02, 0xfe, 0x0a, 0x02, 0x01, 0xf6, 0x00, 0xfa, 0x08, 0x03,\n",
      "  0x05, 0x01, 0x03, 0x01, 0xe6, 0xfd, 0xf7, 0x00, 0xff, 0x00, 0xff, 0xfe,\n",
      "  0xfd, 0x02, 0x00, 0xe7, 0xfd, 0xf5, 0xfd, 0xfd, 0x00, 0x07, 0x05, 0xf8,\n",
      "  0x05, 0xff, 0xaa, 0xfc, 0xfa, 0x02, 0x03, 0x05, 0x05, 0xfd, 0x04, 0xff,\n",
      "  0x03, 0x1a, 0x01, 0xe9, 0xfb, 0xf9, 0x03, 0x01, 0xfa, 0xf9, 0x01, 0x05,\n",
      "  0x3d, 0x03, 0x0c, 0x13, 0xfd, 0x08, 0x05, 0x09, 0xf0, 0x04, 0x0c, 0xfa,\n",
      "  0xfb, 0x24, 0x21, 0xfc, 0x15, 0x07, 0x19, 0x07, 0xfb, 0xf4, 0xfc, 0xf9,\n",
      "  0x0c, 0x04, 0xff, 0x09, 0xf6, 0x04, 0x0f, 0xfa, 0xf3, 0xbb, 0x05, 0xfa,\n",
      "  0xf0, 0xfb, 0xf4, 0xfb, 0xed, 0x07, 0x03, 0x07, 0xcc, 0x03, 0xe7, 0xef,\n",
      "  0xff, 0xfc, 0x00, 0xfb, 0x05, 0xf8, 0x0c, 0xce, 0x01, 0xe7, 0xf0, 0x02,\n",
      "  0x01, 0xff, 0xfc, 0x10, 0xfe, 0xfd, 0xde, 0x05, 0x06, 0xf0, 0x05, 0xfe,\n",
      "  0x11, 0x03, 0x13, 0x01, 0x05, 0xc2, 0xff, 0x05, 0x01, 0xff, 0x05, 0x03,\n",
      "  0x03, 0x05, 0x03, 0x06, 0x25, 0x02, 0x02, 0x03, 0xfb, 0x01, 0x04, 0x04,\n",
      "  0x08, 0x01, 0x04, 0xa3, 0xff, 0xf7, 0xff, 0xfb, 0xfd, 0xff, 0xff, 0x05,\n",
      "  0xfc, 0x06, 0xe2, 0xfe, 0xfe, 0x00, 0x00, 0x03, 0x09, 0x04, 0xfd, 0x00,\n",
      "  0x02, 0xc7, 0x01, 0x01, 0xfe, 0xfe, 0x06, 0x01, 0xff, 0xfd, 0x00, 0x07,\n",
      "  0x17, 0xfe, 0xf1, 0x04, 0xfb, 0x03, 0x07, 0x05, 0xfa, 0x03, 0x00, 0x12,\n",
      "  0xff, 0xff, 0x0e, 0xfa, 0x00, 0x09, 0x06, 0x0c, 0x00, 0x07, 0x29, 0xfc,\n",
      "  0x1d, 0x15, 0x02, 0x10, 0x0f, 0x18, 0x03, 0x01, 0xfc, 0x3c, 0xfd, 0x0f,\n",
      "  0xfa, 0x08, 0x04, 0xfc, 0x08, 0x19, 0xff, 0xf6, 0xcf, 0x02, 0xf8, 0xe8,\n",
      "  0x04, 0xe8, 0xef, 0xeb, 0x0e, 0xff, 0x00, 0xd3, 0x03, 0xf2, 0xec, 0x03,\n",
      "  0xf9, 0x02, 0x01, 0xfc, 0x01, 0xfd, 0x8e, 0x09, 0xfc, 0xf6, 0x06, 0xfe,\n",
      "  0x03, 0x05, 0x09, 0xfc, 0xfd, 0xd3, 0x00, 0x06, 0xfe, 0x04, 0xf7, 0xfe,\n",
      "  0xff, 0x10, 0x02, 0x08, 0x05, 0xfb, 0x02, 0x04, 0xf8, 0x05, 0x06, 0x03,\n",
      "  0x09, 0xfe, 0x09, 0x0e, 0x05, 0x03, 0x01, 0xf8, 0x05, 0x09, 0xfe, 0xff,\n",
      "  0x02, 0x02, 0x00, 0xfa, 0xfa, 0x06, 0xf8, 0xfa, 0x07, 0x06, 0xfd, 0xfc,\n",
      "  0x00, 0xf6, 0xfb, 0x09, 0xff, 0xff, 0xff, 0x07, 0x06, 0xff, 0x00, 0x00,\n",
      "  0x01, 0x01, 0x03, 0x01, 0xff, 0x05, 0x03, 0x00, 0xff, 0xfd, 0xf9, 0x00,\n",
      "  0xfd, 0x06, 0x00, 0xf8, 0xf7, 0x0e, 0x01, 0x02, 0xfa, 0x05, 0x01, 0xfc,\n",
      "  0x13, 0x16, 0x03, 0x08, 0x0c, 0x08, 0xf7, 0x09, 0x0f, 0x11, 0xf7, 0x18,\n",
      "  0x18, 0x05, 0x13, 0x05, 0x1a, 0xf7, 0x02, 0xfe, 0xf9, 0xfa, 0x0b, 0xfa,\n",
      "  0x02, 0xfb, 0x00, 0x02, 0x0f, 0xfc, 0xfd, 0xb6, 0x06, 0xfd, 0xf1, 0x03,\n",
      "  0xf9, 0xef, 0xf3, 0x07, 0xf6, 0x05, 0xe5, 0x00, 0xf7, 0xf3, 0x03, 0xf0,\n",
      "  0xf6, 0xfb, 0x06, 0xfc, 0x07, 0x02, 0x09, 0x01, 0xf0, 0x05, 0xff, 0x04,\n",
      "  0xf7, 0x0f, 0xf7, 0x04, 0xd5, 0xfd, 0x0f, 0xfb, 0x09, 0x00, 0xfd, 0x02,\n",
      "  0x11, 0xfc, 0x02, 0x07, 0xff, 0x04, 0x00, 0xfa, 0x05, 0x00, 0x00, 0x02,\n",
      "  0xfb, 0x08, 0x07, 0xfe, 0xff, 0x00, 0xf5, 0xfe, 0x06, 0xfb, 0xff, 0x03,\n",
      "  0x02, 0xf9, 0xfb, 0xf7, 0x05, 0xfc, 0xfd, 0x04, 0x04, 0xff, 0xfd, 0xfd,\n",
      "  0xf9, 0xfa, 0x04, 0x05, 0xfb, 0x02, 0x06, 0x00, 0xf6, 0x01, 0x01, 0xff,\n",
      "  0x05, 0xff, 0xfe, 0x04, 0xfc, 0x00, 0x01, 0x01, 0xfb, 0x04, 0x07, 0x00,\n",
      "  0xfe, 0x03, 0x01, 0xfc, 0x03, 0x02, 0x01, 0x07, 0x0d, 0x23, 0xfa, 0x0f,\n",
      "  0x04, 0x00, 0x12, 0x05, 0x04, 0xf7, 0x00, 0x07, 0x16, 0xf9, 0x26, 0x1b,\n",
      "  0x00, 0x16, 0x0a, 0x18, 0x1f, 0x05, 0xfe, 0x06, 0xfb, 0xf7, 0x00, 0x03,\n",
      "  0x07, 0x07, 0x00, 0x18, 0x01, 0xef, 0x02, 0xfb, 0xfa, 0xe8, 0x06, 0xf1,\n",
      "  0xf7, 0xed, 0x0d, 0xfb, 0x01, 0x02, 0xfd, 0xf8, 0xeb, 0x02, 0xee, 0xfb,\n",
      "  0xf4, 0x07, 0xff, 0x08, 0xfd, 0xfa, 0x0e, 0xee, 0x08, 0x04, 0x07, 0xf9,\n",
      "  0xff, 0xf9, 0x04, 0x04, 0xfa, 0x05, 0xfe, 0x0e, 0x01, 0xff, 0x01, 0x0f,\n",
      "  0xff, 0xff, 0xfe, 0xfd, 0xff, 0xff, 0xf7, 0xff, 0x05, 0x04, 0x04, 0xfd,\n",
      "  0x06, 0xff, 0x00, 0x03, 0x05, 0xf6, 0xfc, 0x03, 0xfb, 0x03, 0xfb, 0x00,\n",
      "  0xfc, 0x00, 0xf3, 0x02, 0xf9, 0x00, 0x09, 0x00, 0xfc, 0x00, 0x05, 0xfc,\n",
      "  0xfd, 0x04, 0xfc, 0x01, 0x00, 0x07, 0x00, 0xf3, 0x02, 0x05, 0xfe, 0x00,\n",
      "  0xfb, 0xff, 0xfe, 0x05, 0x02, 0x02, 0x04, 0x02, 0xfd, 0x02, 0xfe, 0x0f,\n",
      "  0x02, 0xf6, 0x00, 0x08, 0x02, 0x00, 0x01, 0x09, 0x0a, 0x01, 0x18, 0x09,\n",
      "  0xfb, 0x0e, 0x01, 0x0b, 0x0d, 0x01, 0xfe, 0x20, 0x00, 0x22, 0x2a, 0xfa,\n",
      "  0x0e, 0x06, 0x1a, 0x1a, 0xfd, 0xf4, 0x0d, 0xf8, 0x0c, 0x03, 0x08, 0x06,\n",
      "  0x01, 0x08, 0x1d, 0xfe, 0xef, 0x08, 0x01, 0xff, 0xf6, 0x01, 0xf4, 0xf2,\n",
      "  0xf8, 0x05, 0x00, 0x02, 0xf5, 0xfb, 0xef, 0xe6, 0x05, 0xf3, 0xfb, 0x00,\n",
      "  0x15, 0xfc, 0x08, 0x03, 0x02, 0xf5, 0x02, 0x0d, 0xf7, 0xfe, 0xfc, 0x0d,\n",
      "  0xf9, 0x00, 0xff, 0xfe, 0x0e, 0x05, 0x0d, 0x01, 0x04, 0xff, 0x16, 0xf5,\n",
      "  0x06, 0xff, 0xfe, 0x03, 0x01, 0xf8, 0xfc, 0x02, 0x03, 0x0a, 0x00, 0xff,\n",
      "  0xfa, 0xfc, 0xfd, 0x02, 0xff, 0xf9, 0x04, 0xff, 0x06, 0x01, 0x0b, 0x02,\n",
      "  0xfb, 0xf4, 0x01, 0xff, 0x03, 0xfd, 0xfc, 0xf9, 0x02, 0x02, 0x05, 0x00,\n",
      "  0xfc, 0x02, 0xff, 0x06, 0x0a, 0x01, 0x00, 0x02, 0x04, 0x02, 0xfe, 0x06,\n",
      "  0x00, 0xfb, 0xff, 0x07, 0x05, 0x02, 0xfc, 0x05, 0x05, 0xfd, 0xee, 0x01,\n",
      "  0xf9, 0xf5, 0xf8, 0x00, 0xfc, 0x03, 0x06, 0x06, 0x04, 0x0c, 0x11, 0x01,\n",
      "  0x07, 0x14, 0x0d, 0xf4, 0x06, 0x08, 0x0b, 0xfb, 0x18, 0x18, 0x00, 0x10,\n",
      "  0x0c, 0x10, 0x21, 0xfd, 0x06, 0x04, 0xf7, 0x00, 0xff, 0x0a, 0x04, 0x01,\n",
      "  0x07, 0x25, 0xfb, 0xe5, 0xf8, 0xfc, 0x09, 0xec, 0xff, 0xf1, 0xef, 0xfb,\n",
      "  0x15, 0xfe, 0x01, 0x01, 0x03, 0xe4, 0xe6, 0xff, 0xee, 0xf6, 0xf8, 0x09,\n",
      "  0xfd, 0x0b, 0xfc, 0x00, 0x09, 0x00, 0x08, 0xff, 0x06, 0x00, 0x0b, 0xff,\n",
      "  0xfc, 0x03, 0xfa, 0x19, 0x02, 0x0e, 0xef, 0xfa, 0xfb, 0x12, 0xf9, 0x01,\n",
      "  0x00, 0x01, 0xff, 0xfd, 0xf9, 0x04, 0x04, 0xff, 0x05, 0xfd, 0x01, 0x00,\n",
      "  0x00, 0xf4, 0xfc, 0xfb, 0x00, 0x07, 0x00, 0x00, 0xff, 0xff, 0x02, 0xff,\n",
      "  0x01, 0xff, 0xf9, 0x03, 0x04, 0x00, 0xfa, 0xfd, 0x05, 0x05, 0xfd, 0xf7,\n",
      "  0x08, 0xff, 0xff, 0x07, 0xfe, 0xfe, 0xfd, 0x04, 0xf9, 0x04, 0x03, 0xfe,\n",
      "  0x03, 0x07, 0x02, 0x03, 0xfd, 0x01, 0x06, 0xff, 0x07, 0x02, 0xfd, 0x00,\n",
      "  0xfd, 0x06, 0x02, 0xfa, 0xff, 0x09, 0x11, 0xfe, 0x39, 0x1f, 0xfc, 0x12,\n",
      "  0x0f, 0x0a, 0x15, 0x05, 0x09, 0x06, 0xfa, 0x22, 0x1a, 0xfe, 0x10, 0x13,\n",
      "  0x0e, 0x21, 0xfe, 0xf0, 0x15, 0xf2, 0x07, 0x07, 0x05, 0x07, 0x05, 0x08,\n",
      "  0x12, 0x00, 0xd3, 0x37, 0x04, 0xff, 0xd5, 0x0b, 0xf9, 0xf2, 0xf6, 0x11,\n",
      "  0xfa, 0x00, 0xf7, 0x02, 0xf0, 0xdf, 0x05, 0xf5, 0xea, 0x00, 0xf0, 0x00,\n",
      "  0xfe, 0xfb, 0xfc, 0xe1, 0xee, 0x08, 0xfb, 0x04, 0xfb, 0x1c, 0xfd, 0xfc,\n",
      "  0xf4, 0xfe, 0x0b, 0xf1, 0x0c, 0xfe, 0x01, 0xfe, 0x17, 0xf7, 0x0a, 0x02,\n",
      "  0x02, 0x00, 0x06, 0xfe, 0x02, 0xff, 0x04, 0x03, 0xfc, 0x05, 0x09, 0x02,\n",
      "  0xfc, 0x00, 0xf9, 0xf9, 0x09, 0xfb, 0x03, 0x02, 0x03, 0xf8, 0x00, 0x03,\n",
      "  0xff, 0xf8, 0x02, 0xfd, 0x01, 0xfe, 0xfc, 0x03, 0x02, 0x02, 0x05, 0x05,\n",
      "  0xff, 0x08, 0x07, 0x00, 0xf8, 0x03, 0xfd, 0xfb, 0x04, 0x08, 0x07, 0x04,\n",
      "  0x08, 0xfd, 0x04, 0x05, 0xfd, 0xfe, 0x05, 0x03, 0xfc, 0x06, 0xfc, 0x03,\n",
      "  0x03, 0xfc, 0x00, 0x00, 0x04, 0x02, 0xfc, 0x2b, 0x15, 0x02, 0x0e, 0x14,\n",
      "  0x06, 0xdd, 0x04, 0x08, 0xfa, 0xf8, 0x25, 0x10, 0x01, 0x14, 0x0f, 0x09,\n",
      "  0x10, 0xfb, 0xf5, 0xed, 0xf6, 0x1c, 0xf9, 0x04, 0x0c, 0x0c, 0x04, 0x15,\n",
      "  0xf1, 0xe4, 0xef, 0x00, 0x07, 0xf4, 0x06, 0xf9, 0xed, 0xf7, 0x1e, 0xfb,\n",
      "  0x05, 0x05, 0x02, 0x01, 0xe8, 0xff, 0xef, 0xf4, 0xfc, 0xfe, 0x00, 0x03,\n",
      "  0x13, 0x03, 0x07, 0xe8, 0x02, 0xfa, 0x0b, 0x01, 0x04, 0x03, 0x03, 0x15,\n",
      "  0xf9, 0x0e, 0xf2, 0x0e, 0x03, 0x0d, 0x02, 0xfb, 0xf7, 0x00, 0x01, 0x03,\n",
      "  0xff, 0xfa, 0xff, 0xfe, 0x0a, 0xfc, 0x08, 0xff, 0x05, 0x06, 0xfe, 0x00,\n",
      "  0x01, 0xff, 0x08, 0x10, 0xff, 0x07, 0xff, 0x04, 0x01, 0x01, 0xf1, 0xfd,\n",
      "  0xfb, 0x01, 0x0a, 0x03, 0x08, 0x05, 0x00, 0x02, 0xfc, 0x0c, 0x07, 0x00,\n",
      "  0xfe, 0x0c, 0x03, 0xf6, 0xfd, 0x03, 0x0a, 0xfe, 0x0d, 0x04, 0xfd, 0x02,\n",
      "  0x04, 0xfb, 0xf4, 0x03, 0xff, 0x07, 0xfd, 0xfd, 0x01, 0xfa, 0x07, 0xfc,\n",
      "  0xfd, 0xf7, 0xfe, 0x07, 0x08, 0x01, 0x0a, 0x15, 0x05, 0x0e, 0xfe, 0x10,\n",
      "  0xaa, 0x04, 0x19, 0x00, 0x03, 0x19, 0x1b, 0xff, 0x1c, 0x0e, 0x0f, 0xf4,\n",
      "  0x02, 0x04, 0xfa, 0xf9, 0x0b, 0x0a, 0x09, 0x16, 0xfd, 0x08, 0x07, 0xfa,\n",
      "  0xf8, 0xf2, 0x04, 0xf3, 0xfd, 0x05, 0xf3, 0xf3, 0xf7, 0x07, 0xf9, 0x04,\n",
      "  0xf2, 0x01, 0xf9, 0xee, 0x00, 0xec, 0xe6, 0x04, 0xfd, 0x05, 0xfb, 0xfc,\n",
      "  0x06, 0xec, 0x08, 0x05, 0xf4, 0x0a, 0xfc, 0x16, 0xfe, 0x07, 0x07, 0xf8,\n",
      "  0x12, 0x03, 0x0a, 0xf9, 0xec, 0xfa, 0x1a, 0xf9, 0x07, 0x02, 0x09, 0xfb,\n",
      "  0xff, 0xfb, 0x01, 0x02, 0x04, 0xff, 0x01, 0x04, 0x3b, 0x05, 0x0c, 0x02,\n",
      "  0xfb, 0xf8, 0x0e, 0x02, 0x06, 0x06, 0x04, 0x29, 0x04, 0xf4, 0x04, 0xfc,\n",
      "  0x02, 0x07, 0x00, 0x03, 0x00, 0x07, 0x27, 0xfd, 0xf8, 0x07, 0x05, 0x02,\n",
      "  0x01, 0x03, 0xfb, 0x01, 0x05, 0xeb, 0x06, 0xf7, 0xfb, 0xfb, 0x01, 0xf4,\n",
      "  0x02, 0xf4, 0xff, 0xfd, 0xe4, 0x02, 0x01, 0xfe, 0xff, 0x01, 0xff, 0x00,\n",
      "  0xff, 0xff, 0x0b, 0xec, 0x00, 0x04, 0x19, 0x07, 0x09, 0x11, 0x09, 0xf2,\n",
      "  0xf6, 0x08, 0xb5, 0xfa, 0x0e, 0x0d, 0xfd, 0x1f, 0x05, 0x11, 0x59, 0xf5,\n",
      "  0xef, 0xe9, 0xf3, 0x09, 0xfc, 0x03, 0x12, 0xfd, 0xff, 0x2a, 0xf7, 0xea,\n",
      "  0xd3, 0xfd, 0xc8, 0xe5, 0x07, 0xdc, 0xe7, 0xfb, 0x11, 0xff, 0xf8, 0xd4,\n",
      "  0x03, 0xd7, 0xd4, 0x03, 0xda, 0x02, 0xfb, 0xe1, 0xfc, 0xf8, 0xfe, 0xfd,\n",
      "  0xbb, 0xf6, 0x03, 0x01, 0xfe, 0x07, 0x34, 0xf5, 0x15, 0x22, 0xf8, 0x01,\n",
      "  0xdf, 0x05, 0xfd, 0xf6, 0x01, 0x19, 0xf2, 0x0d, 0xf7, 0x06, 0xf6, 0x02,\n",
      "  0xfb, 0x04, 0xff, 0x03, 0x02, 0xfb, 0xfb, 0x04, 0x09, 0xfc, 0xf5, 0xfa,\n",
      "  0x03, 0xff, 0xff, 0x15, 0x03, 0x04, 0x00, 0xfe, 0xf3, 0x06, 0xfa, 0xf1,\n",
      "  0xfe, 0xff, 0x02, 0xfd, 0x09, 0xfa, 0x02, 0xed, 0xfb, 0xfe, 0x0d, 0x17,\n",
      "  0x05, 0x03, 0xff, 0x03, 0xf3, 0x00, 0xee, 0x0d, 0xfb, 0x10, 0xf9, 0x06,\n",
      "  0xf6, 0x04, 0x12, 0xff, 0x04, 0xfc, 0x05, 0x00, 0x1d, 0xfe, 0xfd, 0xf0,\n",
      "  0x05, 0x06, 0xf7, 0x00, 0x6b, 0x24, 0xff, 0x26, 0x29, 0x11, 0xff, 0xf9,\n",
      "  0x12, 0xeb, 0xf7, 0x52, 0x1b, 0x01, 0x28, 0x17, 0x09, 0x03, 0x01, 0xf1,\n",
      "  0x03, 0xfb, 0x09, 0xff, 0x03, 0x0d, 0xff, 0x05, 0x17, 0xfc, 0x06, 0xd5,\n",
      "  0xfc, 0x15, 0xfb, 0x00, 0xdd, 0xef, 0xfe, 0x0a, 0xfe, 0x06, 0xdc, 0x00,\n",
      "  0xde, 0xdf, 0x00, 0xf5, 0xf9, 0xf3, 0x2b, 0x02, 0x00, 0xe7, 0xfe, 0xfb,\n",
      "  0xea, 0x02, 0xfe, 0x10, 0x00, 0x1b, 0x00, 0x07, 0xe4, 0xf9, 0x20, 0xb9,\n",
      "  0x04, 0xf9, 0xdb, 0x0d, 0x3a, 0xf7, 0x05, 0xfc, 0x04, 0xfa, 0xf6, 0xfd,\n",
      "  0xf5, 0x02, 0x04, 0x05, 0xfd, 0x06, 0x02, 0x02, 0xf6, 0xf9, 0xfa, 0x07,\n",
      "  0x06, 0x02, 0x0d, 0x01, 0x08, 0xf8, 0x02, 0xfc, 0xfa, 0xfe, 0x03, 0xfb,\n",
      "  0x01, 0x02, 0x01, 0x05, 0xfb, 0x02, 0xfd, 0xf3, 0x01, 0x08, 0x09, 0x07,\n",
      "  0x03, 0x01, 0xf2, 0xff, 0x02, 0x00, 0xff, 0x04, 0xf6, 0x08, 0x00, 0xfc,\n",
      "  0xff, 0x14, 0xfc, 0x00, 0xf6, 0xfd, 0xfe, 0x22, 0xff, 0x02, 0x0a, 0x01,\n",
      "  0xfb, 0x02, 0xfd, 0xed, 0x08, 0x02, 0x11, 0x01, 0x0b, 0x0f, 0xff, 0xf7,\n",
      "  0x11, 0x02, 0x10, 0x21, 0xfc, 0x2a, 0x07, 0x0d, 0x1a, 0x01, 0xd3, 0x0a,\n",
      "  0xfe, 0x16, 0xed, 0xfd, 0x12, 0xfd, 0xfb, 0x1d, 0xff, 0xe1, 0xff, 0x00,\n",
      "  0xf7, 0xcb, 0xfe, 0xe4, 0xe1, 0xf6, 0x15, 0xfc, 0x15, 0xfd, 0xfc, 0x09,\n",
      "  0xe4, 0x02, 0x03, 0x09, 0xfb, 0x23, 0x00, 0xf8, 0x0c, 0xfe, 0xf3, 0xab,\n",
      "  0x00, 0xf3, 0xfd, 0x01, 0xf3, 0x01, 0xf9, 0x0e, 0xf7, 0x16, 0xca, 0x05,\n",
      "  0x1c, 0xeb, 0xff, 0x2f, 0xf7, 0xf9, 0x00, 0xff, 0xf7, 0xfe, 0xf6, 0x06,\n",
      "  0x12, 0x07, 0x0e, 0xf8, 0x03, 0x06, 0x04, 0x17, 0x07, 0x00, 0x02, 0x14,\n",
      "  0x00, 0x0c, 0x09, 0x0e, 0xfd, 0x00, 0xe4, 0x03, 0x00, 0x03, 0x0c, 0x02,\n",
      "  0xf9, 0x03, 0x03, 0xfe, 0xfe, 0xef, 0xfe, 0xfe, 0x0a, 0x0c, 0x00, 0xfa,\n",
      "  0x00, 0x08, 0x04, 0x06, 0x13, 0xfa, 0x00, 0xf8, 0x02, 0xfe, 0x03, 0x01,\n",
      "  0xff, 0x03, 0xfc, 0xf7, 0x02, 0x00, 0x10, 0x0a, 0x03, 0x1f, 0x01, 0xfe,\n",
      "  0x0b, 0x01, 0x09, 0x17, 0x01, 0x18, 0xf7, 0x09, 0x01, 0x01, 0xed, 0x0f,\n",
      "  0x00, 0x2a, 0xfd, 0xff, 0x1d, 0x0a, 0x0a, 0x9d, 0xfe, 0xe7, 0x0e, 0xf8,\n",
      "  0x21, 0x25, 0xfb, 0x08, 0x1e, 0xfa, 0x0a, 0xfe, 0xea, 0x01, 0x03, 0xff,\n",
      "  0xe4, 0xff, 0xfb, 0xe4, 0xf3, 0x34, 0xfe, 0x2a, 0x00, 0xfc, 0xdd, 0xff,\n",
      "  0xff, 0xec, 0xf6, 0xfd, 0xdb, 0xff, 0x03, 0x03, 0xfe, 0xea, 0xe9, 0xfa,\n",
      "  0x08, 0xe7, 0xf4, 0x1a, 0x03, 0x0b, 0x04, 0xfa, 0x1f, 0xfb, 0x03, 0x08,\n",
      "  0xfc, 0x06, 0x0b, 0xf3, 0xff, 0x89, 0x05, 0x06, 0xfc, 0x02, 0x02, 0xf2,\n",
      "  0xff, 0x02, 0xfd, 0xfe, 0xe5, 0x00, 0xf6, 0x02, 0x05, 0x05, 0x05, 0x03,\n",
      "  0xf8, 0x04, 0xf6, 0xeb, 0xfc, 0xff, 0xfe, 0x00, 0xf6, 0x01, 0x07, 0x0a,\n",
      "  0xfc, 0x09, 0xeb, 0x08, 0xe2, 0xfa, 0x00, 0x06, 0xea, 0x05, 0x03, 0x02,\n",
      "  0xf2, 0xd1, 0xff, 0x04, 0xf2, 0xfe, 0x16, 0x0d, 0x09, 0xfb, 0x00, 0x1b,\n",
      "  0xeb, 0x04, 0x0a, 0x0c, 0x01, 0xfb, 0x33, 0xe9, 0x10, 0x05, 0xfd, 0xec,\n",
      "  0x05, 0x10, 0x1d, 0xff, 0x0e, 0x00, 0x08, 0x2d, 0x01, 0x12, 0xf2, 0xfe,\n",
      "  0x07, 0x12, 0xfd, 0xed, 0x16, 0x12, 0x03, 0xfa, 0x06, 0xed, 0xfa, 0xff,\n",
      "  0xf8, 0x03, 0xe7, 0x19, 0x12, 0xfb, 0xfa, 0xfe, 0xf0, 0xf6, 0x02, 0x29,\n",
      "  0xfe, 0x0b, 0x0a, 0xfd, 0xff, 0x02, 0xed, 0xe8, 0xf8, 0x02, 0x40, 0x05,\n",
      "  0x0d, 0x13, 0xf8, 0xff, 0x00, 0x21, 0xe8, 0xfb, 0x01, 0x07, 0x02, 0x23,\n",
      "  0x09, 0xea, 0xf9, 0x05, 0xe3, 0xc6, 0x05, 0x08, 0x2a, 0x07, 0x0a, 0x0e,\n",
      "  0xe5, 0xfc, 0x01, 0xff, 0x00, 0x05, 0xfe, 0xff, 0xfe, 0xf8, 0xfb, 0x02,\n",
      "  0x04, 0xfd, 0x00, 0x04, 0xfd, 0xff, 0x04, 0x05, 0x05, 0x02, 0xfc, 0xfe,\n",
      "  0xfd, 0x02, 0x0c, 0xfd, 0xfd, 0xfe, 0x03, 0x05, 0xfb, 0xfc, 0x01, 0x01,\n",
      "  0x03, 0xb0, 0x04, 0xe6, 0xff, 0x00, 0xfc, 0xe9, 0x04, 0xff, 0x02, 0x04,\n",
      "  0xff, 0x06, 0x0d, 0xf2, 0x03, 0xfc, 0x01, 0xf7, 0x02, 0xff, 0xf6, 0x07,\n",
      "  0x00, 0x11, 0xfa, 0xfe, 0xef, 0x17, 0xfb, 0x06, 0x05, 0x0c, 0xff, 0xfa,\n",
      "  0x18, 0x1e, 0x00, 0x06, 0x09, 0x07, 0xf7, 0x00, 0x13, 0x04, 0xfb, 0xfc,\n",
      "  0xe9, 0x00, 0x00, 0xfd, 0x04, 0xf2, 0xfa, 0x13, 0x06, 0x03, 0xe7, 0xf0,\n",
      "  0x01, 0xf8, 0x01, 0x03, 0xf8, 0x09, 0x02, 0x05, 0xfd, 0xf6, 0xfd, 0xff,\n",
      "  0x0c, 0x02, 0xfd, 0xf5, 0x04, 0x17, 0x4f, 0xf4, 0x1a, 0x19, 0x01, 0x0e,\n",
      "  0x17, 0x01, 0xfc, 0x02, 0x2f, 0x08, 0x01, 0x07, 0x17, 0xfe, 0x0d, 0x11,\n",
      "  0xf9, 0xfa, 0x05, 0xf9, 0xff, 0xfd, 0xf8, 0x06, 0x02, 0x03, 0x08, 0x04,\n",
      "  0x06, 0x03, 0xfb, 0xfa, 0x00, 0xfd, 0x03, 0x02, 0x02, 0xfe, 0xfd, 0xfe,\n",
      "  0x01, 0xff, 0xdc, 0x00, 0xfb, 0x06, 0xfa, 0xfb, 0xfe, 0x03, 0xfb, 0x00,\n",
      "  0x03, 0x4b, 0x05, 0x0b, 0x04, 0xfb, 0x08, 0xff, 0x00, 0x00, 0x01, 0xfd,\n",
      "  0xe7, 0x06, 0x10, 0xfc, 0x00, 0x01, 0xf3, 0x02, 0x01, 0x03, 0xff, 0x55,\n",
      "  0xfc, 0xf5, 0xf8, 0x08, 0xfa, 0x02, 0x02, 0x03, 0x02, 0xf4, 0xfe, 0x05,\n",
      "  0x06, 0xfc, 0x02, 0x07, 0x03, 0xfd, 0x03, 0x00, 0xec, 0xfb, 0xfe, 0xed,\n",
      "  0xf0, 0x03, 0xf4, 0xf3, 0xfe, 0x03, 0xf8, 0xf3, 0x04, 0xf9, 0xe9, 0xee,\n",
      "  0x05, 0xec, 0xf4, 0xed, 0xfe, 0xfa, 0x12, 0x1f, 0xfd, 0x06, 0x0f, 0x03,\n",
      "  0x0f, 0x0f, 0x06, 0xef, 0x04, 0xfc, 0x06, 0xfb, 0x0a, 0x11, 0x00, 0x08,\n",
      "  0x05, 0x01, 0x0e, 0x03, 0x05, 0x52, 0xfd, 0xff, 0x20, 0x00, 0x0c, 0x05,\n",
      "  0x02, 0xfb, 0x02, 0xf9, 0x3e, 0xfa, 0x03, 0x1b, 0xfe, 0x0a, 0x01, 0xfd,\n",
      "  0xf9, 0x08, 0xfb, 0x28, 0xfb, 0xef, 0xef, 0xfc, 0x06, 0x04, 0x01, 0xf7,\n",
      "  0xfb, 0xf6, 0xd7, 0x04, 0xfc, 0xf9, 0xfd, 0xff, 0xfb, 0x02, 0x02, 0x03,\n",
      "  0x00, 0xd8, 0x00, 0xff, 0x08, 0xff, 0xf8, 0xff, 0xff, 0xf8, 0x00, 0xfd,\n",
      "  0x60, 0x09, 0x0d, 0x03, 0xff, 0x03, 0xfa, 0x00, 0x01, 0xfe, 0x01, 0x56,\n",
      "  0xff, 0x08, 0x05, 0xfb, 0x00, 0xf5, 0x01, 0x04, 0xfd, 0xfb, 0x75, 0x02,\n",
      "  0x10, 0x07, 0x04, 0x00, 0xfb, 0x02, 0xfe, 0x05, 0xf4, 0xfb, 0x04, 0xf0,\n",
      "  0x03, 0x01, 0xf9, 0x06, 0x06, 0x05, 0x01, 0xfb, 0x00, 0xfe, 0xe5, 0xf5,\n",
      "  0x02, 0xf5, 0xe1, 0xf8, 0x03, 0xfd, 0xee, 0xfc, 0x03, 0xbb, 0xd8, 0x01,\n",
      "  0xec, 0xfa, 0xf1, 0xec, 0x01, 0x01, 0x5c, 0xfb, 0xfb, 0xf7, 0x06, 0x04,\n",
      "  0x01, 0xf4, 0xf2, 0x07, 0x21, 0x30, 0xff, 0x10, 0x09, 0xfe, 0x15, 0x0d,\n",
      "  0xff, 0xff, 0x04, 0xf7, 0x34, 0xfc, 0x06, 0x29, 0x00, 0x0a, 0x01, 0x1d,\n",
      "  0xfc, 0x06, 0xec, 0x14, 0xf9, 0xfb, 0x01, 0x02, 0x01, 0x00, 0x04, 0xed,\n",
      "  0xfe, 0xef, 0xee, 0xfe, 0xe9, 0x03, 0xfe, 0xfd, 0xfe, 0x02, 0xf1, 0xfb,\n",
      "  0xf9, 0xe8, 0xff, 0xfb, 0x06, 0xfc, 0xfe, 0xf4, 0x05, 0xff, 0x00, 0x04,\n",
      "  0x5e, 0xfa, 0x01, 0x00, 0x01, 0xfa, 0xf6, 0xfe, 0xf9, 0x01, 0xff, 0x54,\n",
      "  0x00, 0x0b, 0x00, 0xfe, 0xfd, 0x05, 0x03, 0xff, 0x04, 0x01, 0x17, 0x02,\n",
      "  0x06, 0x06, 0x04, 0xf8, 0xfb, 0xfd, 0x05, 0x00, 0xfd, 0x0c, 0x06, 0xf6,\n",
      "  0xfe, 0xfe, 0xfb, 0xfc, 0x04, 0x04, 0x06, 0x05, 0x0f, 0x06, 0x02, 0xff,\n",
      "  0xff, 0xfb, 0xfa, 0x00, 0x01, 0x02, 0xf7, 0xed, 0x07, 0xe3, 0xf2, 0xff,\n",
      "  0xeb, 0xf6, 0xf7, 0x0f, 0xf8, 0xf7, 0xff, 0x08, 0xd1, 0xea, 0x00, 0xe8,\n",
      "  0xef, 0xe4, 0x04, 0xfa, 0xfd, 0x5a, 0xfa, 0xfd, 0xfd, 0x05, 0x02, 0x0b,\n",
      "  0xf4, 0xe3, 0x07, 0x0e, 0x37, 0xf5, 0x0e, 0x0c, 0xfb, 0x0b, 0x07, 0x0d,\n",
      "  0xf3, 0xfe, 0xfb, 0x18, 0xfe, 0x04, 0x0d, 0x03, 0x04, 0x08, 0x0e, 0xf4,\n",
      "  0x01, 0xf2, 0x0f, 0xf7, 0x07, 0x19, 0xfd, 0x14, 0x08, 0x05, 0xf2, 0x07,\n",
      "  0xf7, 0x18, 0x00, 0x10, 0x00, 0x01, 0xff, 0xff, 0x05, 0xf7, 0x04, 0xfa,\n",
      "  0xb1, 0xfc, 0xff, 0xff, 0xfe, 0xf9, 0x02, 0x06, 0xfd, 0xfe, 0xfb, 0xfb,\n",
      "  0x02, 0x05, 0xff, 0x01, 0x04, 0xf6, 0xfe, 0xfe, 0x02, 0xfd, 0x76, 0x09,\n",
      "  0x07, 0x04, 0x01, 0xfe, 0xfe, 0x03, 0x05, 0x03, 0xfc, 0x03, 0x06, 0xf8,\n",
      "  0xff, 0xfd, 0xfb, 0xff, 0xfe, 0x09, 0x01, 0xff, 0xfb, 0x07, 0x01, 0xfb,\n",
      "  0x00, 0x04, 0xfa, 0x00, 0xfd, 0x01, 0x09, 0x0a, 0x08, 0xf6, 0xfd, 0x03,\n",
      "  0xfe, 0xfb, 0x03, 0x00, 0xfc, 0xf5, 0xd2, 0xfd, 0xd8, 0xea, 0x02, 0xe8,\n",
      "  0xf1, 0xf9, 0xe1, 0xfd, 0xf7, 0xe6, 0x03, 0xf9, 0xf2, 0x05, 0xf1, 0xf5,\n",
      "  0xe1, 0xfa, 0x01, 0x01, 0x2b, 0x06, 0xf3, 0xf5, 0x03, 0xfb, 0x06, 0xf5,\n",
      "  0xf9, 0x04, 0x0c, 0x28, 0xfe, 0x0b, 0x1d, 0x02, 0x0b, 0x08, 0x09, 0xfd,\n",
      "  0x04, 0x13, 0x45, 0xfd, 0x21, 0x1f, 0x02, 0x0b, 0x08, 0x05, 0xfa, 0x00,\n",
      "  0xff, 0x3c, 0xf8, 0x13, 0x10, 0x01, 0x01, 0x03, 0xfe, 0x01, 0x06, 0xf9,\n",
      "  0x36, 0xff, 0xfb, 0xf7, 0xff, 0x01, 0xfd, 0x05, 0xf7, 0x07, 0x02, 0x18,\n",
      "  0x04, 0xfd, 0x01, 0x02, 0xfe, 0x00, 0x01, 0x04, 0xfe, 0xfb, 0x11, 0xff,\n",
      "  0xfe, 0xfd, 0x02, 0x01, 0xfe, 0x01, 0x02, 0xfc, 0xfa, 0x75, 0x08, 0x07,\n",
      "  0xfe, 0xfe, 0xff, 0x00, 0xfb, 0x01, 0x01, 0x01, 0x12, 0x07, 0x0c, 0x02,\n",
      "  0x04, 0xff, 0xfc, 0xfb, 0x01, 0x03, 0xfe, 0x59, 0x06, 0xfa, 0xfc, 0x04,\n",
      "  0xfa, 0xfe, 0xfe, 0x05, 0x03, 0xfe, 0xf7, 0x01, 0xf0, 0xf4, 0x04, 0xfe,\n",
      "  0xfa, 0xfd, 0xfd, 0xfc, 0xfc, 0xc7, 0x02, 0xf4, 0xf3, 0xfb, 0xf4, 0xf5,\n",
      "  0xf9, 0xfe, 0xfd, 0xf6, 0x07, 0x04, 0xf5, 0xf6, 0x05, 0xfc, 0xf8, 0xe4,\n",
      "  0xef, 0xfb, 0x03, 0xf2, 0x07, 0xf1, 0xff, 0xfd, 0xff, 0x03, 0xfb, 0xf7,\n",
      "  0x01, 0x07, 0x38, 0xfb, 0xf8, 0x12, 0xfa, 0x0c, 0x06, 0x0d, 0xfb, 0x00,\n",
      "  0xfc, 0x05, 0x01, 0x03, 0x06, 0x00, 0x00, 0x04, 0xfd, 0x04, 0xfc, 0xf8,\n",
      "  0x04, 0xff, 0x07, 0xff, 0xfb, 0x11, 0x0a, 0x05, 0xf6, 0x08, 0x00, 0x38,\n",
      "  0x05, 0xed, 0xf7, 0x00, 0xfe, 0x01, 0x02, 0xef, 0x02, 0xfe, 0x13, 0x02,\n",
      "  0xfb, 0xff, 0x04, 0xfc, 0x06, 0xfd, 0x01, 0xfe, 0xfc, 0x04, 0xfe, 0x01,\n",
      "  0x01, 0xfe, 0xfb, 0xfe, 0x06, 0xfa, 0x01, 0xfa, 0x19, 0x03, 0x07, 0x03,\n",
      "  0x07, 0xfe, 0xff, 0xff, 0x04, 0xff, 0xfd, 0x15, 0x04, 0x07, 0xfc, 0x00,\n",
      "  0xf9, 0xfa, 0xfe, 0x01, 0x02, 0xfe, 0x58, 0x00, 0x07, 0xfc, 0x05, 0x00,\n",
      "  0x02, 0xfc, 0xef, 0x00, 0xff, 0xed, 0x05, 0x16, 0x04, 0x01, 0xfc, 0xfc,\n",
      "  0xfa, 0x01, 0xfd, 0xfe, 0xc7, 0x03, 0xf6, 0xea, 0xfc, 0xfc, 0xf6, 0xf5,\n",
      "  0x0f, 0xfd, 0xfe, 0x05, 0x05, 0xe3, 0xe1, 0xfd, 0xec, 0xf9, 0xe8, 0xfb,\n",
      "  0xf9, 0x07, 0xfe, 0x0b, 0xf3, 0xfb, 0x00, 0x03, 0x05, 0xfa, 0xf3, 0xfe,\n",
      "  0x02, 0x42, 0x00, 0x07, 0x17, 0xf9, 0x14, 0x02, 0x0c, 0xf4, 0x08, 0x04,\n",
      "  0x36, 0x03, 0x12, 0x07, 0xfa, 0x02, 0x05, 0x05, 0xfc, 0xfe, 0xfe, 0x33,\n",
      "  0xf9, 0x1b, 0x14, 0xfa, 0x06, 0x08, 0x02, 0xf7, 0x04, 0x03, 0x1f, 0x06,\n",
      "  0xf3, 0x0f, 0xfe, 0x08, 0xf0, 0x06, 0xf8, 0x03, 0x00, 0x44, 0x00, 0xfc,\n",
      "  0xff, 0x08, 0x00, 0xfb, 0x00, 0xfa, 0x01, 0xf4, 0xda, 0x01, 0x01, 0x04,\n",
      "  0x0c, 0xfd, 0xfd, 0x02, 0x03, 0xfc, 0xff, 0x63, 0x02, 0x0a, 0x00, 0x07,\n",
      "  0x05, 0xf7, 0xff, 0x07, 0x06, 0x02, 0x22, 0x04, 0x0b, 0xfb, 0x00, 0xf8,\n",
      "  0xfc, 0xfe, 0x05, 0xff, 0xfc, 0x3e, 0x05, 0x01, 0xfa, 0x05, 0x02, 0x08,\n",
      "  0x00, 0x01, 0xfe, 0xfe, 0xea, 0x00, 0x0e, 0xff, 0x04, 0x00, 0x05, 0xfb,\n",
      "  0x07, 0xfd, 0x02, 0xf5, 0xfe, 0xfb, 0xe9, 0x02, 0xfc, 0xf3, 0xf7, 0xf1,\n",
      "  0xff, 0xf8, 0xd4, 0xff, 0xde, 0xea, 0x00, 0xe9, 0xf4, 0xf0, 0xfc, 0xfc,\n",
      "  0x00, 0xcd, 0x05, 0xf2, 0xff, 0x01, 0x01, 0xfa, 0x03, 0xe6, 0x02, 0x0b,\n",
      "  0x36, 0x00, 0x06, 0x12, 0xfc, 0x0a, 0x08, 0x0e, 0xf0, 0x0a, 0xf9, 0x24,\n",
      "  0x01, 0x0c, 0x16, 0xf7, 0xfe, 0x07, 0xf9, 0xfc, 0x07, 0x04, 0x75, 0x01,\n",
      "  0x03, 0xfd, 0xf7, 0x07, 0x06, 0x08, 0xf7, 0x03, 0x07, 0x2c, 0x05, 0x00,\n",
      "  0x01, 0xf9, 0x04, 0x00, 0x03, 0xf7, 0x0a, 0x01, 0xee, 0xfb, 0xfb, 0x05,\n",
      "  0x06, 0xff, 0xfd, 0x02, 0x02, 0xfe, 0xff, 0xf0, 0x05, 0x00, 0xfc, 0x05,\n",
      "  0xfe, 0xf9, 0xfd, 0x00, 0x02, 0xfc, 0x03, 0x02, 0x03, 0x08, 0x01, 0xfc,\n",
      "  0xfe, 0x07, 0x02, 0x01, 0xfd, 0x08, 0x01, 0xf6, 0x01, 0x0a, 0xfe, 0xf7,\n",
      "  0x00, 0x08, 0xfe, 0xfa, 0xfa, 0x03, 0x06, 0x00, 0x02, 0x01, 0xf8, 0xff,\n",
      "  0x05, 0xfc, 0xfb, 0x01, 0xfd, 0xf9, 0x06, 0xff, 0x01, 0xfa, 0x01, 0xfe,\n",
      "  0xfc, 0xff, 0xf4, 0xfa, 0xf1, 0xf3, 0x06, 0x01, 0xff, 0xf9, 0x09, 0x01,\n",
      "  0xf8, 0xec, 0x01, 0xe7, 0xe6, 0xff, 0xf1, 0xf5, 0xf0, 0x0a, 0xff, 0x04,\n",
      "  0x04, 0x08, 0xfb, 0x04, 0xfd, 0xfe, 0x05, 0xf8, 0xec, 0x03, 0x06, 0x49,\n",
      "  0x02, 0x02, 0x14, 0xf5, 0x0c, 0x0b, 0x07, 0xff, 0x05, 0x03, 0x1c, 0xff,\n",
      "  0x09, 0x18, 0xf9, 0x07, 0x0b, 0xfb, 0xfc, 0x07, 0xfe, 0x06, 0x03, 0x07,\n",
      "  0x07, 0xf3, 0x01, 0xfb, 0x06, 0xfc, 0x02, 0x05, 0x24, 0x05, 0xf3, 0x05,\n",
      "  0xfb, 0x07, 0x04, 0x09, 0xef, 0x0a, 0xff, 0x00, 0x04, 0x02, 0x03, 0x07,\n",
      "  0x02, 0x00, 0xff, 0xfc, 0xfe, 0xfc, 0x02, 0xfb, 0xfe, 0x03, 0x0a, 0xf9,\n",
      "  0xfb, 0xfd, 0xfa, 0xff, 0xfc, 0x0e, 0x02, 0x0a, 0x02, 0x0b, 0x02, 0x03,\n",
      "  0x02, 0x05, 0x02, 0xfa, 0x01, 0xff, 0xfc, 0xfa, 0x00, 0xfa, 0xfb, 0xfc,\n",
      "  0x04, 0xfe, 0xfc, 0x00, 0x04, 0xf9, 0xf8, 0x07, 0xfe, 0xfd, 0x05, 0x05,\n",
      "  0xfd, 0xfe, 0xfe, 0x01, 0x0d, 0xfc, 0x0b, 0x0a, 0x05, 0xfe, 0x05, 0xfe,\n",
      "  0xf8, 0xe1, 0xfa, 0xf8, 0xf3, 0x01, 0xec, 0xf2, 0xf9, 0x05, 0xfd, 0xfa,\n",
      "  0xe9, 0x01, 0xd2, 0xdf, 0x03, 0xf5, 0xf4, 0xeb, 0xe1, 0x03, 0xff, 0x03,\n",
      "  0x0a, 0x01, 0x07, 0xf8, 0xf9, 0x00, 0xfc, 0xe6, 0x05, 0x17, 0x06, 0xf9,\n",
      "  0x05, 0x11, 0xfd, 0x09, 0x07, 0x10, 0xf4, 0x06, 0x01, 0xfb, 0xfc, 0x07,\n",
      "  0x13, 0xfa, 0x10, 0x09, 0x01, 0xf2, 0x05, 0xfa, 0x01, 0xfc, 0xe8, 0x16,\n",
      "  0xf6, 0x02, 0xfa, 0xfb, 0xfb, 0xff, 0xff, 0x01, 0xfd, 0x01, 0x06, 0xfb,\n",
      "  0xf5, 0x08, 0x05, 0xf1, 0x05, 0xf7, 0x01, 0xfd, 0x04, 0xfd, 0x0e, 0xfd,\n",
      "  0xfb, 0xfe, 0xfe, 0xfe, 0xfd, 0xff, 0xff, 0xfc, 0x04, 0x0b, 0xfa, 0xfa,\n",
      "  0xfd, 0xfd, 0xf9, 0xf9, 0x06, 0xff, 0x0c, 0x04, 0x05, 0x02, 0xfd, 0xfe,\n",
      "  0xfa, 0x01, 0x00, 0x02, 0xfc, 0xfe, 0x01, 0x09, 0xf9, 0xff, 0xfd, 0x08,\n",
      "  0xfc, 0x00, 0xfe, 0xff, 0x06, 0xfd, 0x01, 0xfa, 0xfd, 0x00, 0xfd, 0x02,\n",
      "  0xfd, 0xfa, 0x00, 0xf3, 0xff, 0x01, 0xfc, 0xff, 0xfb, 0x00, 0xf8, 0x00,\n",
      "  0xf2, 0x03, 0xe5, 0xf7, 0xfb, 0xfc, 0x00, 0xfe, 0xee, 0xff, 0xfa, 0xdf,\n",
      "  0x05, 0xd4, 0xd2, 0xfc, 0xf3, 0xfa, 0xe4, 0xe3, 0xfd, 0x01, 0xed, 0x09,\n",
      "  0xfa, 0xfb, 0xfb, 0x00, 0x00, 0x00, 0xe0, 0x06, 0x10, 0xfd, 0xfb, 0x09,\n",
      "  0x0b, 0xfb, 0x10, 0x0a, 0x09, 0xf7, 0x04, 0xf9, 0x01, 0xfc, 0x0d, 0x1d,\n",
      "  0xff, 0x0e, 0x08, 0x02, 0xf2, 0x00, 0x01, 0xff, 0x00, 0x0b, 0x07, 0xf5,\n",
      "  0x02, 0x0c, 0xfa, 0xee, 0x01, 0xfe, 0x01, 0x04, 0xf2, 0x02, 0xf4, 0x05,\n",
      "  0xf2, 0x02, 0xf1, 0x09, 0x00, 0xff, 0xfe, 0xfc, 0x03, 0x06, 0xf7, 0xfc,\n",
      "  0x05, 0x00, 0xff, 0xf9, 0xfd, 0xf9, 0xf7, 0xfe, 0x08, 0xfc, 0xf8, 0xfd,\n",
      "  0xf9, 0x02, 0x00, 0x01, 0xfd, 0x0b, 0x01, 0x0a, 0x01, 0x02, 0xfb, 0xfe,\n",
      "  0x02, 0xff, 0x04, 0x04, 0xf9, 0xfc, 0xfd, 0x00, 0xfc, 0xfe, 0x0b, 0xff,\n",
      "  0xfe, 0xf8, 0xfe, 0xfd, 0x01, 0x02, 0xfb, 0x03, 0xfe, 0x01, 0xfc, 0x00,\n",
      "  0xf8, 0xff, 0x09, 0xf3, 0x02, 0x07, 0xff, 0xfd, 0x02, 0x01, 0x02, 0xf7,\n",
      "  0x09, 0xfd, 0xf0, 0x03, 0xf8, 0xf8, 0xf4, 0x04, 0x00, 0xfb, 0xf7, 0x04,\n",
      "  0xea, 0xe9, 0x00, 0xe8, 0xf1, 0xf7, 0xe9, 0xff, 0xfc, 0xfd, 0x08, 0xff,\n",
      "  0xf9, 0xfd, 0xfb, 0xfb, 0xfe, 0xdc, 0x04, 0x14, 0x09, 0xfc, 0xfd, 0x16,\n",
      "  0xf6, 0x15, 0x07, 0x09, 0xe3, 0x09, 0xfc, 0x07, 0x02, 0x1c, 0x16, 0xfa,\n",
      "  0x0a, 0x04, 0xfe, 0xf9, 0x01, 0xfc, 0x05, 0x02, 0xfa, 0x09, 0xf1, 0x03,\n",
      "  0xf3, 0x04, 0xf1, 0x02, 0xfe, 0x04, 0x03, 0xe6, 0xfc, 0xf7, 0x0b, 0x08,\n",
      "  0xfe, 0xef, 0x0d, 0xf5, 0xf7, 0x03, 0x01, 0x03, 0x05, 0x03, 0xfd, 0xfe,\n",
      "  0x00, 0xfe, 0xf9, 0xf8, 0xff, 0x05, 0x09, 0x07, 0xff, 0xfa, 0xfe, 0x00,\n",
      "  0xfe, 0xf4, 0x00, 0x04, 0xfb, 0xfb, 0x07, 0xfc, 0xfc, 0x00, 0x07, 0xff,\n",
      "  0xfe, 0xf7, 0xff, 0x00, 0x01, 0x04, 0xfb, 0xfb, 0xf9, 0x06, 0xfd, 0xfd,\n",
      "  0xff, 0x05, 0xfb, 0xf6, 0x04, 0xfe, 0x03, 0x05, 0x06, 0xfe, 0x04, 0xf5,\n",
      "  0x04, 0xf6, 0x03, 0x02, 0x02, 0x00, 0x05, 0x03, 0x00, 0xfc, 0xf3, 0xff,\n",
      "  0xc3, 0xe0, 0xfe, 0xf2, 0xee, 0xf0, 0xee, 0x02, 0xf2, 0xf8, 0x02, 0xdc,\n",
      "  0xde, 0xf9, 0xf0, 0xe9, 0xec, 0xe6, 0xfe, 0x0c, 0xf4, 0x04, 0x01, 0xf8,\n",
      "  0xfb, 0xfd, 0x05, 0x00, 0xf6, 0x05, 0x2a, 0xcf, 0x00, 0x00, 0x25, 0xfe,\n",
      "  0x0f, 0x0c, 0x0b, 0xe8, 0x08, 0xfd, 0x02, 0xff, 0x06, 0x23, 0xfe, 0x12,\n",
      "  0x0d, 0x05, 0x06, 0x02, 0xfe, 0x08, 0xfe, 0x18, 0x14, 0xf5, 0x04, 0xfc,\n",
      "  0x03, 0xe3, 0x08, 0x0d, 0x10, 0x0a, 0xfa, 0x11, 0xf8, 0x02, 0x03, 0x02,\n",
      "  0xe7, 0x05, 0xfd, 0x00, 0x04, 0x05, 0xfb, 0x09, 0x03, 0xf9, 0xfe, 0xfd,\n",
      "  0xfe, 0x02, 0x00, 0xfc, 0x09, 0xfc, 0x09, 0x01, 0xf9, 0xfa, 0xfa, 0x02,\n",
      "  0xff, 0x01, 0x02, 0x0a, 0xf9, 0xfd, 0xfe, 0xfc, 0x00, 0x03, 0x01, 0xfc,\n",
      "  0x03, 0x04, 0xfd, 0xff, 0x00, 0xff, 0x01, 0xfd, 0x06, 0x04, 0xf7, 0x06,\n",
      "  0x01, 0xf6, 0x02, 0x06, 0x01, 0xfd, 0xfd, 0x00, 0xff, 0x02, 0x01, 0x02,\n",
      "  0x05, 0x00, 0x02, 0xf1, 0xf3, 0xf9, 0x04, 0x02, 0xfb, 0xfb, 0x03, 0xdb,\n",
      "  0xe7, 0x06, 0xea, 0xe6, 0xf9, 0x1c, 0x01, 0xed, 0x13, 0x05, 0xda, 0xe6,\n",
      "  0xfa, 0xe9, 0xf5, 0xee, 0xf6, 0x00, 0x0b, 0x12, 0x02, 0xe7, 0x02, 0xf9,\n",
      "  0xf0, 0xfb, 0x02, 0xe7, 0x09, 0x10, 0x09, 0xfe, 0xf3, 0x11, 0xfe, 0x08,\n",
      "  0x09, 0x08, 0xe9, 0x09, 0xfc, 0xfa, 0x00, 0x04, 0x20, 0xf6, 0x0f, 0x08,\n",
      "  0x05, 0xfc, 0xff, 0xff, 0xe7, 0x04, 0xf8, 0x22, 0xfa, 0xfe, 0xf4, 0x03,\n",
      "  0xf9, 0x01, 0x02, 0xe4, 0x02, 0xed, 0x06, 0xfd, 0xff, 0xf7, 0x08, 0x04,\n",
      "  0x0e, 0xfd, 0xfd, 0x03, 0xf8, 0x00, 0x05, 0x03, 0xf1, 0xfa, 0xfe, 0xfb,\n",
      "  0xf8, 0x05, 0xfd, 0xfd, 0xfc, 0x04, 0xff, 0xf9, 0xf9, 0xfb, 0x01, 0xf8,\n",
      "  0x03, 0x01, 0x0a, 0x06, 0xfe, 0x08, 0xfc, 0xfe, 0x03, 0x07, 0xfb, 0xfe,\n",
      "  0xff, 0xe9, 0xf5, 0x00, 0xf8, 0xf9, 0xf9, 0x0a, 0xff, 0xfd, 0xfb, 0xfc,\n",
      "  0xfc, 0x01, 0xfe, 0xf7, 0xf2, 0xf8, 0x07, 0xff, 0xf9, 0xfe, 0xfc, 0x01,\n",
      "  0xf8, 0xfd, 0x06, 0x05, 0xfe, 0x0c, 0xff, 0xfc, 0x02, 0x03, 0xf1, 0xe9,\n",
      "  0x00, 0xe8, 0xfd, 0xf7, 0x57, 0xfd, 0xee, 0x02, 0x09, 0xeb, 0xe8, 0xf8,\n",
      "  0xdd, 0xef, 0xf2, 0x02, 0xfb, 0x02, 0x08, 0x0b, 0xfc, 0xf9, 0xfd, 0xed,\n",
      "  0x08, 0xf8, 0xed, 0x05, 0xff, 0x06, 0x00, 0x0e, 0x02, 0xfe, 0x01, 0x0f,\n",
      "  0x10, 0x03, 0x0a, 0x05, 0x0a, 0x00, 0x07, 0x0f, 0xfa, 0x11, 0x17, 0x02,\n",
      "  0x0e, 0x03, 0x02, 0x0c, 0x06, 0x11, 0xf5, 0xfa, 0x07, 0xfc, 0xfe, 0xe4,\n",
      "  0x03, 0xf8, 0xfd, 0x03, 0xf9, 0x00, 0xfe, 0xfe, 0x19, 0x05, 0xe8, 0x08,\n",
      "  0xfb, 0xfc, 0x01, 0x08, 0xfe, 0x03, 0xfb, 0xf6, 0x02, 0x00, 0xff, 0x02,\n",
      "  0xbc, 0x05, 0xfa, 0x06, 0xff, 0x06, 0xfb, 0x03, 0x03, 0x06, 0xf9, 0xd0,\n",
      "  0xfc, 0x07, 0x03, 0xfe, 0x06, 0x00, 0xfd, 0x03, 0xff, 0xfe, 0xd0, 0xfd,\n",
      "  0xff, 0x02, 0x06, 0xf6, 0xfb, 0xf8, 0x05, 0xff, 0xfb, 0x09, 0x01, 0x13,\n",
      "  0xf7, 0xfe, 0xfd, 0x07, 0xf6, 0x06, 0x03, 0xf9, 0x1c, 0xff, 0xff, 0xf8,\n",
      "  0xfd, 0x04, 0xfe, 0xfe, 0xfe, 0x00, 0xf5, 0x13, 0x01, 0xfc, 0xf0, 0x04,\n",
      "  0xf7, 0xf9, 0xf6, 0x06, 0x09, 0xf7, 0x4e, 0x03, 0xf4, 0xec, 0xfa, 0xe4,\n",
      "  0xfa, 0xf5, 0x9f, 0x00, 0x0d, 0x1c, 0x03, 0xf7, 0x00, 0xfc, 0xee, 0x01,\n",
      "  0xf6, 0xd2, 0x03, 0x14, 0x2b, 0xfe, 0x30, 0x25, 0x05, 0x27, 0x1f, 0x10,\n",
      "  0xf7, 0x08, 0x04, 0x26, 0x01, 0x2e, 0x2e, 0xfd, 0x26, 0xf9, 0x0d, 0x18,\n",
      "  0x05, 0x07, 0xfa, 0x02, 0x3c, 0x10, 0x00, 0x04, 0x08, 0xf8, 0xd8, 0x01,\n",
      "  0xee, 0xdd, 0x02, 0xff, 0x1b, 0xff, 0x00, 0xfc, 0xff, 0xea, 0x0d, 0x00,\n",
      "  0xfc, 0x04, 0x0a, 0x04, 0xff, 0xfb, 0xf9, 0x02, 0xfe, 0xfe, 0x01, 0x07,\n",
      "  0x05, 0x04, 0x03, 0x01, 0xf7, 0x00, 0xfe, 0xed, 0xfb, 0xf9, 0xff, 0xff,\n",
      "  0x11, 0xf9, 0xfc, 0x06, 0x01, 0xfd, 0xf9, 0x06, 0x03, 0x00, 0x04, 0x0b,\n",
      "  0x0a, 0xfb, 0xef, 0xf0, 0xfb, 0x04, 0xfd, 0x03, 0x0a, 0xfe, 0x19, 0x00,\n",
      "  0x00, 0xfd, 0x10, 0xf3, 0x12, 0x08, 0xf4, 0xf9, 0x08, 0x00, 0xff, 0x04,\n",
      "  0xe8, 0x0a, 0xfe, 0x0d, 0x04, 0xf5, 0x05, 0xfd, 0x95, 0xd9, 0x00, 0xd6,\n",
      "  0xd8, 0xf5, 0x0c, 0x04, 0xe9, 0x19, 0xfd, 0xab, 0xe0, 0xfe, 0xd1, 0xdd,\n",
      "  0xf2, 0x06, 0xfd, 0x0d, 0x02, 0x00, 0x01, 0xf5, 0xfd, 0xf6, 0xf6, 0xf8,\n",
      "  0xf5, 0x0b, 0x03, 0x35, 0xfb, 0xf3, 0x06, 0xfe, 0x26, 0x14, 0x0e, 0xf7,\n",
      "  0xff, 0xf8, 0x22, 0xfd, 0x1d, 0x25, 0xfe, 0x03, 0xfc, 0x0a, 0xd5, 0x07,\n",
      "  0xf9, 0x16, 0x05, 0x08, 0x11, 0xff, 0x0d, 0xec, 0x09, 0xe6, 0x01, 0xf3,\n",
      "  0x21, 0x01, 0xe3, 0x4c, 0x02, 0x06, 0x2e, 0xfe, 0xc1, 0x0f, 0x03, 0x05,\n",
      "  0x01, 0x06, 0x0a, 0xfc, 0x08, 0x05, 0x03, 0xf8, 0x00, 0x02, 0xf3, 0xfc,\n",
      "  0x01, 0x09, 0xfc, 0xfe, 0xfc, 0x01, 0xf1, 0xfc, 0xf9, 0x04, 0x01, 0x05,\n",
      "  0x02, 0x01, 0x01, 0x07, 0xfc, 0x05, 0x03, 0x00, 0xff, 0xfe, 0xfc, 0x09,\n",
      "  0x01, 0xfc, 0xfe, 0xfe, 0xfe, 0x06, 0x01, 0x01, 0x00, 0xff, 0xfb, 0x02,\n",
      "  0x05, 0xf8, 0xf9, 0x07, 0xfb, 0xeb, 0x03, 0x00, 0x0b, 0x0b, 0xfb, 0xe3,\n",
      "  0x02, 0x06, 0xf4, 0xf7, 0x0f, 0xff, 0x01, 0x0a, 0xf8, 0xfd, 0xef, 0xfd,\n",
      "  0xf3, 0xef, 0x07, 0x02, 0xf1, 0x05, 0xe7, 0xdf, 0xf8, 0xd3, 0xf4, 0xec,\n",
      "  0xe6, 0x04, 0x32, 0xf9, 0x01, 0xe3, 0x16, 0xf9, 0xee, 0xfc, 0xfa, 0xea,\n",
      "  0xfb, 0x20, 0x02, 0xff, 0xfd, 0x2b, 0xff, 0x1a, 0x1e, 0x0a, 0xeb, 0x05,\n",
      "  0xec, 0xfa, 0xfb, 0xee, 0x15, 0x02, 0xf6, 0xf9, 0x00, 0xe2, 0xfb, 0x0d,\n",
      "  0xfd, 0x05, 0x0f, 0x5e, 0xfa, 0x13, 0x00, 0xfd, 0x0f, 0xff, 0x02, 0xef,\n",
      "  0x04, 0xe3, 0x3e, 0x00, 0xe0, 0x16, 0xff, 0xd1, 0x09, 0x08, 0xf7, 0x01,\n",
      "  0x04, 0x0d, 0xfd, 0xfe, 0xf6, 0x05, 0xf2, 0x00, 0xf2, 0xfb, 0x05, 0xe4,\n",
      "  0xfe, 0x00, 0x08, 0xf3, 0xfd, 0xf9, 0xff, 0xf4, 0xfd, 0xfa, 0x22, 0x01,\n",
      "  0x00, 0xf9, 0xf6, 0xfd, 0x04, 0x01, 0xfa, 0x03, 0xfe, 0x10, 0xff, 0xf6,\n",
      "  0x01, 0xee, 0xfc, 0xfb, 0xfe, 0x04, 0xfe, 0x02, 0xed, 0x0d, 0xfc, 0x09,\n",
      "  0xfe, 0x03, 0xf7, 0x06, 0x00, 0xf9, 0x00, 0x04, 0xfd, 0x02, 0xf8, 0xff,\n",
      "  0xfc, 0xe0, 0xff, 0xfe, 0xf5, 0xfd, 0xf6, 0xe8, 0xff, 0xef, 0x09, 0xfc,\n",
      "  0xf9, 0x06, 0x08, 0xf3, 0x03, 0xcf, 0x08, 0xfe, 0xe3, 0xf6, 0xf3, 0x5d,\n",
      "  0xfc, 0x15, 0xfd, 0x05, 0xde, 0xd5, 0xf9, 0xf6, 0xe8, 0x05, 0xf1, 0x04,\n",
      "  0x19, 0x01, 0x00, 0xfa, 0x19, 0x01, 0x07, 0x16, 0x05, 0xce, 0xfe, 0xda,\n",
      "  0x03, 0xfe, 0x25, 0xff, 0xfe, 0x16, 0x0f, 0xfd, 0x2c, 0xfc, 0xfc, 0x08,\n",
      "  0x03, 0x11, 0x17, 0xfa, 0xfb, 0x1d, 0x0b, 0xe7, 0x09, 0xf9, 0xfd, 0x05,\n",
      "  0xe1, 0x05, 0x02, 0x03, 0x08, 0xfc, 0xf5, 0x07, 0xf6, 0xfd, 0xff, 0xff,\n",
      "  0x04, 0x00, 0x00, 0x00, 0x08, 0x00, 0x00, 0x00, 0x9c, 0xfb, 0xff, 0xff,\n",
      "  0x64, 0x04, 0x00, 0x00, 0x0a, 0xfe, 0xff, 0xff, 0x04, 0x00, 0x00, 0x00,\n",
      "  0x08, 0x00, 0x00, 0x00, 0xff, 0xff, 0xff, 0xff, 0x2c, 0x0b, 0x00, 0x00,\n",
      "  0x7c, 0xf1, 0xff, 0xff, 0x22, 0xfe, 0xff, 0xff, 0x04, 0x00, 0x00, 0x00,\n",
      "  0x04, 0x00, 0x00, 0x00, 0x28, 0x00, 0x00, 0x00, 0x32, 0xfe, 0xff, 0xff,\n",
      "  0x04, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0x3c, 0x00, 0x00, 0x00,\n",
      "  0x42, 0xfe, 0xff, 0xff, 0x04, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00,\n",
      "  0x01, 0x00, 0x00, 0x00, 0x52, 0xfe, 0xff, 0xff, 0x04, 0x00, 0x00, 0x00,\n",
      "  0x04, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0xc0, 0xf1, 0xff, 0xff,\n",
      "  0xc4, 0xf1, 0xff, 0xff, 0x0f, 0x00, 0x00, 0x00, 0x4d, 0x4c, 0x49, 0x52,\n",
      "  0x20, 0x43, 0x6f, 0x6e, 0x76, 0x65, 0x72, 0x74, 0x65, 0x64, 0x2e, 0x00,\n",
      "  0x01, 0x00, 0x00, 0x00, 0x14, 0x00, 0x00, 0x00, 0x00, 0x00, 0x0e, 0x00,\n",
      "  0x18, 0x00, 0x14, 0x00, 0x10, 0x00, 0x0c, 0x00, 0x08, 0x00, 0x04, 0x00,\n",
      "  0x0e, 0x00, 0x00, 0x00, 0x14, 0x00, 0x00, 0x00, 0x1c, 0x00, 0x00, 0x00,\n",
      "  0x28, 0x02, 0x00, 0x00, 0x2c, 0x02, 0x00, 0x00, 0x30, 0x02, 0x00, 0x00,\n",
      "  0x04, 0x00, 0x00, 0x00, 0x6d, 0x61, 0x69, 0x6e, 0x00, 0x00, 0x00, 0x00,\n",
      "  0x08, 0x00, 0x00, 0x00, 0xd8, 0x01, 0x00, 0x00, 0x78, 0x01, 0x00, 0x00,\n",
      "  0x20, 0x01, 0x00, 0x00, 0xf8, 0x00, 0x00, 0x00, 0x98, 0x00, 0x00, 0x00,\n",
      "  0x70, 0x00, 0x00, 0x00, 0x38, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00,\n",
      "  0xb2, 0xfe, 0xff, 0xff, 0x14, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x09,\n",
      "  0x14, 0x00, 0x00, 0x00, 0x18, 0x00, 0x00, 0x00, 0x06, 0x00, 0x00, 0x00,\n",
      "  0xf6, 0xfe, 0xff, 0xff, 0x00, 0x00, 0x80, 0x3f, 0x01, 0x00, 0x00, 0x00,\n",
      "  0x12, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x11, 0x00, 0x00, 0x00,\n",
      "  0xe2, 0xfe, 0xff, 0xff, 0x14, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x08,\n",
      "  0x10, 0x00, 0x00, 0x00, 0x14, 0x00, 0x00, 0x00, 0x05, 0x00, 0x00, 0x00,\n",
      "  0x84, 0xf2, 0xff, 0xff, 0x01, 0x00, 0x00, 0x00, 0x11, 0x00, 0x00, 0x00,\n",
      "  0x03, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00, 0x08, 0x00, 0x00, 0x00,\n",
      "  0x07, 0x00, 0x00, 0x00, 0x8a, 0xff, 0xff, 0xff, 0x0c, 0x00, 0x00, 0x00,\n",
      "  0x10, 0x00, 0x00, 0x00, 0x03, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
      "  0x10, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00, 0x0f, 0x00, 0x00, 0x00,\n",
      "  0x06, 0x00, 0x00, 0x00, 0x3a, 0xff, 0xff, 0xff, 0x20, 0x00, 0x00, 0x00,\n",
      "  0x00, 0x00, 0x00, 0x01, 0x2c, 0x00, 0x00, 0x00, 0x30, 0x00, 0x00, 0x00,\n",
      "  0x04, 0x00, 0x00, 0x00, 0x0c, 0x00, 0x14, 0x00, 0x13, 0x00, 0x0c, 0x00,\n",
      "  0x08, 0x00, 0x07, 0x00, 0x0c, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01,\n",
      "  0x03, 0x00, 0x00, 0x00, 0x03, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01,\n",
      "  0x01, 0x00, 0x00, 0x00, 0x0f, 0x00, 0x00, 0x00, 0x03, 0x00, 0x00, 0x00,\n",
      "  0x0e, 0x00, 0x00, 0x00, 0x0a, 0x00, 0x00, 0x00, 0x09, 0x00, 0x00, 0x00,\n",
      "  0x00, 0x00, 0x0a, 0x00, 0x10, 0x00, 0x0c, 0x00, 0x08, 0x00, 0x04, 0x00,\n",
      "  0x0a, 0x00, 0x00, 0x00, 0x0c, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00,\n",
      "  0x03, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x0e, 0x00, 0x00, 0x00,\n",
      "  0x02, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x0d, 0x00, 0x00, 0x00,\n",
      "  0xba, 0xff, 0xff, 0xff, 0x1c, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x3b,\n",
      "  0x1c, 0x00, 0x00, 0x00, 0x20, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00,\n",
      "  0x00, 0x00, 0x06, 0x00, 0x08, 0x00, 0x04, 0x00, 0x06, 0x00, 0x00, 0x00,\n",
      "  0x04, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x0d, 0x00, 0x00, 0x00,\n",
      "  0x04, 0x00, 0x00, 0x00, 0x0c, 0x00, 0x00, 0x00, 0x03, 0x00, 0x00, 0x00,\n",
      "  0x04, 0x00, 0x00, 0x00, 0x05, 0x00, 0x00, 0x00, 0x00, 0x00, 0x0e, 0x00,\n",
      "  0x1a, 0x00, 0x14, 0x00, 0x10, 0x00, 0x0c, 0x00, 0x0b, 0x00, 0x04, 0x00,\n",
      "  0x0e, 0x00, 0x00, 0x00, 0x24, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x20,\n",
      "  0x24, 0x00, 0x00, 0x00, 0x28, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
      "  0x00, 0x00, 0x0e, 0x00, 0x08, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
      "  0x00, 0x00, 0x04, 0x00, 0x0e, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
      "  0x01, 0x00, 0x00, 0x00, 0x0c, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00,\n",
      "  0x0b, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00,\n",
      "  0x02, 0x00, 0x00, 0x00, 0x00, 0x00, 0x0e, 0x00, 0x16, 0x00, 0x00, 0x00,\n",
      "  0x10, 0x00, 0x0c, 0x00, 0x0b, 0x00, 0x04, 0x00, 0x0e, 0x00, 0x00, 0x00,\n",
      "  0x18, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x37, 0x18, 0x00, 0x00, 0x00,\n",
      "  0x1c, 0x00, 0x00, 0x00, 0x00, 0x00, 0x06, 0x00, 0x08, 0x00, 0x07, 0x00,\n",
      "  0x06, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02, 0x01, 0x00, 0x00, 0x00,\n",
      "  0x0b, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
      "  0x01, 0x00, 0x00, 0x00, 0x12, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
      "  0x00, 0x00, 0x00, 0x00, 0x13, 0x00, 0x00, 0x00, 0x00, 0x0c, 0x00, 0x00,\n",
      "  0xa4, 0x0b, 0x00, 0x00, 0x4c, 0x0b, 0x00, 0x00, 0x10, 0x0b, 0x00, 0x00,\n",
      "  0xd4, 0x0a, 0x00, 0x00, 0x98, 0x0a, 0x00, 0x00, 0x58, 0x0a, 0x00, 0x00,\n",
      "  0xf8, 0x09, 0x00, 0x00, 0x94, 0x09, 0x00, 0x00, 0xb8, 0x08, 0x00, 0x00,\n",
      "  0xd4, 0x07, 0x00, 0x00, 0x30, 0x07, 0x00, 0x00, 0x80, 0x06, 0x00, 0x00,\n",
      "  0xcc, 0x05, 0x00, 0x00, 0xe4, 0x04, 0x00, 0x00, 0xa0, 0x02, 0x00, 0x00,\n",
      "  0xc4, 0x01, 0x00, 0x00, 0x80, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00,\n",
      "  0x62, 0xf4, 0xff, 0xff, 0x00, 0x00, 0x00, 0x01, 0x18, 0x00, 0x00, 0x00,\n",
      "  0x20, 0x00, 0x00, 0x00, 0x3c, 0x00, 0x00, 0x00, 0x13, 0x00, 0x00, 0x00,\n",
      "  0x00, 0x00, 0x00, 0x09, 0x50, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00,\n",
      "  0xff, 0xff, 0xff, 0xff, 0x02, 0x00, 0x00, 0x00, 0x4c, 0xf4, 0xff, 0xff,\n",
      "  0x08, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
      "  0x80, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0x01, 0x00, 0x00, 0x00,\n",
      "  0x00, 0x00, 0x80, 0x3b, 0x19, 0x00, 0x00, 0x00, 0x53, 0x74, 0x61, 0x74,\n",
      "  0x65, 0x66, 0x75, 0x6c, 0x50, 0x61, 0x72, 0x74, 0x69, 0x74, 0x69, 0x6f,\n",
      "  0x6e, 0x65, 0x64, 0x43, 0x61, 0x6c, 0x6c, 0x5f, 0x31, 0x00, 0x00, 0x00,\n",
      "  0x02, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00,\n",
      "  0xda, 0xf4, 0xff, 0xff, 0x00, 0x00, 0x00, 0x01, 0x18, 0x00, 0x00, 0x00,\n",
      "  0x20, 0x00, 0x00, 0x00, 0x40, 0x00, 0x00, 0x00, 0x12, 0x00, 0x00, 0x00,\n",
      "  0x00, 0x00, 0x00, 0x09, 0x18, 0x01, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00,\n",
      "  0xff, 0xff, 0xff, 0xff, 0x02, 0x00, 0x00, 0x00, 0xc4, 0xf4, 0xff, 0xff,\n",
      "  0x08, 0x00, 0x00, 0x00, 0x14, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
      "  0xfa, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0x00, 0x00, 0x00, 0x00,\n",
      "  0x01, 0x00, 0x00, 0x00, 0x78, 0x5c, 0xd4, 0x3d, 0xdd, 0x00, 0x00, 0x00,\n",
      "  0x73, 0x65, 0x71, 0x75, 0x65, 0x6e, 0x74, 0x69, 0x61, 0x6c, 0x5f, 0x36,\n",
      "  0x5f, 0x31, 0x2f, 0x64, 0x65, 0x6e, 0x73, 0x65, 0x5f, 0x36, 0x5f, 0x31,\n",
      "  0x2f, 0x4d, 0x61, 0x74, 0x4d, 0x75, 0x6c, 0x3b, 0x53, 0x74, 0x61, 0x74,\n",
      "  0x65, 0x66, 0x75, 0x6c, 0x50, 0x61, 0x72, 0x74, 0x69, 0x74, 0x69, 0x6f,\n",
      "  0x6e, 0x65, 0x64, 0x43, 0x61, 0x6c, 0x6c, 0x5f, 0x31, 0x2f, 0x53, 0x74,\n",
      "  0x61, 0x74, 0x65, 0x66, 0x75, 0x6c, 0x50, 0x61, 0x72, 0x74, 0x69, 0x74,\n",
      "  0x69, 0x6f, 0x6e, 0x65, 0x64, 0x43, 0x61, 0x6c, 0x6c, 0x2f, 0x73, 0x65,\n",
      "  0x71, 0x75, 0x65, 0x6e, 0x74, 0x69, 0x61, 0x6c, 0x5f, 0x36, 0x5f, 0x31,\n",
      "  0x2f, 0x64, 0x65, 0x6e, 0x73, 0x65, 0x5f, 0x36, 0x5f, 0x31, 0x2f, 0x4d,\n",
      "  0x61, 0x74, 0x4d, 0x75, 0x6c, 0x3b, 0x73, 0x65, 0x71, 0x75, 0x65, 0x6e,\n",
      "  0x74, 0x69, 0x61, 0x6c, 0x5f, 0x36, 0x5f, 0x31, 0x2f, 0x64, 0x65, 0x6e,\n",
      "  0x73, 0x65, 0x5f, 0x36, 0x5f, 0x31, 0x2f, 0x41, 0x64, 0x64, 0x3b, 0x53,\n",
      "  0x74, 0x61, 0x74, 0x65, 0x66, 0x75, 0x6c, 0x50, 0x61, 0x72, 0x74, 0x69,\n",
      "  0x74, 0x69, 0x6f, 0x6e, 0x65, 0x64, 0x43, 0x61, 0x6c, 0x6c, 0x5f, 0x31,\n",
      "  0x2f, 0x53, 0x74, 0x61, 0x74, 0x65, 0x66, 0x75, 0x6c, 0x50, 0x61, 0x72,\n",
      "  0x74, 0x69, 0x74, 0x69, 0x6f, 0x6e, 0x65, 0x64, 0x43, 0x61, 0x6c, 0x6c,\n",
      "  0x2f, 0x73, 0x65, 0x71, 0x75, 0x65, 0x6e, 0x74, 0x69, 0x61, 0x6c, 0x5f,\n",
      "  0x36, 0x5f, 0x31, 0x2f, 0x64, 0x65, 0x6e, 0x73, 0x65, 0x5f, 0x36, 0x5f,\n",
      "  0x31, 0x2f, 0x41, 0x64, 0x64, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00,\n",
      "  0x01, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00, 0x1a, 0xf6, 0xff, 0xff,\n",
      "  0x00, 0x00, 0x00, 0x01, 0x18, 0x00, 0x00, 0x00, 0x20, 0x00, 0x00, 0x00,\n",
      "  0x40, 0x00, 0x00, 0x00, 0x11, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x09,\n",
      "  0xb0, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00, 0xff, 0xff, 0xff, 0xff,\n",
      "  0x2c, 0x0b, 0x00, 0x00, 0x04, 0xf6, 0xff, 0xff, 0x08, 0x00, 0x00, 0x00,\n",
      "  0x14, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x80, 0xff, 0xff, 0xff,\n",
      "  0xff, 0xff, 0xff, 0xff, 0x00, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
      "  0x11, 0xe7, 0xcf, 0x3d, 0x77, 0x00, 0x00, 0x00, 0x73, 0x65, 0x71, 0x75,\n",
      "  0x65, 0x6e, 0x74, 0x69, 0x61, 0x6c, 0x5f, 0x36, 0x5f, 0x31, 0x2f, 0x66,\n",
      "  0x6c, 0x61, 0x74, 0x74, 0x65, 0x6e, 0x5f, 0x36, 0x5f, 0x31, 0x2f, 0x52,\n",
      "  0x65, 0x73, 0x68, 0x61, 0x70, 0x65, 0x3b, 0x53, 0x74, 0x61, 0x74, 0x65,\n",
      "  0x66, 0x75, 0x6c, 0x50, 0x61, 0x72, 0x74, 0x69, 0x74, 0x69, 0x6f, 0x6e,\n",
      "  0x65, 0x64, 0x43, 0x61, 0x6c, 0x6c, 0x5f, 0x31, 0x2f, 0x53, 0x74, 0x61,\n",
      "  0x74, 0x65, 0x66, 0x75, 0x6c, 0x50, 0x61, 0x72, 0x74, 0x69, 0x74, 0x69,\n",
      "  0x6f, 0x6e, 0x65, 0x64, 0x43, 0x61, 0x6c, 0x6c, 0x2f, 0x73, 0x65, 0x71,\n",
      "  0x75, 0x65, 0x6e, 0x74, 0x69, 0x61, 0x6c, 0x5f, 0x36, 0x5f, 0x31, 0x2f,\n",
      "  0x66, 0x6c, 0x61, 0x74, 0x74, 0x65, 0x6e, 0x5f, 0x36, 0x5f, 0x31, 0x2f,\n",
      "  0x52, 0x65, 0x73, 0x68, 0x61, 0x70, 0x65, 0x00, 0x02, 0x00, 0x00, 0x00,\n",
      "  0x01, 0x00, 0x00, 0x00, 0x2c, 0x0b, 0x00, 0x00, 0xf2, 0xf6, 0xff, 0xff,\n",
      "  0x00, 0x00, 0x00, 0x01, 0x18, 0x00, 0x00, 0x00, 0x28, 0x00, 0x00, 0x00,\n",
      "  0x44, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x09,\n",
      "  0x10, 0x02, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0xff, 0xff, 0xff, 0xff,\n",
      "  0x14, 0x00, 0x00, 0x00, 0x0d, 0x00, 0x00, 0x00, 0x0b, 0x00, 0x00, 0x00,\n",
      "  0xe4, 0xf6, 0xff, 0xff, 0x08, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00,\n",
      "  0x01, 0x00, 0x00, 0x00, 0x80, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,\n",
      "  0x01, 0x00, 0x00, 0x00, 0x11, 0xe7, 0xcf, 0x3d, 0xd1, 0x01, 0x00, 0x00,\n",
      "  0x73, 0x65, 0x71, 0x75, 0x65, 0x6e, 0x74, 0x69, 0x61, 0x6c, 0x5f, 0x36,\n",
      "  0x5f, 0x31, 0x2f, 0x63, 0x6f, 0x6e, 0x76, 0x32, 0x64, 0x5f, 0x36, 0x5f,\n",
      "  0x31, 0x2f, 0x52, 0x65, 0x6c, 0x75, 0x3b, 0x53, 0x74, 0x61, 0x74, 0x65,\n",
      "  0x66, 0x75, 0x6c, 0x50, 0x61, 0x72, 0x74, 0x69, 0x74, 0x69, 0x6f, 0x6e,\n",
      "  0x65, 0x64, 0x43, 0x61, 0x6c, 0x6c, 0x5f, 0x31, 0x2f, 0x53, 0x74, 0x61,\n",
      "  0x74, 0x65, 0x66, 0x75, 0x6c, 0x50, 0x61, 0x72, 0x74, 0x69, 0x74, 0x69,\n",
      "  0x6f, 0x6e, 0x65, 0x64, 0x43, 0x61, 0x6c, 0x6c, 0x2f, 0x73, 0x65, 0x71,\n",
      "  0x75, 0x65, 0x6e, 0x74, 0x69, 0x61, 0x6c, 0x5f, 0x36, 0x5f, 0x31, 0x2f,\n",
      "  0x63, 0x6f, 0x6e, 0x76, 0x32, 0x64, 0x5f, 0x36, 0x5f, 0x31, 0x2f, 0x52,\n",
      "  0x65, 0x6c, 0x75, 0x3b, 0x73, 0x65, 0x71, 0x75, 0x65, 0x6e, 0x74, 0x69,\n",
      "  0x61, 0x6c, 0x5f, 0x36, 0x5f, 0x31, 0x2f, 0x63, 0x6f, 0x6e, 0x76, 0x32,\n",
      "  0x64, 0x5f, 0x36, 0x5f, 0x31, 0x2f, 0x61, 0x64, 0x64, 0x3b, 0x53, 0x74,\n",
      "  0x61, 0x74, 0x65, 0x66, 0x75, 0x6c, 0x50, 0x61, 0x72, 0x74, 0x69, 0x74,\n",
      "  0x69, 0x6f, 0x6e, 0x65, 0x64, 0x43, 0x61, 0x6c, 0x6c, 0x5f, 0x31, 0x2f,\n",
      "  0x53, 0x74, 0x61, 0x74, 0x65, 0x66, 0x75, 0x6c, 0x50, 0x61, 0x72, 0x74,\n",
      "  0x69, 0x74, 0x69, 0x6f, 0x6e, 0x65, 0x64, 0x43, 0x61, 0x6c, 0x6c, 0x2f,\n",
      "  0x73, 0x65, 0x71, 0x75, 0x65, 0x6e, 0x74, 0x69, 0x61, 0x6c, 0x5f, 0x36,\n",
      "  0x5f, 0x31, 0x2f, 0x63, 0x6f, 0x6e, 0x76, 0x32, 0x64, 0x5f, 0x36, 0x5f,\n",
      "  0x31, 0x2f, 0x61, 0x64, 0x64, 0x3b, 0x73, 0x65, 0x71, 0x75, 0x65, 0x6e,\n",
      "  0x74, 0x69, 0x61, 0x6c, 0x5f, 0x36, 0x5f, 0x31, 0x2f, 0x63, 0x6f, 0x6e,\n",
      "  0x76, 0x32, 0x64, 0x5f, 0x36, 0x5f, 0x31, 0x2f, 0x63, 0x6f, 0x6e, 0x76,\n",
      "  0x6f, 0x6c, 0x75, 0x74, 0x69, 0x6f, 0x6e, 0x3b, 0x53, 0x74, 0x61, 0x74,\n",
      "  0x65, 0x66, 0x75, 0x6c, 0x50, 0x61, 0x72, 0x74, 0x69, 0x74, 0x69, 0x6f,\n",
      "  0x6e, 0x65, 0x64, 0x43, 0x61, 0x6c, 0x6c, 0x5f, 0x31, 0x2f, 0x53, 0x74,\n",
      "  0x61, 0x74, 0x65, 0x66, 0x75, 0x6c, 0x50, 0x61, 0x72, 0x74, 0x69, 0x74,\n",
      "  0x69, 0x6f, 0x6e, 0x65, 0x64, 0x43, 0x61, 0x6c, 0x6c, 0x2f, 0x73, 0x65,\n",
      "  0x71, 0x75, 0x65, 0x6e, 0x74, 0x69, 0x61, 0x6c, 0x5f, 0x36, 0x5f, 0x31,\n",
      "  0x2f, 0x63, 0x6f, 0x6e, 0x76, 0x32, 0x64, 0x5f, 0x36, 0x5f, 0x31, 0x2f,\n",
      "  0x63, 0x6f, 0x6e, 0x76, 0x6f, 0x6c, 0x75, 0x74, 0x69, 0x6f, 0x6e, 0x3b,\n",
      "  0x73, 0x65, 0x71, 0x75, 0x65, 0x6e, 0x74, 0x69, 0x61, 0x6c, 0x5f, 0x36,\n",
      "  0x5f, 0x31, 0x2f, 0x63, 0x6f, 0x6e, 0x76, 0x32, 0x64, 0x5f, 0x36, 0x5f,\n",
      "  0x31, 0x2f, 0x52, 0x65, 0x73, 0x68, 0x61, 0x70, 0x65, 0x3b, 0x53, 0x74,\n",
      "  0x61, 0x74, 0x65, 0x66, 0x75, 0x6c, 0x50, 0x61, 0x72, 0x74, 0x69, 0x74,\n",
      "  0x69, 0x6f, 0x6e, 0x65, 0x64, 0x43, 0x61, 0x6c, 0x6c, 0x5f, 0x31, 0x2f,\n",
      "  0x53, 0x74, 0x61, 0x74, 0x65, 0x66, 0x75, 0x6c, 0x50, 0x61, 0x72, 0x74,\n",
      "  0x69, 0x74, 0x69, 0x6f, 0x6e, 0x65, 0x64, 0x43, 0x61, 0x6c, 0x6c, 0x2f,\n",
      "  0x73, 0x65, 0x71, 0x75, 0x65, 0x6e, 0x74, 0x69, 0x61, 0x6c, 0x5f, 0x36,\n",
      "  0x5f, 0x31, 0x2f, 0x63, 0x6f, 0x6e, 0x76, 0x32, 0x64, 0x5f, 0x36, 0x5f,\n",
      "  0x31, 0x2f, 0x52, 0x65, 0x73, 0x68, 0x61, 0x70, 0x65, 0x00, 0x00, 0x00,\n",
      "  0x04, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x14, 0x00, 0x00, 0x00,\n",
      "  0x0d, 0x00, 0x00, 0x00, 0x0b, 0x00, 0x00, 0x00, 0x32, 0xf9, 0xff, 0xff,\n",
      "  0x00, 0x00, 0x00, 0x01, 0x18, 0x00, 0x00, 0x00, 0x28, 0x00, 0x00, 0x00,\n",
      "  0x44, 0x00, 0x00, 0x00, 0x0f, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x09,\n",
      "  0xb4, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0xff, 0xff, 0xff, 0xff,\n",
      "  0x3c, 0x00, 0x00, 0x00, 0x28, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
      "  0x24, 0xf9, 0xff, 0xff, 0x08, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00,\n",
      "  0x01, 0x00, 0x00, 0x00, 0x7f, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
      "  0x01, 0x00, 0x00, 0x00, 0xa1, 0xa0, 0xa0, 0x3e, 0x77, 0x00, 0x00, 0x00,\n",
      "  0x73, 0x65, 0x71, 0x75, 0x65, 0x6e, 0x74, 0x69, 0x61, 0x6c, 0x5f, 0x36,\n",
      "  0x5f, 0x31, 0x2f, 0x72, 0x65, 0x73, 0x68, 0x61, 0x70, 0x65, 0x5f, 0x36,\n",
      "  0x5f, 0x31, 0x2f, 0x52, 0x65, 0x73, 0x68, 0x61, 0x70, 0x65, 0x3b, 0x53,\n",
      "  0x74, 0x61, 0x74, 0x65, 0x66, 0x75, 0x6c, 0x50, 0x61, 0x72, 0x74, 0x69,\n",
      "  0x74, 0x69, 0x6f, 0x6e, 0x65, 0x64, 0x43, 0x61, 0x6c, 0x6c, 0x5f, 0x31,\n",
      "  0x2f, 0x53, 0x74, 0x61, 0x74, 0x65, 0x66, 0x75, 0x6c, 0x50, 0x61, 0x72,\n",
      "  0x74, 0x69, 0x74, 0x69, 0x6f, 0x6e, 0x65, 0x64, 0x43, 0x61, 0x6c, 0x6c,\n",
      "  0x2f, 0x73, 0x65, 0x71, 0x75, 0x65, 0x6e, 0x74, 0x69, 0x61, 0x6c, 0x5f,\n",
      "  0x36, 0x5f, 0x31, 0x2f, 0x72, 0x65, 0x73, 0x68, 0x61, 0x70, 0x65, 0x5f,\n",
      "  0x36, 0x5f, 0x31, 0x2f, 0x52, 0x65, 0x73, 0x68, 0x61, 0x70, 0x65, 0x00,\n",
      "  0x04, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x3c, 0x00, 0x00, 0x00,\n",
      "  0x28, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x6e, 0xfa, 0xff, 0xff,\n",
      "  0x00, 0x00, 0x00, 0x01, 0x14, 0x00, 0x00, 0x00, 0x14, 0x00, 0x00, 0x00,\n",
      "  0x0e, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02, 0x90, 0x00, 0x00, 0x00,\n",
      "  0x58, 0xfa, 0xff, 0xff, 0x83, 0x00, 0x00, 0x00, 0x73, 0x65, 0x71, 0x75,\n",
      "  0x65, 0x6e, 0x74, 0x69, 0x61, 0x6c, 0x5f, 0x36, 0x5f, 0x31, 0x2f, 0x72,\n",
      "  0x65, 0x73, 0x68, 0x61, 0x70, 0x65, 0x5f, 0x36, 0x5f, 0x31, 0x2f, 0x52,\n",
      "  0x65, 0x73, 0x68, 0x61, 0x70, 0x65, 0x2f, 0x73, 0x68, 0x61, 0x70, 0x65,\n",
      "  0x3b, 0x53, 0x74, 0x61, 0x74, 0x65, 0x66, 0x75, 0x6c, 0x50, 0x61, 0x72,\n",
      "  0x74, 0x69, 0x74, 0x69, 0x6f, 0x6e, 0x65, 0x64, 0x43, 0x61, 0x6c, 0x6c,\n",
      "  0x5f, 0x31, 0x2f, 0x53, 0x74, 0x61, 0x74, 0x65, 0x66, 0x75, 0x6c, 0x50,\n",
      "  0x61, 0x72, 0x74, 0x69, 0x74, 0x69, 0x6f, 0x6e, 0x65, 0x64, 0x43, 0x61,\n",
      "  0x6c, 0x6c, 0x2f, 0x73, 0x65, 0x71, 0x75, 0x65, 0x6e, 0x74, 0x69, 0x61,\n",
      "  0x6c, 0x5f, 0x36, 0x5f, 0x31, 0x2f, 0x72, 0x65, 0x73, 0x68, 0x61, 0x70,\n",
      "  0x65, 0x5f, 0x36, 0x5f, 0x31, 0x2f, 0x52, 0x65, 0x73, 0x68, 0x61, 0x70,\n",
      "  0x65, 0x2f, 0x73, 0x68, 0x61, 0x70, 0x65, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
      "  0x04, 0x00, 0x00, 0x00, 0x1e, 0xfb, 0xff, 0xff, 0x00, 0x00, 0x00, 0x01,\n",
      "  0x14, 0x00, 0x00, 0x00, 0x14, 0x00, 0x00, 0x00, 0x0d, 0x00, 0x00, 0x00,\n",
      "  0x00, 0x00, 0x00, 0x02, 0x90, 0x00, 0x00, 0x00, 0x08, 0xfb, 0xff, 0xff,\n",
      "  0x83, 0x00, 0x00, 0x00, 0x73, 0x65, 0x71, 0x75, 0x65, 0x6e, 0x74, 0x69,\n",
      "  0x61, 0x6c, 0x5f, 0x36, 0x5f, 0x31, 0x2f, 0x72, 0x65, 0x73, 0x68, 0x61,\n",
      "  0x70, 0x65, 0x5f, 0x36, 0x5f, 0x31, 0x2f, 0x73, 0x74, 0x72, 0x69, 0x64,\n",
      "  0x65, 0x64, 0x5f, 0x73, 0x6c, 0x69, 0x63, 0x65, 0x3b, 0x53, 0x74, 0x61,\n",
      "  0x74, 0x65, 0x66, 0x75, 0x6c, 0x50, 0x61, 0x72, 0x74, 0x69, 0x74, 0x69,\n",
      "  0x6f, 0x6e, 0x65, 0x64, 0x43, 0x61, 0x6c, 0x6c, 0x5f, 0x31, 0x2f, 0x53,\n",
      "  0x74, 0x61, 0x74, 0x65, 0x66, 0x75, 0x6c, 0x50, 0x61, 0x72, 0x74, 0x69,\n",
      "  0x74, 0x69, 0x6f, 0x6e, 0x65, 0x64, 0x43, 0x61, 0x6c, 0x6c, 0x2f, 0x73,\n",
      "  0x65, 0x71, 0x75, 0x65, 0x6e, 0x74, 0x69, 0x61, 0x6c, 0x5f, 0x36, 0x5f,\n",
      "  0x31, 0x2f, 0x72, 0x65, 0x73, 0x68, 0x61, 0x70, 0x65, 0x5f, 0x36, 0x5f,\n",
      "  0x31, 0x2f, 0x73, 0x74, 0x72, 0x69, 0x64, 0x65, 0x64, 0x5f, 0x73, 0x6c,\n",
      "  0x69, 0x63, 0x65, 0x00, 0x00, 0x00, 0x00, 0x00, 0xca, 0xfb, 0xff, 0xff,\n",
      "  0x00, 0x00, 0x00, 0x01, 0x14, 0x00, 0x00, 0x00, 0x14, 0x00, 0x00, 0x00,\n",
      "  0x0c, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02, 0x80, 0x00, 0x00, 0x00,\n",
      "  0xb4, 0xfb, 0xff, 0xff, 0x73, 0x00, 0x00, 0x00, 0x73, 0x65, 0x71, 0x75,\n",
      "  0x65, 0x6e, 0x74, 0x69, 0x61, 0x6c, 0x5f, 0x36, 0x5f, 0x31, 0x2f, 0x72,\n",
      "  0x65, 0x73, 0x68, 0x61, 0x70, 0x65, 0x5f, 0x36, 0x5f, 0x31, 0x2f, 0x53,\n",
      "  0x68, 0x61, 0x70, 0x65, 0x3b, 0x53, 0x74, 0x61, 0x74, 0x65, 0x66, 0x75,\n",
      "  0x6c, 0x50, 0x61, 0x72, 0x74, 0x69, 0x74, 0x69, 0x6f, 0x6e, 0x65, 0x64,\n",
      "  0x43, 0x61, 0x6c, 0x6c, 0x5f, 0x31, 0x2f, 0x53, 0x74, 0x61, 0x74, 0x65,\n",
      "  0x66, 0x75, 0x6c, 0x50, 0x61, 0x72, 0x74, 0x69, 0x74, 0x69, 0x6f, 0x6e,\n",
      "  0x65, 0x64, 0x43, 0x61, 0x6c, 0x6c, 0x2f, 0x73, 0x65, 0x71, 0x75, 0x65,\n",
      "  0x6e, 0x74, 0x69, 0x61, 0x6c, 0x5f, 0x36, 0x5f, 0x31, 0x2f, 0x72, 0x65,\n",
      "  0x73, 0x68, 0x61, 0x70, 0x65, 0x5f, 0x36, 0x5f, 0x31, 0x2f, 0x53, 0x68,\n",
      "  0x61, 0x70, 0x65, 0x00, 0x01, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00,\n",
      "  0x6a, 0xfc, 0xff, 0xff, 0x00, 0x00, 0x00, 0x01, 0x14, 0x00, 0x00, 0x00,\n",
      "  0xa8, 0x00, 0x00, 0x00, 0x0b, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x09,\n",
      "  0xb4, 0x00, 0x00, 0x00, 0xec, 0xfb, 0xff, 0xff, 0x08, 0x00, 0x00, 0x00,\n",
      "  0x60, 0x00, 0x00, 0x00, 0x0b, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
      "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
      "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
      "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
      "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
      "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
      "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
      "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
      "  0x0b, 0x00, 0x00, 0x00, 0x72, 0x4b, 0x13, 0x3b, 0x1c, 0x21, 0x61, 0x3b,\n",
      "  0xb5, 0xaa, 0xf7, 0x3a, 0x16, 0x8a, 0xd2, 0x3a, 0xed, 0xf4, 0xf1, 0x3a,\n",
      "  0x18, 0x7e, 0x18, 0x3a, 0x95, 0xa4, 0xe5, 0x3a, 0x6e, 0x95, 0xdb, 0x3a,\n",
      "  0x82, 0xb8, 0xc1, 0x3a, 0x43, 0x7d, 0xfc, 0x3a, 0xa9, 0x55, 0xd1, 0x3a,\n",
      "  0x12, 0x00, 0x00, 0x00, 0x74, 0x66, 0x6c, 0x2e, 0x70, 0x73, 0x65, 0x75,\n",
      "  0x64, 0x6f, 0x5f, 0x71, 0x63, 0x6f, 0x6e, 0x73, 0x74, 0x33, 0x00, 0x00,\n",
      "  0x04, 0x00, 0x00, 0x00, 0x0b, 0x00, 0x00, 0x00, 0x03, 0x00, 0x00, 0x00,\n",
      "  0x03, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x4a, 0xfd, 0xff, 0xff,\n",
      "  0x00, 0x00, 0x00, 0x01, 0x14, 0x00, 0x00, 0x00, 0xac, 0x00, 0x00, 0x00,\n",
      "  0x0a, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02, 0xb8, 0x00, 0x00, 0x00,\n",
      "  0xcc, 0xfc, 0xff, 0xff, 0x08, 0x00, 0x00, 0x00, 0x64, 0x00, 0x00, 0x00,\n",
      "  0x0b, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
      "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
      "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
      "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
      "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
      "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
      "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
      "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
      "  0x0b, 0x00, 0x00, 0x00, 0x26, 0xd7, 0x38, 0x3a, 0xf4, 0x41, 0x8d, 0x3a,\n",
      "  0x18, 0x66, 0x1b, 0x3a, 0x68, 0x1a, 0x04, 0x3a, 0xe5, 0xd0, 0x17, 0x3a,\n",
      "  0xfb, 0x5c, 0x3f, 0x39, 0xf4, 0x16, 0x10, 0x3a, 0x2c, 0xc7, 0x09, 0x3a,\n",
      "  0xbd, 0x19, 0xf3, 0x39, 0xb7, 0x6c, 0x1e, 0x3a, 0xe3, 0x58, 0x03, 0x3a,\n",
      "  0x12, 0x00, 0x00, 0x00, 0x74, 0x66, 0x6c, 0x2e, 0x70, 0x73, 0x65, 0x75,\n",
      "  0x64, 0x6f, 0x5f, 0x71, 0x63, 0x6f, 0x6e, 0x73, 0x74, 0x32, 0x00, 0x00,\n",
      "  0x01, 0x00, 0x00, 0x00, 0x0b, 0x00, 0x00, 0x00, 0x22, 0xfe, 0xff, 0xff,\n",
      "  0x00, 0x00, 0x00, 0x01, 0x14, 0x00, 0x00, 0x00, 0x30, 0x00, 0x00, 0x00,\n",
      "  0x09, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x09, 0x3c, 0x00, 0x00, 0x00,\n",
      "  0xa4, 0xfd, 0xff, 0xff, 0x08, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00,\n",
      "  0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
      "  0x01, 0x00, 0x00, 0x00, 0x43, 0xf5, 0xd2, 0x3b, 0x12, 0x00, 0x00, 0x00,\n",
      "  0x74, 0x66, 0x6c, 0x2e, 0x70, 0x73, 0x65, 0x75, 0x64, 0x6f, 0x5f, 0x71,\n",
      "  0x63, 0x6f, 0x6e, 0x73, 0x74, 0x31, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00,\n",
      "  0x02, 0x00, 0x00, 0x00, 0x2c, 0x0b, 0x00, 0x00, 0x82, 0xfe, 0xff, 0xff,\n",
      "  0x00, 0x00, 0x00, 0x01, 0x14, 0x00, 0x00, 0x00, 0x30, 0x00, 0x00, 0x00,\n",
      "  0x08, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02, 0x3c, 0x00, 0x00, 0x00,\n",
      "  0x04, 0xfe, 0xff, 0xff, 0x08, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00,\n",
      "  0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
      "  0x01, 0x00, 0x00, 0x00, 0xba, 0x52, 0x2b, 0x3a, 0x11, 0x00, 0x00, 0x00,\n",
      "  0x74, 0x66, 0x6c, 0x2e, 0x70, 0x73, 0x65, 0x75, 0x64, 0x6f, 0x5f, 0x71,\n",
      "  0x63, 0x6f, 0x6e, 0x73, 0x74, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
      "  0x02, 0x00, 0x00, 0x00, 0xde, 0xfe, 0xff, 0xff, 0x00, 0x00, 0x00, 0x01,\n",
      "  0x14, 0x00, 0x00, 0x00, 0x14, 0x00, 0x00, 0x00, 0x07, 0x00, 0x00, 0x00,\n",
      "  0x00, 0x00, 0x00, 0x02, 0x1c, 0x00, 0x00, 0x00, 0xc8, 0xfe, 0xff, 0xff,\n",
      "  0x0f, 0x00, 0x00, 0x00, 0x61, 0x72, 0x69, 0x74, 0x68, 0x2e, 0x63, 0x6f,\n",
      "  0x6e, 0x73, 0x74, 0x61, 0x6e, 0x74, 0x35, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
      "  0x02, 0x00, 0x00, 0x00, 0x1a, 0xff, 0xff, 0xff, 0x00, 0x00, 0x00, 0x01,\n",
      "  0x14, 0x00, 0x00, 0x00, 0x14, 0x00, 0x00, 0x00, 0x03, 0x00, 0x00, 0x00,\n",
      "  0x00, 0x00, 0x00, 0x02, 0x1c, 0x00, 0x00, 0x00, 0x04, 0xff, 0xff, 0xff,\n",
      "  0x0f, 0x00, 0x00, 0x00, 0x61, 0x72, 0x69, 0x74, 0x68, 0x2e, 0x63, 0x6f,\n",
      "  0x6e, 0x73, 0x74, 0x61, 0x6e, 0x74, 0x34, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
      "  0x52, 0xff, 0xff, 0xff, 0x00, 0x00, 0x00, 0x01, 0x14, 0x00, 0x00, 0x00,\n",
      "  0x14, 0x00, 0x00, 0x00, 0x05, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02,\n",
      "  0x1c, 0x00, 0x00, 0x00, 0x3c, 0xff, 0xff, 0xff, 0x0f, 0x00, 0x00, 0x00,\n",
      "  0x61, 0x72, 0x69, 0x74, 0x68, 0x2e, 0x63, 0x6f, 0x6e, 0x73, 0x74, 0x61,\n",
      "  0x6e, 0x74, 0x33, 0x00, 0x00, 0x00, 0x00, 0x00, 0x8a, 0xff, 0xff, 0xff,\n",
      "  0x00, 0x00, 0x00, 0x01, 0x14, 0x00, 0x00, 0x00, 0x14, 0x00, 0x00, 0x00,\n",
      "  0x04, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02, 0x1c, 0x00, 0x00, 0x00,\n",
      "  0x74, 0xff, 0xff, 0xff, 0x0f, 0x00, 0x00, 0x00, 0x61, 0x72, 0x69, 0x74,\n",
      "  0x68, 0x2e, 0x63, 0x6f, 0x6e, 0x73, 0x74, 0x61, 0x6e, 0x74, 0x32, 0x00,\n",
      "  0x00, 0x00, 0x00, 0x00, 0xc2, 0xff, 0xff, 0xff, 0x00, 0x00, 0x00, 0x01,\n",
      "  0x14, 0x00, 0x00, 0x00, 0x14, 0x00, 0x00, 0x00, 0x03, 0x00, 0x00, 0x00,\n",
      "  0x00, 0x00, 0x00, 0x02, 0x1c, 0x00, 0x00, 0x00, 0xac, 0xff, 0xff, 0xff,\n",
      "  0x0f, 0x00, 0x00, 0x00, 0x61, 0x72, 0x69, 0x74, 0x68, 0x2e, 0x63, 0x6f,\n",
      "  0x6e, 0x73, 0x74, 0x61, 0x6e, 0x74, 0x31, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
      "  0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x16, 0x00, 0x1c, 0x00, 0x18, 0x00,\n",
      "  0x17, 0x00, 0x10, 0x00, 0x0c, 0x00, 0x08, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
      "  0x00, 0x00, 0x07, 0x00, 0x16, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01,\n",
      "  0x18, 0x00, 0x00, 0x00, 0x18, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00,\n",
      "  0x00, 0x00, 0x00, 0x02, 0x20, 0x00, 0x00, 0x00, 0x04, 0x00, 0x04, 0x00,\n",
      "  0x04, 0x00, 0x00, 0x00, 0x0e, 0x00, 0x00, 0x00, 0x61, 0x72, 0x69, 0x74,\n",
      "  0x68, 0x2e, 0x63, 0x6f, 0x6e, 0x73, 0x74, 0x61, 0x6e, 0x74, 0x00, 0x00,\n",
      "  0x01, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x16, 0x00,\n",
      "  0x20, 0x00, 0x1c, 0x00, 0x1b, 0x00, 0x14, 0x00, 0x10, 0x00, 0x0c, 0x00,\n",
      "  0x00, 0x00, 0x00, 0x00, 0x08, 0x00, 0x07, 0x00, 0x16, 0x00, 0x00, 0x00,\n",
      "  0x00, 0x00, 0x00, 0x01, 0x18, 0x00, 0x00, 0x00, 0x2c, 0x00, 0x00, 0x00,\n",
      "  0x48, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x09,\n",
      "  0x60, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00, 0xff, 0xff, 0xff, 0xff,\n",
      "  0x60, 0x09, 0x00, 0x00, 0x0c, 0x00, 0x0c, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
      "  0x08, 0x00, 0x04, 0x00, 0x0c, 0x00, 0x00, 0x00, 0x08, 0x00, 0x00, 0x00,\n",
      "  0x10, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x7f, 0x00, 0x00, 0x00,\n",
      "  0x00, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0xa1, 0xa0, 0xa0, 0x3e,\n",
      "  0x1f, 0x00, 0x00, 0x00, 0x73, 0x65, 0x72, 0x76, 0x69, 0x6e, 0x67, 0x5f,\n",
      "  0x64, 0x65, 0x66, 0x61, 0x75, 0x6c, 0x74, 0x5f, 0x6b, 0x65, 0x72, 0x61,\n",
      "  0x73, 0x5f, 0x74, 0x65, 0x6e, 0x73, 0x6f, 0x72, 0x5f, 0x33, 0x30, 0x00,\n",
      "  0x02, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x60, 0x09, 0x00, 0x00,\n",
      "  0x07, 0x00, 0x00, 0x00, 0x88, 0x00, 0x00, 0x00, 0x6c, 0x00, 0x00, 0x00,\n",
      "  0x5c, 0x00, 0x00, 0x00, 0x4c, 0x00, 0x00, 0x00, 0x38, 0x00, 0x00, 0x00,\n",
      "  0x18, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0xe0, 0xff, 0xff, 0xff,\n",
      "  0x19, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x19,\n",
      "  0xf0, 0xff, 0xff, 0xff, 0x09, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00,\n",
      "  0x00, 0x00, 0x00, 0x09, 0x0c, 0x00, 0x10, 0x00, 0x0f, 0x00, 0x00, 0x00,\n",
      "  0x08, 0x00, 0x04, 0x00, 0x0c, 0x00, 0x00, 0x00, 0x03, 0x00, 0x00, 0x00,\n",
      "  0x03, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x03, 0xdc, 0xff, 0xff, 0xff,\n",
      "  0x16, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x16, 0xe8, 0xff, 0xff, 0xff,\n",
      "  0x53, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x53, 0xf4, 0xff, 0xff, 0xff,\n",
      "  0x2d, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x2d, 0x0c, 0x00, 0x0c, 0x00,\n",
      "  0x0b, 0x00, 0x00, 0x00, 0x00, 0x00, 0x04, 0x00, 0x0c, 0x00, 0x00, 0x00,\n",
      "  0x4d, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x4d\n",
      "};\n",
      "unsigned int g_model_len = 10472;\n"
     ]
    }
   ],
   "source": [
    "!cat {MODEL_TFLITE_MICRO}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea651213-3bd3-42de-bb8c-74426ded1665",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
